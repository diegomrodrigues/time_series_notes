## M√©dia M√≥vel Ponderada (WMA): Uma Abordagem Refinada para Previs√£o de Demanda

### Introdu√ß√£o

Em continuidade √† discuss√£o sobre modelos de s√©ries temporais, e ap√≥s explorar a m√©dia m√≥vel simples (SMA) [^61], abordaremos agora a **M√©dia M√≥vel Ponderada (WMA)**, um m√©todo que refina o conceito da SMA ao introduzir pesos diferenciados para os pontos de dados hist√≥ricos [^62]. Como vimos anteriormente, a SMA trata todos os dados do per√≠odo de forma igual, o que pode levar a previs√µes que respondem lentamente a mudan√ßas de demanda. A WMA, por outro lado, busca endere√ßar essa limita√ß√£o, dando maior import√¢ncia aos dados mais recentes, e portanto, potencialmente mais relevantes para o futuro pr√≥ximo [^62].

### Conceitos Fundamentais

A principal caracter√≠stica da WMA √© a atribui√ß√£o de pesos distintos a cada ponto de dados hist√≥rico, em contraste com a SMA, que atribui o mesmo peso a todos os dados [^62]. A formula√ß√£o matem√°tica da WMA no per√≠odo *t* √© dada por:

$$
WMA_t = w_1 A_{t-1} + w_2 A_{t-2} + \ldots + w_n A_{t-n}
$$

onde:

*   $WMA_t$ representa a previs√£o da m√©dia m√≥vel ponderada para o per√≠odo *t*.
*   $A_{t-i}$ √© a demanda real no per√≠odo *t-i*.
*   $w_i$ √© o peso atribu√≠do √† demanda no per√≠odo *t-i*, com a restri√ß√£o de que $\sum_{i=1}^{n} w_i = 1$ [^62].

Essa f√≥rmula destaca a flexibilidade do m√©todo, permitindo que o analista ajuste a import√¢ncia de cada ponto de dados de acordo com o contexto espec√≠fico e o comportamento da s√©rie temporal.
**A escolha dos pesos (w):**
   - Os pesos na WMA s√£o definidos por julgamento e tentativa e erro [^62].
   - N√£o existe uma regra fixa para derivar a distribui√ß√£o de pesos, requerendo an√°lise emp√≠rica do dom√≠nio ou aplica√ß√£o de modelos Bayesianos [^62].
   - √â essencial que a soma dos pesos seja igual a 1, garantindo que a previs√£o seja uma m√©dia ponderada dos dados hist√≥ricos [^62].

> üí° **Exemplo Num√©rico:** Suponha que temos os seguintes dados de demanda para os √∫ltimos 4 per√≠odos: $A_{t-1} = 100$, $A_{t-2} = 110$, $A_{t-3} = 120$, e $A_{t-4} = 130$. Queremos calcular a WMA usando pesos lineares decrescentes. Podemos escolher os seguintes pesos: $w_1 = 0.4$, $w_2 = 0.3$, $w_3 = 0.2$, e $w_4 = 0.1$. Note que $0.4 + 0.3 + 0.2 + 0.1 = 1$. A WMA para o per√≠odo *t* seria:
>
> $WMA_t = (0.4 \times 100) + (0.3 \times 110) + (0.2 \times 120) + (0.1 \times 130) = 40 + 33 + 24 + 13 = 110$.
> Isso significa que a previs√£o para o per√≠odo *t* √© 110, com os dados mais recentes (100) tendo maior influ√™ncia na previs√£o.

**Lema 1:** Se todos os pesos $w_i$ s√£o iguais a $\frac{1}{n}$, ent√£o a WMA se reduz √† SMA.
   *Prova:*
    I.  Seja $w_i = \frac{1}{n}$ para todo $i \in \{1, 2, \ldots, n\}$.
    II. Substituindo esses pesos na f√≥rmula da WMA, temos:
    $$
    WMA_t = \frac{1}{n} A_{t-1} + \frac{1}{n} A_{t-2} + \ldots + \frac{1}{n} A_{t-n}
    $$
    III. Fatorando $\frac{1}{n}$ da express√£o, obtemos:
    $$
    WMA_t = \frac{1}{n} (A_{t-1} + A_{t-2} + \ldots + A_{t-n})
    $$
    IV. A express√£o acima √© a defini√ß√£o da m√©dia m√≥vel simples (SMA). Portanto, se todos os pesos s√£o iguais a $\frac{1}{n}$, a WMA se reduz √† SMA. ‚ñ†

> üí° **Exemplo Num√©rico (Lema 1):**  Considerando os mesmos dados dos 4 per√≠odos anteriores ($A_{t-1} = 100$, $A_{t-2} = 110$, $A_{t-3} = 120$, e $A_{t-4} = 130$) e aplicando pesos iguais $w_i = 1/4 = 0.25$, a WMA se torna a SMA:
>
> $WMA_t = (0.25 \times 100) + (0.25 \times 110) + (0.25 \times 120) + (0.25 \times 130) = 25 + 27.5 + 30 + 32.5 = 115$
>
> A SMA, que neste caso √© igual a WMA com pesos iguais, √© a m√©dia dos dados, ou seja, $\frac{100 + 110 + 120 + 130}{4} = 115$.

**Interpreta√ß√£o Estat√≠stica da WMA**
√â crucial entender que uma s√©rie de m√©dias ponderadas pode ser vista como uma realiza√ß√£o de um **processo estoc√°stico**. A distribui√ß√£o de probabilidades desse processo √© diretamente influenciada pela distribui√ß√£o de pesos escolhida [^62]. Ao manipular os pesos, o analista n√£o apenas ajusta a previs√£o, mas tamb√©m molda a caracter√≠stica estat√≠stica do processo de previs√£o subjacente. A aplica√ß√£o de modelos Bayesianos pode refinar ainda mais a escolha dos pesos, permitindo que se incorpore conhecimento pr√©vio ou informa√ß√µes adicionais no processo de previs√£o.

**Proposi√ß√£o 1:** A WMA pode ser expressa como uma combina√ß√£o linear dos dados hist√≥ricos.
   *Prova:* A f√≥rmula da WMA, $WMA_t = w_1 A_{t-1} + w_2 A_{t-2} + \ldots + w_n A_{t-n}$, j√° demonstra que $WMA_t$ √© uma soma ponderada (combina√ß√£o linear) dos valores passados $A_{t-i}$, onde os pesos $w_i$ s√£o os coeficientes da combina√ß√£o linear. ‚ñ†

> üí° **Exemplo Num√©rico (Proposi√ß√£o 1):** Usando o exemplo anterior onde $WMA_t = (0.4 \times 100) + (0.3 \times 110) + (0.2 \times 120) + (0.1 \times 130)$, podemos ver que $WMA_t$ √© uma combina√ß√£o linear dos dados de demanda, onde os pesos 0.4, 0.3, 0.2 e 0.1 s√£o os coeficientes.

**Lema 2:** Se os pesos $w_i$ s√£o tais que $w_1 > w_2 > \ldots > w_n > 0$, ent√£o a WMA dar√° mais import√¢ncia aos dados mais recentes.
*Prova:*
    I. Por defini√ß√£o, a WMA √© dada por $WMA_t = w_1 A_{t-1} + w_2 A_{t-2} + \ldots + w_n A_{t-n}$.
    II. Dados que $w_1 > w_2 > \ldots > w_n > 0$, o termo $A_{t-1}$ (o dado mais recente) √© multiplicado pelo maior peso $w_1$.
    III. O termo $A_{t-2}$ √© multiplicado por um peso menor $w_2$, e assim sucessivamente.
    IV. O termo $A_{t-n}$ (o dado mais antigo) √© multiplicado pelo menor peso $w_n$.
    V. Consequentemente, os dados mais recentes t√™m maior peso (influ√™ncia) no c√°lculo da $WMA_t$ do que os dados mais antigos, demonstrando que a WMA d√° mais import√¢ncia aos dados mais recentes. ‚ñ†

> üí° **Exemplo Num√©rico (Lema 2):**  Voltando aos dados de demanda e pesos ($w_1 = 0.4$, $w_2 = 0.3$, $w_3 = 0.2$, e $w_4 = 0.1$) a demanda mais recente ($A_{t-1}=100$) tem o maior peso (0.4) influenciando mais o resultado da WMA (110) do que a demanda mais antiga ($A_{t-4} = 130$) com peso de apenas 0.1.
>
> Este exemplo ilustra como a WMA prioriza dados mais recentes, o que √© √∫til quando a demanda est√° mudando rapidamente.

**Vantagens da WMA:**
   - Maior sensibilidade a mudan√ßas recentes na demanda, permitindo que o modelo se adapte mais rapidamente a varia√ß√µes [^62].
   - Ao dar mais import√¢ncia aos dados mais recentes, a WMA busca capturar padr√µes mais atuais, o que pode ser crucial em mercados din√¢micos.

**Desvantagens da WMA:**
   - Requer avalia√ß√£o cont√≠nua e ajuste dos pesos para manter a efic√°cia da previs√£o [^62].
   - N√£o acompanha totalmente padr√µes sazonais ou tend√™ncias de longo prazo, o que a torna mais adequada para previs√µes de curto prazo [^63].
   - A escolha dos pesos √© subjetiva e pode levar a resultados vari√°veis dependendo da experi√™ncia do analista.

> üí° **Exemplo Num√©rico (Desvantagens):** Considere que a demanda mensal para um produto segue um padr√£o sazonal, com picos no ver√£o e vales no inverno. Uma WMA com pesos fixos pode n√£o capturar essa sazonalidade adequadamente, j√° que ela s√≥ considerar√° os √∫ltimos 'n' per√≠odos. Para um cen√°rio com tend√™ncia de crescimento, a WMA tamb√©m ter√° dificuldade de acompanhar o crescimento da demanda por depender de uma m√©dia ponderada do passado. Em ambos os casos, a WMA pode ser um bom modelo para previs√µes de curto prazo com o objetivo de adaptar a demanda, mas n√£o deve ser utilizado como um modelo de longo prazo para previs√£o da demanda.

**Teorema 1:** A WMA com pesos decrescentes linearmente pode ser expressa como uma combina√ß√£o linear dos dados hist√≥ricos com pesos que diminuem aritmeticamente.
*Prova:*
    I. Considere pesos $w_i$ definidos como $w_i = \frac{2(n-i+1)}{n(n+1)}$ para $i = 1, 2, \ldots, n$.
    II. Vamos verificar se a soma dos pesos √© igual a 1:
    $$\sum_{i=1}^{n} w_i = \sum_{i=1}^{n} \frac{2(n-i+1)}{n(n+1)} = \frac{2}{n(n+1)}\sum_{i=1}^{n} (n-i+1)$$
    III. Fazendo uma mudan√ßa de vari√°vel $j = n-i+1$, a soma se torna:
    $$\frac{2}{n(n+1)} \sum_{j=1}^{n} j = \frac{2}{n(n+1)}\frac{n(n+1)}{2} = 1$$
     IV. Assim, os pesos somam 1, como requerido.
    V. Os pesos diminuem linearmente, pois o termo $(n-i+1)$ diminui em 1 a cada incremento de $i$, o que significa que eles diminuem aritmeticamente.
    VI. Portanto, a $WMA_t =  \frac{2n}{n(n+1)}A_{t-1} + \frac{2(n-1)}{n(n+1)}A_{t-2} + \ldots + \frac{2}{n(n+1)}A_{t-n}$ √© uma combina√ß√£o linear dos dados hist√≥ricos com pesos que diminuem aritmeticamente. ‚ñ†

> üí° **Exemplo Num√©rico (Teorema 1):** Para n=4, temos os pesos $w_1 = \frac{2*4}{4*5} = 0.4$, $w_2 = \frac{2*3}{4*5} = 0.3$, $w_3 = \frac{2*2}{4*5} = 0.2$ e $w_4 = \frac{2*1}{4*5} = 0.1$. Substituindo na f√≥rmula da WMA:
> $$WMA_t = 0.4 A_{t-1} + 0.3 A_{t-2} + 0.2 A_{t-3} + 0.1 A_{t-4}$$
>
> Estes pesos, como demonstrado no teorema, decrescem linearmente e sua soma √© igual a 1. Se usarmos a demanda anterior: $A_{t-1} = 100$, $A_{t-2} = 110$, $A_{t-3} = 120$, e $A_{t-4} = 130$, teremos novamente $WMA_t=110$.

### Conclus√£o

A **m√©dia m√≥vel ponderada** oferece uma abordagem mais refinada para a previs√£o de demanda em compara√ß√£o com a m√©dia m√≥vel simples. Sua capacidade de atribuir diferentes pesos aos dados hist√≥ricos permite uma maior responsividade a mudan√ßas recentes na demanda. No entanto, essa flexibilidade traz a necessidade de um ajuste cont√≠nuo e cuidadoso dos pesos para otimizar a efic√°cia da previs√£o. Assim, a WMA se apresenta como uma ferramenta valiosa, especialmente para previs√µes de curto prazo, onde a adapta√ß√£o r√°pida √†s varia√ß√µes de demanda √© essencial [^63]. A complexidade da escolha de pesos e o seu impacto na distribui√ß√£o probabil√≠stica dos resultados de previs√£o ressaltam a import√¢ncia de uma an√°lise estat√≠stica rigorosa. Este m√©todo nos prepara para abordar a suaviza√ß√£o exponencial [^64], onde o peso dos dados hist√≥ricos decresce exponencialmente com a antiguidade.

### Refer√™ncias

[^61]:  O texto faz refer√™ncia √† m√©dia m√≥vel simples (SMA) mencionada anteriormente no contexto.
[^62]:  Refere-se √†s explica√ß√µes sobre a m√©dia m√≥vel ponderada (WMA), pesos, e suas propriedades, presentes no texto fornecido.
[^63]:  Refere-se √† discuss√£o sobre as limita√ß√µes da WMA em rela√ß√£o a padr√µes sazonais e de longo prazo, conforme o texto fornecido.
[^64]: O texto indica que o pr√≥ximo passo ser√° a discuss√£o da suaviza√ß√£o exponencial.
<!-- END -->
