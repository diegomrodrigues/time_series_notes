## DecomposiÃ§Ã£o de SÃ©ries Temporais: AnÃ¡lise Aprofundada da Componente de TendÃªncia

### IntroduÃ§Ã£o
Em continuidade Ã  nossa discussÃ£o sobre a decomposiÃ§Ã£o de sÃ©ries temporais, este capÃ­tulo aprofunda a modelagem matemÃ¡tica e estatÃ­stica da componente de **tendÃªncia** (trend), que representa o movimento de longo prazo na demanda [^3]. Como vimos anteriormente, a tendÃªncia pode ser linear ou nÃ£o linear, influenciada por fatores como mudanÃ§as demogrÃ¡ficas, concorrÃªncia e transformaÃ§Ãµes sociais [^3]. Exploraremos em detalhes como modelar essa componente usando regressÃ£o linear, regressÃ£o polinomial e suavizaÃ§Ã£o por mÃ©dias mÃ³veis, incluindo as nuances matemÃ¡ticas e estatÃ­sticas de cada mÃ©todo. AlÃ©m disso, vamos incluir uma anÃ¡lise da formulaÃ§Ã£o do modelo de espaÃ§o de estados, juntamente com o uso do Filtro de Kalman.

### RegressÃ£o Linear: Modelagem MatemÃ¡tica e Estimativa de ParÃ¢metros

Como introduzido no capÃ­tulo anterior, a **regressÃ£o linear** modela a tendÃªncia como uma linha reta, cuja equaÃ§Ã£o geral Ã© dada por $T_t = a + bt$, onde $T_t$ Ã© a tendÃªncia no perÃ­odo $t$, $a$ Ã© o intercepto e $b$ Ã© o coeficiente angular [^ProposiÃ§Ã£o 1.1]. Vamos detalhar a formulaÃ§Ã£o matricial e a estimativa dos parÃ¢metros $a$ e $b$.

#### FormulaÃ§Ã£o Matricial
A regressÃ£o linear pode ser expressa em notaÃ§Ã£o matricial como:
$$Y = X\beta + \epsilon$$
onde:
-   $Y$ Ã© o vetor de valores observados da sÃ©rie temporal.
-   $X$ Ã© a matriz de design, onde a primeira coluna Ã© um vetor de 1's (para o intercepto $a$) e a segunda coluna contÃ©m os valores de tempo $t$.
-   $\beta$ Ã© o vetor de coeficientes de regressÃ£o (incluindo $a$ e $b$).
-   $\epsilon$ Ã© o vetor de erros aleatÃ³rios.

A matriz de design $X$ assume a forma:
$$ X = \begin{bmatrix} 1 & t_1 \\ 1 & t_2 \\ \vdots & \vdots \\ 1 & t_n \end{bmatrix} $$
onde $t_i$ representa o tempo no ponto de dados $i$.

#### Estimativa dos ParÃ¢metros
O vetor de coeficientes $\beta$, que contÃ©m $a$ e $b$, Ã© estimado minimizando a soma dos quadrados dos erros (SSE) [^Prova da Estimativa de Î²]:
$$ SSE = \epsilon^T \epsilon = (Y - X\beta)^T(Y - X\beta) $$
A estimativa de $\beta$, denotada como $\hat{\beta}$, Ã© obtida atravÃ©s da seguinte equaÃ§Ã£o:
$$\hat{\beta} = (X^TX)^{-1}X^TY$$
onde $(X^TX)^{-1}$ Ã© a inversa da matriz $(X^TX)$.

> ğŸ’¡ **Exemplo NumÃ©rico:** Considere uma sÃ©rie temporal com os seguintes valores de demanda ao longo de 5 perÃ­odos: $Y = [20, 25, 30, 33, 36]$. Os tempos correspondentes sÃ£o $t = [1, 2, 3, 4, 5]$. Queremos ajustar um modelo de regressÃ£o linear para estimar a tendÃªncia.
>
> 1. **ConstruÃ§Ã£o da Matriz X:**
> ```python
> import numpy as np
>
> t = np.array([1, 2, 3, 4, 5])
> X = np.vstack([np.ones(len(t)), t]).T
> print("Matriz X:\n", X)
> ```
> Isso nos dÃ¡:
> $$X = \begin{bmatrix} 1 & 1 \\ 1 & 2 \\ 1 & 3 \\ 1 & 4 \\ 1 & 5 \end{bmatrix}$$
> 2. **CriaÃ§Ã£o do vetor Y:**
> ```python
> Y = np.array([20, 25, 30, 33, 36])
> print("Vetor Y:\n", Y)
> ```
> 3. **CÃ¡lculo de $X^TX$:**
> ```python
> XtX = X.T @ X
> print("X^T * X:\n", XtX)
> ```
> Resultado:
> $$X^TX = \begin{bmatrix} 5 & 15 \\ 15 & 55 \end{bmatrix}$$
> 4. **CÃ¡lculo da inversa de $(X^TX)^{-1}$:**
> ```python
> XtX_inv = np.linalg.inv(XtX)
> print("(X^T * X)^-1:\n", XtX_inv)
> ```
> Resultado:
> $$(X^TX)^{-1} = \begin{bmatrix} 1.1 & -0.3 \\ -0.3 & 0.1 \end{bmatrix}$$
> 5. **CÃ¡lculo de $X^TY$:**
> ```python
> XtY = X.T @ Y
> print("X^T * Y:\n", XtY)
> ```
> Resultado:
> $$X^TY = \begin{bmatrix} 144 \\ 451 \end{bmatrix}$$
> 6. **CÃ¡lculo de $\hat{\beta}$:**
> ```python
> beta_hat = XtX_inv @ XtY
> print("Beta_hat:\n", beta_hat)
> ```
> Resultado:
> $$\hat{\beta} = \begin{bmatrix} 18.4 \\ 4.0 \end{bmatrix}$$
> Portanto, $\hat{a} = 18.4$ e $\hat{b} = 4.0$. O modelo de regressÃ£o linear para a tendÃªncia Ã© $T_t = 18.4 + 4t$. Isso significa que, em mÃ©dia, a demanda aumenta em 4 unidades por perÃ­odo, partindo de um nÃ­vel base de 18.4 no perÃ­odo inicial (t=0).
> 7. **VisualizaÃ§Ã£o do ajuste:**
>
> ```mermaid
>   graph LR
>      A[Dados Observados] --> B(RegressÃ£o Linear);
>      B --> C{Trend Line};
>      C --> D(VisualizaÃ§Ã£o);
> ```
> A linha de tendÃªncia pode ser visualizada com os dados observados para avaliar o ajuste do modelo.
>
> 8.  **CÃ¡lculo dos valores ajustados:**
>
> ```python
> fitted_values = X @ beta_hat
> print("Valores Ajustados:\n", fitted_values)
> ```
> Resultado:
> $$ \text{fitted_values} = [22.4, 26.4, 30.4, 34.4, 38.4]$$
>
> 9. **CÃ¡lculo dos resÃ­duos:**
>
> ```python
> residuals = Y - fitted_values
> print("ResÃ­duos:\n", residuals)
> ```
> Resultado:
> $$\text{residuals} = [-2.4, -1.4, -0.4, -1.4, -2.4]$$
>
> Uma anÃ¡lise dos resÃ­duos pode ser feita para avaliar a adequaÃ§Ã£o do modelo.
> Uma regressÃ£o linear fornece um ponto de partida para entender a tendÃªncia de um conjunto de dados.

**Lema 1.1:** A estimativa de $\beta$ obtida pela fÃ³rmula $\hat{\beta} = (X^TX)^{-1}X^TY$ Ã© um estimador de mÃ­nimos quadrados nÃ£o viesado.

**Prova do Lema 1.1:**
I.  Partindo do modelo de regressÃ£o linear $Y = X\beta + \epsilon$, onde $E[\epsilon]=0$ e $Var(\epsilon)=\sigma^2I$, sendo $I$ a matriz identidade.

II.  A estimativa de $\beta$ Ã© dada por $\hat{\beta} = (X^TX)^{-1}X^TY$. Substituindo a expressÃ£o de $Y$:
    $$\hat{\beta} = (X^TX)^{-1}X^T(X\beta + \epsilon) = (X^TX)^{-1}X^TX\beta + (X^TX)^{-1}X^T\epsilon$$
    Como $(X^TX)^{-1}X^TX=I$, a identidade:
    $$\hat{\beta} = \beta + (X^TX)^{-1}X^T\epsilon$$

III.  Para verificar se o estimador Ã© nÃ£o viesado, calculamos a esperanÃ§a matemÃ¡tica de $\hat{\beta}$:
    $$E[\hat{\beta}] = E[\beta + (X^TX)^{-1}X^T\epsilon] = E[\beta] + E[(X^TX)^{-1}X^T\epsilon]$$
    Como $\beta$ Ã© um vetor de parÃ¢metros fixos, $E[\beta] = \beta$. Como $X$ Ã© uma matriz de valores fixos e $E[\epsilon]=0$, temos:
    $$E[(X^TX)^{-1}X^T\epsilon] = (X^TX)^{-1}X^TE[\epsilon] = (X^TX)^{-1}X^T0 = 0$$
    Portanto,
    $$E[\hat{\beta}] = \beta$$
    Isto mostra que a estimativa $\hat{\beta}$ Ã© um estimador nÃ£o viesado.

IV. Para calcular a variÃ¢ncia do estimador $\hat{\beta}$, usamos a propriedade $Var(AX) = A Var(X)A^T$, onde A Ã© uma constante.
    $$Var(\hat{\beta}) = Var(\beta + (X^TX)^{-1}X^T\epsilon) = Var((X^TX)^{-1}X^T\epsilon)$$
    Como $Var(\epsilon)=\sigma^2 I$:
    $$Var(\hat{\beta}) = (X^TX)^{-1}X^T Var(\epsilon)  ((X^TX)^{-1}X^T)^T = (X^TX)^{-1}X^T \sigma^2 I X(X^TX)^{-1} = \sigma^2(X^TX)^{-1}$$
   Portanto, a variÃ¢ncia do estimador Ã© $\sigma^2(X^TX)^{-1}$.
    Assim, demonstramos que o estimador de mÃ­nimos quadrados $\hat{\beta}$ Ã© nÃ£o viesado e possui variÃ¢ncia $\sigma^2(X^TX)^{-1}$.â– 

**Lema 1.2:** A matriz $(X^TX)$ Ã© inversÃ­vel se e somente se as colunas de X sÃ£o linearmente independentes.

**Prova do Lema 1.2:**
I. Suponha que as colunas de X sÃ£o linearmente dependentes. EntÃ£o existe um vetor $c \neq 0$ tal que $Xc = 0$.
II. Multiplicando por $X^T$, temos $X^TXc = X^T0 = 0$.
III. Isso significa que existe um vetor nÃ£o nulo $c$ tal que $(X^TX)c=0$, o que implica que a matriz $X^TX$ nÃ£o Ã© inversÃ­vel.
IV. Agora, suponha que a matriz $X^TX$ nÃ£o Ã© inversÃ­vel. EntÃ£o existe um vetor $c \neq 0$ tal que $(X^TX)c = 0$.
V. Multiplicando por $c^T$ temos $c^T(X^TX)c = 0$, ou $(Xc)^T(Xc)=0$, o que implica que $Xc=0$
VI. Portanto, as colunas de X sÃ£o linearmente dependentes, completando a prova.â– 

**Lema 1.3:** A estimativa de $\hat{\beta}$ Ã© Ãºnica se e somente se as colunas de X sÃ£o linearmente independentes.

**Prova do Lema 1.3:**
I. Se as colunas de X sÃ£o linearmente independentes, entÃ£o a matriz $X^TX$ Ã© invertÃ­vel (pelo Lema 1.2) e a estimativa $\hat{\beta}=(X^TX)^{-1}X^TY$ Ã© Ãºnica.
II. Reciprocamente, se a estimativa $\hat{\beta}$ Ã© Ãºnica, entÃ£o a matriz $X^TX$ deve ser invertÃ­vel. Caso contrÃ¡rio, se $X^TX$ nÃ£o fosse invertÃ­vel, terÃ­amos a possibilidade de mÃºltiplos vetores $\hat{\beta}$ que minimizam SSE, contradizendo a unicidade da estimativa. Assim, se a estimativa $\hat{\beta}$ Ã© Ãºnica, as colunas de X devem ser linearmente independentes, completando a prova.â– 

### RegressÃ£o Polinomial: Modelagem de TendÃªncias NÃ£o Lineares

Quando a tendÃªncia nÃ£o Ã© linear, a **regressÃ£o polinomial** oferece uma alternativa, representando a tendÃªncia como uma curva [^ProposiÃ§Ã£o 1.1]. A equaÃ§Ã£o geral de um polinÃ´mio de grau *n* para a tendÃªncia Ã©:
$$ T_t = a_0 + a_1t + a_2t^2 + \ldots + a_nt^n $$
onde $a_0, a_1, \ldots, a_n$ sÃ£o os parÃ¢metros do polinÃ´mio.

#### FormulaÃ§Ã£o Matricial
Semelhante Ã  regressÃ£o linear, a regressÃ£o polinomial pode ser formulada em notaÃ§Ã£o matricial:
$$ Y = X\beta + \epsilon $$
Neste caso, a matriz de design $X$ inclui as potÃªncias de $t$:
$$ X = \begin{bmatrix} 1 & t_1 & t_1^2 & \dots & t_1^n \\ 1 & t_2 & t_2^2 & \dots & t_2^n \\ \vdots & \vdots & \vdots & \ddots & \vdots \\ 1 & t_m & t_m^2 & \dots & t_m^n \end{bmatrix} $$
O vetor $\beta$ Ã© dado por $[a_0, a_1, \dots, a_n]^T$, representando os coeficientes do polinÃ´mio.
#### Estimativa dos ParÃ¢metros
A estimativa dos parÃ¢metros $\hat{\beta}$ Ã© realizada da mesma forma que na regressÃ£o linear:
$$\hat{\beta} = (X^TX)^{-1}X^TY$$
A complexidade do modelo aumenta com o grau *n* do polinÃ´mio, o que pode levar a overfitting (sobreajuste) se o grau for muito elevado ou se a quantidade de dados nÃ£o for suficiente.
A seleÃ§Ã£o adequada do grau do polinÃ´mio pode ser feita atravÃ©s de mÃ©todos como validaÃ§Ã£o cruzada ou o uso de critÃ©rios de informaÃ§Ã£o como AIC e BIC. A validaÃ§Ã£o cruzada divide os dados em diferentes grupos e avalia o desempenho do modelo em cada um, prevenindo o overfitting. CritÃ©rios de informaÃ§Ã£o, como o AIC e o BIC, adicionam uma penalizaÃ§Ã£o Ã  complexidade do modelo, preferindo modelos mais simples que se ajustem bem aos dados, balanceando entre ajuste e complexidade.

> ğŸ’¡ **Exemplo NumÃ©rico:** Considere os mesmos dados de demanda, mas agora vamos ajustar um polinÃ´mio de grau 2: $T_t = a_0 + a_1t + a_2t^2$. Usando $Y=[20, 25, 30, 33, 36]$ e $t=[1,2,3,4,5]$, a matriz X torna-se:
>
> $$ X = \begin{bmatrix} 1 & 1 & 1^2 \\ 1 & 2 & 2^2 \\ 1 & 3 & 3^2 \\ 1 & 4 & 4^2 \\ 1 & 5 & 5^2 \end{bmatrix} = \begin{bmatrix} 1 & 1 & 1 \\ 1 & 2 & 4 \\ 1 & 3 & 9 \\ 1 & 4 & 16 \\ 1 & 5 & 25 \end{bmatrix} $$
>
> ```python
> import numpy as np
>
> t = np.array([1, 2, 3, 4, 5])
> Y = np.array([20, 25, 30, 33, 36])
> X = np.vstack([np.ones(len(t)), t, t**2]).T
> print("Matriz X:\n", X)
>
> XtX = X.T @ X
> print("X^T * X:\n", XtX)
>
> XtX_inv = np.linalg.inv(XtX)
> print("(X^T * X)^-1:\n", XtX_inv)
>
> XtY = X.T @ Y
> print("X^T * Y:\n", XtY)
>
> beta_hat = XtX_inv @ XtY
> print("Beta_hat:\n", beta_hat)
>
> fitted_values = X @ beta_hat
> print("Valores Ajustados:\n", fitted_values)
>
> residuals = Y - fitted_values
> print("ResÃ­duos:\n", residuals)
> ```
> Os resultados sÃ£o:
> $$ \hat{\beta} = \begin{bmatrix} 19.2 \\ 1.3 \\ 0.3 \end{bmatrix} $$
> Os valores ajustados sÃ£o: $[20.8, 25.4, 29.4, 32.8, 35.6]$. Os resÃ­duos sÃ£o: $[-0.8, -0.4, 0.6, 0.2, 0.4]$. O modelo ajustado Ã© $T_t = 19.2 + 1.3t + 0.3t^2$. Observe como os resÃ­duos sÃ£o menores em magnitude para este modelo polinomial comparado ao exemplo da regressÃ£o linear. Este modelo captura melhor a curvatura dos dados.

### SuavizaÃ§Ã£o por MÃ©dias MÃ³veis: Abordagem NÃ£o ParamÃ©trica
A **suavizaÃ§Ã£o por mÃ©dias mÃ³veis** (SMA) Ã© um mÃ©todo nÃ£o paramÃ©trico que suaviza as flutuaÃ§Ãµes de curto prazo para revelar a tendÃªncia [^ProposiÃ§Ã£o 1.1]. A mÃ©dia mÃ³vel simples para um perÃ­odo $t$ Ã© calculada como:
$$ SMA_t = \frac{1}{k} \sum_{i=t-k+1}^t Y_i $$
onde *k* Ã© o tamanho da janela da mÃ©dia mÃ³vel.

#### Vantagens da SMA
-   **Simplicidade:** FÃ¡cil de calcular e implementar.
-   **ReduÃ§Ã£o de ruÃ­do:** Suaviza as variaÃ§Ãµes aleatÃ³rias de curto prazo, expondo a tendÃªncia subjacente.

#### Desvantagens da SMA
-   **Defasagem:** A SMA tende a apresentar uma defasagem em relaÃ§Ã£o Ã  tendÃªncia real, especialmente quando ela muda rapidamente.
-   **Sensibilidade ao tamanho da janela:** A escolha de *k* pode afetar o resultado final. Valores de *k* muito pequenos podem nÃ£o suavizar o suficiente o ruÃ­do, enquanto valores muito grandes podem suavizar a tendÃªncia excessivamente, perdendo nuances importantes.
-   **Perda de informaÃ§Ã£o nos extremos:** As primeiras e Ãºltimas observaÃ§Ãµes da sÃ©rie temporal nÃ£o podem ser suavizadas, devido Ã  necessidade de valores passados e futuros dentro da janela, o que leva a perda de informaÃ§Ã£o nesses pontos.

A mÃ©dia mÃ³vel ponderada (WMA), que discutimos no capÃ­tulo anterior [^Lema 1.1], oferece uma extensÃ£o da SMA, permitindo dar pesos diferentes a cada observaÃ§Ã£o dentro da janela. A fÃ³rmula para a WMA Ã©:
$$ WMA_t = \sum_{i=t-k+1}^t w_i Y_i $$
onde $w_i$ sÃ£o os pesos atribuÃ­dos a cada observaÃ§Ã£o, com $\sum_{i=t-k+1}^t w_i = 1$.

> ğŸ’¡ **Exemplo NumÃ©rico:** Usando os dados $Y = [20, 25, 30, 33, 36]$, vamos calcular a mÃ©dia mÃ³vel simples com janela de tamanho k=3.
>
>  -   $SMA_3 = \frac{20 + 25 + 30}{3} = 25$
>  -   $SMA_4 = \frac{25 + 30 + 33}{3} = 29.33$
>  -   $SMA_5 = \frac{30 + 33 + 36}{3} = 33$
>
>  Note que os dois primeiros pontos nÃ£o podem ser calculados com k=3, exemplificando a perda de informaÃ§Ã£o nos extremos.  A SMA suaviza os valores, mas com uma defasagem. Para k = 2:
>
> - $SMA_2 = \frac{20 + 25}{2} = 22.5$
> - $SMA_3 = \frac{25 + 30}{2} = 27.5$
> - $SMA_4 = \frac{30 + 33}{2} = 31.5$
> - $SMA_5 = \frac{33 + 36}{2} = 34.5$
> Para k=2, menos suavizaÃ§Ã£o e menos defasagem sÃ£o observadas.
>
> Uma mÃ©dia mÃ³vel ponderada com pesos [0.2, 0.3, 0.5] e janela k=3 seria calculada como:
>
> - $WMA_3 = 0.2*20 + 0.3*25 + 0.5*30 = 26.5$
> - $WMA_4 = 0.2*25 + 0.3*30 + 0.5*33 = 30$
> - $WMA_5 = 0.2*30 + 0.3*33 + 0.5*36 = 33.9$

##### SuavizaÃ§Ã£o Exponencial
A **suavizaÃ§Ã£o exponencial** Ã© outra tÃ©cnica de suavizaÃ§Ã£o que oferece uma alternativa para a SMA e WMA. Em essÃªncia, a suavizaÃ§Ã£o exponencial calcula uma mÃ©dia ponderada dos valores passados, onde os pesos decrescem exponencialmente Ã  medida que os dados ficam mais antigos. A suavizaÃ§Ã£o exponencial Ã© modelada como:
$$ ES_t = \alpha Y_{t-1} + (1-\alpha)ES_{t-1} $$
Onde $\alpha$ Ã© o fator de suavizaÃ§Ã£o, sendo $0 < \alpha < 1$. A escolha de $\alpha$ controla o peso dado aos dados mais recentes em relaÃ§Ã£o aos dados mais antigos. Valores de $\alpha$ prÃ³ximos de 1 dÃ£o mais peso aos dados recentes, tornando o modelo mais sensÃ­vel a mudanÃ§as, enquanto valores prÃ³ximos a 0 dÃ£o mais peso aos dados antigos, tornando o modelo mais estÃ¡vel.
Uma desvantagem da suavizaÃ§Ã£o exponencial Ã© que ela nÃ£o modela explicitamente a tendÃªncia e sazonalidade.

> ğŸ’¡ **Exemplo NumÃ©rico:** Usando os dados $Y = [20, 25, 30, 33, 36]$, vamos calcular a suavizaÃ§Ã£o exponencial com $\alpha = 0.6$. Inicializamos $ES_1 = Y_1$.
>
> - $ES_2 = 0.6*20 + 0.4*20 = 20$
> - $ES_3 = 0.6*25 + 0.4*20 = 23$
> - $ES_4 = 0.6*30 + 0.4*23 = 27.2$
> - $ES_5 = 0.6*33 + 0.4*27.2 = 30.7$
>
> Com $\alpha = 0.2$, com a mesma inicializaÃ§Ã£o:
>
> - $ES_2 = 0.2*20 + 0.8*20 = 20$
> - $ES_3 = 0.2*25 + 0.8*20 = 21$
> - $ES_4 = 0.2*30 + 0.8*21 = 22.8$
> - $ES_5 = 0.2*33 + 0.8*22.8 = 24.8$
>
> Valores maiores de $\alpha$ (0.6) tornam o modelo mais sensÃ­vel a mudanÃ§as recentes nos dados, enquanto valores menores (0.2) resultam em maior suavizaÃ§Ã£o.

**ProposiÃ§Ã£o 1.1:** A suavizaÃ§Ã£o exponencial simples assume que a sÃ©rie temporal nÃ£o possui tendÃªncia. Para sÃ©ries com tendÃªncia, pode-se utilizar a suavizaÃ§Ã£o exponencial dupla.

**Prova da ProposiÃ§Ã£o 1.1:**
I. A suavizaÃ§Ã£o exponencial simples, como definida acima, estima o nÃ­vel da sÃ©rie, mas nÃ£o sua tendÃªncia, jÃ¡ que considera que o nÃ­vel Ã© constante ao longo do tempo.

II. A suavizaÃ§Ã£o exponencial dupla adiciona uma componente de tendÃªncia, modelando-a como um valor variÃ¡vel no tempo. As equaÃ§Ãµes da suavizaÃ§Ã£o exponencial dupla sÃ£o:
   $$ S_t = \alpha Y_t + (1-\alpha)(S_{t-1} + b_{t-1}) $$
   $$ b_t = \beta(S_t - S_{t-1}) + (1-\beta)b_{t-1} $$
  Onde $S_t$ Ã© o nÃ­vel suavizado e $b_t$ Ã© a estimativa da tendÃªncia no tempo $t$, $\alpha$ e $\beta$ sÃ£o parÃ¢metros de suavizaÃ§Ã£o.

III. Portanto, a suavizaÃ§Ã£o exponencial simples nÃ£o Ã© adequada para sÃ©ries com tendÃªncia, e o uso da suavizaÃ§Ã£o exponencial dupla se faz necessÃ¡rio para capturar tanto o nÃ­vel quanto a tendÃªncia da sÃ©rie.â– 

### Modelos de EspaÃ§o de Estados e Filtro de Kalman
Os modelos de espaÃ§o de estados fornecem uma estrutura flexÃ­vel para modelar sistemas dinÃ¢micos, incluindo aqueles com componentes de tendÃªncia. Eles sÃ£o definidos por duas equaÃ§Ãµes principais: a equaÃ§Ã£o de estado e a equaÃ§Ã£o de observaÃ§Ã£o.

A equaÃ§Ã£o de estado descreve como o estado do sistema evolui ao longo do tempo:
$$ \mathbf{x}_{t+1} = \mathbf{F}\mathbf{x}_t + \mathbf{G}\mathbf{w}_t $$

A equaÃ§Ã£o de observaÃ§Ã£o relaciona o estado do sistema Ã s observaÃ§Ãµes:
$$ \mathbf{y}_t = \mathbf{H}\mathbf{x}_t + \mathbf{v}_t $$

Para modelar uma tendÃªncia, podemos incluir uma variÃ¡vel para a tendÃªncia no vetor de estado:
$$ \mathbf{x}_t = \begin{bmatrix} \text{nÃ­vel}_t \\ \text{tendÃªncia}_t \end{bmatrix} $$

O filtro de Kalman usa essas equaÃ§Ãµes para estimar iterativamente o estado do sistema, incluindo a tendÃªncia.

#### Passos do Filtro de Kalman
1.  **PrevisÃ£o:**
    -   Estado previsto:
        $$ \hat{\mathbf{x}}_{t|t-1} = \mathbf{F} \hat{\mathbf{x}}_{t-1|t-1} $$
    -   CovariÃ¢ncia do estado prevista:
        $$ \mathbf{P}_{t|t-1} = \mathbf{F} \mathbf{P}_{t-1|t-1} \mathbf{F}^T + \mathbf{G} \mathbf{Q} \mathbf{G}^T $$

2.  **AtualizaÃ§Ã£o:**
    -   Ganho de Kalman:
        $$ \mathbf{K}_t = \mathbf{P}_{t|t-1} \mathbf{H}^T (\mathbf{H} \mathbf{P}_{t|t-1} \mathbf{H}^T + \mathbf{R})^{-1} $$
    -   Estado atualizado:
        $$ \hat{\mathbf{x}}_{t|t} = \hat{\mathbf{x}}_{t|t-1} + \mathbf{K}_t (\mathbf{y}_t - \mathbf{H} \hat{\mathbf{x}}_{t|t-1}) $$
    -   CovariÃ¢ncia do estado atualizada:
        $$ \mathbf{P}_{t|t} = (\mathbf{I} - \mathbf{K}_t \mathbf{H}) \mathbf{P}_{t|t-1} $$

O filtro de Kalman permite estimar o estado subjacente (incluindo tendÃªncia), usando as mediÃ§Ãµes ruidosas. Os modelos de espaÃ§o de estados e o Filtro de Kalman, portanto, oferecem uma abordagem mais flexÃ­vel e poderosa para lidar com componentes de tendÃªncia, permitindo a combinaÃ§Ã£o com outras componentes (sazonalidade, ciclo) e modelos mais avanÃ§ados.

> ğŸ’¡ **Exemplo NumÃ©rico:** Vamos simplificar e apresentar um exemplo com valores hipotÃ©ticos para ilustrar o processo do filtro de Kalman para estimar uma tendÃªncia.
>
> Suponha que temos um modelo onde o estado $\mathbf{x}_t$ Ã© composto pelo nÃ­vel e pela tendÃªncia. Vamos comeÃ§ar com:
>
> - Estado inicial: $\mathbf{x}_{0|0} = \begin{bmatrix} 20 \\ 2 \end{bmatrix}$ (nÃ­vel inicial 20, tendÃªncia inicial 2)
> - CovariÃ¢ncia inicial: $\mathbf{P}_{0|0} = \begin{bmatrix} 1 & 0 \\ 0 & 0.1 \end{bmatrix}$
> - Matriz de transiÃ§Ã£o de estado: $\mathbf{F} = \begin{bmatrix} 1 & 1 \\ 0 & 1 \end{bmatrix}$ (o nÃ­vel aumenta pela tendÃªncia, a tendÃªncia mantÃ©m-se)
> - Matriz de ruÃ­do do processo: $\mathbf{G} = \begin{bmatrix} 0.5 & 0 \\ 0 & 0.1 \end{bmatrix}$
> - Matriz de covariÃ¢ncia do ruÃ­do do processo: $\mathbf{Q} = \begin{bmatrix} 0.01 & 0 \\ 0 & 0.001 \end{bmatrix}$
> - Matriz de observaÃ§Ã£o: $\mathbf{H} = \begin{bmatrix} 1 & 0 \end{bmatrix}$ (observamos apenas o nÃ­vel)
> - VariÃ¢ncia do ruÃ­do da observaÃ§Ã£o: $\mathbf{R} = [0.5]$
>
> Suponha que a observaÃ§Ã£o no tempo $t=1$ Ã© $\mathbf{y}_1 = 23$.
>
> 1. **PrevisÃ£o:**
>     - Estado previsto:
>       $$\hat{\mathbf{x}}_{1|0} = \mathbf{F} \hat{\mathbf{x}}_{0|0} = \begin{bmatrix} 1 & 1 \\ 0 & 1 \end{bmatrix} \begin{bmatrix} 20 \\ 2 \end{bmatrix} = \begin{bmatrix} 22 \\ 2 \end{bmatrix}$$
>     - CovariÃ¢ncia do estado prevista:
>        $$\mathbf{P}_{1|0} = \mathbf{F} \mathbf{P}_{0|0} \mathbf{F}^T + \mathbf{G} \mathbf{Q} \mathbf{G}^T$$
>       $$\mathbf{P}_{1|0} = \begin{bmatrix} 1 & 1 \\ 0 & 1 \end{bmatrix} \begin{bmatrix} 1 & 0 \\ 0 & 0.1 \end{bmatrix} \begin{bmatrix} 1 & 0 \\ 1 & 1 \end{bmatrix} + \begin{bmatrix} 0.5 & 0 \\ 0 & 0.1 \end{bmatrix}  \begin{bmatrix} 0.01 & 0 \\ 0 & 0.001 \end{bmatrix} \begin{bmatrix} 0.5 & 0 \\ 0 & 0.1 \end{bmatrix}^T$$
>        $$\mathbf{P}_{1|0} \approx \begin{bmatrix} 1.1025 & 0.1 \\ 0.1 & 0.101 \end{bmatrix}$$
> 2. **AtualizaÃ§Ã£o:**
>     - Ganho de Kalman:
>      $$ \mathbf{K}_1 = \mathbf{P}_{1|0} \mathbf{H}^T (\mathbf{H} \mathbf{P}_{1|0} \mathbf{H}^T + \mathbf{R})^{-1} $$
>      $$ \mathbf{K}_1 = \begin{bmatrix} 1.1025 & 0.1 \\ 0.1 & 0.101 \end{bmatrix} \begin{bmatrix} 1 \\ 0 \end{bmatrix}  ( \begin{bmatrix} 1 & 0 \end{bmatrix} \begin{bmatrix} 1.1025 & 0.1 \\ 0.1 & 0.101 \end{bmatrix} \begin{bmatrix} 1 \\ 0 \end{bmatrix} + 0.5 )^{-1} $$
>       $$\mathbf{K}_1 =  \begin{bmatrix} 1.1025 \\ 0.1 \end{bmatrix}  (1.1025+0.5)^{-1}  = \begin{bmatrix} 0.688 \\ 0.062 \end{bmatrix}$$
>     - Estado atualizado:
>      $$ \hat{\mathbf{x}}_{1|1} = \hat{\mathbf{x}}_{1|0} + \mathbf{K}_1 (\mathbf{y}_1 - \mathbf{H} \hat{\mathbf{x}}_{1|0}) $$
>     $$ \hat{\mathbf{x}}_{1|1} = \begin{bmatrix} 22 \\ 2 \end{bmatrix} + \begin{bmatrix} 0.688 \\ 0.062 \end{bmatrix} (23 - \begin{bmatrix} 1 & 0 \end{bmatrix} \begin{bmatrix} 22 \\ 2 \end{bmatrix} ) = \begin{bmatrix} 22 \\ 2 \end{bmatrix} + \begin{bmatrix} 0.688 \\ 0.062 \end{bmatrix} (23-22) = \begin{bmatrix} 22.688 \\ 2.062 \end{bmatrix}$$
>     - CovariÃ¢ncia do estado atualizada:
>        $$ \mathbf{P}_{1|1} = (\mathbf{I} - \mathbf{K}_1 \mathbf{H}) \mathbf{P}_{1|0} $$
>       $$ \mathbf{P}_{1|1} = \left( \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} - \begin{bmatrix} 0.688 \\ 0.062 \end{bmatrix} \begin{bmatrix} 1 & 0 \end{bmatrix} \right) \begin{bmatrix} 1.1025 & 0.1 \\ 0.1 & 0.101 \end{bmatrix} = \begin{bmatrix} 0.347 & 0.031 \\ 0.031 & 0.1 \end{bmatrix}$$
>
> ApÃ³s essa atualizaÃ§Ã£o, a estimativa do nÃ­vel passou de 22 para 22.688, e a tendÃªncia foi ligeiramente ajustada para 2.062. Este processo Ã© repetido para cada nova observaÃ§Ã£o, permitindo que o filtro de Kalman rastreie a tendÃªncia e o nÃ­vel da sÃ©rie temporal.

**Teorema 1:** Se o modelo de espaÃ§o de estados Ã© linear e Gaussiano, o filtro de Kalman fornece a estimativa Ã³tima do estado no sentido de mÃ­nimos quadrados e tambÃ©m no sentido de mÃ¡xima verossimilhanÃ§a.

**Prova do Teorema 1:**
I.  Se o modelo de espaÃ§o de estados Ã© linear, as equaÃ§Ãµes de estado e observaÃ§Ã£o sÃ£o lineares em relaÃ§Ã£o aos estados e ruÃ­dos. Ou seja, $\mathbf{x}_{t+1} = \mathbf{F}\mathbf{x}_t + \mathbf{G}\mathbf{w}_t$ e $\mathbf{y}_t = \mathbf{H}\mathbf{x}_t + \mathbf{v}_t$, onde $\mathbf{w}_t$ e $\mathbf{v}_t$ sÃ£o ruÃ­dos gaussianos com mÃ©dia zero.

II.  Se os ruÃ­dos sÃ£o gaussianos, e o estado inicial $\mathbf{x}_0$ tambÃ©m Ã© gaussiano, entÃ£o todos os estados $\mathbf{x}_t$ sÃ£o gaussianos e todasas distribuiÃ§Ãµes $\mathbf{x}_t$ sÃ£o completamente descritas pelas suas mÃ©dias e matrizes de covariÃ¢ncia. Assumindo que $\mathbf{x}_0 \sim \mathcal{N}(\boldsymbol{\mu}_0, \mathbf{\Sigma}_0)$ e que $\mathbf{v}_t \sim \mathcal{N}(\mathbf{0}, \mathbf{R}_t)$, entÃ£o, recursivamente:

\begin{align*}
\boldsymbol{\mu}_t &= \mathbf{F}_t \boldsymbol{\mu}_{t-1} + \mathbf{b}_t \\
\mathbf{\Sigma}_t &= \mathbf{F}_t \mathbf{\Sigma}_{t-1} \mathbf{F}_t^T + \mathbf{R}_t
\end{align*}

Estas equaÃ§Ãµes descrevem a evoluÃ§Ã£o da mÃ©dia e covariÃ¢ncia do estado ao longo do tempo, dadas as dinÃ¢micas do sistema ($\mathbf{F}_t$, $\mathbf{b}_t$) e o ruÃ­do do processo ($\mathbf{R}_t$).

### Modelo de ObservaÃ§Ã£o

Similarmente, assumimos que as mediÃ§Ãµes $\mathbf{y}_t$ sÃ£o tambÃ©m afetadas por um ruÃ­do $\mathbf{w}_t$:

$$ \mathbf{y}_t = \mathbf{H}_t \mathbf{x}_t + \mathbf{c}_t + \mathbf{w}_t$$

Onde:
-   $\mathbf{H}_t$ Ã© a matriz de observaÃ§Ã£o no instante $t$.
-   $\mathbf{c}_t$ Ã© um vetor de deslocamento.
-   $\mathbf{w}_t$ sÃ£o ruÃ­dos gaussianos com mÃ©dia zero.

Assumindo que $\mathbf{w}_t \sim \mathcal{N}(\mathbf{0}, \mathbf{Q}_t)$, e que $\mathbf{x}_t$ Ã© gaussiano, entÃ£o $\mathbf{y}_t$ Ã© tambÃ©m gaussiano:

$$ \mathbf{y}_t | \mathbf{x}_t \sim \mathcal{N}(\mathbf{H}_t \mathbf{x}_t + \mathbf{c}_t, \mathbf{Q}_t) $$

### InferÃªncia

O objetivo Ã© estimar o estado $\mathbf{x}_t$ com base nas mediÃ§Ãµes $\mathbf{y}_{1:t}$. Para isso, podemos usar o filtro de Kalman, que calcula a distribuiÃ§Ã£o preditiva e a distribuiÃ§Ã£o de atualizaÃ§Ã£o:

**PrevisÃ£o:**

\begin{align*}
\boldsymbol{\mu}_{t|t-1} &= \mathbf{F}_t \boldsymbol{\mu}_{t-1|t-1} + \mathbf{b}_t \\
\mathbf{\Sigma}_{t|t-1} &= \mathbf{F}_t \mathbf{\Sigma}_{t-1|t-1} \mathbf{F}_t^T + \mathbf{R}_t
\end{align*}

**AtualizaÃ§Ã£o:**
Primeiro calculamos o ganho de Kalman:

$$ \mathbf{K}_t = \mathbf{\Sigma}_{t|t-1} \mathbf{H}_t^T (\mathbf{H}_t \mathbf{\Sigma}_{t|t-1} \mathbf{H}_t^T + \mathbf{Q}_t)^{-1} $$

Em seguida, atualizamos a mÃ©dia e a covariÃ¢ncia:

\begin{align*}
\boldsymbol{\mu}_{t|t} &= \boldsymbol{\mu}_{t|t-1} + \mathbf{K}_t (\mathbf{y}_t - \mathbf{H}_t \boldsymbol{\mu}_{t|t-1} - \mathbf{c}_t) \\
\mathbf{\Sigma}_{t|t} &= (\mathbf{I} - \mathbf{K}_t \mathbf{H}_t) \mathbf{\Sigma}_{t|t-1}
\end{align*}

Onde:
- $\boldsymbol{\mu}_{t|t-1}$ e $\mathbf{\Sigma}_{t|t-1}$ sÃ£o a mÃ©dia e covariÃ¢ncia do estado predito no instante $t$, dado o histÃ³rico atÃ© $t-1$.
- $\boldsymbol{\mu}_{t|t}$ e $\mathbf{\Sigma}_{t|t}$ sÃ£o a mÃ©dia e covariÃ¢ncia do estado atualizado no instante $t$, dado o histÃ³rico atÃ© $t$.

### InicializaÃ§Ã£o

O filtro de Kalman precisa ser inicializado com valores iniciais para a mÃ©dia e a covariÃ¢ncia do estado: $\boldsymbol{\mu}_{0|0} = \boldsymbol{\mu}_0$ e $\mathbf{\Sigma}_{0|0} = \mathbf{\Sigma}_0$.

<!-- END -->
