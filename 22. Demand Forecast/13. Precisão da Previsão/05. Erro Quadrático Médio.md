## Erro QuadrÃ¡tico MÃ©dio (MSE) na AvaliaÃ§Ã£o da PrecisÃ£o da PrevisÃ£o em SÃ©ries Temporais

### IntroduÃ§Ã£o
Dando continuidade Ã  nossa discussÃ£o sobre modelagem de sÃ©ries temporais e avaliaÃ§Ã£o da precisÃ£o de previsÃµes, este capÃ­tulo se aprofunda no Erro QuadrÃ¡tico MÃ©dio (MSE), uma mÃ©trica essencial para quantificar a magnitude e a distribuiÃ§Ã£o dos erros de previsÃ£o, com especial Ãªnfase na penalizaÃ§Ã£o de grandes erros [^12]. Como vimos nos capÃ­tulos anteriores, a modelagem de sÃ©ries temporais envolve analisar dados sequenciais ao longo do tempo para prever valores futuros [^5]. Dada a natureza imperfeita das previsÃµes, Ã© fundamental quantificar e avaliar a diferenÃ§a entre os valores previstos e os valores reais, e o MSE fornece uma abordagem robusta para esta tarefa [^10]. O MSE Ã© frequentemente utilizado em conjunto com outras mÃ©tricas, como o Desvio Absoluto MÃ©dio (MAD) e o Erro Percentual Absoluto MÃ©dio (MAPE) para oferecer uma visÃ£o abrangente do desempenho do modelo. Este capÃ­tulo tem como objetivo analisar em profundidade a mÃ©trica MSE, suas propriedades, como calculÃ¡-la e interpretar os resultados obtidos.

### Conceitos Fundamentais
O Erro QuadrÃ¡tico MÃ©dio (MSE) Ã© uma mÃ©trica comumente utilizada para avaliar a precisÃ£o de previsÃµes em sÃ©ries temporais [^12]. Ele representa a mÃ©dia dos quadrados dos erros de previsÃ£o, em que o erro de previsÃ£o Ã© definido como a diferenÃ§a entre a demanda real e a previsÃ£o [^9]. Ao elevar os erros ao quadrado, o MSE penaliza erros maiores de forma mais significativa do que os erros menores [^12]. Essa caracterÃ­stica Ã© particularmente Ãºtil em situaÃ§Ãµes onde grandes erros de previsÃ£o podem ter consequÃªncias mais graves ou dispendiosas. Matematicamente, o MSE Ã© expresso como:

$$ \text{MSE} = \frac{\sum (\text{Demanda Real} - \text{PrevisÃ£o})^2}{n} $$ [^12]

Onde:
-  $\text{Demanda Real}$ Ã© o valor real da sÃ©rie temporal no perÃ­odo considerado;
- $\text{PrevisÃ£o}$ Ã© o valor previsto para o mesmo perÃ­odo pelo modelo;
- $\sum$ denota a soma dos quadrados das diferenÃ§as entre a demanda real e a previsÃ£o em todos os perÃ­odos considerados;
-  $n$ Ã© o nÃºmero de perÃ­odos incluÃ­dos no cÃ¡lculo.

Ã‰ crucial lembrar que a avaliaÃ§Ã£o da precisÃ£o da previsÃ£o Ã© feita no passado, usando dados histÃ³ricos para verificar a adequaÃ§Ã£o da abordagem de previsÃ£o. [^10].

**ProposiÃ§Ã£o 3.1:** O MSE Ã© equivalente ao quadrado da norma-2 do vetor de erros de previsÃ£o dividido pelo nÃºmero de perÃ­odos.

**Prova:**
I. O erro de previsÃ£o no perÃ­odo t, denotado por $e_t$, Ã© dado por: $e_t = \text{Demanda Real}_t - \text{PrevisÃ£o}_t$.
II. O quadrado do erro de previsÃ£o Ã© dado por: $e_t^2 = (\text{Demanda Real}_t - \text{PrevisÃ£o}_t)^2$.
III. A soma dos quadrados dos erros de previsÃ£o Ã©:  $\sum e_t^2 = \sum (\text{Demanda Real}_t - \text{PrevisÃ£o}_t)^2$.
IV. O MSE Ã© definido como a mÃ©dia desses quadrados: $\text{MSE} = \frac{\sum e_t^2}{n} = \frac{\sum (\text{Demanda Real} - \text{PrevisÃ£o})^2}{n}$.
V.  A norma-2 (ou norma euclidiana) de um vetor $\mathbf{e} = [e_1, e_2,\ldots,e_n]$ Ã© definida como: $||\mathbf{e}||_2 = \sqrt{\sum_{t=1}^n e_t^2}$.
VI. Portanto, o MSE pode ser expresso como: $\text{MSE} = \frac{||\mathbf{e}||_2^2}{n}$, demonstrando que Ã© equivalente ao quadrado da norma-2 do vetor de erros de previsÃ£o dividido pelo nÃºmero de perÃ­odos. $\blacksquare$

**ObservaÃ§Ã£o 3.1:** A ProposiÃ§Ã£o 3.1 revela uma conexÃ£o direta entre o MSE e a norma-2, o que implica que o MSE minimiza a soma dos quadrados dos erros. Essa caracterÃ­stica faz com que o MSE penalize erros maiores mais severamente do que erros menores.

**Lema 3.1.1:** O MSE Ã© nÃ£o-negativo.

**Prova:**
I. O MSE Ã© definido como a mÃ©dia dos quadrados dos erros de previsÃ£o: $\text{MSE} = \frac{\sum (y_t - \hat{y}_t)^2}{n}$, onde $y_t$ Ã© a demanda real e $\hat{y}_t$ Ã© a previsÃ£o.
II.  O quadrado de qualquer nÃºmero real Ã© sempre nÃ£o-negativo: $(y_t - \hat{y}_t)^2 \geq 0$ para todo $t$.
III. A soma de nÃºmeros nÃ£o-negativos Ã© tambÃ©m nÃ£o-negativa: $\sum (y_t - \hat{y}_t)^2 \geq 0$.
IV. Dividindo uma soma nÃ£o-negativa pelo nÃºmero de perÃ­odos $n$, que Ã© um nÃºmero positivo, resulta num valor nÃ£o-negativo: $\frac{\sum (y_t - \hat{y}_t)^2}{n} \geq 0$.
V.  Portanto, o MSE Ã© sempre nÃ£o-negativo. $\blacksquare$

#### InterpretaÃ§Ã£o do MSE
Valores menores de MSE indicam que as previsÃµes estÃ£o mais prÃ³ximas da demanda real, sugerindo maior precisÃ£o do modelo. Por outro lado, valores mais altos de MSE indicam que as previsÃµes estÃ£o mais distantes da demanda real, implicando menor precisÃ£o [^12]. O MSE penaliza erros maiores de forma mais significativa do que erros menores, o que pode ser Ãºtil quando grandes erros de previsÃ£o sÃ£o mais dispendiosos ou tÃªm consequÃªncias graves [^12]. O MSE Ã© expresso em unidades ao quadrado, o que pode dificultar sua interpretaÃ§Ã£o em termos de magnitude do erro em comparaÃ§Ã£o ao MAD, o que torna sua interpretaÃ§Ã£o menos intuitiva que a do MAD.

#### CÃ¡lculo do MSE
Para calcular o MSE, Ã© necessÃ¡rio:
1. Calcular o erro de previsÃ£o para cada perÃ­odo: Subtrair a previsÃ£o da demanda real para cada perÃ­odo na sÃ©rie temporal.
2. Elevar ao quadrado cada erro: Elevar ao quadrado os erros para que todos se tornem valores positivos.
3. Calcular a mÃ©dia desses valores ao quadrado: Somar todos os erros ao quadrado e dividir pelo nÃºmero total de perÃ­odos considerados.

> ðŸ’¡ **Exemplo NumÃ©rico:**
> Consideremos uma sÃ©rie temporal de demanda e suas respectivas previsÃµes:
>
> | PerÃ­odo | Demanda Real ($y_t$) | PrevisÃ£o ($\hat{y}_t$) |
> |---|---|---|
> | 1 | 100 | 110 |
> | 2 | 120 | 115 |
> | 3 | 130 | 125 |
> | 4 | 150 | 140 |
> | 5 | 160 | 155 |
>
> $\text{Step 1: Calcular os erros de previsÃ£o: }$
>
> $100-110 = -10$
> $120-115 = 5$
> $130-125 = 5$
> $150-140 = 10$
> $160-155 = 5$
>
> $\text{Step 2: Calcular o quadrado dos erros: }$
>
> $(-10)^2 = 100$
> $(5)^2 = 25$
> $(5)^2 = 25$
> $(10)^2 = 100$
> $(5)^2 = 25$
>
> $\text{Step 3: Calcular a mÃ©dia dos quadrados dos erros: }$
>
> $\text{MSE} = \frac{100 + 25 + 25 + 100 + 25}{5} = \frac{275}{5} = 55$
>
> Um MSE de 55 indica que a mÃ©dia dos quadrados dos erros de previsÃ£o Ã© de 55 unidades ao quadrado.
>
> ```python
> import numpy as np
>
> actual_demand = np.array([100, 120, 130, 150, 160])
> forecast = np.array([110, 115, 125, 140, 155])
>
> errors = actual_demand - forecast
> squared_errors = errors ** 2
> mse = np.mean(squared_errors)
> print(f"MSE: {mse}")
> ```

> ðŸ’¡ **Exemplo NumÃ©rico:**
> Suponha que estejamos analisando a demanda diÃ¡ria de um produto em um pequeno varejo. As vendas reais nos Ãºltimos 7 dias e as previsÃµes do modelo sÃ£o dadas na tabela abaixo:
>
> | Dia | Demanda Real | PrevisÃ£o |
> |-----|--------------|----------|
> | 1   | 25           | 28       |
> | 2   | 30           | 27       |
> | 3   | 22           | 24       |
> | 4   | 28           | 31       |
> | 5   | 35           | 32       |
> | 6   | 29           | 26       |
> | 7   | 32           | 30       |
>
> $\text{Step 1: Calcular os erros de previsÃ£o: }$
>
> $25-28 = -3$
> $30-27 = 3$
> $22-24 = -2$
> $28-31 = -3$
> $35-32 = 3$
> $29-26 = 3$
> $32-30 = 2$
>
> $\text{Step 2: Calcular o quadrado dos erros: }$
>
> $(-3)^2 = 9$
> $(3)^2 = 9$
> $(-2)^2 = 4$
> $(-3)^2 = 9$
> $(3)^2 = 9$
> $(3)^2 = 9$
> $(2)^2 = 4$
>
> $\text{Step 3: Calcular a mÃ©dia dos erros ao quadrado: }$
>
> $\text{MSE} = \frac{9 + 9 + 4 + 9 + 9 + 9 + 4}{7} = \frac{53}{7} \approx 7.57$
>
>  O MSE Ã© aproximadamente 7.57, o que indica a mÃ©dia dos quadrados dos erros de previsÃ£o.
>
> ```python
> import numpy as np
>
> actual_demand = np.array([25, 30, 22, 28, 35, 29, 32])
> forecast = np.array([28, 27, 24, 31, 32, 26, 30])
>
> errors = actual_demand - forecast
> squared_errors = errors ** 2
> mse = np.mean(squared_errors)
> print(f"MSE: {mse}")
> ```
>
> Em termos prÃ¡ticos, um MSE de 7.57 significa que, em mÃ©dia, os erros de previsÃ£o ao quadrado sÃ£o de aproximadamente 7.57 unidades. Isso implica que o modelo tem um certo grau de imprecisÃ£o nas suas previsÃµes, e em mÃ©dia a distÃ¢ncia entre os valores previstos e reais Ã© de  aproximadamente $\sqrt{7.57} \approx 2.75$ unidades.

#### ComparaÃ§Ã£o com outras mÃ©tricas de erro
Enquanto o MSE enfatiza a magnitude dos erros, outras mÃ©tricas como o Desvio Absoluto MÃ©dio (MAD) e o Erro Percentual Absoluto MÃ©dio (MAPE) tambÃ©m sÃ£o utilizadas para avaliar a precisÃ£o da previsÃ£o [^10, 12]. O MAD calcula a mÃ©dia dos erros absolutos, enquanto o MSE eleva os erros ao quadrado, dando mais peso aos erros maiores, o que pode ser Ãºtil em situaÃ§Ãµes em que grandes erros podem ser dispendiosos [^10, 12]. O MAPE expressa o erro como uma porcentagem da demanda real, sendo Ãºtil quando se quer avaliar a precisÃ£o da previsÃ£o em termos relativos [^12]. A Raiz do Erro QuadrÃ¡tico MÃ©dio (RMSE) Ã© a raiz quadrada do MSE, o que traz o erro de volta Ã  mesma unidade dos dados originais, facilitando sua interpretaÃ§Ã£o e permitindo avaliar a magnitude do erro em termos absolutos. O Erro MÃ©dio Absoluto Escalonado (MASE) Ã© Ãºtil para comparar o modelo com um modelo naive, e resolve problemas quando a demanda Ã© prÃ³xima de zero. Uma anÃ¡lise abrangente, portanto, deve considerar o uso de diversas mÃ©tricas de erro.

**Lema 3.1:** O MSE Ã© mais sensÃ­vel a *outliers* (valores discrepantes) do que o MAD.

**Prova:**
I. O MSE Ã© dado por $\text{MSE} = \frac{\sum (y_t - \hat{y}_t)^2}{n}$, enquanto o MAD Ã© dado por $\text{MAD} = \frac{\sum |y_t - \hat{y}_t|}{n}$, onde $y_t$ Ã© a demanda real e $\hat{y}_t$ Ã© a previsÃ£o.

II.  Se um ponto de dados Ã© um *outlier* (ou seja, o erro $e_t = y_t - \hat{y}_t$ Ã© um valor atÃ­pico), o MSE eleva este erro ao quadrado, tornando o impacto do *outlier* no MSE ainda maior, jÃ¡ que $(y_t - \hat{y}_t)^2 > |y_t - \hat{y}_t|$.

III. O MAD usa o valor absoluto dos erros, o que significa que o impacto de um *outlier* Ã© linear no MAD, e nÃ£o quadrÃ¡tico.

IV. Portanto, o MSE Ã© mais sensÃ­vel a outliers do que o MAD, o que significa que o MSE serÃ¡ afetado de forma mais significativa do que o MAD quando houver valores discrepantes no conjunto de dados. $\blacksquare$

**Teorema 3.1:** O MSE Ã© igual ao MAD ao quadrado apenas quando todos os erros de previsÃ£o sÃ£o iguais a 0 ou 1.

**Prova:**
I.  O MSE Ã© definido como $\text{MSE} = \frac{\sum e_i^2}{n}$ e o MAD como $\text{MAD} = \frac{\sum |e_i|}{n}$, onde $e_i$ sÃ£o os erros de previsÃ£o.

II.  A condiÃ§Ã£o para que o MSE seja igual ao MAD ao quadrado Ã© $\text{MSE} = \text{MAD}^2$. Ou seja, $\frac{\sum e_i^2}{n} = \left( \frac{\sum |e_i|}{n} \right)^2$.

III.  Multiplicando ambos os lados por $n^2$, temos $n\sum e_i^2 = (\sum |e_i|)^2$.

IV. Pela desigualdade de Cauchy-Schwarz,  $(\sum |e_i|)^2 \leq n \sum e_i^2$, e a igualdade sÃ³ ocorre quando $|e_1|=|e_2|=\dots=|e_n|$.

V.  Substituindo a igualdade, a condiÃ§Ã£o $\text{MSE} = \text{MAD}^2$ implica em $\sum e_i^2 = \sum |e_i|^2 = \frac{1}{n}(\sum |e_i|)^2 $.

VI. Se  todos os erros forem 0, $\text{MSE} = \text{MAD} = 0$, e a condiÃ§Ã£o Ã© satisfeita. Se todos os erros forem 1, $\text{MSE} = \text{MAD} = 1$, e a condiÃ§Ã£o tambÃ©m Ã© satisfeita.

VII. Se os erros nÃ£o forem todos 0 ou 1, a igualdade nÃ£o Ã© satisfeita, demonstrando que a igualdade ocorre apenas nesses casos especÃ­ficos. $\blacksquare$

**Teorema 3.2:** O MSE pode ser decomposto na soma da variÃ¢ncia do erro de previsÃ£o e o quadrado do viÃ©s da previsÃ£o.

**Prova:**
I. Seja $Y$ a variÃ¡vel aleatÃ³ria representando a demanda real e $\hat{Y}$ a variÃ¡vel aleatÃ³ria representando a previsÃ£o. O erro de previsÃ£o Ã© dado por $e = Y - \hat{Y}$.
II.  O MSE pode ser expresso como o valor esperado do quadrado do erro de previsÃ£o: $\text{MSE} = E[(Y - \hat{Y})^2]$.
III.  Adicionando e subtraindo o valor esperado da previsÃ£o $E[\hat{Y}]$, temos:
    $E[(Y - \hat{Y})^2] = E[(Y - E[\hat{Y}] + E[\hat{Y}] - \hat{Y})^2] = E[((Y - E[\hat{Y}]) - (\hat{Y} - E[\hat{Y}]))^2]$.
IV. Expandindo o quadrado:
$E[(Y - E[\hat{Y}])^2 - 2(Y - E[\hat{Y}])(\hat{Y} - E[\hat{Y}]) + (\hat{Y} - E[\hat{Y}])^2]$.
V.  Assumindo que $Y$ e $\hat{Y}$ sÃ£o independentes, $E[(Y - E[\hat{Y}])(\hat{Y} - E[\hat{Y}])] = 0$.

VI. Separando os termos:
$E[(Y - E[\hat{Y}])^2] - 2E[(Y - E[\hat{Y}])(\hat{Y} - E[\hat{Y}])] + E[(\hat{Y} - E[\hat{Y}])^2] = E[(Y - E[\hat{Y}])^2] + E[(\hat{Y} - E[\hat{Y}])^2]$.

VII. Temos que $E[(Y - E[\hat{Y}])^2]$ Ã© a variÃ¢ncia do erro da previsÃ£o, e $E[(\hat{Y} - E[\hat{Y}])^2]$ Ã© o quadrado do viÃ©s, logo:
  $\text{MSE} = \text{Var}(Y - \hat{Y}) + (E[\hat{Y}] - E[Y])^2$

VIII. Portanto,  o MSE Ã© igual Ã  soma da variÃ¢ncia do erro de previsÃ£o e o quadrado do viÃ©s. $\blacksquare$

> ðŸ’¡ **Exemplo NumÃ©rico:**
> Para ilustrar a decomposiÃ§Ã£o do MSE em variÃ¢ncia e viÃ©s, vamos considerar um modelo de previsÃ£o simples.
>
> Suponha que a demanda real ($Y$) siga uma distribuiÃ§Ã£o normal com mÃ©dia $\mu_Y = 100$ e desvio padrÃ£o $\sigma_Y = 10$, ou seja, $Y \sim N(100, 10^2)$.
>
> Consideremos dois modelos de previsÃ£o:
>
> Modelo A: $\hat{Y}_A = 0.8Y + 10$, onde as previsÃµes tem viÃ©s e variÃ¢ncia
> Modelo B: $\hat{Y}_B = 1.0Y$ onde as previsÃµes tem variÃ¢ncia, mas pouco viÃ©s
>
> Calculando os valores esperados:
>
> $E[\hat{Y}_A] = 0.8E[Y] + 10 = 0.8 \times 100 + 10 = 90$
>
> $E[\hat{Y}_B] = 1.0 E[Y] = 100$
>
> Calculando os viÃ©ses:
>
> $Bias_A = E[\hat{Y}_A] - E[Y] = 90 - 100 = -10$
> $Bias_B = E[\hat{Y}_B] - E[Y] = 100 - 100 = 0$
>
> Calculando as variÃ¢ncias:
> $Var(\hat{Y}_A) = Var(0.8Y + 10) = 0.8^2 Var(Y) = 0.64 \times 10^2= 64$
> $Var(\hat{Y}_B) = Var(Y) = 10^2 = 100$
>
> Vamos simular 1000 amostras usando `numpy` e calcular o MSE dos dois modelos
>
> ```python
> import numpy as np
>
> np.random.seed(42) # Para reprodutibilidade
>
> num_samples = 1000
>
> # Simula a demanda real
> Y = np.random.normal(loc=100, scale=10, size=num_samples)
>
> # Gera as previsÃµes do Modelo A e B
> Y_hat_A = 0.8 * Y + 10
> Y_hat_B = 1.0 * Y
>
> # Calcula o MSE para ambos os modelos
> mse_A = np.mean((Y - Y_hat_A) ** 2)
> mse_B = np.mean((Y - Y_hat_B) ** 2)
>
> # Calcula o viÃ©s e a variÃ¢ncia
> bias_A = np.mean(Y_hat_A) - np.mean(Y)
> var_error_A = np.var(Y - Y_hat_A)
> bias_B = np.mean(Y_hat_B) - np.mean(Y)
> var_error_B = np.var(Y - Y_hat_B)
>
> print(f"MSE Modelo A: {mse_A:.2f}")
> print(f"ViÃ©s Modelo A: {bias_A:.2f}")
> print(f"VariÃ¢ncia do Erro Modelo A: {var_error_A:.2f}")
> print(f"MSE Modelo B: {mse_B:.2f}")
> print(f"ViÃ©s Modelo B: {bias_B:.2f}")
> print(f"VariÃ¢ncia do Erro Modelo B: {var_error_B:.2f}")
>
> # Verifica a decomposiÃ§Ã£o do MSE:
> mse_A_decomposed = var_error_A + bias_A**2
> mse_B_decomposed = var_error_B + bias_B**2
>
> print(f"MSE Modelo A (decomposto): {mse_A_decomposed:.2f}")
> print(f"MSE Modelo B (decomposto): {mse_B_decomposed:.2f}")
>
> ```
>
> No modelo A o MSE Ã© dado por:
>
> $\text{MSE}_A = \text{Var}(Y - \hat{Y}_A) + (E[\hat{Y}_A] - E[Y])^2 = 64 + (-10)^2 = 64 + 100 = 164$
>
> No modelo B o MSE Ã© dado por:
>
>  $\text{MSE}_B = \text{Var}(Y - \hat{Y}_B) + (E[\hat{Y}_B] - E[Y])^2 = 100 + (0)^2 = 100$
>
> O modelo B tem um MSE menor, pois nÃ£o apresenta viÃ©s e tem uma variÃ¢ncia menor.
>
> Este exemplo demonstra como o MSE pode ser decomposto em viÃ©s e variÃ¢ncia, ajudando a entender a natureza dos erros do modelo.

**CorolÃ¡rio 3.1:** Minimizar o MSE implica em minimizar tanto a variÃ¢ncia quanto o viÃ©s das previsÃµes.

**Prova:**
I. Pelo Teorema 3.2, o MSE Ã© dado por  $\text{MSE} = \text{Var}(Y - \hat{Y}) + (E[\hat{Y}] - E[Y])^2$.

II. O MSE Ã© uma soma de dois termos nÃ£o-negativos: a variÃ¢ncia do erro e o quadrado do viÃ©s.

III. Para minimizar o MSE, Ã© necessÃ¡rio minimizar cada termo da soma.

IV. Minimizar a variÃ¢ncia do erro significa reduzir a dispersÃ£o dos erros de previsÃ£o em relaÃ§Ã£o Ã  sua mÃ©dia, tornando as previsÃµes mais consistentes.

V. Minimizar o viÃ©s significa tornar a mÃ©dia das previsÃµes mais prÃ³xima da mÃ©dia dos valores reais, garantindo que as previsÃµes nÃ£o sejam sistematicamente subestimadas ou superestimadas.

VI.  Portanto, minimizar o MSE implica em simultaneamente minimizar a variÃ¢ncia e o viÃ©s da previsÃ£o. $\blacksquare$

### ConclusÃ£o
O Erro QuadrÃ¡tico MÃ©dio (MSE) Ã© uma mÃ©trica essencial na avaliaÃ§Ã£o da precisÃ£o de previsÃµes em sÃ©ries temporais. Sua capacidade de penalizar erros maiores o torna particularmente Ãºtil em situaÃ§Ãµes onde grandes erros sÃ£o mais dispendiosos [^12]. Ao comparar o MSE com o MAD, o RMSE, o MAPE, e o MASE, Ã© possÃ­vel obter uma compreensÃ£o mais abrangente do desempenho de um modelo preditivo. A seleÃ§Ã£o da mÃ©trica apropriada deve ser baseada no contexto do problema, com cada mÃ©trica fornecendo uma perspectiva Ãºnica sobre a precisÃ£o da previsÃ£o. Em Ãºltima anÃ¡lise, a capacidade de avaliar a precisÃ£o da previsÃ£o Ã© essencial para escolher o melhor modelo e, consequentemente, aprimorar o processo de tomada de decisÃµes e o planejamento e alocaÃ§Ã£o de recursos [^23].

### ReferÃªncias
[^5]: *Time series models assume that past demand data are representative of future demand.*
[^9]: *Forecast error = Actual demand - Forecast.*
[^10]: *Because a forecast predicts future demand, we cannot compare it to actual demand. However, because we have assumed that historical demand is representative of future demand, we can formulate "forecasts of the past" using a particular model and compare those forecasts to historical demand.*
[^12]: *With both the MAD and MSE, the size of the deviations depends on the volume of the item being forecast. For example, if the demand is in thousands of units, the absolute and squared deviations could be quite large. The mean absolute percentage error (MAPE) remedies this problem by expressing the deviation as a percentage of the actual demand.*
[^23]: *Forecasting demand is important to be able to plan and allocate the resources necessary to provide uninterrupted, quality customer service and avoid the excess costs arising from mismatched demand and supply.*
<!-- END -->
