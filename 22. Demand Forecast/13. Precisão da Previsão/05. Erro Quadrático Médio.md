## Erro Quadr√°tico M√©dio (MSE) na Avalia√ß√£o da Precis√£o da Previs√£o em S√©ries Temporais

### Introdu√ß√£o
Dando continuidade √† nossa discuss√£o sobre modelagem de s√©ries temporais e avalia√ß√£o da precis√£o de previs√µes, este cap√≠tulo se aprofunda no Erro Quadr√°tico M√©dio (MSE), uma m√©trica essencial para quantificar a magnitude e a distribui√ß√£o dos erros de previs√£o, com especial √™nfase na penaliza√ß√£o de grandes erros [^12]. Como vimos nos cap√≠tulos anteriores, a modelagem de s√©ries temporais envolve analisar dados sequenciais ao longo do tempo para prever valores futuros [^5]. Dada a natureza imperfeita das previs√µes, √© fundamental quantificar e avaliar a diferen√ßa entre os valores previstos e os valores reais, e o MSE fornece uma abordagem robusta para esta tarefa [^10]. O MSE √© frequentemente utilizado em conjunto com outras m√©tricas, como o Desvio Absoluto M√©dio (MAD) e o Erro Percentual Absoluto M√©dio (MAPE) para oferecer uma vis√£o abrangente do desempenho do modelo. Este cap√≠tulo tem como objetivo analisar em profundidade a m√©trica MSE, suas propriedades, como calcul√°-la e interpretar os resultados obtidos.

### Conceitos Fundamentais
O Erro Quadr√°tico M√©dio (MSE) √© uma m√©trica comumente utilizada para avaliar a precis√£o de previs√µes em s√©ries temporais [^12]. Ele representa a m√©dia dos quadrados dos erros de previs√£o, em que o erro de previs√£o √© definido como a diferen√ßa entre a demanda real e a previs√£o [^9]. Ao elevar os erros ao quadrado, o MSE penaliza erros maiores de forma mais significativa do que os erros menores [^12]. Essa caracter√≠stica √© particularmente √∫til em situa√ß√µes onde grandes erros de previs√£o podem ter consequ√™ncias mais graves ou dispendiosas. Matematicamente, o MSE √© expresso como:

$$ \text{MSE} = \frac{\sum (\text{Demanda Real} - \text{Previs√£o})^2}{n} $$ [^12]

Onde:
-  $\text{Demanda Real}$ √© o valor real da s√©rie temporal no per√≠odo considerado;
- $\text{Previs√£o}$ √© o valor previsto para o mesmo per√≠odo pelo modelo;
- $\sum$ denota a soma dos quadrados das diferen√ßas entre a demanda real e a previs√£o em todos os per√≠odos considerados;
-  $n$ √© o n√∫mero de per√≠odos inclu√≠dos no c√°lculo.

√â crucial lembrar que a avalia√ß√£o da precis√£o da previs√£o √© feita no passado, usando dados hist√≥ricos para verificar a adequa√ß√£o da abordagem de previs√£o. [^10].

**Proposi√ß√£o 3.1:** O MSE √© equivalente ao quadrado da norma-2 do vetor de erros de previs√£o dividido pelo n√∫mero de per√≠odos.

**Prova:**
I. O erro de previs√£o no per√≠odo t, denotado por $e_t$, √© dado por: $e_t = \text{Demanda Real}_t - \text{Previs√£o}_t$.
II. O quadrado do erro de previs√£o √© dado por: $e_t^2 = (\text{Demanda Real}_t - \text{Previs√£o}_t)^2$.
III. A soma dos quadrados dos erros de previs√£o √©:  $\sum e_t^2 = \sum (\text{Demanda Real}_t - \text{Previs√£o}_t)^2$.
IV. O MSE √© definido como a m√©dia desses quadrados: $\text{MSE} = \frac{\sum e_t^2}{n} = \frac{\sum (\text{Demanda Real} - \text{Previs√£o})^2}{n}$.
V.  A norma-2 (ou norma euclidiana) de um vetor $\mathbf{e} = [e_1, e_2,\ldots,e_n]$ √© definida como: $||\mathbf{e}||_2 = \sqrt{\sum_{t=1}^n e_t^2}$.
VI. Portanto, o MSE pode ser expresso como: $\text{MSE} = \frac{||\mathbf{e}||_2^2}{n}$, demonstrando que √© equivalente ao quadrado da norma-2 do vetor de erros de previs√£o dividido pelo n√∫mero de per√≠odos. $\blacksquare$

**Observa√ß√£o 3.1:** A Proposi√ß√£o 3.1 revela uma conex√£o direta entre o MSE e a norma-2, o que implica que o MSE minimiza a soma dos quadrados dos erros. Essa caracter√≠stica faz com que o MSE penalize erros maiores mais severamente do que erros menores.

**Lema 3.1.1:** O MSE √© n√£o-negativo.

**Prova:**
I. O MSE √© definido como a m√©dia dos quadrados dos erros de previs√£o: $\text{MSE} = \frac{\sum (y_t - \hat{y}_t)^2}{n}$, onde $y_t$ √© a demanda real e $\hat{y}_t$ √© a previs√£o.
II.  O quadrado de qualquer n√∫mero real √© sempre n√£o-negativo: $(y_t - \hat{y}_t)^2 \geq 0$ para todo $t$.
III. A soma de n√∫meros n√£o-negativos √© tamb√©m n√£o-negativa: $\sum (y_t - \hat{y}_t)^2 \geq 0$.
IV. Dividindo uma soma n√£o-negativa pelo n√∫mero de per√≠odos $n$, que √© um n√∫mero positivo, resulta num valor n√£o-negativo: $\frac{\sum (y_t - \hat{y}_t)^2}{n} \geq 0$.
V.  Portanto, o MSE √© sempre n√£o-negativo. $\blacksquare$

#### Interpreta√ß√£o do MSE
Valores menores de MSE indicam que as previs√µes est√£o mais pr√≥ximas da demanda real, sugerindo maior precis√£o do modelo. Por outro lado, valores mais altos de MSE indicam que as previs√µes est√£o mais distantes da demanda real, implicando menor precis√£o [^12]. O MSE penaliza erros maiores de forma mais significativa do que erros menores, o que pode ser √∫til quando grandes erros de previs√£o s√£o mais dispendiosos ou t√™m consequ√™ncias graves [^12]. O MSE √© expresso em unidades ao quadrado, o que pode dificultar sua interpreta√ß√£o em termos de magnitude do erro em compara√ß√£o ao MAD, o que torna sua interpreta√ß√£o menos intuitiva que a do MAD.

#### C√°lculo do MSE
Para calcular o MSE, √© necess√°rio:
1. Calcular o erro de previs√£o para cada per√≠odo: Subtrair a previs√£o da demanda real para cada per√≠odo na s√©rie temporal.
2. Elevar ao quadrado cada erro: Elevar ao quadrado os erros para que todos se tornem valores positivos.
3. Calcular a m√©dia desses valores ao quadrado: Somar todos os erros ao quadrado e dividir pelo n√∫mero total de per√≠odos considerados.

> üí° **Exemplo Num√©rico:**
> Consideremos uma s√©rie temporal de demanda e suas respectivas previs√µes:
>
> | Per√≠odo | Demanda Real ($y_t$) | Previs√£o ($\hat{y}_t$) |
> |---|---|---|
> | 1 | 100 | 110 |
> | 2 | 120 | 115 |
> | 3 | 130 | 125 |
> | 4 | 150 | 140 |
> | 5 | 160 | 155 |
>
> $\text{Step 1: Calcular os erros de previs√£o: }$
>
> $100-110 = -10$
> $120-115 = 5$
> $130-125 = 5$
> $150-140 = 10$
> $160-155 = 5$
>
> $\text{Step 2: Calcular o quadrado dos erros: }$
>
> $(-10)^2 = 100$
> $(5)^2 = 25$
> $(5)^2 = 25$
> $(10)^2 = 100$
> $(5)^2 = 25$
>
> $\text{Step 3: Calcular a m√©dia dos quadrados dos erros: }$
>
> $\text{MSE} = \frac{100 + 25 + 25 + 100 + 25}{5} = \frac{275}{5} = 55$
>
> Um MSE de 55 indica que a m√©dia dos quadrados dos erros de previs√£o √© de 55 unidades ao quadrado.
>
> ```python
> import numpy as np
>
> actual_demand = np.array([100, 120, 130, 150, 160])
> forecast = np.array([110, 115, 125, 140, 155])
>
> errors = actual_demand - forecast
> squared_errors = errors ** 2
> mse = np.mean(squared_errors)
> print(f"MSE: {mse}")
> ```

> üí° **Exemplo Num√©rico:**
> Suponha que estejamos analisando a demanda di√°ria de um produto em um pequeno varejo. As vendas reais nos √∫ltimos 7 dias e as previs√µes do modelo s√£o dadas na tabela abaixo:
>
> | Dia | Demanda Real | Previs√£o |
> |-----|--------------|----------|
> | 1   | 25           | 28       |
> | 2   | 30           | 27       |
> | 3   | 22           | 24       |
> | 4   | 28           | 31       |
> | 5   | 35           | 32       |
> | 6   | 29           | 26       |
> | 7   | 32           | 30       |
>
> $\text{Step 1: Calcular os erros de previs√£o: }$
>
> $25-28 = -3$
> $30-27 = 3$
> $22-24 = -2$
> $28-31 = -3$
> $35-32 = 3$
> $29-26 = 3$
> $32-30 = 2$
>
> $\text{Step 2: Calcular o quadrado dos erros: }$
>
> $(-3)^2 = 9$
> $(3)^2 = 9$
> $(-2)^2 = 4$
> $(-3)^2 = 9$
> $(3)^2 = 9$
> $(3)^2 = 9$
> $(2)^2 = 4$
>
> $\text{Step 3: Calcular a m√©dia dos erros ao quadrado: }$
>
> $\text{MSE} = \frac{9 + 9 + 4 + 9 + 9 + 9 + 4}{7} = \frac{53}{7} \approx 7.57$
>
>  O MSE √© aproximadamente 7.57, o que indica a m√©dia dos quadrados dos erros de previs√£o.
>
> ```python
> import numpy as np
>
> actual_demand = np.array([25, 30, 22, 28, 35, 29, 32])
> forecast = np.array([28, 27, 24, 31, 32, 26, 30])
>
> errors = actual_demand - forecast
> squared_errors = errors ** 2
> mse = np.mean(squared_errors)
> print(f"MSE: {mse}")
> ```
>
> Em termos pr√°ticos, um MSE de 7.57 significa que, em m√©dia, os erros de previs√£o ao quadrado s√£o de aproximadamente 7.57 unidades. Isso implica que o modelo tem um certo grau de imprecis√£o nas suas previs√µes, e em m√©dia a dist√¢ncia entre os valores previstos e reais √© de  aproximadamente $\sqrt{7.57} \approx 2.75$ unidades.

#### Compara√ß√£o com outras m√©tricas de erro
Enquanto o MSE enfatiza a magnitude dos erros, outras m√©tricas como o Desvio Absoluto M√©dio (MAD) e o Erro Percentual Absoluto M√©dio (MAPE) tamb√©m s√£o utilizadas para avaliar a precis√£o da previs√£o [^10, 12]. O MAD calcula a m√©dia dos erros absolutos, enquanto o MSE eleva os erros ao quadrado, dando mais peso aos erros maiores, o que pode ser √∫til em situa√ß√µes em que grandes erros podem ser dispendiosos [^10, 12]. O MAPE expressa o erro como uma porcentagem da demanda real, sendo √∫til quando se quer avaliar a precis√£o da previs√£o em termos relativos [^12]. A Raiz do Erro Quadr√°tico M√©dio (RMSE) √© a raiz quadrada do MSE, o que traz o erro de volta √† mesma unidade dos dados originais, facilitando sua interpreta√ß√£o e permitindo avaliar a magnitude do erro em termos absolutos. O Erro M√©dio Absoluto Escalonado (MASE) √© √∫til para comparar o modelo com um modelo naive, e resolve problemas quando a demanda √© pr√≥xima de zero. Uma an√°lise abrangente, portanto, deve considerar o uso de diversas m√©tricas de erro.

**Lema 3.1:** O MSE √© mais sens√≠vel a *outliers* (valores discrepantes) do que o MAD.

**Prova:**
I. O MSE √© dado por $\text{MSE} = \frac{\sum (y_t - \hat{y}_t)^2}{n}$, enquanto o MAD √© dado por $\text{MAD} = \frac{\sum |y_t - \hat{y}_t|}{n}$, onde $y_t$ √© a demanda real e $\hat{y}_t$ √© a previs√£o.

II.  Se um ponto de dados √© um *outlier* (ou seja, o erro $e_t = y_t - \hat{y}_t$ √© um valor at√≠pico), o MSE eleva este erro ao quadrado, tornando o impacto do *outlier* no MSE ainda maior, j√° que $(y_t - \hat{y}_t)^2 > |y_t - \hat{y}_t|$.

III. O MAD usa o valor absoluto dos erros, o que significa que o impacto de um *outlier* √© linear no MAD, e n√£o quadr√°tico.

IV. Portanto, o MSE √© mais sens√≠vel a outliers do que o MAD, o que significa que o MSE ser√° afetado de forma mais significativa do que o MAD quando houver valores discrepantes no conjunto de dados. $\blacksquare$

**Teorema 3.1:** O MSE √© igual ao MAD ao quadrado apenas quando todos os erros de previs√£o s√£o iguais a 0 ou 1.

**Prova:**
I.  O MSE √© definido como $\text{MSE} = \frac{\sum e_i^2}{n}$ e o MAD como $\text{MAD} = \frac{\sum |e_i|}{n}$, onde $e_i$ s√£o os erros de previs√£o.

II.  A condi√ß√£o para que o MSE seja igual ao MAD ao quadrado √© $\text{MSE} = \text{MAD}^2$. Ou seja, $\frac{\sum e_i^2}{n} = \left( \frac{\sum |e_i|}{n} \right)^2$.

III.  Multiplicando ambos os lados por $n^2$, temos $n\sum e_i^2 = (\sum |e_i|)^2$.

IV. Pela desigualdade de Cauchy-Schwarz,  $(\sum |e_i|)^2 \leq n \sum e_i^2$, e a igualdade s√≥ ocorre quando $|e_1|=|e_2|=\dots=|e_n|$.

V.  Substituindo a igualdade, a condi√ß√£o $\text{MSE} = \text{MAD}^2$ implica em $\sum e_i^2 = \sum |e_i|^2 = \frac{1}{n}(\sum |e_i|)^2 $.

VI. Se  todos os erros forem 0, $\text{MSE} = \text{MAD} = 0$, e a condi√ß√£o √© satisfeita. Se todos os erros forem 1, $\text{MSE} = \text{MAD} = 1$, e a condi√ß√£o tamb√©m √© satisfeita.

VII. Se os erros n√£o forem todos 0 ou 1, a igualdade n√£o √© satisfeita, demonstrando que a igualdade ocorre apenas nesses casos espec√≠ficos. $\blacksquare$

**Teorema 3.2:** O MSE pode ser decomposto na soma da vari√¢ncia do erro de previs√£o e o quadrado do vi√©s da previs√£o.

**Prova:**
I. Seja $Y$ a vari√°vel aleat√≥ria representando a demanda real e $\hat{Y}$ a vari√°vel aleat√≥ria representando a previs√£o. O erro de previs√£o √© dado por $e = Y - \hat{Y}$.
II.  O MSE pode ser expresso como o valor esperado do quadrado do erro de previs√£o: $\text{MSE} = E[(Y - \hat{Y})^2]$.
III.  Adicionando e subtraindo o valor esperado da previs√£o $E[\hat{Y}]$, temos:
    $E[(Y - \hat{Y})^2] = E[(Y - E[\hat{Y}] + E[\hat{Y}] - \hat{Y})^2] = E[((Y - E[\hat{Y}]) - (\hat{Y} - E[\hat{Y}]))^2]$.
IV. Expandindo o quadrado:
$E[(Y - E[\hat{Y}])^2 - 2(Y - E[\hat{Y}])(\hat{Y} - E[\hat{Y}]) + (\hat{Y} - E[\hat{Y}])^2]$.
V.  Assumindo que $Y$ e $\hat{Y}$ s√£o independentes, $E[(Y - E[\hat{Y}])(\hat{Y} - E[\hat{Y}])] = 0$.

VI. Separando os termos:
$E[(Y - E[\hat{Y}])^2] - 2E[(Y - E[\hat{Y}])(\hat{Y} - E[\hat{Y}])] + E[(\hat{Y} - E[\hat{Y}])^2] = E[(Y - E[\hat{Y}])^2] + E[(\hat{Y} - E[\hat{Y}])^2]$.

VII. Temos que $E[(Y - E[\hat{Y}])^2]$ √© a vari√¢ncia do erro da previs√£o, e $E[(\hat{Y} - E[\hat{Y}])^2]$ √© o quadrado do vi√©s, logo:
  $\text{MSE} = \text{Var}(Y - \hat{Y}) + (E[\hat{Y}] - E[Y])^2$

VIII. Portanto,  o MSE √© igual √† soma da vari√¢ncia do erro de previs√£o e o quadrado do vi√©s. $\blacksquare$

> üí° **Exemplo Num√©rico:**
> Para ilustrar a decomposi√ß√£o do MSE em vari√¢ncia e vi√©s, vamos considerar um modelo de previs√£o simples.
>
> Suponha que a demanda real ($Y$) siga uma distribui√ß√£o normal com m√©dia $\mu_Y = 100$ e desvio padr√£o $\sigma_Y = 10$, ou seja, $Y \sim N(100, 10^2)$.
>
> Consideremos dois modelos de previs√£o:
>
> Modelo A: $\hat{Y}_A = 0.8Y + 10$, onde as previs√µes tem vi√©s e vari√¢ncia
> Modelo B: $\hat{Y}_B = 1.0Y$ onde as previs√µes tem vari√¢ncia, mas pouco vi√©s
>
> Calculando os valores esperados:
>
> $E[\hat{Y}_A] = 0.8E[Y] + 10 = 0.8 \times 100 + 10 = 90$
>
> $E[\hat{Y}_B] = 1.0 E[Y] = 100$
>
> Calculando os vi√©ses:
>
> $Bias_A = E[\hat{Y}_A] - E[Y] = 90 - 100 = -10$
> $Bias_B = E[\hat{Y}_B] - E[Y] = 100 - 100 = 0$
>
> Calculando as vari√¢ncias:
> $Var(\hat{Y}_A) = Var(0.8Y + 10) = 0.8^2 Var(Y) = 0.64 \times 10^2= 64$
> $Var(\hat{Y}_B) = Var(Y) = 10^2 = 100$
>
> Vamos simular 1000 amostras usando `numpy` e calcular o MSE dos dois modelos
>
> ```python
> import numpy as np
>
> np.random.seed(42) # Para reprodutibilidade
>
> num_samples = 1000
>
> # Simula a demanda real
> Y = np.random.normal(loc=100, scale=10, size=num_samples)
>
> # Gera as previs√µes do Modelo A e B
> Y_hat_A = 0.8 * Y + 10
> Y_hat_B = 1.0 * Y
>
> # Calcula o MSE para ambos os modelos
> mse_A = np.mean((Y - Y_hat_A) ** 2)
> mse_B = np.mean((Y - Y_hat_B) ** 2)
>
> # Calcula o vi√©s e a vari√¢ncia
> bias_A = np.mean(Y_hat_A) - np.mean(Y)
> var_error_A = np.var(Y - Y_hat_A)
> bias_B = np.mean(Y_hat_B) - np.mean(Y)
> var_error_B = np.var(Y - Y_hat_B)
>
> print(f"MSE Modelo A: {mse_A:.2f}")
> print(f"Vi√©s Modelo A: {bias_A:.2f}")
> print(f"Vari√¢ncia do Erro Modelo A: {var_error_A:.2f}")
> print(f"MSE Modelo B: {mse_B:.2f}")
> print(f"Vi√©s Modelo B: {bias_B:.2f}")
> print(f"Vari√¢ncia do Erro Modelo B: {var_error_B:.2f}")
>
> # Verifica a decomposi√ß√£o do MSE:
> mse_A_decomposed = var_error_A + bias_A**2
> mse_B_decomposed = var_error_B + bias_B**2
>
> print(f"MSE Modelo A (decomposto): {mse_A_decomposed:.2f}")
> print(f"MSE Modelo B (decomposto): {mse_B_decomposed:.2f}")
>
> ```
>
> No modelo A o MSE √© dado por:
>
> $\text{MSE}_A = \text{Var}(Y - \hat{Y}_A) + (E[\hat{Y}_A] - E[Y])^2 = 64 + (-10)^2 = 64 + 100 = 164$
>
> No modelo B o MSE √© dado por:
>
>  $\text{MSE}_B = \text{Var}(Y - \hat{Y}_B) + (E[\hat{Y}_B] - E[Y])^2 = 100 + (0)^2 = 100$
>
> O modelo B tem um MSE menor, pois n√£o apresenta vi√©s e tem uma vari√¢ncia menor.
>
> Este exemplo demonstra como o MSE pode ser decomposto em vi√©s e vari√¢ncia, ajudando a entender a natureza dos erros do modelo.

**Corol√°rio 3.1:** Minimizar o MSE implica em minimizar tanto a vari√¢ncia quanto o vi√©s das previs√µes.

**Prova:**
I. Pelo Teorema 3.2, o MSE √© dado por  $\text{MSE} = \text{Var}(Y - \hat{Y}) + (E[\hat{Y}] - E[Y])^2$.

II. O MSE √© uma soma de dois termos n√£o-negativos: a vari√¢ncia do erro e o quadrado do vi√©s.

III. Para minimizar o MSE, √© necess√°rio minimizar cada termo da soma.

IV. Minimizar a vari√¢ncia do erro significa reduzir a dispers√£o dos erros de previs√£o em rela√ß√£o √† sua m√©dia, tornando as previs√µes mais consistentes.

V. Minimizar o vi√©s significa tornar a m√©dia das previs√µes mais pr√≥xima da m√©dia dos valores reais, garantindo que as previs√µes n√£o sejam sistematicamente subestimadas ou superestimadas.

VI.  Portanto, minimizar o MSE implica em simultaneamente minimizar a vari√¢ncia e o vi√©s da previs√£o. $\blacksquare$

### Conclus√£o
O Erro Quadr√°tico M√©dio (MSE) √© uma m√©trica essencial na avalia√ß√£o da precis√£o de previs√µes em s√©ries temporais. Sua capacidade de penalizar erros maiores o torna particularmente √∫til em situa√ß√µes onde grandes erros s√£o mais dispendiosos [^12]. Ao comparar o MSE com o MAD, o RMSE, o MAPE, e o MASE, √© poss√≠vel obter uma compreens√£o mais abrangente do desempenho de um modelo preditivo. A sele√ß√£o da m√©trica apropriada deve ser baseada no contexto do problema, com cada m√©trica fornecendo uma perspectiva √∫nica sobre a precis√£o da previs√£o. Em √∫ltima an√°lise, a capacidade de avaliar a precis√£o da previs√£o √© essencial para escolher o melhor modelo e, consequentemente, aprimorar o processo de tomada de decis√µes e o planejamento e aloca√ß√£o de recursos [^23].

### Refer√™ncias
[^5]: *Time series models assume that past demand data are representative of future demand.*
[^9]: *Forecast error = Actual demand - Forecast.*
[^10]: *Because a forecast predicts future demand, we cannot compare it to actual demand. However, because we have assumed that historical demand is representative of future demand, we can formulate "forecasts of the past" using a particular model and compare those forecasts to historical demand.*
[^12]: *With both the MAD and MSE, the size of the deviations depends on the volume of the item being forecast. For example, if the demand is in thousands of units, the absolute and squared deviations could be quite large. The mean absolute percentage error (MAPE) remedies this problem by expressing the deviation as a percentage of the actual demand.*
[^23]: *Forecasting demand is important to be able to plan and allocate the resources necessary to provide uninterrupted, quality customer service and avoid the excess costs arising from mismatched demand and supply.*
<!-- END -->
