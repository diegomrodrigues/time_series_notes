## Erro Quadr√°tico M√©dio (MSE) na An√°lise de Previs√£o

### Introdu√ß√£o
Este cap√≠tulo aprofunda a discuss√£o sobre m√©tricas de avalia√ß√£o de precis√£o de previs√£o, focando no Erro Quadr√°tico M√©dio (MSE) [^1]. Como vimos, o erro de previs√£o √© inerente ao processo, e medir sua magnitude √© essencial para selecionar modelos adequados e tomar decis√µes informadas [^6]. O MSE, ao contr√°rio do Desvio M√©dio Absoluto (MAD), que trata todos os erros de forma igual, penaliza os erros maiores de forma mais acentuada. Esta caracter√≠stica torna o MSE particularmente √∫til em cen√°rios onde as consequ√™ncias de erros grandes s√£o significativamente mais graves do que as de erros pequenos [^6]. Este cap√≠tulo explorar√° em detalhes o MSE, incluindo sua defini√ß√£o, c√°lculo, propriedades, rela√ß√£o com outras m√©tricas e aplica√ß√µes pr√°ticas em modelos de s√©ries temporais.

### Conceitos Fundamentais
O **Erro Quadr√°tico M√©dio (MSE)** √© uma m√©trica que quantifica a m√©dia dos quadrados dos erros de previs√£o. A f√≥rmula para calcular o MSE √© a seguinte [^6]:
$$
MSE = \frac{\sum{(\text{Demanda Real} - \text{Previs√£o})^2}}{n}
$$
Onde:
*   $(\text{Demanda Real} - \text{Previs√£o})^2$ representa o quadrado do erro de previs√£o em cada per√≠odo.
*   $n$ √© o n√∫mero total de per√≠odos considerados no c√°lculo.

**Observa√ß√£o 8:** O MSE √© expresso nas unidades da demanda ao quadrado, o que pode dificultar sua interpreta√ß√£o direta. No entanto, o MSE se destaca por sua capacidade de penalizar erros maiores, tornando-o prefer√≠vel quando grandes erros s√£o cr√≠ticos [^6].

#### Rela√ß√£o do MSE com a Norma-2
Matematicamente, o MSE est√° relacionado √† **norma-2** (ou norma euclidiana) do vetor de erros de previs√£o. A norma-2 de um vetor $\mathbf{x}$ √© definida como:
$$ ||\mathbf{x}||_2 = \sqrt{\sum_{i=1}^{n} x_i^2} $$
No contexto do MSE, o vetor $\mathbf{x}$ √© o vetor de erros de previs√£o, onde cada elemento $x_i$ representa a diferen√ßa entre a demanda real e a previs√£o para o per√≠odo *i*. Portanto, a soma dos quadrados dos erros no MSE √© equivalente ao quadrado da norma-2 do vetor de erros. Dividindo pelo n√∫mero de per√≠odos e desconsiderando a raiz, obt√©m-se o MSE.

**Teorema 4:** O MSE √© uma medida da magnitude m√©dia dos erros de previs√£o, expressa como a norma-2 ao quadrado do vetor de erros de previs√£o dividida pelo n√∫mero de per√≠odos.
*Prova:*
I.   A norma-2 de um vetor √© a raiz quadrada da soma dos quadrados dos seus elementos.
II.  No contexto da previs√£o, os elementos do vetor s√£o os erros de previs√£o $ e_i = \text{Demanda Real}_i - \text{Previs√£o}_i $.
III. Portanto, a norma-2 do vetor de erros de previs√£o √©:
$$ ||\mathbf{e}||_2 = \sqrt{\sum_{i=1}^{n} e_i^2} = \sqrt{\sum_{i=1}^{n} (\text{Demanda Real}_i - \text{Previs√£o}_i)^2} $$
IV. O MSE √© dado por:
$$
MSE = \frac{\sum_{i=1}^{n} (\text{Demanda Real}_i - \text{Previs√£o}_i)^2}{n} = \frac{||\mathbf{e}||_2^2}{n}
$$
V. Logo, o MSE √© o quadrado da norma-2 dos erros de previs√£o dividida pelo n√∫mero de per√≠odos. ‚ñ†

**Proposi√ß√£o 2:** A norma-2, e consequentemente o MSE, √© estritamente convexa, o que garante que existe um √∫nico m√≠nimo global em processos de otimiza√ß√£o.
*Prova:*
I. A norma-2 de um vetor √© a raiz quadrada da soma dos quadrados dos seus elementos.
II. Uma fun√ß√£o *f* √© estritamente convexa se, para quaisquer pontos distintos $\mathbf{x}$ e $\mathbf{y}$, e para todo escalar $\lambda$ entre 0 e 1, temos:
$$f(\lambda\mathbf{x} + (1-\lambda)\mathbf{y}) < \lambda f(\mathbf{x}) + (1-\lambda) f(\mathbf{y})$$
III. A norma-2 ao quadrado, $f(\mathbf{x}) = ||\mathbf{x}||_2^2 = \sum_{i=1}^n x_i^2$ √© uma fun√ß√£o estritamente convexa.
IV. Para provar isso, considere dois vetores distintos $\mathbf{x}$ e $\mathbf{y}$ e um escalar $\lambda \in (0, 1)$. A fun√ß√£o objetivo para otimizar o erro quadr√°tico √©:
$$f(\lambda\mathbf{x} + (1-\lambda)\mathbf{y}) = ||\lambda\mathbf{x} + (1-\lambda)\mathbf{y}||_2^2 = \sum_{i=1}^n (\lambda x_i + (1-\lambda) y_i)^2$$
V. Expandindo e reorganizando, obtemos:
$$f(\lambda\mathbf{x} + (1-\lambda)\mathbf{y}) = \lambda^2 \sum_i x_i^2 + 2\lambda(1-\lambda)\sum_i x_i y_i + (1-\lambda)^2 \sum_i y_i^2 $$
VI. Sabemos que para vetores distintos,  $\sum_i x_i y_i < ||\mathbf{x}||_2 ||\mathbf{y}||_2$, a menos que os vetores sejam paralelos. Portanto, podemos dizer que $ \sum_i x_i y_i < \sqrt{\sum_i x_i^2} \sqrt{\sum_i y_i^2}$, e temos:
$$f(\lambda\mathbf{x} + (1-\lambda)\mathbf{y}) < \lambda^2 \sum_i x_i^2 + 2\lambda(1-\lambda) \sqrt{\sum_i x_i^2} \sqrt{\sum_i y_i^2} + (1-\lambda)^2 \sum_i y_i^2$$
VII. A express√£o $\left(\lambda \sqrt{\sum_i x_i^2} + (1-\lambda)\sqrt{\sum_i y_i^2}\right)^2$  √© um termo maior do que $f(\lambda\mathbf{x} + (1-\lambda)\mathbf{y})$.
VIII. A propriedade de convexidade da fun√ß√£o do MSE garante que a fun√ß√£o do MSE possui apenas um m√≠nimo global, que pode ser encontrado por algoritmos de otimiza√ß√£o.

**Lema 2.1:** A estrita convexidade do MSE implica que qualquer algoritmo de otimiza√ß√£o que garanta converg√™ncia para um m√≠nimo local, tamb√©m garante converg√™ncia para o m√≠nimo global.
*Prova:*
I. A estrita convexidade de uma fun√ß√£o garante que existe um √∫nico m√≠nimo global.
II. Se um algoritmo de otimiza√ß√£o converge para um m√≠nimo local, e a fun√ß√£o √© estritamente convexa, ent√£o o m√≠nimo local √© o m√≠nimo global.
III. Portanto, se um algoritmo de otimiza√ß√£o garante convergir para um m√≠nimo local do MSE, ent√£o ele tamb√©m converge para o √∫nico m√≠nimo global do MSE. ‚ñ†

### Propriedades do MSE
*   **Sensibilidade a Outliers:** O MSE √© mais sens√≠vel a outliers do que o MAD, pois eleva os erros ao quadrado [^6]. Isso significa que erros de previs√£o muito grandes ter√£o um impacto desproporcionalmente maior no MSE do que erros pequenos.
*   **Unidades:** O MSE √© expresso nas unidades da demanda ao quadrado, o que dificulta sua interpreta√ß√£o direta.
*   **Penaliza√ß√£o de Erros Maiores:** O MSE penaliza erros maiores de forma mais acentuada, o que √© √∫til quando grandes erros s√£o mais custosos ou t√™m consequ√™ncias mais graves.

#### MSE vs. MAD vs. MAPE
Como j√° discutido [^6], MAD, MSE e MAPE s√£o m√©tricas que avaliam a acur√°cia de previs√£o de maneiras distintas:
*   **MAD:** Mede a magnitude m√©dia dos erros de previs√£o em unidades absolutas. √â menos sens√≠vel a outliers.
*   **MSE:** Mede a m√©dia dos quadrados dos erros de previs√£o, penalizando erros maiores de forma mais acentuada.
*   **MAPE:** Expressa o erro de previs√£o como um percentual da demanda real, sendo √∫til para comparar modelos em diferentes escalas, mas pode ser inst√°vel quando a demanda √© pr√≥xima de zero.

A tabela abaixo resume as principais diferen√ßas entre MAD, MSE e MAPE:

| Caracter√≠stica | MAD | MSE | MAPE |
|----------------|------|-----|------|
| C√°lculo | M√©dia dos valores absolutos dos erros | M√©dia dos quadrados dos erros | M√©dia dos erros percentuais absolutos |
| Unidades | Unidades da demanda | Unidades da demanda¬≤ | Percentual |
| Sensibilidade a Outliers | Baixa | Alta | Moderada (inst√°vel se demanda real ‚âà 0) |
| Penaliza√ß√£o de Erros Maiores | N√£o | Sim | N√£o |
| Interpreta√ß√£o | Magnitude m√©dia dos erros | Magnitude m√©dia dos erros (com penaliza√ß√£o para erros maiores) | Magnitude m√©dia dos erros como percentual da demanda real |
| Aplica√ß√£o | Vis√£o geral da escala dos erros | Penalizar grandes erros | Comparar modelos em diferentes escalas e contextos |

**Lema 3:** A escolha entre MAD, MSE ou MAPE depende do contexto do problema.
*Prova:*
I.  O MAD fornece uma medida da magnitude geral dos erros de previs√£o, sem distinguir erros grandes e pequenos.
II. O MSE √© prefer√≠vel quando grandes erros t√™m um impacto desproporcionalmente maior, penalizando esses erros de forma mais acentuada.
III. O MAPE √© uma m√©trica √∫til quando a demanda tem diferentes escalas, mas deve ser usado com cautela se os valores de demanda s√£o pr√≥ximos de zero, pois pode se tornar inst√°vel.
IV.  A sele√ß√£o da m√©trica adequada depende do contexto e dos objetivos da previs√£o, devendo considerar as especificidades do problema e as consequ√™ncias dos diferentes tipos de erro. ‚ñ†

**Teorema 4.1:** O MSE e o MAD s√£o m√©tricas que n√£o podem ser diretamente comparadas, dado que um n√£o √© um m√∫ltiplo fixo do outro, e eles medem diferentes aspectos da performance do modelo.
*Prova:*
I. A m√©trica MAD √© calculada como a m√©dia dos erros absolutos: $MAD = \frac{1}{n} \sum |e_i|$, enquanto o MSE √© a m√©dia dos erros quadrados: $MSE = \frac{1}{n} \sum e_i^2$, onde $e_i$ s√£o os erros em cada per√≠odo *i*.
II. A fun√ß√£o de valor absoluto, $|e_i|$ usada no c√°lculo do MAD, √© uma fun√ß√£o n√£o linear.
III. A fun√ß√£o $e_i^2$ √© uma fun√ß√£o n√£o linear que atribui pesos maiores a erros maiores.
IV. Dado que $|e_i|$ e $e_i^2$ s√£o fun√ß√µes n√£o lineares, em geral $\frac{\sum |e_i|}{n}$ e $\frac{\sum e_i^2}{n}$ n√£o s√£o m√∫ltiplos fixos um do outro, pois s√£o fun√ß√µes n√£o lineares diferentes dos erros e n√£o s√£o comutativas com a opera√ß√£o de m√©dia.
V. A rela√ß√£o entre MAD e MSE depende dos erros, e n√£o √© geral.
VI. Portanto, n√£o existe uma rela√ß√£o direta que permita comparar o MSE com o MAD, e cada m√©trica deve ser utilizada quando apropriada. ‚ñ†

**Lema 4.2:**  Embora o MSE e o MAD n√£o sejam diretamente compar√°veis, em algumas situa√ß√µes espec√≠ficas, podemos ter rela√ß√µes de desigualdade entre eles. Por exemplo, se todos os erros forem iguais, ent√£o $MSE = MAD^2$.
*Prova:*
I. Seja $e_i$ o erro no per√≠odo *i*. Ent√£o $MAD = \frac{1}{n}\sum_{i=1}^n |e_i|$ e $MSE = \frac{1}{n}\sum_{i=1}^n e_i^2$.
II. Se todos os erros t√™m a mesma magnitude, ou seja, $|e_i| = |e|$ para todo *i*, ent√£o $MAD = \frac{1}{n} \sum_{i=1}^n |e| = |e|$.
III. Nesse caso, $MSE = \frac{1}{n}\sum_{i=1}^n e^2 = e^2$.
IV.  Logo, se os erros tem magnitude constante, temos a rela√ß√£o $MSE = MAD^2$.
V. No entanto, esta rela√ß√£o n√£o se mant√©m quando os erros t√™m diferentes magnitudes, o que refor√ßa a necessidade de avaliar cada m√©trica em seu contexto. ‚ñ†

### C√°lculo do MSE em Modelos de Previs√£o
O c√°lculo do MSE envolve os seguintes passos:
1.  **Calcular os erros de previs√£o:** Para cada per√≠odo, subtraia a previs√£o da demanda real.
2.  **Elevar os erros ao quadrado:** Eleve ao quadrado cada erro de previs√£o calculado no passo anterior.
3.  **Somar os quadrados dos erros:** Some todos os valores dos erros ao quadrado.
4.  **Dividir pela quantidade de per√≠odos:** Divida a soma dos quadrados dos erros pelo n√∫mero total de per√≠odos.

> üí° **Exemplo Num√©rico:** Usando os dados do exemplo anterior do cap√≠tulo de acur√°cia [^1]:
>
> | Per√≠odo | Demanda Real | Previs√£o | Erro | Erro¬≤|
> |---------|-------------|----------|------|------|
> | 1       | 1000        | 900      | 100  | 10000|
> | 2       | 1200        | 1150     | 50   | 2500 |
> | 3       | 1300        | 1350     | -50  | 2500 |
> | 4       | 1100        | 1200     | -100 | 10000|
> | 5       | 1250        | 1180     | 70   | 4900 |
>
> O MSE √© calculado como:
>
> $\text{MSE} = \frac{10000 + 2500 + 2500 + 10000 + 4900}{5} = \frac{29900}{5} = 5980$

> üí° **Exemplo Num√©rico:** Vamos considerar a previs√£o da demanda para um produto espec√≠fico e temos os seguintes dados para 7 per√≠odos:
>
> | Per√≠odo | Demanda Real | Previs√£o | Erro | Erro¬≤|
> |---------|-------------|----------|------|------|
> | 1       | 250         | 230      | 20   | 400  |
> | 2       | 280         | 270      | 10   | 100  |
> | 3       | 310         | 320      | -10  | 100  |
> | 4       | 290         | 285      | 5    | 25   |
> | 5       | 300         | 315      | -15  | 225  |
> | 6       | 320         | 310      | 10   | 100  |
> | 7       | 330         | 340      | -10  | 100  |
>
> Para calcular o MSE:
>
> 1.  **Erros:** Calculados como Demanda Real - Previs√£o (e.g. 250 - 230 = 20)
> 2. **Erros ao Quadrado:** Elevar cada erro ao quadrado (e.g. 20^2 = 400)
> 3. **Soma dos Erros ao Quadrado:** 400 + 100 + 100 + 25 + 225 + 100 + 100 = 1050
> 4. **MSE:** 1050 / 7 = 150
>
> O MSE para este conjunto de dados √© 150. Isso significa que, em m√©dia, o quadrado dos erros √© de 150. Note que essa m√©trica enfatiza os erros maiores.

#### MSE em Modelos de S√©ries Temporais
Em modelos de s√©ries temporais, o MSE √© usado para avaliar a precis√£o de modelos de previs√£o com base em dados hist√≥ricos. Ao comparar diferentes modelos, o modelo com o menor MSE √© geralmente considerado o mais adequado.
Como no MAD, o MSE pode ser utilizado para ajustar par√¢metros de modelos de previs√£o como SMA e WMA. Em modelos como o suaviza√ß√£o exponencial, um $ \alpha $ maior resulta em menor MSE quando as mudan√ßas na demanda s√£o mais r√°pidas.

**Corol√°rio 4.1:** O MSE √© uma m√©trica de avalia√ß√£o √∫til para modelos de previs√£o, especialmente quando grandes erros t√™m um custo desproporcionalmente maior, mas deve ser usado em conjunto com outras m√©tricas para uma avalia√ß√£o completa.
*Prova:*
I. O MSE penaliza erros maiores devido √† opera√ß√£o de quadratura, tornando-o √∫til em situa√ß√µes em que grandes erros s√£o mais custosos.
II. No entanto, apenas o MSE n√£o oferece uma vis√£o completa do desempenho do modelo.
III. Outras m√©tricas, como o MAD e o MAPE, podem fornecer informa√ß√µes complementares e devem ser usadas em conjunto para uma avalia√ß√£o abrangente do modelo de previs√£o. ‚ñ†

**Proposi√ß√£o 4.2:** Em modelos de s√©ries temporais, a minimiza√ß√£o do MSE pode ser usada para otimizar os par√¢metros do modelo, como a constante de suaviza√ß√£o no suaviza√ß√£o exponencial ou os pesos em um modelo de m√©dia m√≥vel ponderada.
*Prova:*
I. O MSE √© uma fun√ß√£o dos erros de previs√£o.
II. Os erros de previs√£o dependem dos par√¢metros do modelo.
III. Portanto, o MSE √© uma fun√ß√£o dos par√¢metros do modelo.
IV. Minimizar o MSE em rela√ß√£o aos par√¢metros do modelo nos permite encontrar os valores √≥timos que resultam no menor erro quadr√°tico m√©dio.
V. Essa otimiza√ß√£o √© geralmente feita atrav√©s de algoritmos iterativos que ajustam os par√¢metros do modelo. ‚ñ†

### Aplica√ß√µes do MSE
O MSE tem diversas aplica√ß√µes pr√°ticas, incluindo:
*   **Sele√ß√£o de Modelos de Previs√£o:** O MSE pode ser usado para comparar a precis√£o de diferentes modelos, selecionando aquele que minimiza o erro quadr√°tico m√©dio.
*   **Ajuste de Par√¢metros de Modelos:** Modelos de previs√£o, como o suaviza√ß√£o exponencial ou redes neurais, podem ter seus par√¢metros ajustados utilizando t√©cnicas de otimiza√ß√£o para minimizar o MSE.
*   **Avalia√ß√£o de Risco:** Em aplica√ß√µes financeiras e de seguros, o MSE pode ser usado para avaliar o risco de modelos de previs√£o, dado que ele penaliza grandes erros, que podem causar perdas financeiras significativas.
*   **Monitoramento da Precis√£o:** Ao longo do tempo, o MSE pode monitorar a precis√£o dos modelos, identificando se o desempenho do modelo est√° diminuindo, e sinalizando a necessidade de revis√£o e ajuste.

> üí° **Exemplo Num√©rico:**  Compara√ß√£o de dois modelos de previs√£o utilizando o MSE.  Com os mesmos dados de demanda real e previs√µes dos modelos A e B do exemplo anterior do MAD, vamos calcular o MSE:
>
> | Per√≠odo | Demanda Real | Previs√£o (Modelo A) | Erro (A) | Erro¬≤(A)| Previs√£o (Modelo B) | Erro (B) | Erro¬≤(B)|
> |---------|-------------|-------------------|----------|---------|-------------------|----------|---------|
> | 1       | 250         | 240               | 10       | 100     | 220               | 30       | 900     |
> | 2       | 280         | 275               | 5        | 25      | 260               | 20       | 400     |
> | 3       | 310         | 315               | -5       | 25      | 300               | 10       | 100     |
> | 4       | 290         | 295               | -5       | 25      | 270               | 20       | 400     |
> | 5       | 300         | 305               | -5       | 25      | 320               | -20      | 400     |
> | 6       | 320         | 310               | 10       | 100     | 300               | 20       | 400     |
> | 7       | 330         | 325               | 5        | 25      | 330               | 0        | 0       |
>
> **C√°lculo do MSE para o Modelo A:**
> 1. Soma dos Erros ao Quadrado: 100+25+25+25+25+100+25 = 325
> 2. MSE (Modelo A): 325 / 7 = 46.43
>
> **C√°lculo do MSE para o Modelo B:**
> 1. Soma dos Erros ao Quadrado: 900+400+100+400+400+400+0 = 2200
> 2. MSE (Modelo B): 2200/7 = 314.29
>
>  Nesse caso, o Modelo A tem um MSE significativamente menor do que o Modelo B (46.43 vs. 314.29), indicando que, de acordo com o MSE, o Modelo A √© melhor que o Modelo B.
>
> üí° **Exemplo Num√©rico:** Vamos considerar a aplica√ß√£o do MSE no contexto de ajuste de par√¢metros de um modelo de suaviza√ß√£o exponencial simples. Suponha que temos os seguintes dados de demanda para os √∫ltimos 5 per√≠odos: 100, 110, 125, 120, e 135. Queremos encontrar o valor ideal para o par√¢metro de suaviza√ß√£o alfa (Œ±) que minimiza o MSE, considerando os valores de Œ± de 0.2, 0.5 e 0.8. A previs√£o para o per√≠odo 1 √© o valor de demanda do per√≠odo anterior, que vamos considerar 95.
>
> | Per√≠odo | Demanda Real | Previs√£o (Œ±=0.2) | Erro (0.2)| Erro¬≤ (0.2) | Previs√£o (Œ±=0.5) | Erro (0.5)| Erro¬≤ (0.5) | Previs√£o (Œ±=0.8) | Erro (0.8)| Erro¬≤ (0.8) |
> |---------|-------------|-----------------|-----------|-------------|-----------------|-----------|-------------|-----------------|-----------|-------------|
> | 1       | 100         | 95              | 5         | 25          | 95              | 5         | 25          | 95              | 5         | 25          |
> | 2       | 110         | 96              | 14        | 196         | 97.5            | 12.5      | 156.25      | 99              | 11        | 121         |
> | 3       | 125         | 98.8            | 26.2      | 686.44      | 103.75          | 21.25     | 451.56      | 107.8           | 17.2      | 295.84      |
> | 4       | 120         | 103.94          | 16.06     | 257.92      | 114.375         | 5.625     | 31.64       | 121.56          | -1.56     | 2.43        |
> | 5       | 135         | 107.15          | 27.85     | 775.62      | 117.1875        | 17.8125   | 317.28      | 122.31          | 12.69     | 161.03      |
>
> Onde a previs√£o para o per√≠odo $t$ √© calculada por $\text{Previs√£o}_t = \alpha \cdot \text{Demanda Real}_{t-1} + (1 - \alpha) \cdot \text{Previs√£o}_{t-1}$
>
>  Calculando os MSEs:
>
>  *   **MSE (Œ±=0.2):**  (25 + 196 + 686.44 + 257.92 + 775.62) / 5 = 388.20
>  *  **MSE (Œ±=0.5):** (25 + 156.25 + 451.56 + 31.64 + 317.28) / 5 = 196.35
>  *   **MSE (Œ±=0.8):** (25 + 121 + 295.84 + 2.43 + 161.03) / 5 = 121.06
>
>
>  O menor MSE ocorre quando Œ± = 0.8, o que sugere que esse valor do par√¢metro √© o que melhor se ajusta aos dados, dado o crit√©rio do MSE, neste caso, pois penaliza mais os erros maiores e se adapta mais rapidamente a mudan√ßas de tend√™ncia na demanda.

### Conclus√£o
O Erro Quadr√°tico M√©dio (MSE) √© uma m√©trica valiosa para avaliar a acur√°cia de modelos de previs√£o, especialmente quando grandes erros s√£o mais custosos. Sua propriedade de penalizar erros maiores de forma acentuada, o torna uma ferramenta poderosa em contextos de alto risco ou onde as consequ√™ncias de grandes desvios s√£o significativas [^6]. √â importante lembrar que, assim como o MAD e o MAPE, o MSE fornece apenas uma perspectiva da acur√°cia da previs√£o e deve ser utilizado em conjunto com outras m√©tricas para uma avalia√ß√£o abrangente da qualidade do modelo. Ao compreender os benef√≠cios e limita√ß√µes de cada m√©trica, os tomadores de decis√£o podem selecionar os modelos de previs√£o mais adequados e gerenciar seus recursos com maior efici√™ncia e confian√ßa.

### Refer√™ncias
[^1]: Cap√≠tulo anterior sobre acur√°cia de previs√£o e m√©tricas de avalia√ß√£o.
[^6]: Cap√≠tulo 3, Se√ß√£o sobre Acur√°cia da Previs√£o.
<!-- END -->
