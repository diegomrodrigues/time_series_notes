## A Distribuição Assintótica de ÎÎ e Erros Padrão em Modelos VAR: Uma Análise Detalhada

### Introdução
Neste capítulo, aprofundaremos nossa análise sobre a distribuição assintótica do estimador de máxima verossimilhança (**MLE**) para os coeficientes em modelos de vetores autorregressivos (**VAR**). Partindo dos fundamentos estabelecidos em seções anteriores, onde derivamos os estimadores **MLE** dos coeficientes **ÎÎ** [^1, ^2] e da matriz de covariância residual **Ω** [^2, ^3], agora investigamos em detalhes como a distribuição assintótica desses estimadores nos permite realizar inferências estatísticas. Especificamente, o foco estará na derivação de erros padrão, que são essenciais para a construção de testes de hipóteses e intervalos de confiança. Discutiremos como os resultados padrão da regressão de **mínimos quadrados ordinários (OLS)** se aplicam a esse contexto e como as propriedades assintóticas dos estimadores de OLS se estendem ao cenário multivariado dos modelos VAR.

### Distribuição Assintótica e Derivação dos Erros Padrão
Como já demonstrado, os estimadores **MLE** dos coeficientes de um modelo VAR, representados por **ÎÎ**, podem ser obtidos através de regressões de OLS de cada variável do sistema em relação a um termo constante e as defasagens de todas as variáveis [^2]. Formalmente, o estimador **ÎÎ** é dado por:

$$
\hat{\Pi}' = \left[ \sum_{t=1}^T y_t x_t' \right] \left[ \sum_{t=1}^T x_t x_t' \right]^{-1}
$$ [^2]

onde $y_t$ é um vetor $n \times 1$ das variáveis endógenas e $x_t$ é um vetor $(np+1) \times 1$ que contém um termo constante e $p$ defasagens de cada variável em $y_t$.

A *j*-ésima linha de **ÎÎ** contém os coeficientes da *j*-ésima equação do VAR. A distribuição condicional de $y_t$ é expressa como:

$$
y_t|y_{t-1}, y_{t-2}, \ldots, y_{t-p+1} \sim N(\Pi'x_t, \Omega)
$$[^1]

O ponto fundamental aqui é que, mesmo que as inovações no sistema não sigam uma distribuição normal, os estimadores **MLE** para os coeficientes **ÎÎ** são assintoticamente consistentes [^4]. A consistência assintótica é um conceito chave, pois nos permite inferir que, à medida que o tamanho da amostra aumenta, as estimativas convergem para os valores verdadeiros.

A Proposição 11.1 [^4] estabelece formalmente que, sob certas condições, a distribuição assintótica do estimador $\hat{\pi}_T$ (que é um vetor que contém as estimativas dos parâmetros) é dada por:

$$
\sqrt{T}(\hat{\pi}_T - \pi) \xrightarrow{d} N(0, (\Omega \otimes Q^{-1})),
$$

onde $\pi$ é o vetor de parâmetros populacionais, $\hat{\pi}_T$ é o vetor de estimadores,  $\Omega$ é a matriz de covariância das inovações e $Q$ é o limite da matriz de covariância amostral das regressoras $x_t$ [^4].

O resultado anterior tem uma consequência importante: sob certas condições, a distribuição assintótica de cada linha de **ÎÎ** é dada por:
$$
\sqrt{T}(\hat{\pi}_{i,T} - \pi_i) \xrightarrow{d} N(0, \sigma_i^2 Q^{-1})
$$[^4]
onde $\sigma_i^2$ é a variância do resíduo da *i*-ésima equação do modelo VAR.

Isso implica que os erros padrão dos coeficientes em uma regressão OLS para o modelo VAR são assintoticamente válidos e podem ser calculados utilizando a formulação padrão de OLS [^4]. Especificamente, a variância assintótica de um estimador de coeficiente OLS é dada por $s^2(X'X)^{-1}$, onde $s^2$ é um estimador consistente da variância residual [^4]. Nesse contexto, $s^2$ é um estimador para $\sigma_i^2$. Assim, o erro padrão de um coeficiente é dado por $\sigma_i \left[ \sum_{t=1}^T x_t x_t' \right]^{-1}$ [^4], e esta expressão deriva diretamente das fórmulas de OLS.

No entanto, é crucial observar que, apesar de $s^2$ ser assintoticamente equivalente a $\sigma_i^2$, seguir o argumento de Sims (1980) [^6] sugere que o uso dos erros padrão derivados das fórmulas de OLS é mais conservador (maiores), e portanto, preferível em certas aplicações [^4]. Assim, embora a distribuição subjacente das inovações possa não ser normal, as estatísticas $t$ e $F$ usadas em OLS ainda são válidas para inferência assintótica [^4].

### Cálculo da Matriz de Covariância e Erros Padrão
Para implementar a inferência estatística e computar os erros padrão dos coeficientes no modelo VAR, é crucial estimar a matriz de covariância dos resíduos e a matriz Q. Em um contexto VAR, cada equação é estimada por OLS, e para uma equação i-ésima, o estimador da variância residual, $s_i^2$, é dado por:

$$
s_i^2 = \frac{1}{T-k} \sum_{t=1}^T \hat{\epsilon}_{it}^2,
$$

onde $\hat{\epsilon}_{it}$ são os resíduos da regressão da *i*-ésima equação. A matriz de covariância residual, $\hat{\Omega}$, é uma matriz de dimensões $n \times n$, onde cada elemento, $\hat{\omega}_{ij}$, representa a covariância entre os resíduos das equações *i* e *j*, calculada como:

$$
\hat{\omega}_{ij} = \frac{1}{T-k} \sum_{t=1}^T \hat{\epsilon}_{it} \hat{\epsilon}_{jt},
$$

onde $\hat{\epsilon}_{it}$ e $\hat{\epsilon}_{jt}$ são os resíduos das equações *i* e *j* respectivamente. A matriz Q, que é o limite da matriz de covariância das regressoras, é estimada por:

$$
\hat{Q} = \frac{1}{T} \sum_{t=1}^T x_t x_t'.
$$

Assim, para calcular o erro padrão do *i*-ésimo coeficiente de um modelo VAR, primeiro se estima a *i*-ésima equação por OLS,  obtém-se o estimador da variância do resíduo ($s^2_i$) e estimador da matriz Q. O erro padrão do coeficiente estimado é então dado pela raiz quadrada do elemento diagonal correspondente da matriz  $s^2_i \hat{Q}^{-1}$. Para  estimar o erro padrão de um conjunto de coeficientes, usa-se  o resultado da proposição 11.1 (d), obtendo a matriz de covariância como $\hat{\Omega} \otimes \hat{Q}^{-1}$.

### Conclusão
Nesta seção, demonstramos como a distribuição assintótica dos estimadores **MLE** para os coeficientes de um modelo VAR, juntamente com as propriedades da regressão OLS, permite calcular os erros padrão. A proposição 11.1 [^4] estabelece a validade assintótica da distribuição normal e garante que os erros padrão, que são cruciais para inferência estatística, podem ser calculados através das fórmulas padrão de OLS, usando o estimador da variância residual de cada equação. Esta conexão com OLS não só simplifica os cálculos, mas também valida a utilização de estatísticas $t$ e $F$ para testes de hipóteses. Isso significa que modelos VAR, embora complexos, podem ser analisados através de métodos estatísticos relativamente simples e bem compreendidos.  A consistência assintótica e a distribuição normal nos permitem obter um arcabouço sólido para a inferência em modelos VAR, sendo uma ferramenta fundamental para a análise empírica de séries temporais multivariadas.

### Referências
[^1]: p. 292, [11.1.4] e [11.1.7]
[^2]: p. 293, [11.1.11] e [11.1.12]
[^3]: p. 295, [11.1.25]
[^4]: p. 298-299, Proposição 11.1 e [11.1.36]
[^5]: p. 299, [11.1.37]
[^6]: p. 297, [11.1.34]
<!-- END -->
