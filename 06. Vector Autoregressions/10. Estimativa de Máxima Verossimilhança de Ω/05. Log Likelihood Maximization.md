## Estimativa de Máxima Verossimilhança de $\Omega$: Maximização da Verossimilhança e Derivação

### Introdução
Este capítulo visa detalhar o processo de encontrar uma matriz $\Omega$ simétrica e definida positiva que maximize a função de verossimilhança em modelos de *Vector Autoregressions (VAR)*. Expandindo sobre os conceitos previamente estabelecidos sobre a estimativa de máxima verossimilhança e as propriedades da matriz de covariância $\Omega$, iremos agora focar especificamente na derivação matemática deste resultado, partindo da função de log-verossimilhança e utilizando resultados de cálculo matricial [^1]. A compreensão desta derivação é fundamental para validar e aplicar a MLE de $\Omega$ em análises empíricas.

### Derivação da MLE de $\Omega$
O objetivo é encontrar a matriz $\Omega$ que maximize a função de log-verossimilhança para um modelo VAR quando avaliada na MLE dos coeficientes $\Pi$, denotada como $\hat{\Pi}$ [^1]. Esta função, conforme estabelecido anteriormente, é dada por:
$$
L(\Omega, \hat{\Pi}) = -(Tn/2) \log(2\pi) + (T/2) \log|\Omega^{-1}| - (1/2) \sum_{t=1}^{T} \hat{\epsilon}_t'\Omega^{-1}\hat{\epsilon}_t
$$
onde $\hat{\epsilon}_t = y_t - \hat{\Pi}'x_t$ representam os resíduos da regressão OLS.

Para maximizar esta função em relação a $\Omega$, é conveniente diferenciá-la com respeito a $\Omega^{-1}$. Como $\Omega$ é uma matriz simétrica, é mais eficiente trabalhar com $\Omega^{-1}$ e então inverter o resultado. Utilizaremos os resultados de cálculo matricial [^1]:
1.  $\frac{\partial x'Ax}{\partial A} = xx'$
2.  $\frac{\partial \log|A|}{\partial A} = (A^{-1})'$

Aplicando a segunda propriedade, e lembrando que $\log|\Omega^{-1}| = -\log|\Omega|$, temos que a derivada do segundo termo na função de log-verossimilhança é:
$$
\frac{\partial (T/2) \log|\Omega^{-1}|}{\partial \Omega^{-1}} = (T/2) \frac{\partial (-\log|\Omega|)}{\partial \Omega^{-1}} = (T/2)\frac{\partial (-\log|\Omega|)}{\partial \Omega} \frac{\partial \Omega}{\partial \Omega^{-1}}
$$
Como $\frac{\partial \log|A|}{\partial A} = (A^{-1})'$ e, pela regra da cadeia, $\frac{\partial \Omega}{\partial \Omega^{-1}} = - \Omega^2$, o termo acima torna-se:
$$
(T/2)(-\Omega^{-1})' \frac{\partial \Omega}{\partial \Omega^{-1}} = (T/2)(-\Omega)(-\Omega^2) = (T/2) \Omega
$$
Para o terceiro termo, utilizaremos a primeira propriedade. Expandindo a expressão, temos:
$$
\sum_{t=1}^T \hat{\epsilon}_t'\Omega^{-1}\hat{\epsilon}_t = tr \left(\Omega^{-1} \sum_{t=1}^T \hat{\epsilon}_t\hat{\epsilon}_t'\right)
$$
e então,
$$
\frac{\partial}{\partial \Omega^{-1}} \left[ \sum_{t=1}^T \hat{\epsilon}_t'\Omega^{-1}\hat{\epsilon}_t \right] = \sum_{t=1}^T \hat{\epsilon}_t \hat{\epsilon}_t'
$$
Assim, diferenciando $L(\Omega, \hat{\Pi})$ em relação a $\Omega^{-1}$, obtemos:
$$
\frac{\partial L(\Omega, \hat{\Pi})}{\partial \Omega^{-1}} = (T/2)\Omega - (1/2) \sum_{t=1}^T \hat{\epsilon}_t \hat{\epsilon}_t'
$$
Igualando a derivada a zero para encontrar o ponto crítico, temos:
$$
(T/2)\Omega = (1/2) \sum_{t=1}^T \hat{\epsilon}_t \hat{\epsilon}_t'
$$
Isolando $\Omega$, encontramos a estimativa de máxima verossimilhança:
$$
\hat{\Omega} = \frac{1}{T} \sum_{t=1}^{T} \hat{\epsilon}_t \hat{\epsilon}_t'
$$
Este resultado mostra que a matriz $\hat{\Omega}$ que maximiza a função de verossimilhança, no contexto das estimativas MLE, é a matriz de covariância amostral dos resíduos da regressão, dividida pelo número de observações *T*. Como discutido nos capítulos anteriores, esta matriz é simétrica e definida positiva, o que a qualifica como um estimador válido para a matriz de covariância.

### Conclusão
Neste capítulo, realizamos uma derivação detalhada da estimativa de máxima verossimilhança (MLE) da matriz de covariância $\Omega$ em um modelo VAR. Através da diferenciação da função de log-verossimilhança em relação a $\Omega^{-1}$ e da aplicação de resultados de cálculo matricial, demonstramos como a MLE para $\Omega$ resulta na média dos produtos externos dos resíduos da regressão OLS. A compreensão desta derivação matemática reforça a base teórica para o uso da MLE de $\Omega$ em inferências estatísticas e análises de modelos VAR, que iremos abordar nos próximos capítulos.

### Referências
[^1]: Contexto fornecido.
<!-- END -->
