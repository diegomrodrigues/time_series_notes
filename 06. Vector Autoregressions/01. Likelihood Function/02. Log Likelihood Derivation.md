## A Densidade Conjunta e a Log-Verossimilhança em Modelos VAR

### Introdução

Este capítulo detalha a construção da densidade conjunta das observações em um modelo Vetorial Autorregressivo (VAR), bem como o cálculo do logaritmo da função de verossimilhança. Expandindo o conceito apresentado anteriormente, onde cada observação é modelada condicionalmente ao seu histórico, abordaremos agora como essas densidades condicionais se combinam para formar a verossimilhança da amostra completa e como o logaritmo desta verossimilhança simplifica a análise.

### Conceitos Fundamentais

Como estabelecido anteriormente, em um modelo VAR, cada observação $y_t$ é modelada condicionalmente ao seu histórico passado, ou seja, $y_{t-1}, y_{t-2}, ..., y_{t-p+1}$ [^1]. A densidade condicional de $y_t$, dado seu histórico, é descrita por uma função gaussiana multivariada. Para construir a função de verossimilhança para a amostra completa, precisamos considerar a densidade conjunta das observações de 1 até $T$, condicionada ao histórico inicial $(y_0, y_{-1}, \ldots, y_{-p+1})$.

A densidade conjunta de observações $y_1, y_2, ..., y_T$, condicionada ao histórico inicial, é expressa como o produto das densidades condicionais individuais, conforme estabelecido em [^1]:
$$
f(y_1, y_2, \ldots, y_T | y_0, y_{-1}, \ldots, y_{-p+1}; \Theta) = \prod_{t=1}^{T} f(y_t | y_{t-1}, y_{t-2}, \ldots, y_{t-p+1}; \Theta)
$$
Esta expressão reflete a suposição de independência condicional entre as observações, ou seja, dado o histórico, cada observação $y_t$ é independente das outras observações.

O logaritmo da função de verossimilhança (log-verossimilhança), denotado por $\mathcal{L}(\Theta)$, é então obtido aplicando o logaritmo natural à densidade conjunta [^1]:
$$
\mathcal{L}(\Theta) = \log \left( \prod_{t=1}^{T} f(y_t | y_{t-1}, y_{t-2}, \ldots, y_{t-p+1}; \Theta) \right)
$$
Usando as propriedades do logaritmo, podemos reescrever essa expressão como uma soma de logaritmos:
$$
\mathcal{L}(\Theta) = \sum_{t=1}^{T} \log f(y_t | y_{t-1}, y_{t-2}, \ldots, y_{t-p+1}; \Theta)
$$
Substituindo a densidade condicional gaussiana, obtemos a log-verossimilhança:
$$
\mathcal{L}(\Theta) = \sum_{t=1}^{T} \left( -\frac{n}{2}\log(2\pi) - \frac{1}{2}\log|\Omega| - \frac{1}{2}(y_t - \Pi'x_t)'\Omega^{-1}(y_t - \Pi'x_t) \right)
$$
Onde:

*   $n$ é a dimensão do vetor $y_t$.
*   $|\Omega|$ é o determinante da matriz de covariância $\Omega$.
*   $(y_t - \Pi'x_t)'\Omega^{-1}(y_t - \Pi'x_t)$ é a distância de Mahalanobis do vetor $y_t$ à sua média condicional $\Pi'x_t$.

Essa expressão final para a log-verossimilhança é uma soma de termos de densidade gaussiana, cada um dependendo dos parâmetros do modelo, representados por $\Pi$ e $\Omega$. O objetivo é encontrar os valores desses parâmetros que maximizam a log-verossimilhança, fornecendo as estimativas de máxima verossimilhança para o modelo VAR [^1].

*O logaritmo da função de verossimilhança é usado para simplificar as operações de otimização [^1].* A soma de logaritmos transforma o produto de probabilidades em uma soma, o que facilita a derivação e otimização da função.

### Conclusão
Neste capítulo, estabelecemos a forma da densidade conjunta das observações em um modelo VAR, demonstrando como essa densidade é construída a partir do produto das densidades condicionais individuais. Detalhamos também a derivação da função de log-verossimilhança, mostrando que essa função é composta de uma soma de termos gaussianos, dependentes dos parâmetros do modelo. Esta construção é fundamental para a estimação de máxima verossimilhança, permitindo a obtenção de estimativas consistentes e eficientes para os parâmetros do modelo VAR.

### Referências
[^1]: Seções "Likelihood Function" e "Maximum Likelihood Estimate of II" do texto fornecido.
<!-- END -->
