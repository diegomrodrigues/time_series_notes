## Minimização da Matriz de Covariância de Resíduos e sua Conexão com OLS em Modelos VAR

### Introdução

Este capítulo tem como objetivo demonstrar como a **matriz de covariância dos resíduos** em modelos **Vector Autoregressions (VAR)** é minimizada ao definir os coeficientes do modelo como seus estimadores de mínimos quadrados (OLS). Este resultado, intimamente ligado ao conceito de **máxima verossimilhança**,  estabelece uma conexão fundamental entre as abordagens de otimização de modelos. Este capítulo complementa os desenvolvimentos anteriores, especialmente os relacionados ao uso de **derivadas de matrizes** e do operador **traço** [^1], ao mostrar como a escolha dos estimadores de OLS impacta a forma da matriz de covariância e, consequentemente, a função de log-verossimilhança. O objetivo é fornecer uma compreensão clara e concisa da relação entre MLE e OLS no contexto de modelos VAR não restritos.

### Conceitos Fundamentais

Como abordado em capítulos anteriores [^1], a função de log-verossimilhança para um modelo VAR é definida como:
$$
L(\theta) = -\frac{Tn}{2}\log(2\pi) + \frac{T}{2}\log|\Omega^{-1}| - \frac{1}{2} \sum_{t=1}^T (y_t - \Pi'x_t)'\Omega^{-1}(y_t - \Pi'x_t)
$$
onde $y_t$ é o vetor de variáveis endógenas, $x_t$ é o vetor de variáveis explicativas (incluindo lags), $\Pi$ é a matriz de coeficientes e $\Omega$ é a matriz de covariância dos resíduos. Nos capítulos anteriores, mostramos que o estimador de máxima verossimilhança (MLE) da matriz de coeficientes $\Pi$ pode ser obtido através de regressão OLS em cada equação do modelo VAR [^1].

O processo de estimação de máxima verossimilhança envolve a maximização da função de log-verossimilhança com respeito a todos os parâmetros, incluindo os elementos da matriz de coeficientes $\Pi$ e a matriz de covariância $\Omega$. Quando calculamos o MLE de $\Pi$, encontramos um estimador $\hat{\Pi}$ que minimiza a soma ponderada de quadrados dos resíduos.  Esse estimador é idêntico ao estimador OLS.

Em relação à matriz de covariância, $\Omega$, mostramos em capítulos anteriores que o seu estimador de máxima verossimilhança é [^1]:
$$
\hat{\Omega} = \frac{1}{T} \sum_{t=1}^T \hat{\epsilon}_t \hat{\epsilon}_t'
$$
onde $\hat{\epsilon}_t$ são os resíduos do modelo, ou seja,  $\hat{\epsilon}_t = y_t - \hat{\Pi}'x_t$.

O ponto fundamental deste capítulo é como a matriz de covariância dos resíduos, $\Omega$, é influenciada pela escolha dos estimadores de $\Pi$ como os estimadores OLS. Especificamente, demonstraremos como a soma de quadrados ponderada dos resíduos é minimizada pelos estimadores de OLS, o que implica que o termo $\sum_{t=1}^T (y_t - \Pi'x_t)'\Omega^{-1}(y_t - \Pi'x_t)$  na função de verossimilhança é minimizado ao definir $\Pi$ como o estimador OLS $\hat{\Pi}$.

### Derivação da Minimização da Matriz de Covariância dos Resíduos

Para demonstrar como a matriz de covariância dos resíduos é minimizada ao definir $\Pi$ como o estimador OLS, reescrevemos a soma dos quadrados ponderados dos resíduos:
$$
\sum_{t=1}^T (y_t - \Pi'x_t)'\Omega^{-1}(y_t - \Pi'x_t)
$$
Usando que  $y_t - \Pi'x_t = (y_t - \hat{\Pi}'x_t) + (\hat{\Pi}' - \Pi')x_t = \hat{\epsilon}_t + (\hat{\Pi} - \Pi)'x_t$, podemos reescrever a soma como:
$$
\sum_{t=1}^T (\hat{\epsilon}_t + (\hat{\Pi} - \Pi)'x_t)'\Omega^{-1}(\hat{\epsilon}_t + (\hat{\Pi} - \Pi)'x_t)
$$
Expandindo essa expressão, obtemos:
$$
\sum_{t=1}^T \hat{\epsilon}_t' \Omega^{-1} \hat{\epsilon}_t + \sum_{t=1}^T \hat{\epsilon}_t' \Omega^{-1} (\hat{\Pi} - \Pi)' x_t +  \sum_{t=1}^T x_t'(\hat{\Pi} - \Pi) \Omega^{-1} \hat{\epsilon}_t + \sum_{t=1}^T x_t'(\hat{\Pi} - \Pi) \Omega^{-1} (\hat{\Pi} - \Pi)' x_t
$$
Os resíduos $\hat{\epsilon}_t$ são ortogonais às variáveis explicativas $x_t$, ou seja, $\sum_{t=1}^T \hat{\epsilon}_t x_t' = 0$. Assim, os termos do meio na expressão anterior se anulam e obtemos:
$$
\sum_{t=1}^T \hat{\epsilon}_t' \Omega^{-1} \hat{\epsilon}_t + \sum_{t=1}^T x_t'(\hat{\Pi} - \Pi) \Omega^{-1} (\hat{\Pi} - \Pi)' x_t
$$
O primeiro termo desta expressão é o traço da matriz de covariância amostral dos resíduos ponderada por $\Omega^{-1}$, ou seja,  $\text{trace}\left(\Omega^{-1} \sum_{t=1}^T \hat{\epsilon}_t \hat{\epsilon}_t'\right)$.  O segundo termo é sempre não-negativo, pois é uma forma quadrática com a matriz $\Omega^{-1}$, que é definida positiva. Este termo só se anula quando $\hat{\Pi}=\Pi$. Portanto, ao escolher $\hat{\Pi}$ como o estimador OLS (que é o mesmo que o MLE) minimizamos a função de log-verossimilhança.

O fato de que o estimador OLS minimiza a soma de quadrados implica que ele também minimiza o termo na função de log-verossimilhança associado à matriz de covariância dos resíduos. Isso demonstra a forte ligação entre OLS e MLE neste contexto, e como o uso da estimativa OLS resulta em uma redução da matriz de covariância dos resíduos, de acordo com as propriedades do MLE. Especificamente, o último termo, que é sempre não negativo, é minimizado quando $\Pi$ é igual a $\hat{\Pi}$, que corresponde ao estimador OLS.

Usando o operador traço, podemos reescrever a soma ponderada dos resíduos como [^1]:
$$
\sum_{t=1}^T \hat{\epsilon}_t' \Omega^{-1} \hat{\epsilon}_t = \text{trace}\left(\Omega^{-1}\sum_{t=1}^T \hat{\epsilon}_t \hat{\epsilon}_t'\right)
$$
Ao usar o estimador OLS para $\Pi$, o segundo termo da expressão se anula, e o termo restante na log-verossimilhança torna-se:
$$
\frac{1}{2} \text{trace}\left(\Omega^{-1} \sum_{t=1}^T \hat{\epsilon}_t \hat{\epsilon}_t'\right)
$$
Essa simplificação é fundamental, pois indica que a escolha de $\hat{\Pi}$ minimiza a parte da função de verossimilhança relacionada à matriz de covariância dos resíduos.

### Conclusão

Este capítulo demonstrou como a matriz de covariância dos resíduos é minimizada ao se definir os coeficientes do modelo como seus estimadores de mínimos quadrados (OLS).  A minimização da soma de quadrados ponderada dos resíduos, obtida com o uso dos estimadores OLS, é diretamente relacionada à maximização da função de log-verossimilhança e à obtenção dos estimadores de máxima verossimilhança em modelos VAR não restritos.  Essa demonstração consolida e conecta os resultados anteriores sobre a estimação dos parâmetros do modelo e o papel do operador traço. A escolha dos estimadores de máxima verossimilhança (que são equivalentes ao OLS nesse contexto) não apenas simplifica as derivações, mas também minimiza a matriz de covariância dos resíduos, e maximiza a função de verossimilhança. Este capítulo enfatiza a conexão entre OLS e MLE, preparando o terreno para explorar os casos em que essa conexão pode não ser direta, como em modelos VAR restritos.

### Referências

[^1]: [11.1.10], [11.1.11], [11.1.12], [11.1.13], [11.1.14], [11.1.15], [11.1.16], [11.1.17]
<!-- END -->
