## A Densidade Condicional em Modelos VAR e a Construção da Função de Verossimilhança

### Introdução
Em continuidade ao capítulo anterior, onde estabelecemos a **função de verossimilhança** para modelos VAR, vamos agora nos aprofundar na forma específica da **densidade condicional** de cada observação. Essa densidade, crucial para a construção da função de verossimilhança, é baseada na distribuição normal multivariada e envolve o vetor de observações $y_t$, a média condicional $\Pi'x_t$, e a matriz de covariância $\Omega$. A compreensão detalhada dessa densidade e sua derivação são essenciais para a estimação de máxima verossimilhança em modelos VAR [^1].

### A Forma da Densidade Condicional
Como vimos, a função de verossimilhança para modelos VAR é construída multiplicando as densidades condicionais de cada observação. A densidade condicional da $t$-ésima observação, dado o histórico anterior, é dada por:

$$ f(y_t|y_{t-1}, y_{t-2}, \ldots, y_{t-p}; \theta) = (2\pi)^{-n/2} |\Omega|^{-1/2} \exp \left\{ -\frac{1}{2} (y_t - \Pi'x_t)'\Omega^{-1}(y_t - \Pi'x_t) \right\} $$
[11.1.8]

Esta expressão representa a densidade de uma **distribuição normal multivariada**, com média $\Pi'x_t$ e matriz de covariância $\Omega$. O termo $(2\pi)^{-n/2}$ é um fator de normalização para garantir que a integral da densidade seja igual a 1, onde $n$ é o número de variáveis no sistema VAR.  O termo $|\Omega|^{-1/2}$ é o determinante da inversa da matriz de covariância, que ajusta a escala da densidade. O termo exponencial contém a distância quadrática de Mahalanobis entre a observação $y_t$ e a média condicional $\Pi'x_t$, ponderada pela inversa da matriz de covariância $\Omega$.

**Detalhes da Derivação**
Para uma compreensão mais profunda, é útil destrinchar cada componente da densidade condicional. O vetor $y_t$ representa as observações no tempo $t$ das $n$ variáveis em análise. O vetor $\Pi'x_t$ representa a média condicional de $y_t$, que é uma função linear do termo constante e das defasagens de $y$. A matriz $\Omega$ captura as covariâncias entre os termos de erro nas diferentes equações do VAR.
A expressão $(y_t - \Pi'x_t)$ é um vetor que representa a diferença entre a observação real $y_t$ e a média condicional $\Pi'x_t$. O termo $(y_t - \Pi'x_t)'\Omega^{-1}(y_t - \Pi'x_t)$ é a forma quadrática que calcula a distância ponderada entre a observação e sua média condicional. A matriz $\Omega^{-1}$ é a inversa da matriz de covariância e ajusta a escala da distância de acordo com as variâncias e covariâncias dos termos de erro. O termo exponencial $ \exp \left\{ -\frac{1}{2} (y_t - \Pi'x_t)'\Omega^{-1}(y_t - \Pi'x_t) \right\}$  determina a forma da distribuição normal multivariada, com maior probabilidade em torno da média condicional e probabilidade decrescente à medida que a distância aumenta.

### A Construção da Função de Verossimilhança
A construção da função de verossimilhança segue diretamente da definição da densidade condicional. A **função de verossimilhança**, para uma amostra de $T$ observações, é o produto das densidades condicionais para cada observação:

$$ f(y_T, y_{T-1}, \ldots, y_1|y_0, y_{-1}, \ldots, y_{-p+1};\theta) = \prod_{t=1}^T f(y_t|y_{t-1}, y_{t-2}, \ldots, y_{t-p}; \theta) $$
[11.1.9]
A forma logarítmica dessa função, conhecida como **log-verossimilhança**, é dada por:

$$ L(\theta) = \sum_{t=1}^T \log f(y_t|y_{t-1}, y_{t-2}, \ldots, y_{t-p}; \theta) $$
[11.1.10]
Ao substituir a densidade condicional em [11.1.8] nesta última expressão, obtemos a log-verossimilhança para o modelo VAR:
$$ L(\theta) = - \frac{Tn}{2} \log(2\pi) - \frac{T}{2} \log|\Omega| - \frac{1}{2} \sum_{t=1}^T (y_t - \Pi'x_t)'\Omega^{-1}(y_t - \Pi'x_t) $$
[11.1.10]
O objetivo da estimação de máxima verossimilhança é encontrar os valores de $\Pi$ e $\Omega$ que maximizem essa função, fornecendo a melhor adequação do modelo VAR aos dados observados.
### Conexão com Modelos de Autorregressão Escalar
É importante destacar que o processo de derivação da função de verossimilhança em modelos VAR é análogo ao de uma autorregressão escalar. No contexto de um VAR, estamos simplesmente trabalhando com vetores e matrizes em vez de escalares e, portanto, usamos a distribuição normal multivariada em vez da normal univariada. A estrutura da função de verossimilhança, no entanto, é semelhante, baseada no produto das densidades condicionais. O uso da distribuição normal multivariada é motivado pela suposição de que os termos de erro têm uma distribuição conjunta normal.

### Conclusão
Este capítulo detalhou a forma da densidade condicional da $t$-ésima observação em um modelo VAR, com foco na distribuição normal multivariada,  e como ela é usada para construir a função de verossimilhança. Através desta análise detalhada, compreendemos como a estrutura do modelo VAR, as propriedades dos termos de erro e o conceito de independência condicional se unem para derivar uma função que pode ser usada para estimar os parâmetros do modelo. A expressão da densidade condicional é fundamental para a otimização e inferência em modelos VAR, e a sua compreensão nos permite proceder com os métodos de estimação e testes de hipóteses, nos próximos capítulos.
### Referências
[^1]: Refere-se ao texto original da página 292, parágrafos anteriores e ao redor da equação [11.1.8].
<!-- END -->
