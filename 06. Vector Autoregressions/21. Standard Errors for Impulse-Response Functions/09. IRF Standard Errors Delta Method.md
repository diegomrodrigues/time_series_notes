## Erros Padrão para Funções de Resposta ao Impulso: Derivação Analítica e Implementação Computacional Detalhada

### Introdução
Este capítulo tem como objetivo apresentar uma análise aprofundada do cálculo dos **erros padrão das funções de resposta ao impulso (IRFs)** em modelos de Vetores Auto-regressivos (VAR), com foco específico na *derivação analítica* e em sua *implementação computacional eficiente*, incluindo otimizações para lidar com a complexidade inerente a modelos de alta dimensionalidade [^1, ^2]. Conforme abordado em capítulos anteriores [^1, ^2], as IRFs são ferramentas essenciais para avaliar a resposta de um sistema de variáveis a choques exógenos, sendo fundamentais para análise de modelos VAR. No entanto, a incerteza nos parâmetros do modelo VAR, estimada por meio de regressões OLS, se propaga para as estimativas das IRFs, tornando o cálculo dos erros padrão um passo crucial para a inferência estatística e a avaliação da robustez das conclusões obtidas com modelos VAR.
Neste capítulo, exploraremos em detalhes a *derivação analítica* dos erros padrão das IRFs não ortogonalizadas utilizando o método *delta*, que envolve o cálculo das derivadas parciais das IRFs em relação aos parâmetros do modelo. Além disso, discutiremos abordagens para otimizar o cálculo dessas derivadas, com foco na eficiência computacional, que é crucial para modelos de alta dimensão.

### Derivação Analítica dos Erros Padrão para IRFs Não Ortogonalizadas
Como discutido anteriormente [^1, ^2], um modelo VAR de ordem $p$ pode ser representado como:
$$ y_t = \Pi_1 y_{t-1} + \Pi_2 y_{t-2} + \dots + \Pi_p y_{t-p} + \epsilon_t $$
onde $y_t$ é um vetor $(n \times 1)$ de variáveis endógenas, $\Pi_i$ são as matrizes de coeficientes $(n \times n)$ e $\epsilon_t$ é um vetor de inovação $(n \times 1)$. As IRFs, denotadas por $\Psi_s$, descrevem a resposta das variáveis no período $t+s$ a um choque no período $t$. Essas matrizes são obtidas através da representação de média móvel (MA) do VAR:
$$ y_t = \mu + \epsilon_t + \Psi_1 \epsilon_{t-1} + \Psi_2 \epsilon_{t-2} + \dots $$

A matriz $\Psi_s$ representa a resposta das variáveis no período $t+s$ a um choque no período $t$. As IRFs são uma função dos parâmetros do modelo VAR, que são empilhados no vetor $\pi = vec(\Pi)$, onde $\Pi$ é a matriz que empilha todos os parâmetros do VAR, e o operador $vec$ transforma a matriz em um vetor coluna.
A estimativa das IRFs, denotada por $\hat{\psi}_s = vec(\hat{\Psi}_s)$, é função das estimativas OLS dos parâmetros do modelo VAR, $\hat{\pi} = vec(\hat{\Pi})$. O método *delta*, que será utilizado neste capítulo para obter os erros padrão das IRFs, parte do princípio de que a distribuição amostral de $\hat{\psi}_s$ pode ser aproximada por uma distribuição normal com média $\psi_s$ e matriz de variância-covariância dependente das derivadas de $\psi_s$ em relação a $\pi$. Como vimos anteriormente,  $\hat{\pi}$ segue uma distribuição assintoticamente normal:
$$ \sqrt{T}(\hat{\pi} - \pi) \xrightarrow{L} N(0, \Omega \otimes Q^{-1}) $$
onde $T$ é o tamanho da amostra, $\Omega$ é a matriz de covariância dos resíduos do VAR, e $Q^{-1}$ é a inversa da matriz de covariância das variáveis defasadas. Definindo $\psi_s = vec(\Psi_s)$, a aplicação do método *delta* nos leva a:
$$ \sqrt{T}(\hat{\psi}_{s,T} - \psi_s) \xrightarrow{L} N(0, G_s(\Omega \otimes Q^{-1})G_s') $$
[11.7.3]
onde $G_s$ é a matriz de derivadas, que expressa a sensibilidade de $\psi_s$ em relação a mudanças em $\pi$:
$$ G_s = \left.\frac{\partial \psi_s(\pi)}{\partial \pi'}\right|_{\pi=\hat{\pi}} $$
[11.7.2]
O erro padrão da IRF em uma posição específica da matriz $\Psi_s$ corresponde à raiz quadrada do elemento diagonal apropriado da matriz $ (1/T) G_s(\Omega \otimes Q^{-1})G_s' $.

O cálculo da matriz de derivadas $G_s$ é o ponto crucial dessa abordagem e, como vimos, pode ser obtido de forma recursiva [11.7.4]:
$$ G_s = [I_n, (0_n' \otimes \Psi_{s-1}), \ldots, (0_n' \otimes \Psi_{s-p})] + \sum_{i=1}^p(\Phi_i \otimes I_n)G_{s-i} $$
ou através da solução de forma fechada [11.7.5]:
$$ G_s = \sum_{i=1}^s \left[\Psi_{s-i} (0_n' \otimes I_n) \ldots (0_n' \otimes \Psi_{s-i-p+1}) \right] $$
Estas expressões são essenciais para a implementação computacional dos erros padrão, sendo necessário considerar a natureza recursiva, e o uso de matrizes e produtos de Kronecker.

### Implementação Computacional das Derivadas Analíticas
A tradução das expressões analíticas anteriores em código computacional exige atenção à detalhes de implementação, para evitar problemas de desempenho e precisão [^2]. A principal dificuldade computacional é o cálculo eficiente da matriz de derivadas $G_s$.

**Implementação da Expressão Recursiva [11.7.4]:**
1. **Inicialização:** Inicializa-se a iteração com as matrizes $G_0 = I_n$ e $G_i = 0$ para $i<0$. O uso de memória eficiente é fundamental nesta etapa. Deve-se reservar espaço na memória apenas para os objetos necessários, evitando alocações de memória desnecessárias.
2. **Produto de Kronecker:** O produto de Kronecker $(0_n' \otimes \Psi_{s-i})$ e $(\Phi_i \otimes I_n)$ deve ser implementado de maneira otimizada, usando funções nativas de bibliotecas de álgebra linear ou através de rotinas vetorizadas. A alocação de memória para as matrizes resultantes do produto de Kronecker também deve ser gerenciada com cuidado.
3. **Multiplicação de Matrizes:** A multiplicação de matrizes envolvida na recursão deve ser implementada usando bibliotecas de computação científica para acelerar o processo.
4.  **Recursão:** A iteração deve ser feita de forma eficiente, evitando recálculos. O uso de caching (armazenamento temporário de dados) pode reduzir o custo computacional, especialmente para modelos VAR com um grande número de lags.
5. **Vetores de Zeros:** A criação dos vetores de zeros $(0_n')$ deve ser feita de forma otimizada. Evite criar novos vetores a cada iteração. Reutilize a memória alocada.

**Implementação da Expressão em Forma Fechada [11.7.5]:**
1. **Alocação de Memória:** Reserve a memória necessária para armazenar as matrizes $\Psi_i$ para $i=0, 1, \dots, s$.
2. **Somatório:** Implemente o somatório de forma eficiente. Para isso, utilize o vetorização sempre que possível e evite a criação de objetos desnecessários.
3. **Produto de Matrizes:** O produto de matrizes deve ser computado de forma otimizada, utilizando bibliotecas de álgebra linear e explorando o paralelismo se disponível.

A implementação computacional das derivadas analíticas, mesmo utilizando as melhores práticas e bibliotecas especializadas, pode se tornar cara em termos de tempo de computação e memória para modelos de alta dimensão. Por isso, abordagens alternativas como a derivação numérica podem ser mais adequadas em tais cenários.

### Abordagem Numérica: Derivadas por Diferenças Finitas
A aproximação numérica das derivadas usando diferenças finitas oferece uma maneira alternativa de calcular a matriz $G_s$ sem precisar derivar as IRFs analiticamente. A principal vantagem deste método é a sua simplicidade e facilidade de implementação. No entanto, é importante ter em mente que esta abordagem gera uma aproximação, não o valor exato da derivada. Para aplicar a diferenciação numérica, é necessário perturbar cada elemento $\pi_i$ do vetor $\pi$ separadamente, utilizando um pequeno valor $\Delta$.
A derivada em relação a $\pi_i$ é aproximada por:
$$ \left. \frac{\partial \psi_s(\pi)}{\partial \pi_i} \right|_{\pi=\hat{\pi}} \approx \frac{\hat{\psi}_s(\hat{\pi} + e_i \Delta) - \hat{\psi}_s(\hat{\pi})}{\Delta} $$

onde $e_i$ é um vetor $(nk \times 1)$ com todos os elementos iguais a zero, exceto o $i$-ésimo, que é igual a um, e $\hat{\pi}$ representa a estimativa OLS do vetor $\pi$.

A implementação da diferenciação numérica deve levar em consideração as seguintes questões:
1.  **Escolha de $\Delta$:** O valor de $\Delta$ deve ser escolhido cuidadosamente. Valores muito pequenos podem introduzir erros de arredondamento, enquanto valores muito grandes podem levar a uma aproximação pouco precisa da derivada. Um valor adequado para $\Delta$ pode ser algo próximo de $10^{-3}$ ou $10^{-4}$ , mas este valor pode precisar ser ajustado dependendo da escala dos parâmetros do modelo VAR em análise.
2.  **Calculo das IRFs:** O cálculo das IRFs para cada valor perturbado do vetor $\pi$ é o passo mais custoso computacionalmente. Para otimizar esta etapa, implemente a simulação de IRFs de forma vetorizada, evitando loops explícitos, e reutilize cálculos sempre que possível.
3.  **Paralelização:** O cálculo das derivadas para diferentes elementos do vetor $\pi$ pode ser paralelizado, o que pode reduzir o tempo de processamento.

### Abordagem Computacional: Simulações de Monte Carlo

Como alternativa à derivação analítica e à aproximação numérica, simulações de Monte Carlo oferecem uma forma flexível para estimar os erros padrão das IRFs. O procedimento é direto:
1. Simule uma amostra $\pi^{(i)}$ da distribuição assintótica de $\hat{\pi}$, que é $N(\hat{\pi}, (1/T)(\Omega \otimes Q^{-1}))$.
2.  Calcule as IRFs $\hat{\psi}_s^{(i)} = \psi_s(\pi^{(i)})$ para cada amostra simulada $\pi^{(i)}$.
3. Repita os passos 1 e 2 para um grande número de simulações ($N$).
4. Com as $N$ estimativas das IRFs $\hat{\psi}_s^{(i)}$, obtenha a média, o desvio padrão e outros quantis para construir os intervalos de confiança.

A implementação deste método envolve:
1. **Geração de números aleatórios:** A qualidade das amostras simuladas depende da qualidade do gerador de números aleatórios utilizado.
2. **Cálculo das IRFs:** O cálculo das IRFs para cada simulação deve ser eficiente.
3. **Paralelização:** Como cada simulação é independente das outras, é possível utilizar paralelização para reduzir o tempo de computação.

### Conclusão
Este capítulo detalhou as abordagens para o cálculo dos erros padrão das IRFs não ortogonalizadas em modelos VAR, com um foco especial na derivação analítica, nas suas otimizações computacionais e nas abordagens alternativas de diferenciação numérica, e simulações Monte Carlo. As abordagens analíticas, apesar de apresentarem um entendimento profundo da propagação da incerteza dos parâmetros do VAR para as IRFs, podem ser computacionalmente intensivas para modelos de alta dimensão e longos horizontes. A escolha entre as derivadas analíticas ou numéricas, assim como o uso de simulações de Monte Carlo, depende dos objetivos da análise, da precisão desejada e da disponibilidade de recursos computacionais. Em geral, a derivação analítica é preferível quando os modelos VAR são pequenos e a expressão da matriz de derivadas é relativamente simples, enquanto métodos numéricos e simulações podem ser utilizados quando os modelos são grandes ou quando a complexidade da expressão da matriz de derivadas torna a abordagem analítica difícil de aplicar. Uma implementação eficiente, utilizando bibliotecas de álgebra linear, vetorização, paralelização e estratégias de otimização, é crucial para que os cálculos sejam realizados de forma rápida e precisa.
### Referências
[^1]: Capítulo anterior sobre Vetores Autoregressivos (VAR).
[^2]: Contexto fornecido para criação do capítulo.
<!-- END -->
