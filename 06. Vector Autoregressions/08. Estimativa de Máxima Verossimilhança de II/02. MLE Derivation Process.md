## Estimativa de Máxima Verossimilhança de Π em Modelos VAR
### Introdução
Em continuidade à discussão sobre modelos de vetores autorregressivos (VAR), este capítulo aprofunda a obtenção da **estimativa de máxima verossimilhança (MLE)** para a matriz de parâmetros Π. Como vimos anteriormente, os modelos VAR são ferramentas poderosas para analisar as inter-relações dinâmicas entre múltiplas variáveis [^1]. A MLE de Π é um passo fundamental para a estimação precisa dos parâmetros do modelo, permitindo inferências estatísticas válidas e previsões confiáveis. Este capítulo irá explorar a derivação matemática da MLE de Π, demonstrando que ela corresponde à solução de regressões de mínimos quadrados ordinários (OLS) separadas para cada equação do sistema VAR.

### Conceitos Fundamentais
A **função de verossimilhança condicional** para um modelo VAR é dada por [^1]:
$$
f(y_t | y_{t-1}, y_{t-2}, \ldots, y_{t-p}; \theta) \sim N(\Pi'x_t, \Omega)
$$
onde $x_t$ é um vetor contendo um termo constante e $p$ lags de cada elemento de $y$, e Π' é a matriz de parâmetros que contém o termo constante 'c' e os coeficientes autorregressivos Φ [^1].
O objetivo é encontrar a **MLE de Π**, denotada como $\hat{\Pi}$, que maximiza a função de verossimilhança, ou equivalentemente, minimiza o negativo do log-verossimilhança. O log da função de verossimilhança amostral é dado por [^1]:
$$
L(\theta) = -\frac{Tn}{2} \log(2\pi) + \frac{T}{2} \log|\Omega^{-1}| - \frac{1}{2} \sum_{t=1}^{T} (y_t - \Pi'x_t)'\Omega^{-1}(y_t - \Pi'x_t)
$$
A MLE de Π é obtida maximizando esta função com respeito a Π. De acordo com [^1], a **MLE de Π** é dada por:
$$
\hat{\Pi}' = \left[ \sum_{t=1}^{T} y_t x_t' \right] \left[ \sum_{t=1}^{T} x_t x_t' \right]^{-1}
$$
Esta expressão [11.1.11] pode ser vista como o **análogo amostral da projeção linear da população** de $y_t$ em uma constante e $x_t$, como discutido em [4.1.23] [^1]. A *j-ésima linha de $\hat{\Pi}'$ é dada por*:
$$
\hat{\pi}'_j = \left[ \sum_{t=1}^{T} y_{jt} x_t' \right] \left[ \sum_{t=1}^{T} x_t x_t' \right]^{-1}
$$
Esta expressão [11.1.12] representa o vetor de coeficientes estimados de uma **regressão OLS** de $y_{jt}$ em $x_t$. Portanto, a MLE dos coeficientes para a *j-ésima equação de um VAR* são encontradas através de uma **regressão OLS de $y_{jt}$ em uma constante e $p$ lags de todas as variáveis do sistema** [^1].

O objetivo desta seção é detalhar o processo para verificar a equação [11.1.11], mostrando que a solução obtida por regressão OLS de fato maximiza a função de verossimilhança e, portanto, corresponde à **MLE de Π**. Para tal, vamos manipular a soma que aparece no último termo do log da função de verossimilhança [11.1.10], que é dada por [^1]:
$$
\sum_{t=1}^{T} (y_t - \Pi'x_t)' \Omega^{-1} (y_t - \Pi'x_t)
$$
O primeiro passo é **decompor** o termo $(y_t - \Pi'x_t)$ adicionando e subtraindo $\hat{\Pi}'x_t$, onde $\hat{\Pi}$ é a estimativa de Π obtida por OLS, e então expandir a expressão [^1]:
$$
\sum_{t=1}^{T} (y_t - \hat{\Pi}'x_t + \hat{\Pi}'x_t - \Pi'x_t)' \Omega^{-1} (y_t - \hat{\Pi}'x_t + \hat{\Pi}'x_t - \Pi'x_t)
$$
Essa expressão pode ser reescrita como:
$$
\sum_{t=1}^{T} [\hat{\epsilon}_t + (\hat{\Pi} - \Pi)'x_t]' \Omega^{-1} [\hat{\epsilon}_t + (\hat{\Pi} - \Pi)'x_t]
$$
onde $\hat{\epsilon}_t = y_t - \hat{\Pi}'x_t$ é o **resíduo amostral** da regressão OLS de $y_t$ em $x_t$ [^1]. Expandindo novamente essa expressão, obtemos [^1]:
$$
\sum_{t=1}^{T} [\hat{\epsilon}_t' \Omega^{-1} \hat{\epsilon}_t + \hat{\epsilon}_t' \Omega^{-1} (\hat{\Pi} - \Pi)'x_t + x_t' (\hat{\Pi} - \Pi) \Omega^{-1} \hat{\epsilon}_t +  x_t' (\hat{\Pi} - \Pi) \Omega^{-1} (\hat{\Pi} - \Pi)'x_t]
$$
Reorganizando os termos e usando a propriedade de transposição $(AB)' = B'A'$, obtemos:
$$
\sum_{t=1}^{T} \hat{\epsilon}_t' \Omega^{-1} \hat{\epsilon}_t + 2 \sum_{t=1}^{T} \hat{\epsilon}_t' \Omega^{-1} (\hat{\Pi} - \Pi)'x_t + \sum_{t=1}^{T} x_t' (\hat{\Pi} - \Pi) \Omega^{-1} (\hat{\Pi} - \Pi)'x_t
$$
O termo do meio da equação acima é um escalar, e podemos reescrevê-lo usando o operador 'trace' (traço), que permite aplicar a propriedade $tr(AB) = tr(BA)$ de maneira conveniente [^1]:
$$
2 \sum_{t=1}^{T} \hat{\epsilon}_t' \Omega^{-1} (\hat{\Pi} - \Pi)'x_t = \text{trace}\left[ 2 \sum_{t=1}^{T} x_t'(\hat{\Pi} - \Pi) \Omega^{-1}\hat{\epsilon}_t \right]
$$
É fundamental observar que, por construção, os **resíduos de uma regressão OLS são ortogonais às variáveis explicativas**, o que significa que $\sum_{t=1}^{T} x_t \hat{\epsilon}_t' = 0$ (a soma dos produtos entre a matriz de variáveis explicativas e o vetor de resíduos é zero). Portanto, também temos  $\sum_{t=1}^{T} \hat{\epsilon}_t x_t' = 0$. Consequentemente, o termo do meio da equação acima se torna zero [^1]:
$$
\text{trace}\left[ 2 \sum_{t=1}^{T} x_t'(\hat{\Pi} - \Pi) \Omega^{-1}\hat{\epsilon}_t \right] = 0
$$
Assim, a expressão original se simplifica para [^1]:
$$
\sum_{t=1}^{T} \hat{\epsilon}_t' \Omega^{-1} \hat{\epsilon}_t + \sum_{t=1}^{T} x_t' (\hat{\Pi} - \Pi) \Omega^{-1} (\hat{\Pi} - \Pi)'x_t
$$
Como $\Omega$ é uma **matriz definida positiva**, $\Omega^{-1}$ também é uma matriz definida positiva. Isso implica que o termo $x_t' (\hat{\Pi} - \Pi) \Omega^{-1} (\hat{\Pi} - \Pi)'x_t$ é sempre não negativo, pois é uma forma quadrática envolvendo uma matriz definida positiva. Além disso, esse termo será igual a zero se, e somente se, $\hat{\Pi} = \Pi$. Consequentemente, a expressão acima atingirá seu valor mínimo quando $\hat{\Pi} = \Pi$.

### Conclusão
Este processo de derivação detalhado demonstra que a estimativa de Π obtida por regressão OLS, apresentada em [11.1.11], corresponde à **MLE da matriz de coeficientes Π**. A equivalência entre a MLE e as regressões OLS simplifica a estimação e confirma a validade do uso de regressão OLS para calcular a estimativa de Π. A expansão e manipulação da expressão original do termo quadrático na função de verossimilhança, usando a ortogonalidade dos resíduos da regressão OLS, foi essencial para demonstrar que a solução por OLS minimiza essa expressão. Ao minimizar o termo quadrático, a função de verossimilhança é maximizada, validando assim o uso da OLS para a obtenção da MLE de Π. Essa compreensão detalhada permite uma base sólida para os próximos tópicos que envolvem a estimação de outros parâmetros do modelo VAR, como a matriz de covariância dos resíduos e a realização de testes de hipóteses.

### Referências
[^1]: Trechos do contexto fornecido, incluindo as equações (11.1.3), (11.1.4), (11.1.5), (11.1.6), (11.1.7), (11.1.8), (11.1.10), (11.1.11), (11.1.12), (11.1.13), (11.1.14), (11.1.15), (11.1.16) e (11.1.17)
<!-- END -->
