## Estimativa de Máxima Verossimilhança da Matriz de Covariância $\Omega$ em Modelos VAR

### Introdução
Este capítulo avança na análise de modelos de vetores autorregressivos (VAR), concentrando-se agora na estimação da **matriz de covariância** $\Omega$ utilizando o método da **máxima verossimilhança** (MLE). Conforme vimos anteriormente, a função de verossimilhança é uma ferramenta crucial para estimar os parâmetros de um modelo, e a MLE é o valor dos parâmetros que maximiza essa função [^1]. Depois de obtermos a MLE dos coeficientes do modelo, o próximo passo é obter a MLE da matriz de covariância dos resíduos, que é um componente essencial para a inferência estatística em modelos VAR. Esta discussão complementa a apresentação anterior, consolidando as bases para testes de hipóteses e análises mais avançadas.

### Conceitos Fundamentais
A estimação de máxima verossimilhança da matriz de covariância $\Omega$ é um passo crucial na análise de modelos VAR. Após obter a MLE de $\Pi$, a função de log-verossimilhança, avaliada em $\hat{\Pi}$, torna-se:

$$
\mathcal{L}(\Omega, \hat{\Pi}) = -(Tn/2) \log(2\pi) + (T/2) \log|\Omega^{-1}| - \frac{1}{2} \sum_{t=1}^{T} \hat{\epsilon}_t'\Omega^{-1}\hat{\epsilon}_t
$$
[11.1.25]

O objetivo agora é encontrar uma matriz simétrica definida positiva $\Omega$ que maximize essa função. Para isso, inicialmente, considera-se a maximização de [11.1.25] permitindo que $\Omega$ seja qualquer matriz (n x n) irrestrita. Para isso, deriva-se [11.1.25] em relação aos elementos de $\Omega^{-1}$, utilizando [11.1.20] e [11.1.22]:

$$
\frac{\partial \mathcal{L}(\Omega, \hat{\Pi})}{\partial \Omega^{-1}} = (T/2)\Omega - (1/2) \sum_{t=1}^{T} \hat{\epsilon}_t\hat{\epsilon}_t'
$$
[11.1.26]

A função de log-verossimilhança é maximizada quando essa derivada é igual a zero, o que ocorre quando:

$$
\hat{\Omega} = \frac{1}{T} \sum_{t=1}^{T} \hat{\epsilon}_t\hat{\epsilon}_t'
$$
[11.1.27]

É importante observar que, embora a otimização tenha sido realizada sobre o espaço de todas as matrizes (n x n), a matriz $\hat{\Omega}$ resultante é simétrica e definida positiva. Essa é uma propriedade conveniente que garante que a MLE de $\Omega$ também seja a MLE quando a busca é restrita ao espaço de matrizes simétricas e definidas positivas [^1].

O elemento (i,j) de $\hat{\Omega}$, denotado como $\hat{\sigma}_{ij}$, é dado por:
$$
\hat{\sigma}_{ij} = \frac{1}{T}\sum_{t=1}^{T}\hat{\epsilon}_{it}\hat{\epsilon}_{jt}
$$
[11.1.30]
Essa expressão representa o produto médio dos resíduos OLS para a variável *i* e os resíduos OLS para a variável *j*.

A MLE de  $\Omega$  pode também ser expressa em termos de seus elementos diagonais e não diagonais. O elemento (i, i) é dado por:

$$
\hat{\sigma}_{ii} = \frac{1}{T} \sum_{t=1}^{T} \hat{\epsilon}_{it}^2
$$
[11.1.29]
que corresponde ao resíduo médio ao quadrado de uma regressão OLS para a i-ésima variável do VAR [^1].

### Relação com Regressão OLS
Como demonstrado anteriormente, a MLE dos coeficientes do modelo VAR, $\hat{\Pi}$, é obtida através de regressões OLS [^1]. Similarmente, a MLE da matriz de covariância $\Omega$ envolve o cálculo dos produtos médios dos resíduos dessas mesmas regressões OLS. Assim, a regressão OLS fornece não apenas os coeficientes de cada equação do VAR, mas também os elementos que compõem a estimativa de máxima verossimilhança da matriz de covariância dos resíduos. Essa conexão entre OLS e MLE simplifica a implementação prática da estimação de modelos VAR.

### Implicações para Testes de Hipóteses
A obtenção da MLE de $\Omega$ é crucial para a realização de testes de hipóteses em modelos VAR. Com a matriz de covariância estimada, é possível realizar testes de razão de verossimilhança e outras análises estatísticas. No tópico a seguir, por exemplo, será abordado o teste de razão de verossimilhança para determinar o número apropriado de defasagens em um modelo VAR [^1].

### Conclusão

A derivação da MLE para $\Omega$ demonstrou que a matriz de covariância das inovações pode ser estimada de forma eficiente através do cálculo dos produtos médios dos resíduos da regressão OLS. Este processo completa a estimativa dos parâmetros de um modelo VAR não restrito, que consiste em $\hat{\Pi}$ e  $\hat{\Omega}$.  Com esses resultados, estabelece-se um mecanismo para calcular os estimadores de máxima verossimilhança, que são essenciais para testes de hipóteses, e análise de causalidade, bem como inferências estatísticas em modelos VAR. O próximo passo é explorar a utilização desses resultados para a análise do número de defasagens apropriado em um modelo VAR.

### Referências
[^1]:  "...the likelihood function and the value of 0 that maximizes [11.1.2] as the “max-imum likelihood estimate.”"
[11.1.25]:  "L($\Omega$, $\hat{\Pi}$) = - (Tn/2) log(2$\pi$) + (T/2) log|$\Omega^{-1}$| - (1/2) $\sum_{t=1}^{T}$ $\hat{\epsilon}$'$_t$$\Omega^{-1}$$\hat{\epsilon}$$_t$."
[11.1.26]: "$\frac{\partial \mathcal{L}(\Omega, \hat{\Pi})}{\partial \Omega^{-1}}$ = (T/2)$\Omega$ - (1/2) $\sum_{t=1}^{T}$ $\hat{\epsilon}$$_t$$\hat{\epsilon}$'$_{t}$"
[11.1.27]: "The likelihood is maximized when this derivative is set to zero, or when   $\hat{\Omega}$  = (1/T)$\sum_{t=1}^{T}$ $\hat{\epsilon}$$_t$$\hat{\epsilon}$'$_{t}$."
[11.1.29]: "The row i, column i element of $\Omega$ is given by   $\hat{\sigma}$$_{ii}$ = (1/T) $\sum_{t=1}^{T}$ $\hat{\epsilon}$$_{it}^2$, which is just the average squared residual from a regression of the ith variable in the VAR on a constant term and p lags of all the variables."
[11.1.30]: "The row i, column j element of $\Omega$ is  $\hat{\sigma}$$_{ij}$  = (1/T) $\sum_{t=1}^{T}$ $\hat{\epsilon}$$_{it}$$\hat{\epsilon}$$_{jt}$ , which is the average product of the OLS residual for variable i and the OLS residual for variable j."
<!-- END -->
