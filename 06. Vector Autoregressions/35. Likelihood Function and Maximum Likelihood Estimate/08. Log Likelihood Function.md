## A Função de Log-Verossimilhança em Modelos VAR: Simplificação e Otimização

### Introdução
Este capítulo aprofunda a análise da **função de log-verossimilhança** em modelos de vetores autorregressivos (VAR), destacando sua importância na simplificação dos cálculos e na busca pelo **estimador de máxima verossimilhança** (MLE). Conforme discutido em capítulos anteriores [^1], a função de verossimilhança é uma ferramenta fundamental para a estimação de parâmetros em modelos estatísticos, e a MLE é o valor dos parâmetros que maximiza essa função. Este capítulo se concentra na derivação e interpretação da função de log-verossimilhança, demonstrando como ela facilita a aplicação de métodos numéricos para encontrar as estimativas dos parâmetros de modelos VAR. Além disso, estabelecemos a conexão desta função com a obtenção das estimativas de máxima verossimilhança de $\Pi$ e $\Omega$, construindo sobre o conhecimento dos capítulos anteriores.

### A Função de Log-Verossimilhança em Modelos VAR
Como vimos, a função de verossimilhança para um modelo VAR é expressa como o produto das densidades condicionais das observações [^2]:
$$
f(y_T, y_{T-1}, \ldots, y_1 | y_0, y_{-1}, \ldots, y_{-p+1}; \theta) = \prod_{t=1}^{T} f(y_t | y_{t-1}, y_{t-2}, \ldots, y_{t-p+1}; \theta)
$$
[11.1.9]
onde:
$$
f(y_t | y_{t-1}, y_{t-2}, \ldots, y_{t-p+1}; \theta) = (2\pi)^{-n/2} |\Omega|^{-1/2} \exp\left(-\frac{1}{2}(y_t - \Pi'x_t)'\Omega^{-1}(y_t - \Pi'x_t)\right)
$$
[11.1.8]
Onde $\theta$ representa o conjunto de parâmetros a serem estimados ($\Pi$ e $\Omega$). Em vez de maximizar a função de verossimilhança original,  é mais conveniente maximizar o seu logaritmo, resultando na **função de log-verossimilhança**, dada por [^3]:
$$
\mathcal{L}(\theta) = \sum_{t=1}^{T} \log f(y_t | y_{t-1}, y_{t-2}, \ldots, y_{t-p+1}; \theta)
$$
Ao substituir a expressão da densidade condicional, obtemos:
$$
\mathcal{L}(\theta) = -(Tn/2) \log(2\pi) + (T/2) \log|\Omega^{-1}| - \frac{1}{2} \sum_{t=1}^{T} (y_t - \Pi'x_t)'\Omega^{-1}(y_t - \Pi'x_t)
$$
[11.1.10]
Essa expressão,  $\mathcal{L}(\theta)$,  é a função de log-verossimilhança para um modelo VAR, e é a forma que é geralmente usada na estimação dos parâmetros por máxima verossimilhança.

### Vantagens de Usar a Função de Log-Verossimilhança
O uso da função de log-verossimilhança oferece diversas vantagens em relação à função de verossimilhança original, incluindo:
1. **Simplificação dos Cálculos:** A operação de logaritmo transforma o produto de densidades em uma soma de logaritmos, o que simplifica os cálculos e a derivação analítica.
2. **Transformação de Produtos em Somas:** A função logarítmica transforma o produto de probabilidades em uma soma, o que facilita a otimização. A soma é geralmente mais fácil de manipular que o produto.
3. **Função Mais Concava:** O logaritmo transforma a função de verossimilhança em uma função mais côncava, o que facilita a busca do máximo global e diminui a probabilidade de encontrar máximos locais.
4.  **Propriedades Assintóticas:** O uso da função de log-verossimilhança permite que as propriedades assintóticas dos estimadores sejam obtidas e seus erros padrões sejam derivados.

Essas propriedades tornam a função de log-verossimilhança mais adequada para a aplicação de métodos numéricos de otimização, e para derivar as propriedades dos estimadores de máxima verossimilhança.

### Maximizar a Função de Log-Verossimilhança
A obtenção das estimativas de máxima verossimilhança (MLE) envolve a maximização da função de log-verossimilhança com respeito aos parâmetros do modelo: $\Pi$ e $\Omega$. Como discutido anteriormente, a maximização de $\mathcal{L}(\theta)$ com respeito a $\Pi$ leva à regressão OLS [^4]:

$$
\hat{\Pi}'_j = \left[ \sum_{t=1}^{T} y_{jt}x_t' \right] \left[ \sum_{t=1}^{T} x_tx_t' \right]^{-1}
$$
[11.1.12]
A maximização de $\mathcal{L}(\theta)$ com respeito a $\Omega$ leva a:
$$
\hat{\Omega} = (1/T) \sum_{t=1}^{T} \hat{\epsilon}_t \hat{\epsilon}_t'
$$
[11.1.28]
onde $\hat{\epsilon}_t = y_t - \hat{\Pi}'x_t$ são os resíduos das regressões OLS.

A função de log-verossimilhança é utilizada tanto para obter as estimativas de máxima verossimilhança dos parâmetros do modelo, quanto para realizar testes de hipóteses, como os testes de razão de verossimilhança.

### Métodos Numéricos para Otimização
Em muitos casos, a obtenção das MLE por meio de derivação analítica pode ser difícil ou impossível, especialmente em modelos mais complexos. Nesses casos, são utilizados métodos numéricos de otimização para encontrar os valores dos parâmetros que maximizam a função de log-verossimilhança. Esses métodos incluem:
1. **Gradiente Descendente:** Utiliza o gradiente da função para direcionar a busca pelo máximo.
2. **Método de Newton-Raphson:** Utiliza a segunda derivada da função para acelerar a convergência do algoritmo.
3. **Algoritmos Quasi-Newton:** Utilizam aproximações da segunda derivada para evitar o cálculo computacionalmente intensivo da Hessiana.
4. **Algoritmos Genéticos:** Utilizam simulações que imitam a evolução biológica para encontrar o máximo global da função.
5. **Algoritmos de Busca em Grade:** Avaliam a função de log-verossimilhança em uma grade de parâmetros para encontrar o máximo global.

A escolha do método de otimização depende das características da função de log-verossimilhança e da complexidade do modelo. É importante garantir que o método utilizado encontre um máximo global, e não um máximo local.

### Conexão com Resultados Anteriores
A função de log-verossimilhança apresentada neste capítulo é consistente com os resultados obtidos nos capítulos anteriores. A forma da função de log-verossimilhança justifica o uso de métodos de otimização numéricos e da regressão OLS para obter as estimativas de máxima verossimilhança dos parâmetros do modelo VAR. Em adição, a função de log-verossimilhança será usada como base para desenvolver os resultados dos testes de razão de verossimilhança.

### Implicações para Modelagem VAR
O entendimento da função de log-verossimilhança e seu papel na estimação de parâmetros é essencial para a correta aplicação de modelos VAR. Essa compreensão é fundamental para:
1.  **Interpretar os resultados:** A função de log-verossimilhança fornece uma medida da qualidade de ajuste do modelo aos dados, que é útil para avaliar a adequação do modelo e comparar entre modelos.
2.  **Realizar testes de hipóteses:** A função de log-verossimilhança é usada em testes de hipóteses, como o teste de razão de verossimilhança, para comparar modelos com diferentes restrições.
3.  **Avançar para análises adicionais:** O conhecimento das MLEs é essencial para análises como a análise de causalidade e a derivação das funções de impulso-resposta.

### Conclusão
A função de log-verossimilhança simplifica a estimação dos parâmetros em modelos VAR, transformando o problema da maximização de um produto de probabilidades em um problema de maximização de uma soma. Ela fornece uma medida da probabilidade dos dados, dados os parâmetros do modelo, e é a base para a obtenção dos estimadores de máxima verossimilhança, quer por meio de regressão OLS ou por algoritmos de otimização numérica. Além disso, esta função nos permite derivar as propriedades assintóticas dos estimadores, além de prover uma base para a realização de testes estatísticos. Este conhecimento é crucial para a aplicação correta e significativa de modelos VAR na prática.

### Referências
[^1]: "the likelihood function and the value of 0 that maximizes [11.1.2] as the “max-imum likelihood estimate.”"
[^2]:  "A função de verossimilhança para uma amostra completa, condicionada a observações iniciais, é o produto das densidades condicionais individuais, que é fundamental para a estimação de parâmetros."
[11.1.9]: "The joint density of observations 1 through t conditioned on y<sub>0</sub>, y<sub>-1</sub>,..., y<sub>-p+1</sub> satisfies $f(y_T, y_{T-1}, \ldots, y_1 | y_0, y_{-1}, \ldots, y_{-p+1}; \theta) = \prod_{t=1}^{T} f(y_t | y_{t-1}, y_{t-2}, \ldots, y_{t-p+1}; \theta)$."
[11.1.8]: "$f(y_t | y_{t-1}, y_{t-2}, \ldots, y_{t-p+1}; \theta) = (2\pi)^{-n/2}|\Omega|^{-1/2} \exp[(-1/2)(y_{t} - \Pi'x_{t})'\Omega^{-1}(y_{t} - \Pi'x_{t})]$."
[11.1.10]: "$\mathcal{L}(\theta) =  \sum_{t=1}^{T} \log f(y_t| y_{t-1}, y_{t-2}, \ldots, y_{t-p+1}; \theta) = - (Tn/2) \log(2\pi) + (T/2) \log|-\Omega^{-1}| - (1/2) \sum_{t=1}^{T} (y_{t} - \Pi'x_{t})'\Omega^{-1}(y_{t} - \Pi'x_{t})$."
[^4]: "The jth row of $\Pi'$ is  $\hat{\Pi}'_j$ = [$\sum^{T}_{t=1} y_{jt}x'_{t}$][$\sum^{T}_{t=1} x_{t}x'_{t}$]$^{-1}$. which is just the estimated coefficient vector from an OLS regression of $y_{jt}$ on $x_{t}$."
[11.1.12]: "The jth row of $\Pi'$ is  $\hat{\Pi}'_j$ = [$\sum^{T}_{t=1} y_{jt}x'_{t}$][$\sum^{T}_{t=1} x_{t}x'_{t}$]$^{-1}$. which is just the estimated coefficient vector from an OLS regression of $y_{jt}$ on $x_{t}$."
<!-- END -->
