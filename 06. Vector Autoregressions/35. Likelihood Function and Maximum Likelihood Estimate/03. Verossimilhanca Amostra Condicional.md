## A Função de Verossimilhança para Amostras Completas em Modelos VAR

### Introdução
Este capítulo se aprofunda na construção da **função de verossimilhança** para um modelo de vetores autorregressivos (VAR) considerando uma amostra completa de dados, condicionada às observações iniciais. Como vimos nos tópicos anteriores [^1], a função de verossimilhança é uma ferramenta fundamental para estimar os parâmetros de um modelo estatístico, e o estimador de máxima verossimilhança é o valor dos parâmetros que maximiza essa função [^2]. Este capítulo detalha o cálculo da função de verossimilhança para o modelo VAR, destacando como ela é derivada a partir do produto das densidades condicionais individuais. Este tópico também complementa a discussão anterior sobre a estimação de $\Pi$ e $\Omega$, fornecendo a base necessária para a realização de testes de hipóteses e inferências sobre o modelo VAR.

### Conceitos Fundamentais

A **função de verossimilhança** para uma amostra completa em um modelo VAR é construída considerando a densidade conjunta de todas as observações, condicionada a um conjunto de observações iniciais. Já vimos que a densidade condicional de uma observação *t*, dada as observações anteriores, é dada por [^3]:

$$
f(y_t | y_{t-1}, y_{t-2}, \ldots, y_{t-p+1}; \theta) = (2\pi)^{-n/2} |\Omega|^{-1/2} \exp\left(-\frac{1}{2}(y_t - \Pi'x_t)'\Omega^{-1}(y_t - \Pi'x_t)\right)
$$
[11.1.8]

Para construir a função de verossimilhança da amostra completa, é necessário considerar a **densidade conjunta** de todas as observações de 1 a *T*, condicionada às *p* observações iniciais, isto é,  $y_0, y_{-1}, \ldots, y_{-p+1}$. Essa densidade conjunta é expressa como o produto das densidades condicionais individuais:

$$
f(y_T, y_{T-1}, \ldots, y_1 | y_0, y_{-1}, \ldots, y_{-p+1}; \theta) = \prod_{t=1}^{T} f(y_t | y_{t-1}, y_{t-2}, \ldots, y_{t-p+1}; \theta)
$$
[11.1.9]

Essa expressão representa a probabilidade de observar a sequência de dados de *1* a *T*, dadas as observações iniciais e os parâmetros do modelo, e serve como base para a função de verossimilhança.

Para facilitar os cálculos e a interpretação, toma-se o logaritmo da função de verossimilhança, obtendo a **função de log-verossimilhança**:

$$
\mathcal{L}(\theta) = \sum_{t=1}^{T} \log f(y_t | y_{t-1}, y_{t-2}, \ldots, y_{t-p+1}; \theta)
$$
Substituindo a expressão da densidade condicional [11.1.8] em [11.1.9] e tomando o logaritmo, obtemos:

$$
\mathcal{L}(\theta) = -(Tn/2) \log(2\pi) + (T/2) \log|\Omega^{-1}| - \frac{1}{2} \sum_{t=1}^{T} (y_t - \Pi'x_t)'\Omega^{-1}(y_t - \Pi'x_t)
$$
[11.1.10]

Essa função,  $\mathcal{L}(\theta)$,  é a função de log-verossimilhança da amostra completa e expressa a probabilidade de observar a amostra completa, dados os parâmetros do modelo. A maximização dessa função em relação aos parâmetros $\Pi$ e $\Omega$ leva às **estimativas de máxima verossimilhança** (MLE).

O primeiro termo, -(Tn/2)log(2π), é uma constante e não depende dos parâmetros $\Pi$ e $\Omega$. O segundo termo, (T/2)log|$|\Omega^{-1}$|, depende da matriz de covariância dos resíduos, e o terceiro termo, $-\frac{1}{2} \sum_{t=1}^{T} (y_t - \Pi'x_t)'\Omega^{-1}(y_t - \Pi'x_t)$, depende tanto dos coeficientes $\Pi$ quanto da matriz de covariância $\Omega$. A MLE dos parâmetros é encontrada maximizando a função de log-verossimilhança em relação a esses parâmetros.

### Conexão com Resultados Anteriores
A forma da função de log-verossimilhança apresentada aqui é consistente com os resultados derivados em capítulos anteriores. A maximização desta função leva às MLE para os parâmetros $\Pi$ e $\Omega$ como já demonstrado [^4]. A MLE de $\Pi$ é obtida através de regressões OLS, e a MLE de $\Omega$ é dada pela matriz de covariância amostral dos resíduos dessas regressões.

### Implicações para Análise de Séries Temporais
O conhecimento da função de verossimilhança para uma amostra completa é essencial para diversas aplicações em modelos VAR, incluindo:

1.  **Estimação de Parâmetros**: A função de verossimilhança permite obter as estimativas de máxima verossimilhança dos parâmetros do modelo, que são as estimativas mais eficientes, sob certas condições.

2.  **Testes de Hipóteses**: A função de verossimilhança é a base para os testes de razão de verossimilhança (LR), que são utilizados para comparar a qualidade do ajuste entre modelos com diferentes restrições.

3.  **Seleção de Modelo**: O valor da função de verossimilhança (ou o valor de critérios de informação como AIC e BIC) pode ser usado para comparar modelos com diferentes números de defasagens, auxiliando na escolha da estrutura mais apropriada para o modelo VAR.

### Conclusão
A construção da função de verossimilhança para uma amostra completa, condicionada às observações iniciais, fornece uma base sólida para a estimação e inferência em modelos VAR. Compreendemos que a função é o produto das densidades condicionais individuais e que a sua maximização nos permite obter as estimativas de máxima verossimilhança para os parâmetros $\Pi$ e $\Omega$. Esses resultados preparam o terreno para a discussão de testes de hipóteses e análises mais avançadas, como a análise de causalidade de Granger e as funções de impulso-resposta. A compreensão detalhada da função de verossimilhança é essencial para uma aplicação correta e interpretação significativa de modelos VAR.

### Referências
[^1]: "The likelihood function is calculated in the same way as for a scalar auto-regression."
[^2]: "...the likelihood function and the value of 0 that maximizes [11.1.2] as the “max-imum likelihood estimate."
[^3]:  "f(y<sub>t</sub> | y<sub>t-1</sub>, y<sub>t-2</sub>, ..., y<sub>t-p+1</sub>; θ) = (2π)<sup>-n/2</sup>|Ω|<sup>-1/2</sup> exp[(-1/2)(y<sub>t</sub> - Π'x<sub>t</sub>)'Ω<sup>-1</sup>(y<sub>t</sub> - Π'x<sub>t</sub>)]."
[^4]: "The jth row of Π' is  $\hat{\Pi}'_j$ = [∑<sup>T</sup><sub>t=1</sub> y<sub>jt</sub>x'<sub>t</sub>][∑<sup>T</sup><sub>t=1</sub> x<sub>t</sub>x'<sub>t</sub>]<sup>-1</sup>. which is just the estimated coefficient vector from an OLS regression of y<sub>jt</sub> on x<sub>t</sub>."
[11.1.8]:  "f(y<sub>t</sub> | y<sub>t-1</sub>, y<sub>t-2</sub>, ..., y<sub>t-p+1</sub>; θ) = (2π)<sup>-n/2</sup>|Ω|<sup>-1/2</sup> exp[(-1/2)(y<sub>t</sub> - Π'x<sub>t</sub>)'Ω<sup>-1</sup>(y<sub>t</sub> - Π'x<sub>t</sub>)]."
[11.1.9]: "The joint density of observations 1 through t conditioned on y<sub>0</sub>, y<sub>-1</sub>,..., y<sub>-p+1</sub> satisfies f(y<sub>T</sub>, y<sub>T-1</sub>, ..., y<sub>1</sub> | y<sub>0</sub>, y<sub>-1</sub>, ..., y<sub>-p+1</sub>; θ) = ∏<sub>t=1</sub><sup>T</sup> f(y<sub>t</sub> | y<sub>t-1</sub>, y<sub>t-2</sub>, ..., y<sub>t-p+1</sub>; θ)."
[11.1.10]: "L(θ) =  ∑<sub>t=1</sub><sup>T</sup> log f(y<sub>t</sub>| y<sub>t-1</sub>, y<sub>t-2</sub>, ..., y<sub>t-p+1</sub>; θ) = - (Tn/2) log(2π) + (T/2) log|-Ω<sup>-1</sup>| - (1/2) ∑<sub>t=1</sub><sup>T</sup> (y<sub>t</sub> - Π'x<sub>t</sub>)'Ω<sup>-1</sup>(y<sub>t</sub> - Π'x<sub>t</sub>)."
<!-- END -->
