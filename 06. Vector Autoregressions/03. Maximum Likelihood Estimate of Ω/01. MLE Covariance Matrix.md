## Estimação de Máxima Verossimilhança de $\Omega$

### Introdução
Neste capítulo, exploramos em detalhes a estimação de máxima verossimilhança (MLE) para modelos de Vetores Autorregressivos (VAR). Como vimos anteriormente [^2], o modelo VAR é uma ferramenta poderosa para análise de séries temporais multivariadas, e a estimação de seus parâmetros é crucial para inferências e previsões precisas. Agora, focaremos especificamente na obtenção da MLE da matriz de covariância residual $\Omega$, um componente fundamental para a compreensão da variabilidade e correlação dos erros no sistema VAR. A estimativa da MLE para $\Omega$ envolve a maximização da função de log-verossimilhança, um processo que requer o uso de resultados do cálculo matricial e álgebra linear.

### Conceitos Fundamentais
A função de verossimilhança condicional para o modelo VAR é dada por [^1]
$$f(y_t | y_{t-1}, y_{t-2}, \ldots, y_{t-p}; \Theta) \sim N(\Pi'x_t, \Omega)$$.
Onde $y_t$ é o vetor de observações no tempo $t$, $x_t$ é o vetor de termos constantes e lags de y, $\Pi$ é a matriz de parâmetros, e $\Omega$ é a matriz de covariância dos resíduos. O log da função de verossimilhança para o modelo VAR é expresso como [^2]:
$$L(\Theta) = -\frac{Tn}{2} \log(2\pi) + \frac{T}{2} \log|\Omega^{-1}| - \frac{1}{2} \sum_{t=1}^{T} (y_t - \Pi'x_t)'\Omega^{-1}(y_t - \Pi'x_t)$$ [11.1.10].
Nosso objetivo agora é encontrar a matriz $\Omega$ que maximiza essa função. Para isso, utilizaremos resultados do cálculo matricial.

Para encontrar a MLE de $\Omega$, primeiro precisamos obter as derivadas da função log-verossimilhança em relação aos elementos de $\Omega^{-1}$. Utilizando resultados de [^2] como [11.1.20] e [11.1.22], que apresentam as derivadas de formas quadráticas e do determinante de uma matriz, respectivamente.
A derivada de uma forma quadrática em uma matriz é expressa como:
$$\frac{\partial x'Ax}{\partial A} = xx'$$ [11.1.20]
E a derivada do log do determinante de uma matriz é dada por:
$$\frac{\partial \log|A|}{\partial A} = (A^{-1})'$$ [11.1.21]

Aplicando esses resultados, e lembrando que $\Omega$ é uma matriz simétrica positiva definida, a função de verossimilhança logarítmica pode ser reescrita como [^2]:
$$\mathcal{L}(\Omega, \hat{\Pi}) = -\frac{Tn}{2} \log(2\pi) + \frac{T}{2} \log|\Omega^{-1}| - \frac{1}{2} \sum_{t=1}^{T} \hat{\epsilon}_t'\Omega^{-1} \hat{\epsilon}_t$$ [11.1.25]
onde $\hat{\epsilon}_t$ são os resíduos da regressão OLS de $y_t$ em $x_t$, ou seja, $\hat{\epsilon}_t = y_t - \hat{\Pi}'x_t$ [11.1.14]. Para facilitar a diferenciação, podemos expressar o log-determinante da inversa da matriz como $\log|\Omega^{-1}| = -\log|\Omega|$, o que nos permite aplicar os resultados conhecidos sobre derivadas matriciais [^2].

Diferenciando a função de log-verossimilhança [11.1.25] em relação a $\Omega^{-1}$ e igualando a zero para encontrar o máximo, obtemos [^2]:
$$\frac{\partial \mathcal{L}(\Omega, \hat{\Pi})}{\partial \Omega^{-1}} = \frac{T}{2}\Omega - \frac{1}{2} \sum_{t=1}^{T} \hat{\epsilon}_t\hat{\epsilon}_t' = 0$$ [11.1.26]
Resolvendo para $\Omega$ temos:
$$\Omega = \frac{1}{T} \sum_{t=1}^{T} \hat{\epsilon}_t\hat{\epsilon}_t'$$ [11.1.27]
Essa é a MLE para a matriz de covariância $\Omega$ do modelo VAR. O estimador é a média da soma dos produtos dos resíduos, e pode ser interpretado como a média amostral da matriz de covariância dos erros.

Para formalizar a prova de [11.1.27] e explicitar a importância do operador “traço” na sua obtenção, detalhamos os passos intermediários [^2]. Partimos da soma na função de verossimilhança, e aplicando o operador traço, temos:
$$\sum_{t=1}^{T} (y_t - \Pi'x_t)' \Omega^{-1} (y_t - \Pi'x_t) = \sum_{t=1}^{T} \text{trace}[(y_t - \Pi'x_t)' \Omega^{-1} (y_t - \Pi'x_t)]$$
Como o traço de um escalar é o próprio escalar e usando a propriedade do traço para permutar a ordem do produto cíclico, podemos escrever [^2]:
$$\sum_{t=1}^{T} \text{trace}[(y_t - \Pi'x_t)' \Omega^{-1} (y_t - \Pi'x_t)] = \sum_{t=1}^{T} \text{trace}[\Omega^{-1} (y_t - \Pi'x_t)(y_t - \Pi'x_t)']$$
A expressão pode ser reescrita como [^2]:
$$\sum_{t=1}^{T} \text{trace}[\Omega^{-1} \hat{\epsilon}_t \hat{\epsilon}_t'] = \text{trace} [\Omega^{-1} \sum_{t=1}^{T} \hat{\epsilon}_t \hat{\epsilon}_t']$$
A derivada da função de verossimilhança em relação a $\Omega^{-1}$ é dada por [^2]:
$$\frac{\partial}{\partial \Omega^{-1}} \left(-\frac{1}{2} \sum_{t=1}^{T} \hat{\epsilon}_t'\Omega^{-1} \hat{\epsilon}_t \right) = -\frac{1}{2} \sum_{t=1}^{T} \hat{\epsilon}_t\hat{\epsilon}_t'$$
E da derivada em relação a $\log|\Omega^{-1}|$ [^2]:
$$\frac{\partial}{\partial \Omega^{-1}} \left( \frac{T}{2} \log|\Omega^{-1}| \right) = \frac{T}{2}\Omega$$

Igualando a derivada total da função de verossimilhança a zero, obtemos [^2]:
$$\frac{T}{2}\Omega - \frac{1}{2} \sum_{t=1}^{T} \hat{\epsilon}_t\hat{\epsilon}_t' = 0$$
E consequentemente, a MLE para a matriz de covariância, como já estabelecido:
$$\hat{\Omega} = \frac{1}{T}\sum_{t=1}^{T} \hat{\epsilon}_t\hat{\epsilon}_t'$$ [11.1.27]
onde $\hat{\epsilon}_t$ são os resíduos OLS da regressão de $y_t$ em $x_t$. Este resultado formaliza a obtenção da estimativa de máxima verossimilhança de $\Omega$ através do cálculo matricial e da aplicação do operador “traço”.

### Conclusão
Neste capítulo, detalhamos o processo de estimação da MLE para a matriz de covariância $\Omega$ em modelos VAR. Através do uso de técnicas de cálculo matricial e propriedades do traço, derivamos o estimador de máxima verossimilhança, que corresponde à média da soma dos produtos dos resíduos. Este resultado é fundamental para a estimação de modelos VAR, pois permite uma compreensão precisa da variabilidade e correlação dos erros. Como vimos, a obtenção da MLE de $\Omega$ envolve a maximização da função de log-verossimilhança, um processo que combina resultados de otimização e álgebra linear, evidenciando a importância desses conceitos para a análise de séries temporais multivariadas.

### Referências
[^1]:  *página 1*, [11.1.10]
[^2]:  *página 1-3*, [11.1.27], [11.1.26], [11.1.25], [11.1.20], [11.1.21], [11.1.14]
<!-- END -->
