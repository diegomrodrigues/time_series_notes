## Estimativa de Máxima Verossimilhança de Π em Modelos VAR
### Introdução
Este capítulo aborda a estimativa de parâmetros em modelos de Vetores Auto-regressivos (VAR). Em particular, focaremos na derivação da estimativa de máxima verossimilhança (MLE) da matriz Π, que contém os termos constantes e os coeficientes auto-regressivos do modelo. O modelo VAR, como apresentado anteriormente, é fundamental para a análise de séries temporais multivariadas, onde as relações dinâmicas entre múltiplas variáveis são investigadas [^1].

### Conceitos Fundamentais
A função de verossimilhança para um modelo VAR, condicional aos valores observados de $y$ até o instante $t-1$, é dada por [^1]:
$$
f(y_t | y_{t-1}, y_{t-2}, \ldots, y_{t-p}; \theta) \sim N(c + \Phi_1 y_{t-1} + \Phi_2 y_{t-2} + \ldots + \Phi_p y_{t-p}, \Omega)
$$
onde $c$ é um vetor constante,  $\Phi_1$, ..., $\Phi_p$ são as matrizes de coeficientes auto-regressivos, e $\Omega$ é a matriz de covariância dos erros.

Para derivar a estimativa de máxima verossimilhança (MLE) de Π, primeiro representamos a média condicional de forma mais compacta. Definimos $x_t$ como um vetor contendo um termo constante e as defasagens $p$ de cada elemento de $y$ [^1]:
$$
x_t = \begin{bmatrix}
1 \\
y_{t-1} \\
y_{t-2} \\
\vdots \\
y_{t-p}
\end{bmatrix}
$$
onde $x_t$ é um vetor de dimensão $(np + 1) \times 1$.  Definimos também Π' como a matriz de dimensão $n \times (np + 1)$ [^1]:
$$
\Pi' = \begin{bmatrix}
c & \Phi_1 & \Phi_2 & \cdots & \Phi_p
\end{bmatrix}
$$

Com essa notação, a média condicional pode ser expressa como Π' $x_t$, e a densidade condicional da t-ésima observação é dada por [^1]:
$$
f(y_t | y_{t-1}, y_{t-2}, \ldots, y_{t-p}; \theta) = (2\pi)^{-n/2}|\Omega|^{-1/2} \exp[(-1/2)(y_t - \Pi'x_t)'\Omega^{-1}(y_t - \Pi'x_t)].
$$
A função de log-verossimilhança para uma amostra completa, condicionada a $y_0$, $y_{-1}$, ..., $y_{-p+1}$, é dada por [^1]:
$$
\mathcal{L}(\theta) = \sum_{t=1}^T \log f(y_t | y_{t-1}, \ldots, y_{t-p}; \theta) = - (Tn/2) \log(2\pi) + (T/2) \log|\Omega^{-1}| - (1/2) \sum_{t=1}^T (y_t - \Pi'x_t)'\Omega^{-1}(y_t - \Pi'x_t)
$$
A MLE de Π é obtida maximizando esta função de log-verossimilhança ou, equivalentemente, minimizando o termo quadrático na soma [^1].

A MLE de Π, denotada por $\hat{\Pi}'$, é dada por [^1]:
$$
\hat{\Pi}' = \left[ \sum_{t=1}^T y_t x_t' \right] \left[ \sum_{t=1}^T x_t x_t' \right]^{-1}
$$
Esta solução representa o análogo amostral da projeção linear da população de $y_t$ sobre uma constante e $x_t$. Cada linha $j$ de $\hat{\Pi}'$ é o vetor de coeficientes estimado por regressão OLS de $y_{jt}$ em $x_t$ [^1].  Para verificar que esta solução maximiza a verossimilhança, podemos escrever a soma que aparece no último termo da equação da log-verossimilhança e manipular os termos para mostrar que os valores estimados correspondem a OLS [^1]:
$$
\sum_{t=1}^T (y_t - \Pi'x_t)'\Omega^{-1}(y_t - \Pi'x_t)
= \sum_{t=1}^T (\hat{\epsilon}_t + (\hat{\Pi}' - \Pi')x_t)'\Omega^{-1}(\hat{\epsilon}_t + (\hat{\Pi}' - \Pi')x_t),
$$
onde $\hat{\epsilon}_t$ são os resíduos de uma regressão OLS de $y_t$ em $x_t$ [^1]. A expansão desta expressão inclui um termo quadrático em relação à diferença entre os estimadores e os parâmetros verdadeiros, e um termo com os resíduos, e a minimização dessa expressão leva à solução de regressão OLS [^1]. Este resultado mostra que a MLE dos coeficientes em um VAR pode ser calculada através da aplicação de regressões OLS separadas para cada equação do modelo.  Cada linha do MLE de $\hat{\Pi}'$ é equivalente ao vetor de coeficientes estimados por regressão OLS da respectiva variável dependente em uma constante e todas as variáveis defasadas no sistema [^1].

A MLE da matriz Π é, portanto, obtida ao calcular separadamente as regressões OLS para cada equação do sistema VAR. Cada linha da matriz $\hat{\Pi}'$ corresponde aos coeficientes obtidos por essa regressão [^1].  Este resultado simplifica enormemente a estimativa de modelos VAR, pois ela pode ser realizada com técnicas de regressão padrão. A MLE de Π' é a solução da amostra análoga à projeção linear da população de $y_t$ em $x_t$, onde cada linha de $\hat{\Pi}'$ corresponde a uma regressão OLS separada de $y_{jt}$ sobre $x_t$ [^1].

### Conclusão
Em resumo, a estimativa de máxima verossimilhança da matriz Π em modelos VAR é obtida através da realização de regressões OLS separadas para cada equação do sistema, o que simplifica a computação. Cada linha de Π corresponde a um vetor de coeficientes obtido por regressão OLS de cada variável dependente em um termo constante e as defasagens das variáveis do sistema. Este resultado fornece uma conexão direta entre a teoria da máxima verossimilhança e as técnicas de regressão linear padrão, e estabelece uma base computacional robusta para a análise de modelos VAR [^1].

### Referências
[^1]: Texto fornecido para análise
<!-- END -->
