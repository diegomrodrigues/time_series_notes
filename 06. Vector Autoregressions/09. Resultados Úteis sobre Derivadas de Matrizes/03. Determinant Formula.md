## Resultados Úteis sobre Derivadas de Matrizes em Modelos VAR

### Introdução
Este capítulo aborda a estimação e testes de hipóteses em modelos de Vetores Auto-regressivos (VAR), utilizando ferramentas matemáticas avançadas. Como vimos anteriormente, o cálculo de derivadas de matrizes é crucial para derivar estimadores de máxima verossimilhança em modelos VAR, em particular, resultados envolvendo determinantes de matrizes são peças chaves para a estimação desses modelos [^2]. Nesta seção, aprofundaremos a nossa compreensão sobre o determinante de uma matriz e sua fórmula, que é essencial para entender a derivação da sua derivada.

### Conceitos Fundamentais
Como vimos anteriormente, para derivar os estimadores de máxima verossimilhança (MLE) de $\Pi$ e $\Omega$, necessitamos de resultados do cálculo matricial, incluindo a derivada do determinante de uma matriz [^2]. Recordamos que a derivada do determinante de uma matriz $A$ é essencial para maximizar a função de verossimilhança.

1. **Determinante de uma Matriz**:
   O determinante de uma matriz $A$, denotado por $|A|$, é um escalar que fornece informações cruciais sobre a matriz. Ele indica se a matriz é invertível (determinante diferente de zero), e aparece em diversos contextos na matemática e estatística, incluindo a otimização da função de verossimilhança em modelos VAR.
   
   A fórmula geral para o determinante de uma matriz $A$ de ordem $n \times n$ é dada por:
   $$|A| = \sum_{j=1}^{n} (-1)^{i+j} a_{ij} |A_{ij}|$$ [^4, 11.1.23]
   onde $i$ é qualquer linha fixa, $a_{ij}$ é o elemento da linha $i$, coluna $j$ de $A$ e $|A_{ij}|$ é o determinante da submatriz $(n-1) \times (n-1)$ obtida pela remoção da linha $i$ e coluna $j$ da matriz $A$.  Esta fórmula expressa o determinante de $A$ como uma soma alternada de produtos envolvendo elementos da matriz e seus cofatores.

   *Detalhes Matemáticos:*
   O determinante pode ser computado através da expansão de Laplace, onde escolhemos uma linha (ou coluna) da matriz e expressamos o determinante como uma soma ponderada dos determinantes de matrizes menores. Cada termo na soma é o produto de um elemento da linha/coluna escolhida por seu cofator (que é o determinante da matriz menor, multiplicado por -1 elevado a soma dos índices da linha e coluna).

   *Propriedades Importantes*:
    - O determinante de uma matriz identidade é 1.
    - Se duas linhas (ou colunas) de uma matriz são trocadas, o determinante troca de sinal.
    - Se uma linha (ou coluna) de uma matriz é multiplicada por um escalar, o determinante é multiplicado por esse escalar.
    - Se duas linhas (ou colunas) de uma matriz são iguais, o determinante é zero.
    - O determinante de uma matriz triangular (superior ou inferior) é o produto dos elementos da diagonal principal.
  
   *Implicações na Prática:*
   Na prática, o cálculo do determinante através da fórmula de expansão de Laplace pode se tornar computacionalmente custoso para matrizes grandes, por isso há algoritmos mais eficientes que usam decomposições matriciais. Em nosso contexto de modelos VAR, o determinante da matriz de covariância dos erros ($\Omega$) aparece na função de verossimilhança, tornando seu cálculo essencial para obter as estimativas dos parâmetros do modelo.

   A derivada do logaritmo do determinante de $A$ em relação a um elemento $a_{ij}$ é, como mostrado na seção anterior, dada por:
   $$\frac{\partial \log|A|}{\partial a_{ij}} = a^{ji}$$ [^4, 11.1.21]
   onde $a^{ji}$ é o elemento linha $j$, coluna $i$ da matriz inversa $A^{-1}$. Em forma matricial, temos:
   $$\frac{\partial \log|A|}{\partial A} = (A^{-1})'$$ [^4, 11.1.22]
  
   Este resultado é obtido usando a regra da cadeia e a fórmula do cofator para o determinante, que como vimos, estabelece a relação com a matriz inversa de $A$.

**Exemplo**:
   Para ilustrar a fórmula do determinante, considere uma matriz A de dimensão $2 \times 2$:
    $$
    A = \begin{bmatrix}
    a_{11} & a_{12} \\
    a_{21} & a_{22}
    \end{bmatrix}
    $$
   Usando a primeira linha para a expansão de Laplace, o determinante é:
   $$
   |A| = a_{11} |A_{11}| - a_{12} |A_{12}|
   $$
   Onde:
     - $|A_{11}| = a_{22}$, é o determinante da submatriz obtida pela remoção da primeira linha e primeira coluna.
     - $|A_{12}| = a_{21}$, é o determinante da submatriz obtida pela remoção da primeira linha e segunda coluna.

   Assim:
   $$
   |A| = a_{11} a_{22} - a_{12} a_{21}
   $$

   Este é um exemplo simples da fórmula geral para o determinante de uma matriz, e demonstra que a computação do determinante de A pode ser feita usando seus elementos e submatrizes.

### Conclusão
A fórmula do determinante de uma matriz, como demonstrada, é uma soma alternada de produtos envolvendo elementos da matriz e seus cofatores [^4, 11.1.23], expressando o determinante como uma função das combinações desses elementos. Este conceito é fundamental em diversas áreas da matemática e estatística, sendo de grande importância para a estimação de parâmetros em modelos VAR, onde o determinante da matriz de covariância dos erros aparece na função de verossimilhança. A derivação da sua derivada, como vimos, leva a um resultado importante envolvendo os elementos da inversa da matriz transposta. Este resultado será crucial nas próximas seções onde exploraremos a estimação por máxima verossimilhança em modelos VAR.

### Referências
[^2]:  Os resultados apresentados nesta seção são essenciais para o entendimento da estimação de máxima verossimilhança nos modelos VAR, sendo a base para os desenvolvimentos das próximas seções do capítulo.
[^3]:  As equações 11.1.18 e 11.1.19 definem a derivada de uma forma quadrática com respeito a elementos de uma matriz.
[^4]: As equações 11.1.20, 11.1.21, 11.1.22, 11.1.23 e 11.1.24 definem a derivada do determinante de uma matriz com respeito a seus elementos, utilizando a regra da cadeia e a fórmula do cofator.
<!-- END -->
