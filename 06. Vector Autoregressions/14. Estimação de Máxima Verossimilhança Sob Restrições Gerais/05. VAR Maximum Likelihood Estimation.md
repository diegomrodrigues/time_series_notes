## Estimação de Máxima Verossimilhança Sob Restrições Gerais em Modelos VAR

### Introdução
Este capítulo expande o conceito de **estimação de máxima verossimilhança** (MLE) apresentado anteriormente em modelos de vetores autorregressivos (VAR) não restritos, discutindo agora a estimativa sob restrições gerais nos coeficientes. Enquanto a seção anterior focava em sistemas VAR onde cada equação tinha as mesmas variáveis explicativas, esta seção aborda o cenário onde restrições, que não podem ser expressas de forma recursiva por blocos, são impostas aos coeficientes do modelo. Este problema de otimização com restrições é um tema central no contexto de modelos VAR e necessita de uma abordagem mais sofisticada para obter estimativas consistentes e eficientes dos parâmetros. Como veremos, a **função log-verossimilhança** para este modelo pode ser escrita de forma a facilitar a estimação dos parâmetros, permitindo uma abordagem sistemática para lidar com restrições arbitrárias sobre os coeficientes.

### Conceitos Fundamentais

Em sua forma mais geral, um VAR com restrições nos coeficientes pode ser visto como um sistema de regressões aparentemente não relacionadas, conforme analisado por Zellner (1962) [^1]. Considerando um vetor *$y$* que é descrito por um modelo VAR com restrições, temos:

$y_{1t} = x'_{1t}\beta_1 + \epsilon_{1t}$
$y_{2t} = x'_{2t}\beta_2 + \epsilon_{2t}$
$...$
$y_{nt} = x'_{nt}\beta_n + \epsilon_{nt}$

Aqui, $x_{it}$ é um vetor $(k_i \times 1)$ contendo um termo constante e defasagens das variáveis que aparecem na i-ésima equação do VAR. O sistema é composto por *n* equações, onde $k_i$ denota o número de regressores na i-ésima equação. O objetivo é estimar os parâmetros $\beta_i$ e a matriz de covariância $\Omega$ que maximizam a função de verossimilhança. É importante notar que, diferentemente de um VAR não restrito, onde todas as equações compartilham o mesmo conjunto de variáveis explicativas, em um VAR com restrições gerais, cada equação pode conter um subconjunto diferente de regressores e os coeficientes podem ter relações específicas entre eles.

Como explorado anteriormente, a representação vetorial do modelo VAR torna a abordagem de máxima verossimilhança mais clara. As equações do modelo VAR podem ser escritas em forma matricial, de acordo com [^1]:

$y_t = \mathcal{X}_t \beta + \epsilon_t$,

onde $y_t$ é um vetor $(n \times 1)$ de variáveis endógenas, $\mathcal{X}_t$ é uma matriz $(n \times k)$ de regressores, $\beta$ é um vetor $(k \times 1)$ de coeficientes combinados e $\epsilon_t$ é um vetor $(n \times 1)$ de termos de erro. Aqui, $k = \sum_{i=1}^n k_i$ é o número total de regressores nas *n* equações. Esta representação unifica o modelo VAR em uma única equação vetorial, o que facilita a aplicação de técnicas de otimização para estimar os parâmetros desconhecidos.

A função de verossimilhança, como visto anteriormente [^1], pode ser escrita como:

$$
\mathcal{L}(\beta, \Omega) = - \frac{Tn}{2}\log(2\pi) + \frac{T}{2}\log|\Omega^{-1}| - \frac{1}{2} \sum_{t=1}^T (y_t - \mathcal{X}_t\beta)'\Omega^{-1}(y_t - \mathcal{X}_t\beta)
$$
onde $\mathcal{X}_t$ é uma matriz que contém os regressores correspondentes a cada equação do VAR e $\beta$ é um vetor que contém todos os coeficientes. Esta função representa a probabilidade dos dados observados dado os parâmetros do modelo.

A estimação de máxima verossimilhança para modelos VAR com restrições gerais nos coeficientes envolve um problema de otimização com restrições, onde os parâmetros são escolhidos de forma a maximizar a função de verossimilhança logarítmica, considerando as restrições impostas, de acordo com [^1]. Em particular, a função a ser minimizada é:

$$
\sum_{t=1}^T(y_t - \mathcal{X}_t\beta)'\Omega^{-1}(y_t - \mathcal{X}_t\beta) = \sum_{t=1}^T(\tilde{y}_t - \tilde{\mathcal{X}}_t\beta)'(\tilde{y}_t - \tilde{\mathcal{X}}_t\beta)
$$

onde $\tilde{y}_t = Ly_t$ e $\tilde{\mathcal{X}}_t = L\mathcal{X}_t$, com $L$ sendo a decomposição de Cholesky de $\Omega^{-1}$. Esta transformação permite que o problema de otimização seja resolvido usando regressão OLS, como discutido em [^1].

Para lidar com restrições arbitrárias sobre os coeficientes, podemos começar com estimativas iniciais dos parâmetros, como em [^1]. Por exemplo, estimativas iniciais $\beta(0)$ podem ser obtidas a partir de regressões OLS separadas para cada equação do VAR. Em seguida, a matriz $\Omega$ é estimada usando os resíduos das regressões OLS:
$$
\hat{\Omega}(0) = \frac{1}{T}\sum_{t=1}^T (y_t - \mathcal{X}_t\beta(0))(y_t - \mathcal{X}_t\beta(0))'
$$

Uma vez que $\hat{\Omega}(0)$ é calculada, uma matriz $L(0)$ tal que $(L(0))'L(0) = (\hat{\Omega}(0))^{-1}$ pode ser obtida usando fatorização de Cholesky e transformamos as variáveis originais como $\tilde{y}_t(0) = L(0)y_t$ e $\tilde{\mathcal{X}}_t(0) = L(0)\mathcal{X}_t$. A regressão OLS agrupada de $\tilde{y}_t(0)$ sobre $\tilde{\mathcal{X}}_t(0)$ fornece a nova estimativa $\beta(1)$. Este processo iterativo continua até que as estimativas convirjam, respeitando as restrições impostas.

As equações [11.3.9] a [11.3.12] e [11.3.17] a [11.3.18] desempenham um papel fundamental na compreensão da estrutura do modelo sob restrições gerais. Elas mostram como os coeficientes de modelo e a matriz de covariância estão inter-relacionados e como a função de verossimilhança pode ser decomposta para facilitar a otimização. A utilização da forma alternativa da função de verossimilhança, fornecida por [11.3.13] a [11.3.15], permite uma abordagem mais flexível para lidar com as restrições impostas aos parâmetros, como ilustrado em [^1]. Em particular, a representação da função log-verossimilhança em partes separadas, $l_{1t}$ e $l_{2t}$, permite tratar as equações do modelo VAR separadamente e aplicar diferentes métodos de estimação para cada parte.
Essa decomposição facilita a análise e a implementação de restrições em coeficientes específicos. A estimação em dois estágios, primeiro sob condições restritas e depois com os parâmetros não restritos, é uma técnica poderosa e eficiente para lidar com as complexidades que surgem nesses modelos.

### Conclusão

A estimativa de máxima verossimilhança sob restrições gerais em modelos VAR é um processo mais intrincado do que a estimativa em modelos não restritos. No entanto, ao transformar o modelo em um sistema de regressões aparentemente não relacionadas,  é possível usar técnicas de otimização bem estabelecidas para estimar os parâmetros sob as restrições impostas. Os métodos iterativos discutidos, juntamente com a representação vetorial do modelo e a decomposição da função de verossimilhança, permitem uma abordagem flexível e eficiente para lidar com as complexidades inerentes na modelagem econométrica com restrições gerais nos coeficientes. A utilização das representações alternativas da função log-verossimilhança facilita a abordagem da otimização em etapas diferentes, o que é essencial para modelos complexos.

### Referências
[^1]: *Zellner, A. (1962). An Efficient Method of Estimating Seemingly Unrelated Regressions and Tests for Aggregation Bias. Journal of the American Statistical Association, 57(298), 348–368.*
<!-- END -->
