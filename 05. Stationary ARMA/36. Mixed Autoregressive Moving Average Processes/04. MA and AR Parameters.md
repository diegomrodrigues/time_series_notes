## T√≠tulo Conciso: Par√¢metros da Representa√ß√£o MA vs. AR em Processos ARMA

### Introdu√ß√£o
Este cap√≠tulo aprofunda a an√°lise de processos mistos autorregressivos de m√©dias m√≥veis (ARMA), explorando a rela√ß√£o entre os par√¢metros nas representa√ß√µes de m√©dias m√≥veis (MA) e autorregressivas (AR) de tais processos. Como estabelecido anteriormente [^58], um processo ARMA(p, q) combina componentes AR e MA, e sua an√°lise pode ser realizada atrav√©s de diferentes perspectivas, incluindo a representa√ß√£o como um processo AR de ordem infinita ou como um processo MA de ordem infinita [^65]. Esta se√ß√£o foca em demonstrar que os par√¢metros resultantes dessas representa√ß√µes n√£o s√£o, em geral, id√™nticos, e as implica√ß√µes dessa diferen√ßa.

### Conceitos Fundamentais
Um processo ARMA(p, q) √© definido pela equa√ß√£o:

$$Y_t = c + \sum_{i=1}^{p} \phi_i Y_{t-i} + \epsilon_t + \sum_{i=1}^{q} \theta_i \epsilon_{t-i}$$

onde $Y_t$ √© o valor da s√©rie temporal no tempo $t$, $c$ √© uma constante, $\phi_i$ s√£o os coeficientes autorregressivos, $\theta_i$ s√£o os coeficientes de m√©dias m√≥veis e $\epsilon_t$ √© o termo de erro ou ru√≠do branco [^47]. A representa√ß√£o em termos do operador de defasagem $L$ √© dada por:

$$\Phi(L) Y_t = c + \Theta(L) \epsilon_t$$

onde $\Phi(L) = 1 - \sum_{i=1}^{p} \phi_i L^i$ e $\Theta(L) = 1 + \sum_{i=1}^{q} \theta_i L^i$.

**Representa√ß√£o AR Infinita (AR($\infty$))**: Se o processo ARMA(p, q) √© estacion√°rio (ou seja, as ra√≠zes do polin√¥mio $\Phi(L)$ est√£o fora do c√≠rculo unit√°rio [^57, ^67]), ele pode ser representado como um processo AR de ordem infinita [^65]:

$$Y_t = \sum_{j=1}^{\infty} \pi_j Y_{t-j} + v_t $$

ou, equivalentemente,

$$\Pi(L) Y_t = v_t $$

onde $\Pi(L) = 1 - \sum_{j=1}^{\infty} \pi_j L^j$ e $v_t$ √© um ru√≠do branco.

> üí° **Exemplo Num√©rico:** Considere um processo ARMA(1,0) (equivalente a um AR(1)) definido por $Y_t = 0.7Y_{t-1} + \epsilon_t$.  Aqui, $\phi_1 = 0.7$. A representa√ß√£o AR($\infty$) √© trivialmente $Y_t = 0.7Y_{t-1} + \epsilon_t$, assim $\pi_1 = 0.7$ e $\pi_j = 0$ para $j > 1$. Agora, considere um processo ARMA(1,1) definido por $Y_t = 0.7Y_{t-1} + \epsilon_t + 0.3\epsilon_{t-1}$.  Aqui, $\phi_1 = 0.7$ e $\theta_1 = 0.3$. Para obter a representa√ß√£o AR($\infty$), podemos reescrever a equa√ß√£o e expandir:
>
> $\epsilon_t = Y_t - 0.7Y_{t-1} - 0.3\epsilon_{t-1}$
>
> $\epsilon_{t-1} = Y_{t-1} - 0.7Y_{t-2} - 0.3\epsilon_{t-2}$
>
> Substituindo iterativamente, obtemos:
>
> $Y_t = (\phi_1 + \theta_1)Y_{t-1} - \phi_1\theta_1Y_{t-2} + \phi_1\theta_1^2 Y_{t-3} - ... + \epsilon_t$
>
> $Y_t = (0.7 + 0.3)Y_{t-1} - (0.7)(0.3)Y_{t-2} + (0.7)(0.3)^2 Y_{t-3} + ... + \epsilon_t$
>
> $Y_t = 1.0Y_{t-1} - 0.21Y_{t-2} + 0.063 Y_{t-3} + ... + \epsilon_t$
>
> Portanto, $\pi_1 = 1.0$, $\pi_2 = -0.21$, $\pi_3 = 0.063$, etc.  Note que a inclus√£o do termo MA altera significativamente os coeficientes na representa√ß√£o AR($\infty$).

**Representa√ß√£o MA Infinita (MA($\infty$))**: Se o processo ARMA(p, q) √© invert√≠vel (ou seja, as ra√≠zes do polin√¥mio $\Theta(L)$ est√£o fora do c√≠rculo unit√°rio [^65]), ele pode ser representado como um processo MA de ordem infinita:

$$Y_t = \sum_{k=0}^{\infty} \psi_k \epsilon_{t-k}$$

ou, equivalentemente,

$$Y_t = \Psi(L) \epsilon_t$$

onde $\Psi(L) = \sum_{k=0}^{\infty} \psi_k L^k$ e $\psi_0 = 1$.

> üí° **Exemplo Num√©rico:**  Continuando com o processo ARMA(1,1) do exemplo anterior, $Y_t = 0.7Y_{t-1} + \epsilon_t + 0.3\epsilon_{t-1}$, podemos derivar a representa√ß√£o MA($\infty$). Reescrevendo em termos do operador de defasagem, temos:
>
> $Y_t - 0.7LY_t = \epsilon_t + 0.3L\epsilon_t$
>
> $Y_t = (1 + 0.3L)(1 - 0.7L)^{-1} \epsilon_t$
>
> Expandindo $(1 - 0.7L)^{-1}$ como uma s√©rie geom√©trica, obtemos:
>
> $Y_t = (1 + 0.3L)(1 + 0.7L + (0.7)^2L^2 + (0.7)^3L^3 + ...) \epsilon_t$
>
> $Y_t = (1 + 0.3L + 0.7L + (0.7)(0.3)L^2 + (0.7)^2L^2 + (0.7)^2(0.3)L^3 + (0.7)^3L^3 + ... ) \epsilon_t$
>
> $Y_t = (1 + 1.0L + 0.49L^2 + 0.343L^3+ 0.147 L^3 + ...) \epsilon_t$
>
> $Y_t = \epsilon_t + 1.0 \epsilon_{t-1} + 0.49 \epsilon_{t-2} + 0.343 \epsilon_{t-3} ...$
>
> Portanto, $\psi_0 = 1$, $\psi_1 = 1.0$, $\psi_2 = 0.49$, $\psi_3 = 0.343$, etc. Comparando com o exemplo da representa√ß√£o AR($\infty$), os coeficientes $\pi_j$ e $\psi_j$ s√£o diferentes, demonstrando que as representa√ß√µes AR e MA, embora equivalentes, t√™m par√¢metros distintos.

A autocovari√¢ncia para o processo AR(p) derivada da representa√ß√£o MA infinita [^53] √© dada por:

$$\gamma_j = h_1 \lambda_1^j + h_2 \lambda_2^j + \ldots + h_p \lambda_p^j,$$
com a condi√ß√£o de que $j > q$ [^53]. A mesma fun√ß√£o de autocorrela√ß√£o para processos AR(p) [^53] √© dada por:

$$\gamma_j = g_1 \lambda_1^j + g_2 \lambda_2^j + \ldots + g_p \lambda_p^j,$$
com a condi√ß√£o de que $j > q$ [^53].

**Teorema:** Os par√¢metros $h_k$ na representa√ß√£o MA infinita e os par√¢metros $g_k$ na representa√ß√£o AR infinita n√£o s√£o os mesmos.

> üí° **Explica√ß√£o:** Esta diferen√ßa surge porque os coeficientes $h_k$ e $g_k$ s√£o determinados pelas condi√ß√µes iniciais utilizadas para resolver as equa√ß√µes de diferen√ßa que definem as autocovari√¢ncias do processo ARMA(p,q). As condi√ß√µes iniciais refletem as diferentes formas como as informa√ß√µes passadas s√£o incorporadas nas representa√ß√µes AR e MA, influenciando os pesos dos termos exponenciais $\lambda_i^j$ nas autocovari√¢ncias [^53]. Enquanto os autovalores ($\lambda_i$)  s√£o determinados pelas ra√≠zes do polin√¥mio AR, os coeficientes $h_k$ e $g_k$ refletem como cada modo exponencial √© "iniciado" a partir das condi√ß√µes iniciais em $t = 0$.

Para complementar a an√°lise da diferen√ßa entre $h_k$ e $g_k$, podemos formalizar a rela√ß√£o entre os coeficientes da representa√ß√£o ARMA e os coeficientes das representa√ß√µes AR e MA infinitas.

**Lema 6:** Dado um processo ARMA(p, q) estacion√°rio e invert√≠vel, os coeficientes $\pi_j$ da representa√ß√£o AR($\infty$) e os coeficientes $\psi_k$ da representa√ß√£o MA($\infty$) s√£o unicamente determinados pelos coeficientes $\phi_i$ e $\theta_i$ do processo ARMA(p, q).

*Demonstra√ß√£o:*
I.  Da defini√ß√£o, $\Phi(L) Y_t = \Theta(L) \epsilon_t$.
II. Para a representa√ß√£o AR($\infty$), dividimos ambos os lados por $\Theta(L)$, resultando em $\frac{\Phi(L)}{\Theta(L)} Y_t = \epsilon_t$. Dado que o processo √© invert√≠vel, podemos expandir $\frac{\Phi(L)}{\Theta(L)}$ em uma s√©rie de pot√™ncias do operador de defasagem $L$, obtendo $\Pi(L) = \frac{\Phi(L)}{\Theta(L)} = 1 - \sum_{j=1}^{\infty} \pi_j L^j$.
III. Os coeficientes $\pi_j$ s√£o obtidos igualando os coeficientes das pot√™ncias correspondentes de $L$ na equa√ß√£o acima. Portanto, os $\pi_j$ s√£o fun√ß√µes √∫nicas dos $\phi_i$ e $\theta_i$.
IV. Similarmente, para a representa√ß√£o MA($\infty$), dividimos ambos os lados por $\Phi(L)$, resultando em $Y_t = \frac{\Theta(L)}{\Phi(L)} \epsilon_t$. Dado que o processo √© estacion√°rio, podemos expandir $\frac{\Theta(L)}{\Phi(L)}$ em uma s√©rie de pot√™ncias do operador de defasagem $L$, obtendo $\Psi(L) = \frac{\Theta(L)}{\Phi(L)} = \sum_{k=0}^{\infty} \psi_k L^k$.
V. Os coeficientes $\psi_k$ s√£o obtidos igualando os coeficientes das pot√™ncias correspondentes de $L$ na equa√ß√£o acima. Portanto, os $\psi_k$ s√£o fun√ß√µes √∫nicas dos $\phi_i$ e $\theta_i$.
VI. Isso demonstra que tanto os coeficientes $\pi_j$ quanto os $\psi_k$ s√£o unicamente determinados pelos coeficientes $\phi_i$ e $\theta_i$ do processo ARMA(p, q). $\blacksquare$

Para mostrar que, em geral, $\pi_j \neq \psi_j$, podemos considerar um processo ARMA(1,1) e derivar as express√µes para $\pi_j$ e $\psi_j$.

*Exemplo:*
Considere o processo ARMA(1,1) dado por $Y_t = \phi Y_{t-1} + \epsilon_t + \theta \epsilon_{t-1}$.

I. **Representa√ß√£o AR($\infty$)**: Reescrevemos a equa√ß√£o como $\epsilon_t = Y_t - \phi Y_{t-1} - \theta \epsilon_{t-1}$. Substituindo iterativamente $\epsilon_{t-1}$, $\epsilon_{t-2}$, etc., obtemos:
$\epsilon_t = Y_t - \phi Y_{t-1} - \theta (Y_{t-1} - \phi Y_{t-2} - \theta \epsilon_{t-2}) = Y_t - (\phi + \theta)Y_{t-1} + \phi\theta Y_{t-2} + \theta^2 \epsilon_{t-2}$.

II. Continuando a substitui√ß√£o, chegamos √† forma AR($\infty$):
$Y_t = (\phi + \theta)Y_{t-1} - \phi\theta Y_{t-2} + (\phi\theta^2)Y_{t-3} - (\phi\theta^3) Y_{t-4} + \ldots + \epsilon_t$
$Y_t = \sum_{j=1}^{\infty} \pi_j Y_{t-j} + \epsilon_t$, onde $\pi_j = (\phi + \theta)(-\theta)^{j-1}$.

III. **Representa√ß√£o MA($\infty$)**: Reescrevemos a equa√ß√£o original como $Y_t - \phi Y_{t-1} = \epsilon_t + \theta \epsilon_{t-1}$, e equivalentemente, $\epsilon_t = Y_t - \phi Y_{t-1} - \theta \epsilon_{t-1}$.
Usamos o operador de defasagem $L$: $Y_t = \phi L Y_t + \epsilon_t + \theta L \epsilon_t$, ent√£o $Y_t = \frac{1 + \theta L}{1 - \phi L}\epsilon_t$.

IV. Expandindo $\frac{1}{1 - \phi L}$ como uma s√©rie geom√©trica, temos:
$Y_t = (1 + \theta L)(1 + \phi L + \phi^2 L^2 + \phi^3 L^3 + \ldots) \epsilon_t$
$Y_t = (1 + (\theta + \phi)L + \phi(\theta + \phi)L^2 + \phi^2(\theta + \phi)L^3 + \ldots)\epsilon_t$.

V.  Assim, $Y_t = \sum_{k=0}^{\infty} \psi_k \epsilon_{t-k}$, onde $\psi_0 = 1$ e $\psi_k = \phi^{k-1}(\theta + \phi)$ para $k \geq 1$.

VI. Comparando os coeficientes, temos $\pi_1 = \phi + \theta$ e $\psi_1 = \phi + \theta$. No entanto, $\pi_2 = -\phi \theta$, enquanto $\psi_2 = \phi(\theta + \phi)$. Em geral, $\pi_j \neq \psi_j$ para $j > 1$. Isso demonstra que as representa√ß√µes AR e MA infinitas t√™m coeficientes diferentes, mesmo que ambos dependam de $\phi$ e $\theta$. $\blacksquare$
<!-- END NEW ADDITION -->
> üí° **Exemplo Num√©rico:** Para ilustrar a diferen√ßa entre as representa√ß√µes AR e MA, considere o processo ARMA(1,1):
> $$Y_t = \phi_1 Y_{t-1} + \epsilon_t + \theta_1 \epsilon_{t-1}$$
> Para obter a representa√ß√£o AR($\infty$), reescrevemos a equa√ß√£o como:
> $$\epsilon_t = Y_t - \phi_1 Y_{t-1} - \theta_1 \epsilon_{t-1}$$
> Substituindo iterativamente $\epsilon_{t-1}$ na equa√ß√£o, obtemos uma representa√ß√£o AR($\infty$) da forma:
> $$Y_t = \sum_{j=1}^{\infty} \pi_j Y_{t-j} + v_t$$
> onde os coeficientes $\pi_j$ dependem tanto de $\phi_1$ quanto de $\theta_1$.
> Para obter a representa√ß√£o MA($\infty$), reescrevemos a equa√ß√£o como:
> $$Y_t = \phi_1 Y_{t-1} + \epsilon_t + \theta_1 \epsilon_{t-1}$$
> Substituindo iterativamente $Y_{t-1}$ na equa√ß√£o, obtemos uma representa√ß√£o MA($\infty$) da forma:
> $$Y_t = \sum_{k=0}^{\infty} \psi_k \epsilon_{t-k}$$
> onde os coeficientes $\psi_k$ tamb√©m dependem tanto de $\phi_1$ quanto de $\theta_1$, mas de uma maneira diferente dos coeficientes $\pi_j$. A forma funcional distinta das depend√™ncias implica que, em geral, $\pi_j \neq \psi_j$.

A diferen√ßa entre os par√¢metros $h_k$ e $g_k$ implica que, embora ambas as representa√ß√µes AR e MA infinitas capturem a mesma informa√ß√£o sobre as autocovari√¢ncias do processo ARMA(p,q), elas o fazem de maneiras distintas, com diferentes pesos nos modos exponenciais subjacentes.

Para conectar essa discuss√£o com a otimiza√ß√£o e previs√£o, podemos analisar como a escolha da representa√ß√£o (AR ou MA) afeta os algoritmos de estima√ß√£o de par√¢metros e os m√©todos de previs√£o.

**Observa√ß√£o:** Em cen√°rios pr√°ticos, a escolha entre a representa√ß√£o AR e MA pode influenciar o desempenho dos algoritmos de estima√ß√£o de par√¢metros e dos m√©todos de previs√£o. Em particular:

*   **Estima√ß√£o:** Se o processo ARMA √© mais pr√≥ximo de um processo AR puro, a estima√ß√£o dos par√¢metros $\phi_i$ pode ser mais eficiente do que a estima√ß√£o conjunta dos par√¢metros $\phi_i$ e $\theta_i$. Similarmente, se o processo √© mais pr√≥ximo de um processo MA puro, a estima√ß√£o dos par√¢metros $\theta_i$ pode ser mais eficiente.
*   **Previs√£o:** A representa√ß√£o AR √© mais adequada para previs√£o de curto prazo, pois ela se baseia diretamente nos valores passados da s√©rie temporal. A representa√ß√£o MA, por outro lado, √© mais adequada para previs√£o de longo prazo, pois ela se baseia nos choques passados que afetam a s√©rie temporal.

> üí° **Exemplo Num√©rico:**  Suponha que temos um ARMA(2,1) com $\phi_1 = 1.5$, $\phi_2 = -0.7$, e $\theta_1 = 0.2$.  Neste caso, as ra√≠zes do polin√¥mio AR s√£o $z_1 \approx 1.07$ e $z_2 \approx 1.07$ (complexas conjugadas). Como as ra√≠zes est√£o pr√≥ximas do c√≠rculo unit√°rio, a representa√ß√£o AR convergir√° lentamente e a estima√ß√£o dos par√¢metros AR ser√° mais sens√≠vel aos dados.  A representa√ß√£o MA (se invert√≠vel) pode ser mais eficiente para previs√£o de longo prazo.

Para melhorar ainda mais a compreens√£o da estacionariedade e invertibilidade, podemos introduzir um resultado que conecta as representa√ß√µes AR e MA infinitas com a fun√ß√£o de autocovari√¢ncia do processo ARMA.

**Teorema 7:** Um processo ARMA(p,q) √© estacion√°rio e invert√≠vel se e somente se sua fun√ß√£o de autocovari√¢ncia pode ser representada como uma combina√ß√£o linear de exponenciais decrescentes, com pesos determinados pelos coeficientes das representa√ß√µes AR e MA infinitas. Especificamente, existem constantes $c_i$ e $\lambda_i$ tais que $\gamma(h) = \sum_{i=1}^{max(p,q)} c_i \lambda_i^{|h|}$, onde $|\lambda_i| < 1$ para todo $i$.

*Estrat√©gia da Demonstra√ß√£o:*

A demonstra√ß√£o deste teorema envolve mostrar que a fun√ß√£o de autocovari√¢ncia de um processo ARMA estacion√°rio e invert√≠vel satisfaz uma equa√ß√£o de diferen√ßa linear homog√™nea de ordem `max(p, q)`. As solu√ß√µes desta equa√ß√£o de diferen√ßa s√£o combina√ß√µes lineares de exponenciais, onde as taxas de decaimento s√£o determinadas pelas ra√≠zes dos polin√¥mios caracter√≠sticos associados √†s partes AR e MA do processo. A estacionariedade e a invertibilidade garantem que todas essas ra√≠zes estejam dentro do c√≠rculo unit√°rio, resultando em exponenciais decrescentes. Reciprocamente, se a fun√ß√£o de autocovari√¢ncia tiver essa forma, podemos construir um processo ARMA estacion√°rio e invert√≠vel que a gere.

Al√©m disso, a estacionariedade e invertibilidade de processos ARMA podem ser analisadas utilizando ferramentas da √°lgebra linear.

**Lema:** Um processo ARMA(p,q) √© estacion√°rio e invert√≠vel se e somente se a matriz de Toeplitz associada ao processo √© definida positiva.

*Demonstra√ß√£o:*
I. A matriz de Toeplitz $T$ associada a um processo ARMA(p,q) √© constru√≠da a partir das autocovari√¢ncias do processo:
$$T = \begin{bmatrix}
\gamma_0 & \gamma_1 & \cdots & \gamma_n \\
\gamma_1 & \gamma_0 & \cdots & \gamma_{n-1} \\
\vdots & \vdots & \ddots & \vdots \\
\gamma_n & \gamma_{n-1} & \cdots & \gamma_0
\end{bmatrix}$$
II. Se o processo √© estacion√°rio e invert√≠vel, a fun√ß√£o de autocovari√¢ncia $\gamma(h)$ decai para zero quando $h$ tende ao infinito.
III. Para que uma matriz de Toeplitz seja definida positiva, todos os seus autovalores devem ser positivos. Isso implica que a energia do processo deve estar distribu√≠da positivamente em todas as frequ√™ncias.
IV. A positividade definida da matriz de Toeplitz est√° relacionada √† condi√ß√£o de que o espectro do processo ARMA seja positivo em todas as frequ√™ncias, o que por sua vez est√° ligado √† estacionariedade e invertibilidade.
V. Portanto, a estacionariedade e invertibilidade s√£o equivalentes √† positividade definida da matriz de Toeplitz associada ao processo.

*Prova (Esbo√ßo)*
Para demonstrar este lema, podemos utilizar a teoria espectral de s√©ries temporais. Se o processo for estacion√°rio e invert√≠vel, o seu espectro √© positivo para todas as frequ√™ncias, o que implica que a matriz de Toeplitz constru√≠da a partir das autocovari√¢ncias √© definida positiva. A rec√≠proca tamb√©m √© verdadeira, demonstrando a equival√™ncia.

Para estender o lema anterior e oferecer uma caracteriza√ß√£o mais completa, podemos relacionar a condi√ß√£o de positividade definida da matriz de Toeplitz com a representa√ß√£o espectral do processo.

**Teorema 8:** Um processo ARMA(p, q) com fun√ß√£o espectral $S(f)$ √© estacion√°rio e invert√≠vel se, e somente se, $S(f) > 0$ para todo $f \in [-\pi, \pi]$. Al√©m disso, a matriz de Toeplitz associada ao processo √© definida positiva se, e somente se, a fun√ß√£o espectral correspondente √© estritamente positiva.

*Estrat√©gia da Demonstra√ß√£o:*

A demonstra√ß√£o deste teorema utiliza a representa√ß√£o espectral de processos estacion√°rios. A fun√ß√£o espectral $S(f)$ representa a distribui√ß√£o da vari√¢ncia do processo em diferentes frequ√™ncias. Se o processo √© estacion√°rio, a fun√ß√£o espectral √© real e n√£o negativa. A invertibilidade garante que o processo possa ser representado como uma fun√ß√£o linear do ru√≠do branco presente e passado, o que implica que a fun√ß√£o espectral n√£o pode ser zero em nenhuma frequ√™ncia. A positividade definida da matriz de Toeplitz √© equivalente √† positividade da fun√ß√£o espectral. Especificamente, os autovalores da matriz de Toeplitz se aproximam dos valores da fun√ß√£o espectral quando a dimens√£o da matriz tende ao infinito. Este resultado √© uma consequ√™ncia do teorema de Szeg≈ë.

Para uma prova completa do teorema, √© necess√°rio mergulhar nos detalhes da teoria espectral e das propriedades das matrizes de Toeplitz. Aqui est√° um esbo√ßo da demonstra√ß√£o que pode ser expandido:

*Demonstra√ß√£o (Esbo√ßo)*

I. **Defini√ß√£o da Fun√ß√£o Espectral:** Seja $Y_t$ um processo ARMA(p,q) estacion√°rio. A fun√ß√£o espectral $S(f)$ √© definida como a transformada de Fourier da fun√ß√£o de autocovari√¢ncia $\gamma(h)$:
   $$S(f) = \sum_{h=-\infty}^{\infty} \gamma(h) e^{-i2\pi fh}, \quad f \in [-\pi, \pi]$$

II. **Rela√ß√£o entre Estacionariedade e Fun√ß√£o Espectral:** Para um processo estacion√°rio, $S(f)$ √© real e n√£o negativa: $S(f) \geq 0$.

III. **Rela√ß√£o entre Invertibilidade e Fun√ß√£o Espectral:** Se o processo √© tamb√©m invert√≠vel, ent√£o $S(f) > 0$ para todo $f$. Isso ocorre porque a invertibilidade garante que o processo possa ser expresso como uma combina√ß√£o linear do ru√≠do branco, e, portanto, n√£o pode ter "zeros" no espectro. Se $S(f) = 0$ para algum $f$, ent√£o o processo teria uma componente determin√≠stica nessa frequ√™ncia, o que contradiz a invertibilidade.

IV. **Matriz de Toeplitz e Fun√ß√£o Espectral:** A matriz de Toeplitz $T_n$ de dimens√£o $(n+1) \times (n+1)$ √© definida como:
   $$T_n = [\gamma(i-j)]_{i,j=0}^{n}$$
   onde $\gamma(h)$ √© a fun√ß√£o de autocovari√¢ncia.

V. **Teorema de Szeg≈ë:** O teorema de Szeg≈ë estabelece uma conex√£o entre os autovalores da matriz de Toeplitz e a fun√ß√£o espectral. Especificamente, se $\lambda_0^{(n)} \leq \lambda_1^{(n)} \leq \ldots \leq \lambda_n^{(n)}$ s√£o os autovalores de $T_n$, ent√£o para qualquer fun√ß√£o cont√≠nua $F$,
   $$\lim_{n \to \infty} \frac{1}{n+1} \sum_{k=0}^{n} F(\lambda_k^{(n)}) = \frac{1}{2\pi} \int_{-\pi}^{\pi} F(S(f)) df$$

VI. **Conex√£o com a Positividade Definida:** A matriz de Toeplitz $T_n$ √© definida positiva se todos os seus autovalores s√£o positivos, ou seja, $\lambda_k^{(n)} > 0$ para todo $k$. Pelo teorema de Szeg≈ë, isso implica que a integral da fun√ß√£o espectral √© positiva, o que √© garantido se $S(f) > 0$ para todo $f$.

VII. **Conclus√£o:** Portanto, um processo ARMA(p,q) √© estacion√°rio e invert√≠vel se e somente se sua fun√ß√£o espectral √© estritamente positiva, $S(f) > 0$, e isso √© equivalente √† matriz de Toeplitz associada ser definida positiva. $\blacksquare$

### Conclus√£o
Os par√¢metros $h_k$ e $g_k$ nas representa√ß√µes MA e AR infinitas de um processo ARMA(p, q) n√£o s√£o, em geral, id√™nticos. Essa diferen√ßa decorre das condi√ß√µes iniciais distintas e das diferentes formas como as informa√ß√µes passadas s√£o incorporadas em cada representa√ß√£o. Compreender essa distin√ß√£o √© crucial para a escolha apropriada de m√©todos de estima√ß√£o e previs√£o, bem como para uma interpreta√ß√£o precisa do comportamento da s√©rie temporal modelada. A escolha da representa√ß√£o depende das propriedades espec√≠ficas do processo e dos objetivos da an√°lise.

### Refer√™ncias
[^47]: Se√ß√£o 3.2, White Noise
[^53]: Se√ß√£o 3.4, Autoregressive Processes
[^57]: P√°gina 57
[^58]: Se√ß√£o 3.5, Mixed Autoregressive Moving Average Processes
[^65]: Se√ß√£o 3.7, Invertibility
[^67]: P√°gina 67
<!-- END -->