## White Noise in Time Series Analysis

### Introdu√ß√£o
Expandindo o conceito de **independent white noise** explorado anteriormente, onde fortalecemos a condi√ß√£o de n√£o correla√ß√£o para independ√™ncia temporal, este cap√≠tulo se aprofunda em um tipo espec√≠fico de white noise que √© de particular import√¢ncia em modelagem estat√≠stica e m√©todos bayesianos: o **Gaussian white noise process**. J√° estabelecemos que um processo de white noise $\{\varepsilon_t\}$ possui m√©dia zero, vari√¢ncia constante e, no caso de independent white noise, independ√™ncia temporal [^47, 48]. Agora, adicionamos uma restri√ß√£o crucial: que os elementos $\varepsilon_t$ sigam uma distribui√ß√£o normal (Gaussiana) com m√©dia zero e vari√¢ncia $\sigma^2$, denotado como $\varepsilon_t \sim N(0, \sigma^2)$. Exploraremos as propriedades √∫nicas, implica√ß√µes te√≥ricas e aplica√ß√µes pr√°ticas desta forma espec√≠fica de white noise.

### Conceitos Fundamentais

Um **Gaussian white noise process** √© uma sequ√™ncia de vari√°veis aleat√≥rias independentes, cada uma seguindo uma distribui√ß√£o normal com m√©dia zero e vari√¢ncia constante $\sigma^2$. Esta combina√ß√£o de independ√™ncia e normalidade simplifica a an√°lise e permite a aplica√ß√£o de diversas t√©cnicas estat√≠sticas e probabil√≠sticas.

As caracter√≠sticas principais de um Gaussian white noise process s√£o:

1.  **Distribui√ß√£o Normal:** Cada elemento $\varepsilon_t$ na sequ√™ncia segue uma distribui√ß√£o normal (Gaussiana) [^44].
2.  **M√©dia Zero:** O valor esperado de cada elemento √© zero: $E[\varepsilon_t] = 0$ [^47].
3.  **Vari√¢ncia Constante:** A vari√¢ncia de cada elemento √© constante: $Var[\varepsilon_t] = \sigma^2$ [^47].
4.  **Independ√™ncia:** Os elementos s√£o independentes entre si: $E[\varepsilon_t \varepsilon_\tau] = 0$ para $t \neq \tau$ [^48].

A densidade de probabilidade de cada $\varepsilon_t$ √© dada por [^44]:

$$
f(\varepsilon_t) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{\varepsilon_t^2}{2\sigma^2}\right)
$$

Dado que os elementos s√£o independentes, a densidade conjunta de $n$ observa√ß√µes $\varepsilon_1, \varepsilon_2, \ldots, \varepsilon_n$ √© o produto das densidades marginais:

$$
f(\varepsilon_1, \varepsilon_2, \ldots, \varepsilon_n) = \prod_{t=1}^{n} \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{\varepsilon_t^2}{2\sigma^2}\right) = (2\pi\sigma^2)^{-n/2} \exp\left(-\frac{1}{2\sigma^2}\sum_{t=1}^{n} \varepsilon_t^2\right)
$$

Esta forma da densidade conjunta √© particularmente √∫til em m√©todos de m√°xima verossimilhan√ßa e Bayesianos, pois permite uma representa√ß√£o compacta da probabilidade dos dados.

> üí° **Exemplo Num√©rico:** Considere um Gaussian white noise process com vari√¢ncia $\sigma^2 = 1$. A densidade de probabilidade de observar $\varepsilon_t = 0.5$ √©:
>
> $$
> f(0.5) = \frac{1}{\sqrt{2\pi(1)}} \exp\left(-\frac{0.5^2}{2(1)}\right) = \frac{1}{\sqrt{2\pi}} \exp\left(-\frac{0.25}{2}\right) \approx 0.352
> $$
>
> A densidade conjunta de observar $\varepsilon_1 = 0.5$ e $\varepsilon_2 = -0.2$ √©:
>
> $$
> f(0.5, -0.2) = \frac{1}{2\pi} \exp\left(-\frac{0.5^2 + (-0.2)^2}{2}\right) \approx 0.099
> $$
>
> ```python
> import numpy as np
> import scipy.stats as stats
>
> sigma_squared = 1
> epsilon_1 = 0.5
> epsilon_2 = -0.2
>
> # Densidade marginal para epsilon_1
> density_1 = stats.norm.pdf(epsilon_1, loc=0, scale=np.sqrt(sigma_squared))
> print(f"Marginal density at epsilon_1 = {epsilon_1}: {density_1}")
>
> # Densidade marginal para epsilon_2
> density_2 = stats.norm.pdf(epsilon_2, loc=0, scale=np.sqrt(sigma_squared))
> print(f"Marginal density at epsilon_2 = {epsilon_2}: {density_2}")
>
> # Densidade conjunta
> joint_density = density_1 * density_2
> print(f"Joint density at epsilon_1 = {epsilon_1} and epsilon_2 = {epsilon_2}: {joint_density}")
> ```
Al√©m das propriedades j√° mencionadas, podemos analisar a fun√ß√£o caracter√≠stica de um Gaussian white noise process.

**Proposi√ß√£o 1:** A fun√ß√£o caracter√≠stica de um Gaussian white noise process $\varepsilon_t \sim N(0, \sigma^2)$ √© dada por:
$$
\phi_{\varepsilon_t}(u) = E[e^{iu\varepsilon_t}] = e^{-\frac{1}{2}\sigma^2 u^2}
$$

*Demonstra√ß√£o:*
A fun√ß√£o caracter√≠stica de uma vari√°vel aleat√≥ria $X$ √© definida como $\phi_X(u) = E[e^{iuX}]$. Para uma vari√°vel aleat√≥ria normal $X \sim N(\mu, \sigma^2)$, a fun√ß√£o caracter√≠stica √© dada por $\phi_X(u) = e^{iu\mu - \frac{1}{2}\sigma^2 u^2}$. No caso de Gaussian white noise, $\varepsilon_t \sim N(0, \sigma^2)$, ent√£o $\mu = 0$ e a fun√ß√£o caracter√≠stica se torna:
$$
\phi_{\varepsilon_t}(u) = e^{iu(0) - \frac{1}{2}\sigma^2 u^2} = e^{-\frac{1}{2}\sigma^2 u^2}
$$
$\blacksquare$

A fun√ß√£o caracter√≠stica √© uma ferramenta √∫til para analisar propriedades e transforma√ß√µes de vari√°veis aleat√≥rias, e esta forma espec√≠fica simplifica muitos c√°lculos envolvendo Gaussian white noise.

> üí° **Exemplo Num√©rico:** Considere $\sigma^2 = 4$. Queremos calcular a fun√ß√£o caracter√≠stica para $u = 0.5$.
>
> $$
> \phi_{\varepsilon_t}(0.5) = e^{-\frac{1}{2}(4)(0.5)^2} = e^{-\frac{1}{2}(4)(0.25)} = e^{-0.5} \approx 0.6065
> $$
>
> Isso significa que a transformada de Fourier de $\varepsilon_t$ avaliada em $u=0.5$ tem magnitude aproximadamente 0.6065.
>
> ```python
> import numpy as np
>
> sigma_squared = 4
> u = 0.5
>
> characteristic_function = np.exp(-0.5 * sigma_squared * u**2)
> print(f"Characteristic function at u = {u}: {characteristic_function}")
> ```

**Lema 1:** Seja $\{\varepsilon_t\}_{t=1}^n$ um processo de ru√≠do branco gaussiano com m√©dia zero e vari√¢ncia $\sigma^2$. Ent√£o, a soma dos quadrados dos elementos, $\sum_{t=1}^n \varepsilon_t^2$, segue uma distribui√ß√£o gama escalonada.

**Demonstra√ß√£o:**
Como $\varepsilon_t \sim N(0, \sigma^2)$, ent√£o $\frac{\varepsilon_t}{\sigma} \sim N(0, 1)$. Logo, $\frac{\varepsilon_t^2}{\sigma^2}$ segue uma distribui√ß√£o qui-quadrado com 1 grau de liberdade, ou seja, $\frac{\varepsilon_t^2}{\sigma^2} \sim \chi^2(1)$. Portanto, $\sum_{t=1}^n \frac{\varepsilon_t^2}{\sigma^2} \sim \chi^2(n)$.

I.  Sabemos que a soma de $n$ vari√°veis qui-quadrado independentes, cada uma com 1 grau de liberdade, segue uma distribui√ß√£o qui-quadrado com $n$ graus de liberdade.
II. Uma distribui√ß√£o qui-quadrado com $n$ graus de liberdade √© um caso especial da distribui√ß√£o gama com par√¢metros $\alpha = n/2$ e $\beta = 1/2$. Assim, $\sum_{t=1}^n \frac{\varepsilon_t^2}{\sigma^2} \sim Gamma(\frac{n}{2}, \frac{1}{2})$.

III. Multiplicando por $\sigma^2$, temos que $\sum_{t=1}^n \varepsilon_t^2$ segue uma distribui√ß√£o gama escalonada com par√¢metros $\alpha = n/2$ e $\beta = \frac{1}{2\sigma^2}$, ou seja, $\sum_{t=1}^n \varepsilon_t^2 \sim Gamma(\frac{n}{2}, \frac{1}{2\sigma^2})$. $\blacksquare$

Este resultado √© √∫til em testes de hip√≥teses e estima√ß√£o de par√¢metros, especialmente em contextos bayesianos.

> üí° **Exemplo Num√©rico:** Suponha que temos $n=5$ amostras de um Gaussian white noise process com $\sigma^2 = 2$: $\varepsilon = [0.5, -0.2, 1.1, -0.8, 0.3]$. Ent√£o, $\sum_{t=1}^5 \varepsilon_t^2 = 0.5^2 + (-0.2)^2 + 1.1^2 + (-0.8)^2 + 0.3^2 = 0.25 + 0.04 + 1.21 + 0.64 + 0.09 = 2.23$.
>
> Segundo o Lema 1, esta soma segue uma distribui√ß√£o gama escalonada com $\alpha = 5/2 = 2.5$ e $\beta = \frac{1}{2\sigma^2} = \frac{1}{2(2)} = 0.25$. Podemos calcular a densidade de probabilidade neste ponto:
>
> $$
> f(x; \alpha, \beta) = \frac{\beta^\alpha}{\Gamma(\alpha)} x^{\alpha-1} e^{-\beta x}
> $$
>
> Onde $\Gamma(\alpha)$ √© a fun√ß√£o gama.
>
> $$
> f(2.23; 2.5, 0.25) = \frac{0.25^{2.5}}{\Gamma(2.5)} (2.23)^{2.5-1} e^{-0.25 \times 2.23} \approx 0.184
> $$
>
> ```python
> import numpy as np
> import scipy.stats as stats
> import scipy.special as special
>
> n = 5
> sigma_squared = 2
> epsilon = np.array([0.5, -0.2, 1.1, -0.8, 0.3])
> sum_squared = np.sum(epsilon**2)
>
> alpha = n / 2
> beta = 1 / (2 * sigma_squared)
>
> density = (beta**alpha / special.gamma(alpha)) * (sum_squared**(alpha - 1)) * np.exp(-beta * sum_squared)
> print(f"Sum of squares: {sum_squared}")
> print(f"Gamma density: {density}")
> ```

**Modelos Lineares e Gaussian White Noise**

O Gaussian white noise √© frequentemente utilizado como um componente fundamental em modelos lineares de s√©ries temporais. A suposi√ß√£o Gaussiana simplifica a deriva√ß√£o de estimadores de m√°xima verossimilhan√ßa e permite a aplica√ß√£o de m√©todos de infer√™ncia bayesiana.

Considere o modelo autoregressivo de ordem 1 (AR(1)):

$$
X_t = \phi X_{t-1} + \varepsilon_t
$$

onde $\varepsilon_t$ √© Gaussian white noise com m√©dia zero e vari√¢ncia $\sigma^2$. Sob a suposi√ß√£o de estacionariedade ($|\phi| < 1$), a distribui√ß√£o de $X_t$ tamb√©m √© normal com m√©dia zero e vari√¢ncia $\frac{\sigma^2}{1 - \phi^2}$.

**Teorema 7 (Verossimilhan√ßa para AR(1))**
Dado um modelo AR(1) $X_t = \phi X_{t-1} + \varepsilon_t$, onde $\varepsilon_t \sim N(0, \sigma^2)$, a fun√ß√£o de log-verossimilhan√ßa condicional para $\phi$ e $\sigma^2$ √©:

$$
\log L(\phi, \sigma^2 | X) = -\frac{n}{2} \log(2\pi\sigma^2) - \frac{1}{2\sigma^2} \sum_{t=2}^{n} (X_t - \phi X_{t-1})^2
$$

*Proof:*
Como $\varepsilon_t = X_t - \phi X_{t-1}$ √© normal com m√©dia zero e vari√¢ncia $\sigma^2$, a densidade condicional de $X_t$ dado $X_{t-1}$ √©:

$$
f(X_t | X_{t-1}; \phi, \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(X_t - \phi X_{t-1})^2}{2\sigma^2}\right)
$$

Sob a suposi√ß√£o de independ√™ncia, a fun√ß√£o de verossimilhan√ßa condicional √© o produto das densidades condicionais:

$$
L(\phi, \sigma^2 | X) = \prod_{t=2}^{n} f(X_t | X_{t-1}; \phi, \sigma^2) = \prod_{t=2}^{n} \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(X_t - \phi X_{t-1})^2}{2\sigma^2}\right)
$$

Tomando o logaritmo, obtemos a fun√ß√£o de log-verossimilhan√ßa condicional:

$$
\log L(\phi, \sigma^2 | X) = \sum_{t=2}^{n} \left[-\frac{1}{2} \log(2\pi\sigma^2) - \frac{(X_t - \phi X_{t-1})^2}{2\sigma^2}\right] = -\frac{n}{2} \log(2\pi\sigma^2) - \frac{1}{2\sigma^2} \sum_{t=2}^{n} (X_t - \phi X_{t-1})^2
$$

Esta fun√ß√£o pode ser maximizada para obter as estimativas de m√°xima verossimilhan√ßa de $\phi$ e $\sigma^2$. $\blacksquare$

A suposi√ß√£o de Gaussian white noise √© particularmente √∫til porque simplifica a deriva√ß√£o de propriedades estat√≠sticas e permite a aplica√ß√£o de m√©todos estat√≠sticos padr√£o. No entanto, √© importante notar que esta suposi√ß√£o pode n√£o ser v√°lida em todas as situa√ß√µes. Se os res√≠duos de um modelo n√£o seguem uma distribui√ß√£o normal, m√©todos alternativos podem ser necess√°rios.

Para complementar o Teorema 7, podemos apresentar um resultado relacionado √† distribui√ß√£o do estimador de m√°xima verossimilhan√ßa (MLE) para o par√¢metro $\phi$ no modelo AR(1) sob a suposi√ß√£o de Gaussian white noise.

**Teorema 7.1 (Distribui√ß√£o Assint√≥tica do MLE para AR(1))**
Dado um modelo AR(1) $X_t = \phi X_{t-1} + \varepsilon_t$, onde $\varepsilon_t \sim N(0, \sigma^2)$ e $|\phi| < 1$, o estimador de m√°xima verossimilhan√ßa $\hat{\phi}$ para $\phi$ converge em distribui√ß√£o para uma normal com m√©dia $\phi$ e vari√¢ncia $(1-\phi^2)/n$, ou seja:
$$
\sqrt{n}(\hat{\phi} - \phi) \xrightarrow{d} N\left(0, 1-\phi^2\right)
$$

Este resultado √© importante pois fornece uma maneira de construir intervalos de confian√ßa e testes de hip√≥teses para o par√¢metro $\phi$ com base nos dados observados. A demonstra√ß√£o deste teorema envolve a an√°lise das derivadas da fun√ß√£o de log-verossimilhan√ßa e a aplica√ß√£o do Teorema Central do Limite.

> üí° **Exemplo Num√©rico:** Suponha que temos uma s√©rie temporal de tamanho $n=100$ gerada por um modelo AR(1) com $\phi = 0.5$ e $\sigma^2 = 1$. Estimamos $\hat{\phi} = 0.55$. Podemos construir um intervalo de confian√ßa aproximado para $\phi$ usando o Teorema 7.1.
>
> A vari√¢ncia assint√≥tica de $\hat{\phi}$ √© $\frac{1 - \phi^2}{n} = \frac{1 - 0.5^2}{100} = \frac{0.75}{100} = 0.0075$. O desvio padr√£o √© $\sqrt{0.0075} \approx 0.0866$.
>
> Um intervalo de confian√ßa de 95% para $\phi$ √© dado por:
>
> $$
> \hat{\phi} \pm 1.96 \times \sqrt{\frac{1 - \phi^2}{n}} = 0.55 \pm 1.96 \times 0.0866 = 0.55 \pm 0.17
> $$
>
> Portanto, o intervalo de confian√ßa √© aproximadamente $[0.38, 0.72]$.
>
> ```python
> import numpy as np
>
> n = 100
> phi = 0.5
> phi_hat = 0.55
>
> asymptotic_variance = (1 - phi**2) / n
> asymptotic_std = np.sqrt(asymptotic_variance)
>
> confidence_interval = (phi_hat - 1.96 * asymptotic_std, phi_hat + 1.96 * asymptotic_std)
> print(f"Approximate 95% confidence interval for phi: {confidence_interval}")
> ```

**Lema 7.1.1:** Dado o modelo AR(1) $X_t = \phi X_{t-1} + \varepsilon_t$, com $\varepsilon_t \sim N(0, \sigma^2)$, e assumindo estacionaridade ($|\phi|<1$), a esperan√ßa condicional de $X_t$ dado $X_{t-1}$ √© $E[X_t|X_{t-1}] = \phi X_{t-1}$, e a vari√¢ncia condicional √© $Var[X_t|X_{t-1}] = \sigma^2$.

*Demonstra√ß√£o:*
A esperan√ßa condicional √©:
$E[X_t|X_{t-1}] = E[\phi X_{t-1} + \varepsilon_t | X_{t-1}] = \phi X_{t-1} + E[\varepsilon_t|X_{t-1}] = \phi X_{t-1} + E[\varepsilon_t] = \phi X_{t-1} + 0 = \phi X_{t-1}$.

I. Usamos a linearidade do operador de esperan√ßa condicional: $E[aX + bY | Z] = aE[X|Z] + bE[Y|Z]$.
II. Usamos o fato de que $E[\varepsilon_t|X_{t-1}] = E[\varepsilon_t] = 0$ porque $\varepsilon_t$ √© independente de $X_{t-1}$ e tem m√©dia zero.

A vari√¢ncia condicional √©:
$Var[X_t|X_{t-1}] = Var[\phi X_{t-1} + \varepsilon_t | X_{t-1}] = Var[\varepsilon_t|X_{t-1}] = Var[\varepsilon_t] = \sigma^2$. $\blacksquare$

I. Usamos o fato de que $Var[aX + bY | Z] = b^2Var[Y|Z]$ se $X$ √© conhecido dado $Z$. Aqui, $\phi X_{t-1}$ √© conhecido dado $X_{t-1}$, ent√£o sua vari√¢ncia condicional √© zero.
II. Usamos o fato de que $Var[\varepsilon_t|X_{t-1}] = Var[\varepsilon_t] = \sigma^2$ porque $\varepsilon_t$ √© independente de $X_{t-1}$.

Este lema estabelece resultados fundamentais para a infer√™ncia e previs√£o no modelo AR(1) sob a suposi√ß√£o de ru√≠do branco gaussiano.

### M√©todos Bayesianos e Gaussian White Noise

Em m√©todos Bayesianos, o Gaussian white noise √© frequentemente usado como um modelo para os erros ou ru√≠do em um modelo. Al√©m disso, priors Gaussianas podem ser colocadas nos par√¢metros do modelo.

**Exemplo 3:** Considere novamente o modelo AR(1) $X_t = \phi X_{t-1} + \varepsilon_t$, onde $\varepsilon_t \sim N(0, \sigma^2)$. Em uma abordagem Bayesiana, podemos colocar priors em $\phi$ e $\sigma^2$. Por exemplo, podemos assumir que $\phi \sim N(0, V_\phi)$ e $\sigma^2 \sim Inv-Gamma(\alpha, \beta)$. Ent√£o, a distribui√ß√£o posterior de $\phi$ e $\sigma^2$ dado os dados $X$ √© proporcional ao produto do likelihood e os priors:

$$
p(\phi, \sigma^2 | X) \propto L(\phi, \sigma^2 | X) \cdot p(\phi) \cdot p(\sigma^2)
$$

A suposi√ß√£o de Gaussian white noise simplifica o c√°lculo do likelihood e permite a utiliza√ß√£o de amostradores de Markov Chain Monte Carlo (MCMC) para aproximar a distribui√ß√£o posterior.

> üí° **Exemplo Num√©rico:** Seja $X_t = 0.7 X_{t-1} + \varepsilon_t$, onde $\varepsilon_t \sim N(0, 1)$. Suponha que temos as observa√ß√µes $X = [1.0, 0.8, 0.6, 0.9, 1.1]$. Para realizar a infer√™ncia Bayesiana, precisamos definir priors para $\phi$ e $\sigma^2$. Vamos usar $\phi \sim N(0, 1)$ e $\sigma^2 \sim Inv-Gamma(3, 2)$.
>
> A fun√ß√£o de log-verossimilhan√ßa condicional √©:
>
> $$
> \log L(\phi, \sigma^2 | X) = -\frac{n}{2} \log(2\pi\sigma^2) - \frac{1}{2\sigma^2} \sum_{t=2}^{n} (X_t - \phi X_{t-1})^2
> $$
>
> A densidade do prior para $\phi$ √©:
>
> $$
> p(\phi) = \frac{1}{\sqrt{2\pi}} e^{-\frac{\phi^2}{2}}
> $$
>
> A densidade do prior para $\sigma^2$ √©:
>
> $$
> p(\sigma^2) = \frac{\beta^\alpha}{\Gamma(\alpha)} (\sigma^2)^{-\alpha - 1} e^{-\frac{\beta}{\sigma^2}}
> $$
>
> A distribui√ß√£o posterior √© proporcional ao produto dessas densidades. Para encontrar a distribui√ß√£o posterior, podemos usar MCMC methods, como o algoritmo de Metropolis-Hastings ou Gibbs sampling.

Para a s√©rie de distribui√ß√£o posterior, apresentamos o seguinte teorema:
**Teorema 8:** Se um Gaussian white noise √© usado como ru√≠do de medi√ß√£o no filtro Kalman, ent√£o a distribui√ß√£o posterior do estado do sistema √© Gaussiana.
*Demonstra√ß√£o:*
Seja $x_k$ o estado do sistema no momento $k$, $z_k$ a medi√ß√£o no momento $k$ e $H_k$ a matriz de medi√ß√£o. O ru√≠do de medi√ß√£o √© dado por $v_k \sim \mathcal{N}(0, R_k)$. A atualiza√ß√£o do filtro Kalman √©:

$$
x_{k|k} = x_{k|k-1} + K_k (z_k - H_k x_{k|k-1})
$$

Onde $K_k$ √© o ganho Kalman. Como tanto o estado anterior $x_{k|k-1}$ quanto o ru√≠do de medi√ß√£o $v_k$ s√£o Gaussianos, a distribui√ß√£o posterior $x_{k|k}$ √© uma combina√ß√£o linear de vari√°veis Gaussianas, resultando tamb√©m em uma distribui√ß√£o Gaussiana. ‚ñ†

Este teorema destaca a import√¢ncia da suposi√ß√£o de Gaussian white noise na filtragem de Kalman, permitindo atualiza√ß√µes eficientes e precisas do estado do sistema.

> üí° **Exemplo Num√©rico:** Considere um sistema onde o estado evolui de acordo com $x_k = x_{k-1} + w_k$, onde $w_k \sim N(0, Q)$ e a medi√ß√£o √© dada por $z_k = x_k + v_k$, onde $v_k \sim N(0, R)$. Suponha que $Q = 0.1$ e $R = 0.5$. Inicialmente, $x_0 \sim N(1, 0.2)$.
>
> No primeiro passo, predizemos o estado e a covari√¢ncia:
>
> $$
> x_{1|0} = x_0 = 1
> $$
>
> $$
> P_{1|0} = P_0 + Q = 0.2 + 0.1 = 0.3
> $$
>
> Agora, suponha que a medi√ß√£o $z_1 = 1.2$. Calculamos o ganho de Kalman:
>
> $$
> K_1 = \frac{P_{1|0}}{P_{1|0} + R} = \frac{0.3}{0.3 + 0.5} = \frac{0.3}{0.8} = 0.375
> $$
>
> Atualizamos o estado e a covari√¢ncia:
>
> $$
> x_{1|1} = x_{1|0} + K_1 (z_1 - x_{1|0}) = 1 + 0.375(1.2 - 1) = 1 + 0.375(0.2) = 1.075
> $$
>
> $$
> P_{1|1} = (1 - K_1) P_{1|0} = (1 - 0.375) \times 0.3 = 0.625 \times 0.3 = 0.1875
> $$
>
> Portanto, a distribui√ß√£o posterior do estado no momento $k=1$ √© $x_{1|1} \sim N(1.075, 0.1875)$.
>
> ```python
> import numpy as np
>
> # Par√¢metros
> Q = 0.1
> R = 0.5
> x_0 = 1
> P_0 = 0.2
> z_1 = 1.2
>
> # Predi√ß√£o
> x_1_0 = x_0
> P_1_0 = P_0 + Q
>
> # Atualiza√ß√£o
> K_1 = P_1_0 / (P_1_0 + R)
> x_1_1 = x_1_0 + K_1 * (z_1 - x_1_0)
> P_1_1 = (1 - K_1) * P_1_0
>
> print(f"Posterior state: {x_1_1}")
> print(f"Posterior covariance: {P_1_1}")
> ```

> üí° **Exemplo Num√©rico:** Para modelar uma s√©rie temporal com um componente sazonal e tend√™ncia, podemos empregar uma combina√ß√£o de modelos AR e termos determin√≠sticos para capturar esses padr√µes. Suponha que tenhamos a s√©rie temporal $Y_t$ que exibe uma tend√™ncia linear e um padr√£o sazonal com per√≠odo 12. Podemos modelar esta s√©rie temporal como:
>
> $Y_t = \mu + \beta t + \gamma_1 \sin(2\pi t / 12) + \gamma_2 \cos(2\pi t / 12) + X_t$
>
> Onde:
>
> *   $\mu$ representa o n√≠vel m√©dio.
> *   $\beta$ representa a tend√™ncia linear.
> *   $\gamma_1$ e $\gamma_2$ representam as amplitudes dos componentes seno e cosseno, respectivamente.
> *   $X_t$ √© um processo AR(1) que captura a autocorrela√ß√£o remanescente.
>
> Para determinar os par√¢metros $\mu$, $\beta$, $\gamma_1$, $\gamma_2$ e $\sigma^2$, podemos utilizar o seguinte c√≥digo:
>
> ```python
> import numpy as np
> import statsmodels.api as sm
> import statsmodels.formula.api as smf
> import pandas as pd
>
> # Gerar dados de exemplo
> np.random.seed(0)
> t = np.arange(1, 101) # 100 pontos de dados
> trend = 0.5 * t
> seasonal = 10 * np.sin(2 * np.pi * t / 12)
> ar = np.zeros(100)
> ar[0] = np.random.normal(0, 2, 1)
> for i in range(1, 100):
>     ar[i] = 0.7 * ar[i-1] + np.random.normal(0, 2, 1)
>
> Y = 5 + trend + seasonal + ar
>
> # Criar um DataFrame para o statsmodels
> data = pd.DataFrame({'Y': Y, 't': t})
>
> # Ajustar o modelo
> model = smf.ols("Y ~ t + np.sin(2 * np.pi * t / 12) + np.cos(2 * np.pi * t / 12)", data=data).fit()
> print(model.summary())
>
> # Extrair os par√¢metros
> mu = model.params['Intercept']
> beta = model.params['t']
> gamma_1 = model.params['np.sin(2 * np.pi * t / 12)']
> gamma_2 = model.params['np.cos(2 * np.pi * t / 12)']
> sigma_squared = model.scale # Vari√¢ncia dos res√≠duos
>
> print(f"mu: {mu}, beta: {beta}, gamma_1: {gamma_1}, gamma_2: {gamma_2}, sigma_squared: {sigma_squared}")
> ```

### Cria√ß√£o de Gaussian White Noise

Em aplica√ß√µes pr√°ticas, √© essencial ter procedimentos robustos para gerar Gaussian white noise. Isso √© particularmente importante para simula√ß√µes e testes de desempenho de modelos.

O m√©todo mais comum √© usar um gerador de n√∫meros pseudoaleat√≥rios (PRNG) para gerar amostras de uma distribui√ß√£o normal. A biblioteca NumPy em Python fornece uma fun√ß√£o `numpy.random.normal` que pode ser usada para este prop√≥sito.

**Procedimento:**

1.  Escolha um PRNG com boas propriedades estat√≠sticas e um longo per√≠odo.
2.  Especifique a m√©dia (0) e a vari√¢ncia ($\sigma^2$) desejadas.
3.  Gere $n$ amostras da distribui√ß√£o normal usando o PRNG.
4.  Teste as amostras para verificar se elas se aproximam das propriedades de um Gaussian white noise (m√©dia zero, vari√¢ncia constante, independ√™ncia).

```python
import numpy as np
import matplotlib.pyplot as plt
from statsmodels.graphics.tsaplots import plot_acf

# Especificar os par√¢metros
n = 1000 # N√∫mero de amostras
sigma_squared = 1 # Vari√¢ncia

# Gerar Gaussian white noise
np.random.seed(0) # Para reproducibilidade
white_noise = np.random.normal(0, np.sqrt(sigma_squared), n)

# Verificar as propriedades
print("M√©dia:", np.mean(white_noise))
print("Vari√¢ncia:", np.var(white_noise))

# Plotar a fun√ß√£o de autocorrela√ß√£o (ACF)
plot_acf(white_noise, lags=20)
plt.title("Fun√ß√£o de Autocorrela√ß√£o (ACF)")
plt.show()
```

O c√≥digo acima gera 1000 amostras de Gaussian white noise, verifica sua m√©dia e vari√¢ncia e plota a fun√ß√£o de autocorrela√ß√£o para verificar a aus√™ncia de correla√ß√£o serial.

Para complementar a cria√ß√£o de Gaussian white noise, podemos adicionar um teste formal para verificar se uma dada amostra realmente se comporta como Gaussian white noise. Um teste comum √© o teste de Ljung-Box.

**Teste de Ljung-Box:**

O teste de Ljung-Box √© um teste de hip√≥teses para verificar se uma s√©rie temporal apresenta autocorrela√ß√£o significativa at√© um determinado lag $h$. A hip√≥tese nula √© que a s√©rie temporal √© independente e identicamente distribu√≠da (i.i.d.).

A estat√≠stica de teste √© dada por:

$$
Q = n(n+2)\sum_{k=1}^{h} \frac{\hat{\rho}_k^2}{n-k}
$$

onde $n$ √© o tamanho da amostra, $\hat{\rho}_k$ √© a autocorrela√ß√£o amostral no lag $k$ e $h$ √© o n√∫mero de lags sendo testados. Sob a hip√≥tese nula, $Q$ segue uma distribui√ß√£o $\chi^2$ com $h$ graus de liberdade.

Podemos adicionar o seguinte c√≥digo para realizar o teste de Ljung-Box:

```python
import statsmodels.stats.diagnostic as diag
import scipy.stats as stats

# Realizar o teste de Ljung-Box
lbvalue, pvalue = diag.acorr_ljungbox(white_noise, lags=[20], return_df = False)

print("Estat√≠stica de Ljung-Box:", lbvalue)
print("Valor-p:", pvalue)

# Comparar o valor-p com um n√≠vel de signific√¢ncia (e.g., 0.05)
alpha = 0.05
if pvalue < alpha:
    print("Rejeitamos a hip√≥tese nula: h√° autocorrela√ß√£o significativa.")
else:
    print("N√£o rejeitamos a hip√≥tese nula: n√£o h√° evid√™ncia de autocorrela√ß√£o significativa.")
```

Este teste formal ajuda a validar se a amostra gerada realmente se aproxima das propriedades de white noise, fornecendo uma garantia adicional em aplica√ß√µes pr√°ticas.

**Proposi√ß√£o 2:** Se $X_1, X_2, ..., X_n$ s√£o vari√°veis aleat√≥rias independentes e identicamente distribu√≠das seguindo uma distribui√ß√£o normal padr√£o (i.e., $X_i \sim N(0, 1)$), ent√£o a estat√≠stica de Kolmogorov-Smirnov (KS) entre a fun√ß√£o de distribui√ß√£o emp√≠rica (FDE) dos dados e a fun√ß√£o de distribui√ß√£o cumulativa (FDC) da normal padr√£o converge para 0 √† medida que $n$ tende para infinito.

*Demonstra√ß√£o:*
Seja $F_n(x)$ a fun√ß√£o de distribui√ß√£o emp√≠rica dos dados $X_1, X_2, ..., X_n$, e $F(x)$ a fun√ß√£o de distribui√ß√£o cumulativada vari√°vel aleat√≥ria $X$. O teorema de Glivenko-Cantelli estabelece que

$$
\sup_{x} |F_n(x) - F(x)| \xrightarrow{n \to \infty} 0 \quad \text{quase certamente.}
$$

Ou seja, a maior diferen√ßa absoluta entre a fun√ß√£o de distribui√ß√£o emp√≠rica e a fun√ß√£o de distribui√ß√£o real converge para 0 quando $n$ tende para infinito. Este teorema √© fundamental na estat√≠stica n√£o param√©trica, pois ele garante que a fun√ß√£o de distribui√ß√£o emp√≠rica $F_n(x)$ √© uma estimativa consistente da verdadeira fun√ß√£o de distribui√ß√£o $F(x)$.

### Lei Fraca dos Grandes N√∫meros

A Lei Fraca dos Grandes N√∫meros (LFGN) √© um teorema fundamental na teoria da probabilidade que estabelece que, sob certas condi√ß√µes, a m√©dia amostral de uma sequ√™ncia de vari√°veis aleat√≥rias independentes e identicamente distribu√≠das (i.i.d.) converge em probabilidade para a m√©dia da popula√ß√£o.

*Teorema (Lei Fraca dos Grandes N√∫meros):*
Sejam $X_1, X_2, ..., X_n$ vari√°veis aleat√≥rias i.i.d. com m√©dia $\mu$ finita, i.e., $E[X_i] = \mu$ para todo $i$. Ent√£o, para qualquer $\epsilon > 0$,

$$
\lim_{n \to \infty} P\left( \left| \frac{1}{n} \sum_{i=1}^n X_i - \mu \right| > \epsilon \right) = 0.
$$

Em outras palavras, a probabilidade de que a m√©dia amostral $\frac{1}{n} \sum_{i=1}^n X_i$ difira de $\mu$ por mais de $\epsilon$ tende a zero quando $n$ tende para infinito.

*Demonstra√ß√£o (Usando a Desigualdade de Chebyshev):*
Sejam $X_1, X_2, ..., X_n$ vari√°veis aleat√≥rias i.i.d. com m√©dia $\mu$ e vari√¢ncia $\sigma^2$. Defina a m√©dia amostral como $\bar{X}_n = \frac{1}{n} \sum_{i=1}^n X_i$. Ent√£o,

$$
E[\bar{X}_n] = E\left[ \frac{1}{n} \sum_{i=1}^n X_i \right] = \frac{1}{n} \sum_{i=1}^n E[X_i] = \frac{1}{n} \sum_{i=1}^n \mu = \mu.
$$

A vari√¢ncia da m√©dia amostral √©

$$
Var(\bar{X}_n) = Var\left( \frac{1}{n} \sum_{i=1}^n X_i \right) = \frac{1}{n^2} \sum_{i=1}^n Var(X_i) = \frac{1}{n^2} \sum_{i=1}^n \sigma^2 = \frac{\sigma^2}{n}.
$$

Aplicando a desigualdade de Chebyshev, temos

$$
P(|\bar{X}_n - \mu| > \epsilon) \leq \frac{Var(\bar{X}_n)}{\epsilon^2} = \frac{\sigma^2}{n \epsilon^2}.
$$

Tomando o limite quando $n \to \infty$,

$$
\lim_{n \to \infty} P(|\bar{X}_n - \mu| > \epsilon) \leq \lim_{n \to \infty} \frac{\sigma^2}{n \epsilon^2} = 0.
$$

Portanto, a Lei Fraca dos Grandes N√∫meros est√° demonstrada. $\blacksquare$

### Lei Forte dos Grandes N√∫meros

A Lei Forte dos Grandes N√∫meros (LFGN) √© uma vers√£o mais forte da Lei Fraca dos Grandes N√∫meros. Ela estabelece que a m√©dia amostral converge quase certamente para a m√©dia da popula√ß√£o.

*Teorema (Lei Forte dos Grandes N√∫meros):*
Sejam $X_1, X_2, ..., X_n$ vari√°veis aleat√≥rias i.i.d. com m√©dia $\mu$ finita, i.e., $E[X_i] = \mu$ para todo $i$. Ent√£o,

$$
P\left( \lim_{n \to \infty} \frac{1}{n} \sum_{i=1}^n X_i = \mu \right) = 1.
$$

Em outras palavras, a m√©dia amostral $\frac{1}{n} \sum_{i=1}^n X_i$ converge para $\mu$ com probabilidade 1 quando $n$ tende para infinito.

A prova da Lei Forte dos Grandes N√∫meros √© mais complexa do que a prova da Lei Fraca e geralmente requer t√©cnicas de an√°lise mais avan√ßadas, como a desigualdade de Kolmogorov ou o lema de Borel-Cantelli.

### Teorema do Limite Central (TLC)

O Teorema do Limite Central (TLC) √© um dos resultados mais importantes da teoria da probabilidade e estat√≠stica. Ele afirma que a soma (ou m√©dia) de um grande n√∫mero de vari√°veis aleat√≥rias independentes e identicamente distribu√≠das (i.i.d.), com vari√¢ncia finita, se aproxima de uma distribui√ß√£o normal, independentemente da distribui√ß√£o original das vari√°veis.

*Teorema (Teorema do Limite Central):*
Sejam $X_1, X_2, ..., X_n$ vari√°veis aleat√≥rias i.i.d. com m√©dia $\mu$ e vari√¢ncia $\sigma^2$ finitas. Seja $S_n = \sum_{i=1}^n X_i$ a soma das vari√°veis aleat√≥rias. Ent√£o, a vari√°vel aleat√≥ria padronizada

$$
Z_n = \frac{S_n - n\mu}{\sqrt{n\sigma^2}} = \frac{\bar{X}_n - \mu}{\sigma / \sqrt{n}}
$$

converge em distribui√ß√£o para uma distribui√ß√£o normal padr√£o $N(0, 1)$ quando $n$ tende para infinito. Ou seja, para qualquer $z \in \mathbb{R}$,

$$
\lim_{n \to \infty} P(Z_n \leq z) = \Phi(z),
$$

onde $\Phi(z)$ √© a fun√ß√£o de distribui√ß√£o cumulativa da distribui√ß√£o normal padr√£o.

*Demonstra√ß√£o (Usando Fun√ß√µes Caracter√≠sticas):*
A demonstra√ß√£o formal do TLC envolve o uso de fun√ß√µes caracter√≠sticas. Seja $\phi_X(t)$ a fun√ß√£o caracter√≠stica de uma vari√°vel aleat√≥ria $X$ com m√©dia $\mu$ e vari√¢ncia $\sigma^2$. Ent√£o,

$$
\phi_X(t) = E[e^{itX}].
$$

A fun√ß√£o caracter√≠stica da vari√°vel aleat√≥ria padronizada $Y = \frac{X - \mu}{\sigma}$ √©

$$
\phi_Y(t) = E\left[ e^{it\frac{X - \mu}{\sigma}} \right] = e^{-it\frac{\mu}{\sigma}} \phi_X\left( \frac{t}{\sigma} \right).
$$

Para uma vari√°vel aleat√≥ria i.i.d. $X_i$ com m√©dia $\mu$ e vari√¢ncia $\sigma^2$, a fun√ß√£o caracter√≠stica da vari√°vel aleat√≥ria padronizada $Z_n$ √©

$$
\phi_{Z_n}(t) = \left( \phi_Y\left( \frac{t}{\sqrt{n}} \right) \right)^n = \left( E\left[ e^{it\frac{X_i - \mu}{\sigma\sqrt{n}}} \right] \right)^n.
$$

Usando a expans√£o de Taylor da fun√ß√£o exponencial $e^x \approx 1 + x + \frac{x^2}{2} + ...$, temos

$$
\phi_{Z_n}(t) \approx \left( 1 - \frac{t^2}{2n} \right)^n.
$$

Tomando o limite quando $n \to \infty$,

$$
\lim_{n \to \infty} \phi_{Z_n}(t) = e^{-\frac{t^2}{2}},
$$

que √© a fun√ß√£o caracter√≠stica da distribui√ß√£o normal padr√£o $N(0, 1)$. Portanto, pelo teorema da continuidade de L√©vy, $Z_n$ converge em distribui√ß√£o para $N(0, 1)$. $\blacksquare$

O Teorema do Limite Central √© amplamente utilizado em estat√≠stica para aproximar a distribui√ß√£o de estat√≠sticas amostrais, como a m√©dia amostral, e para construir intervalos de confian√ßa e testes de hip√≥teses. Ele tamb√©m √© fundamental em muitas √°reas da ci√™ncia e engenharia, onde √© usado para modelar fen√¥menos complexos que envolvem a soma de muitas vari√°veis aleat√≥rias.

<!-- END -->