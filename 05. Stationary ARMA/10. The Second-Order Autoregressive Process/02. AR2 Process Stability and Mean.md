## T√≠tulo Conciso
Mean of a Covariance-Stationary AR(2) Process

### Introdu√ß√£o
Este cap√≠tulo estende a an√°lise de processos autorregressivos de segunda ordem (AR(2)), focando especificamente na deriva√ß√£o e interpreta√ß√£o da m√©dia de um processo AR(2) que se assume *covariance-stationary*. Como discutido anteriormente, a estacionariedade √© uma propriedade crucial para modelos de s√©ries temporais, garantindo que suas propriedades estat√≠sticas n√£o mudem com o tempo [^45, 57]. A condi√ß√£o para covariance-stationarity de um processo AR(2) √© que as ra√≠zes da equa√ß√£o caracter√≠stica associada estejam fora do c√≠rculo unit√°rio, condi√ß√£o equivalente √† invertibilidade [^57]. Assume-se a *covariance-stationarity* para calcular a m√©dia, tomando as expectativas da equa√ß√£o AR(2) diretamente.

### Conceitos Fundamentais

Partimos da defini√ß√£o de um processo AR(2) [^56]:

$$Y_t = c + \phi_1 Y_{t-1} + \phi_2 Y_{t-2} + \epsilon_t$$

onde:

*   $Y_t$ √© o valor da s√©rie temporal no instante *t*.
*   *c* √© uma constante.
*   $\phi_1$ e $\phi_2$ s√£o os coeficientes autorregressivos.
*   $Y_{t-1}$ e $Y_{t-2}$ s√£o os valores da s√©rie temporal nos instantes *t-1* e *t-2*, respectivamente.
*   $\epsilon_t$ √© um termo de erro (ru√≠do branco) com m√©dia zero, ou seja, $E[\epsilon_t]=0$ [^47, 48].

Para derivar a m√©dia do processo AR(2), denotada por $\mu$, assumimos que o processo √© *covariance-stationary* [^45]. Isso implica que a m√©dia do processo √© constante ao longo do tempo, ou seja, $E[Y_t] = E[Y_{t-1}] = E[Y_{t-2}] = \mu$. Tomando as expectativas de ambos os lados da equa√ß√£o do processo AR(2) [^57]:

$$E[Y_t] = E[c + \phi_1 Y_{t-1} + \phi_2 Y_{t-2} + \epsilon_t]$$

Usando a linearidade da expectativa, temos:

$$E[Y_t] = E[c] + \phi_1 E[Y_{t-1}] + \phi_2 E[Y_{t-2}] + E[\epsilon_t]$$

Como $E[Y_t] = E[Y_{t-1}] = E[Y_{t-2}] = \mu$ e $E[\epsilon_t] = 0$ [^47, 48], obtemos:

$$\mu = c + \phi_1 \mu + \phi_2 \mu + 0$$

Isolando $\mu$, temos:

$$\mu = c + \phi_1 \mu + \phi_2 \mu$$
$$\mu - \phi_1 \mu - \phi_2 \mu = c$$
$$\mu(1 - \phi_1 - \phi_2) = c$$

Portanto, a m√©dia do processo AR(2) *covariance-stationary* √© dada por [^58]:

$$\mu = \frac{c}{1 - \phi_1 - \phi_2}$$ [^58, 3.4.23]

Esta f√≥rmula para a m√©dia √© v√°lida somente se o processo for *covariance-stationary*. As condi√ß√µes para a *covariance-stationarity*, como demonstrado anteriormente, garantem que o denominador $(1 - \phi_1 - \phi_2)$ n√£o seja zero, assegurando que a m√©dia seja finita e bem definida.

> üí° **Exemplo Num√©rico:**
>
> Considere um processo AR(2) com $c = 5$, $\phi_1 = 0.6$, e $\phi_2 = 0.3$. Para este processo, a m√©dia √©:
>
> $$\mu = \frac{5}{1 - 0.6 - 0.3} = \frac{5}{1 - 0.9} = \frac{5}{0.1} = 50$$
>
> Este exemplo ilustra como a m√©dia do processo √© influenciada pela constante *c* e pelos coeficientes autorregressivos $\phi_1$ e $\phi_2$.
>
> Agora, vamos considerar um caso em que o processo n√£o √© estacion√°rio. Suponha que $\phi_1 = 1.2$ e $\phi_2 = -0.3$, ent√£o:
>
> $$\mu = \frac{5}{1 - 1.2 - (-0.3)} = \frac{5}{1 - 1.2 + 0.3} = \frac{5}{0.1} = 50$$
>
> Embora a f√≥rmula produza um valor, o processo n√£o √© estacion√°rio, e a m√©dia n√£o √© constante ao longo do tempo.
>
> Vamos considerar um processo com $\phi_1 = 0.7$ e $\phi_2 = 0.3$, ent√£o:
>
> $$\mu = \frac{5}{1 - 0.7 - 0.3} = \frac{5}{1 - 1} = \frac{5}{0} = \infty$$
>
> Neste caso, a m√©dia n√£o √© bem definida e tende ao infinito, demonstrando que a *covariance-stationarity* √© uma condi√ß√£o necess√°ria para a validade da f√≥rmula.
>
> Para verificar se os par√¢metros do primeiro exemplo ($c = 5$, $\phi_1 = 0.6$, e $\phi_2 = 0.3$) satisfazem as condi√ß√µes de estacionariedade (Lema 1.1):
> 1.  $\phi_2 + \phi_1 = 0.3 + 0.6 = 0.9 < 1$ (Condi√ß√£o satisfeita)
> 2.  $\phi_2 - \phi_1 = 0.3 - 0.6 = -0.3 < 1$ (Condi√ß√£o satisfeita)
> 3.  $-1 < \phi_2 = 0.3 < 1$ (Condi√ß√£o satisfeita)
>
> Todas as tr√™s condi√ß√µes s√£o satisfeitas, o que confirma que o processo √© *covariance-stationary* e a m√©dia calculada ($\mu = 50$) √© v√°lida.

**Lema 1:** A *covariance-stationarity* do processo AR(2) implica que $|z_1| > 1$ e $|z_2| > 1$, onde $z_1$ e $z_2$ s√£o as ra√≠zes da equa√ß√£o caracter√≠stica $1 - \phi_1 z - \phi_2 z^2 = 0$.

*Proof:* A condi√ß√£o de *covariance-stationarity* exige que as ra√≠zes da equa√ß√£o caracter√≠stica estejam fora do c√≠rculo unit√°rio. Isso garante que o processo seja est√°vel e que suas propriedades estat√≠sticas permane√ßam constantes ao longo do tempo. Se qualquer raiz estiver dentro ou sobre o c√≠rculo unit√°rio, o processo n√£o ser√° *covariance-stationary*.

**Prova:**
I. A equa√ß√£o caracter√≠stica para um processo AR(2) √© dada por:
   $$1 - \phi_1 z - \phi_2 z^2 = 0$$
   onde $z$ representa as ra√≠zes da equa√ß√£o.

II. Para um processo AR(2) ser *covariance-stationary*, ambas as ra√≠zes ($z_1$ e $z_2$) devem estar fora do c√≠rculo unit√°rio, ou seja:
   $$|z_1| > 1 \quad \text{e} \quad |z_2| > 1$$

III. Se qualquer uma das ra√≠zes estiver dentro ou sobre o c√≠rculo unit√°rio (i.e., $|z_i| \leq 1$ para $i = 1$ ou $2$), o processo n√£o ser√° *covariance-stationary*. Isso significa que a vari√¢ncia do processo aumentar√° com o tempo, violando a condi√ß√£o de estacionariedade.

IV. Portanto, a condi√ß√£o para *covariance-stationarity* √© que as ra√≠zes da equa√ß√£o caracter√≠stica estejam fora do c√≠rculo unit√°rio:
   $$|z_1| > 1 \quad \text{e} \quad |z_2| > 1$$ ‚ñ†

**Lema 1.1:**
An alternative representation of the stationarity condition can be expressed in terms of the coefficients $\phi_1$ and $\phi_2$ directly. The AR(2) process is stationary if and only if the following three conditions hold:
1. $\phi_2 + \phi_1 < 1$
2. $\phi_2 - \phi_1 < 1$
3. $-1 < \phi_2 < 1$

*Proof:* These conditions are derived from the requirement that the roots of the characteristic equation lie outside the unit circle. The algebraic manipulation to derive these conditions from $|z_1| > 1$ and $|z_2| > 1$ is a standard result in time series analysis.

**Prova:**
I.  We start with the characteristic equation of the AR(2) process:
    $$1 - \phi_1 z - \phi_2 z^2 = 0$$

II. The roots of this quadratic equation are given by:
    $$z_{1,2} = \frac{\phi_1 \pm \sqrt{\phi_1^2 + 4\phi_2}}{-2\phi_2}$$

III. For the AR(2) process to be stationary, the absolute values of both roots must be greater than 1, i.e., $|z_1| > 1$ and $|z_2| > 1$.

IV. By analyzing the conditions under which both roots satisfy $|z_i| > 1$, we arrive at the following three conditions in terms of the coefficients $\phi_1$ and $\phi_2$:
    1. $\phi_2 + \phi_1 < 1$
    2. $\phi_2 - \phi_1 < 1$
    3. $-1 < \phi_2 < 1$

V. These three conditions ensure that both roots of the characteristic equation lie outside the unit circle, thus guaranteeing the stationarity of the AR(2) process.  This involves several algebraic manipulations and considerations of different cases, which are detailed in standard time series analysis textbooks. ‚ñ†

**Lema 2:**

The formula for the mean, $\mu = \frac{c}{1 - \phi_1 - \phi_2}$, is only valid if the process is covariance-stationary.

*Proof:*
If the process is not covariance-stationary, the expectation $E[Y_t]$ may not be constant over time, rendering the substitution $E[Y_t] = E[Y_{t-1}] = E[Y_{t-2}] = \mu$ invalid. The stationarity conditions ensure that $1 - \phi_1 - \phi_2 \neq 0$, avoiding division by zero in the formula.
In the non-stationary case, one or more roots are on or inside the unit circle, making the above formula inapplicable.

**Prova:**
I. A f√≥rmula para a m√©dia de um processo AR(2) *covariance-stationary* √© derivada tomando as expectativas de ambos os lados da equa√ß√£o AR(2):
   $$Y_t = c + \phi_1 Y_{t-1} + \phi_2 Y_{t-2} + \epsilon_t$$

II. Assumimos que o processo √© *covariance-stationary*, o que implica que a m√©dia √© constante ao longo do tempo:
   $$E[Y_t] = E[Y_{t-1}] = E[Y_{t-2}] = \mu$$

III. Se o processo n√£o for *covariance-stationary*, a m√©dia pode variar com o tempo, invalidando a suposi√ß√£o de que $E[Y_t]$ √© constante.

IV. Al√©m disso, a condi√ß√£o de *covariance-stationarity* garante que o denominador na f√≥rmula da m√©dia n√£o seja zero:
   $$\mu = \frac{c}{1 - \phi_1 - \phi_2}$$
   Se $1 - \phi_1 - \phi_2 = 0$, a m√©dia n√£o √© definida, indicando que o processo n√£o √© *covariance-stationary*.

V. Portanto, a f√≥rmula para a m√©dia √© v√°lida somente se o processo for *covariance-stationary*.  ‚ñ†

**Corol√°rio 1:**
Se $\phi_1 + \phi_2 = 1$, ent√£o o processo AR(2) n√£o √© *covariance-stationary*, e a m√©dia n√£o √© bem definida.

*Proof:*
Quando $\phi_1 + \phi_2 = 1$, o denominador da f√≥rmula da m√©dia torna-se zero: $\mu = \frac{c}{1 - (\phi_1 + \phi_2)} = \frac{c}{1 - 1} = \frac{c}{0}$, que √© indefinido. Portanto, se $\phi_1 + \phi_2 = 1$, o processo n√£o √© *covariance-stationary*, e a m√©dia n√£o pode ser calculada usando esta f√≥rmula.

**Prova:**
I. A f√≥rmula para a m√©dia de um processo AR(2) √© dada por:
   $$\mu = \frac{c}{1 - \phi_1 - \phi_2}$$

II. Se $\phi_1 + \phi_2 = 1$, substitu√≠mos este valor na f√≥rmula da m√©dia:
   $$\mu = \frac{c}{1 - 1} = \frac{c}{0}$$

III. Divis√£o por zero √© indefinida, o que implica que a m√©dia n√£o √© bem definida neste caso.

IV. Adicionalmente, se $\phi_1 + \phi_2 = 1$, o processo AR(2) n√£o √© *covariance-stationary*.  Isso pode ser verificado pelas condi√ß√µes de *covariance-stationarity* para um processo AR(2), que exigem que $\phi_1 + \phi_2 < 1$.

V. Portanto, se $\phi_1 + \phi_2 = 1$, o processo n√£o √© *covariance-stationary* e a m√©dia n√£o pode ser calculada usando a f√≥rmula fornecida.  ‚ñ†

**Teorema 1:** (Yule-Walker Equations for AR(2) Mean) The Yule-Walker equations provide another perspective on the mean of the AR(2) process.

*Proof:* The Yule-Walker equations relate the autocovariances of the AR(2) process to its parameters. Although typically used for estimating $\phi_1$ and $\phi_2$, they can be used to provide an alternative expression for the mean under stationarity. However, the direct derivation from the expectation as presented above is more straightforward for obtaining the mean.

**Teorema 1.1** (Yule-Walker Equations and Autocovariance)
The Yule-Walker equations for a *covariance-stationary* AR(2) process can be expressed as follows:

$$\gamma_0 = \phi_1 \gamma_1 + \phi_2 \gamma_2 + \sigma^2$$
$$\gamma_1 = \phi_1 \gamma_0 + \phi_2 \gamma_1$$
$$\gamma_2 = \phi_1 \gamma_1 + \phi_2 \gamma_0$$

where $\gamma_k = Cov(Y_t, Y_{t-k})$ is the autocovariance at lag k, and $\sigma^2 = Var(\epsilon_t)$ is the variance of the white noise process. These equations, combined with the formula for the mean, provide a complete characterization of the first and second moments of the AR(2) process.

**Prova:**

I.  The Yule-Walker equations are derived from the AR(2) process by multiplying the AR(2) equation by $Y_{t-k}$ and taking expectations.

II. For lag $k=0$:
    $$Y_t Y_t = (c + \phi_1 Y_{t-1} + \phi_2 Y_{t-2} + \epsilon_t) Y_t$$
    Taking expectations:
    $$E[Y_t^2] = cE[Y_t] + \phi_1 E[Y_{t-1}Y_t] + \phi_2 E[Y_{t-2}Y_t] + E[\epsilon_t Y_t]$$
    $$\gamma_0 + \mu^2 = c\mu + \phi_1 (\gamma_1 + \mu^2) + \phi_2 (\gamma_2 + \mu^2) + \sigma^2$$
    where $\gamma_0 = Var(Y_t)$, $\gamma_1 = Cov(Y_t, Y_{t-1})$, $\gamma_2 = Cov(Y_t, Y_{t-2})$, and $\sigma^2 = Var(\epsilon_t)$.

III. For lag $k=1$:
     $$Y_t Y_{t-1} = (c + \phi_1 Y_{t-1} + \phi_2 Y_{t-2} + \epsilon_t) Y_{t-1}$$
     Taking expectations:
     $$E[Y_t Y_{t-1}] = cE[Y_{t-1}] + \phi_1 E[Y_{t-1}^2] + \phi_2 E[Y_{t-2}Y_{t-1}] + E[\epsilon_t Y_{t-1}]$$
     $$\gamma_1 + \mu^2 = c\mu + \phi_1 (\gamma_0 + \mu^2) + \phi_2 (\gamma_1 + \mu^2)$$

IV. For lag $k=2$:
      $$Y_t Y_{t-2} = (c + \phi_1 Y_{t-1} + \phi_2 Y_{t-2} + \epsilon_t) Y_{t-2}$$
      Taking expectations:
      $$E[Y_t Y_{t-2}] = cE[Y_{t-2}] + \phi_1 E[Y_{t-1}Y_{t-2}] + \phi_2 E[Y_{t-2}^2] + E[\epsilon_t Y_{t-2}]$$
      $$\gamma_2 + \mu^2 = c\mu + \phi_1 (\gamma_1 + \mu^2) + \phi_2 (\gamma_0 + \mu^2)$$

V. Simplifying and reorganizing, we obtain the following equations without explicitly substituting for the mean:
    $$\gamma_0 = \phi_1 \gamma_1 + \phi_2 \gamma_2 + \sigma^2$$
    $$\gamma_1 = \phi_1 \gamma_0 + \phi_2 \gamma_1$$
    $$\gamma_2 = \phi_1 \gamma_1 + \phi_2 \gamma_0$$

VI. These equations relate the autocovariances $\gamma_0$, $\gamma_1$, and $\gamma_2$ to the parameters $\phi_1$ and $\phi_2$, and the variance of the error term $\sigma^2$.  They are fundamental in characterizing the second-order properties of the AR(2) process.  ‚ñ†

**Teorema 2**
If the AR(2) process is invertible, its mean exists and is unique.

*Proof:* From the previous discussion, we know that for an AR(2) process, stationarity and invertibility are equivalent. If the process is invertible, it is also stationary, and thus the mean exists and is unique. The converse is also true: if the process is stationary, then it is invertible.

**Prova:**
I.  A process AR(2) √© invert√≠vel se suas ra√≠zes da equa√ß√£o caracter√≠stica estiverem fora do c√≠rculo unit√°rio.

II. Um processo AR(2) √© *covariance-stationary* se suas ra√≠zes da equa√ß√£o caracter√≠stica estiverem fora do c√≠rculo unit√°rio.

III. Portanto, para um processo AR(2), a invertibilidade √© equivalente √† *covariance-stationarity*.

IV. Se o processo for *covariance-stationary*, a m√©dia $\mu$ √© dada por:
    $$\mu = \frac{c}{1 - \phi_1 - \phi_2}$$

V. A condi√ß√£o de *covariance-stationarity* garante que $1 - \phi_1 - \phi_2 \neq 0$, o que implica que a m√©dia existe e √© √∫nica.

VI. Portanto, se o processo AR(2) √© invert√≠vel, a sua m√©dia existe e √© √∫nica. ‚ñ†

**Proposi√ß√£o 1:**
If $c = 0$, then the mean of the *covariance-stationary* AR(2) process is zero.

*Proof:*
Substituting $c = 0$ into the formula for the mean, we have:
$\mu = \frac{0}{1 - \phi_1 - \phi_2} = 0$.
Therefore, if the constant term is zero, the mean of the process is also zero, provided that the process is *covariance-stationary*.

**Prova:**
I.  We start with the formula for the mean of a covariance-stationary AR(2) process:
    $$\mu = \frac{c}{1 - \phi_1 - \phi_2}$$

II. If $c = 0$, we substitute this value into the formula:
    $$\mu = \frac{0}{1 - \phi_1 - \phi_2}$$

III. Since the numerator is zero and the denominator is non-zero (due to the stationarity condition), the result is:
     $$\mu = 0$$

IV. Therefore, if the constant term $c$ is zero, the mean of the covariance-stationary AR(2) process is zero.  ‚ñ†

> üí° **Exemplo Num√©rico:**
> Considere um processo AR(2) com $c = 0$, $\phi_1 = 0.5$ e $\phi_2 = 0.2$. Como $c=0$, a m√©dia do processo √©:
>
> $$\mu = \frac{0}{1 - 0.5 - 0.2} = \frac{0}{0.3} = 0$$
>
> Este exemplo demonstra a Proposi√ß√£o 1, onde a m√©dia do processo √© zero quando a constante *c* √© zero, desde que as condi√ß√µes de estacionariedade sejam satisfeitas. Vamos verificar a estacionariedade:
> 1. $\phi_2 + \phi_1 = 0.2 + 0.5 = 0.7 < 1$
> 2. $\phi_2 - \phi_1 = 0.2 - 0.5 = -0.3 < 1$
> 3. $-1 < \phi_2 = 0.2 < 1$
>
> Como todas as condi√ß√µes s√£o satisfeitas, o processo √© *covariance-stationary* e a m√©dia calculada √© v√°lida.

### Conclus√£o
Este cap√≠tulo demonstrou como derivar a m√©dia de um processo AR(2) assumindo *covariance-stationarity*. A m√©dia √© dada pela f√≥rmula $\mu = \frac{c}{1 - \phi_1 - \phi_2}$, que √© v√°lida somente quando as condi√ß√µes de *covariance-stationarity* s√£o satisfeitas [^58, 3.4.23]. √â fundamental verificar a estacionariedade antes de calcular a m√©dia para garantir que o resultado seja significativo e bem definido. The discussion of the conditions required for the mean to be uniquely defined emphasizes the importance of understanding stationarity in the analysis of AR(2) processes. Compreender esses conceitos √© fundamental para a modelagem e previs√£o precisas de s√©ries temporais usando processos AR(2).

### Refer√™ncias
[^45]: Defini√ß√£o de *covariance-stationary* e autocovari√¢ncias.
[^47]: Defini√ß√£o do termo de erro (ru√≠do branco).
[^48]: Propriedades do ru√≠do branco.
[^56]: Defini√ß√£o de um processo autorregressivo de segunda ordem AR(2).
[^57]: Estacionariedade de um processo AR(2) e a equa√ß√£o de diferen√ßa das autocovari√¢ncias.
[^58]: Como calcular as primeiras autocovari√¢ncias.
<!-- END -->