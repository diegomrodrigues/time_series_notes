## T√≠tulo Conciso
Second-Order Autoregressive Processes: Definition, Stationarity, and Autocovariances

### Introdu√ß√£o
Expandindo o conceito de processos autorregressivos (AR) introduzidos anteriormente, este cap√≠tulo se aprofunda nos processos autorregressivos de segunda ordem, denotados AR(2). Como vimos, os processos AR(1) dependem linearmente do valor anterior da s√©rie temporal [^53]. Os processos AR(2) estendem essa depend√™ncia para incluir as duas observa√ß√µes anteriores, oferecendo maior flexibilidade na modelagem de depend√™ncias temporais. Este cap√≠tulo explorar√° a defini√ß√£o formal de um processo AR(2), as condi√ß√µes para sua estacionariedade, e o c√°lculo das autocovari√¢ncias. Furthermore, we will explore the invertibility of AR(2) processes, a concept closely linked to stationarity.

### Conceitos Fundamentais

Um processo autorregressivo de segunda ordem, denotado AR(2), √© definido pela seguinte equa√ß√£o [^56]:

$$Y_t = c + \phi_1 Y_{t-1} + \phi_2 Y_{t-2} + \epsilon_t$$

onde:

*   $Y_t$ √© o valor da s√©rie temporal no instante *t*.
*   *c* √© uma constante.
*   $\phi_1$ e $\phi_2$ s√£o os coeficientes autorregressivos.
*   $Y_{t-1}$ e $Y_{t-2}$ s√£o os valores da s√©rie temporal nos instantes *t-1* e *t-2*, respectivamente.
*   $\epsilon_t$ √© um termo de erro (ru√≠do branco) com m√©dia zero e vari√¢ncia constante, $\sigma^2$ [^47]. Assume-se que $\{\epsilon_t\}$ seja um processo de ru√≠do branco que satisfaz $E(\epsilon_t) = 0$, $E(\epsilon_t^2) = \sigma^2$ [^47] e $E(\epsilon_t \epsilon_\tau) = 0$ para $t \ne \tau$ [^48].

> üí° **Exemplo Num√©rico:**
> Considere um processo AR(2) com $c = 5$, $\phi_1 = 0.6$, $\phi_2 = 0.3$ e $\sigma^2 = 1$. Se $Y_{t-1} = 10$ e $Y_{t-2} = 8$, e o termo de erro $\epsilon_t = 0.5$, ent√£o:
>
> $Y_t = 5 + 0.6(10) + 0.3(8) + 0.5 = 5 + 6 + 2.4 + 0.5 = 13.9$
>
> Este exemplo ilustra como o valor atual da s√©rie temporal √© influenciado pelos dois valores anteriores e pelo termo de erro.

Em nota√ß√£o de operador de retardo (lag operator), a equa√ß√£o acima pode ser escrita como [^57]:

$$(1 - \phi_1 L - \phi_2 L^2)Y_t = c + \epsilon_t$$ [^57]

onde *L* √© o operador de retardo, tal que $LY_t = Y_{t-1}$.

**Estacionariedade:**

A estacionariedade de um processo AR(2) √© crucial para a interpretabilidade e a aplicabilidade do modelo. Um processo AR(2) √© considerado *covariance-stationary* se sua m√©dia e autocovari√¢ncia n√£o variam com o tempo [^45]. A condi√ß√£o para estacionariedade de um processo AR(2) √© que as ra√≠zes da equa√ß√£o caracter√≠stica associada estejam fora do c√≠rculo unit√°rio [^57]. A equa√ß√£o caracter√≠stica √© dada por [^57]:

$$1 - \phi_1 z - \phi_2 z^2 = 0$$ [^57]

onde *z* √© uma vari√°vel complexa. Equivalentemente, as ra√≠zes da equa√ß√£o podem ser determinadas atrav√©s da f√≥rmula quadr√°tica. As ra√≠zes da equa√ß√£o caracter√≠stica devem estar fora do c√≠rculo unit√°rio para garantir a estabilidade [^57].

> üí° **Exemplo Num√©rico:**
> Vamos verificar se um processo AR(2) com $\phi_1 = 0.5$ e $\phi_2 = 0.3$ √© estacion√°rio. A equa√ß√£o caracter√≠stica √©:
> $1 - 0.5z - 0.3z^2 = 0$, ou $0.3z^2 + 0.5z - 1 = 0$.
> Usando a f√≥rmula quadr√°tica:
>
> $$z = \frac{-0.5 \pm \sqrt{0.5^2 - 4(0.3)(-1)}}{2(0.3)} = \frac{-0.5 \pm \sqrt{0.25 + 1.2}}{0.6} = \frac{-0.5 \pm \sqrt{1.45}}{0.6} \approx \frac{-0.5 \pm 1.204}{0.6}$$
>
> As ra√≠zes s√£o:
> $z_1 \approx \frac{-0.5 + 1.204}{0.6} \approx 1.173$
> $z_2 \approx \frac{-0.5 - 1.204}{0.6} \approx -2.84$
>
> Como $|z_1| > 1$ e $|z_2| > 1$, o processo √© estacion√°rio.

Se as ra√≠zes est√£o dentro do c√≠rculo unit√°rio, o processo n√£o √© estacion√°rio, e as autocovari√¢ncias crescer√£o indefinidamente com o tempo [^53]. As condi√ß√µes em termos de $\phi_1$ e $\phi_2$ para garantir que as ra√≠zes estejam fora do c√≠rculo unit√°rio s√£o as seguintes: o processo AR(2) √© *covariance-stationary* contanto que $\phi_1$ e $\phi_2$ estejam dentro da regi√£o triangular na Figura 1.5 (n√£o fornecida no contexto). These conditions can be explicitly stated as:

$$ \phi_1 + \phi_2 < 1 $$
$$ \phi_2 - \phi_1 < 1 $$
$$ -1 < \phi_2 < 1 $$

> üí° **Exemplo Num√©rico:**
> Usando o mesmo exemplo, $\phi_1 = 0.5$ e $\phi_2 = 0.3$:
>
> $\phi_1 + \phi_2 = 0.5 + 0.3 = 0.8 < 1$
> $\phi_2 - \phi_1 = 0.3 - 0.5 = -0.2 < 1$
> $-1 < \phi_2 = 0.3 < 1$
>
> Todas as condi√ß√µes s√£o satisfeitas, o que confirma a estacionariedade.
>
> Agora, considere $\phi_1 = 1.2$ e $\phi_2 = -0.3$:
>
> $\phi_1 + \phi_2 = 1.2 - 0.3 = 0.9 < 1$
> $\phi_2 - \phi_1 = -0.3 - 1.2 = -1.5 < 1$
> $-1 < \phi_2 = -0.3 < 1$
>
> Apesar de satisfazer as condi√ß√µes individuais, vamos verificar as ra√≠zes da equa√ß√£o caracter√≠stica:
> $1 - 1.2z + 0.3z^2 = 0$, ou $0.3z^2 - 1.2z + 1 = 0$.
>
> $$z = \frac{1.2 \pm \sqrt{(-1.2)^2 - 4(0.3)(1)}}{2(0.3)} = \frac{1.2 \pm \sqrt{1.44 - 1.2}}{0.6} = \frac{1.2 \pm \sqrt{0.24}}{0.6} \approx \frac{1.2 \pm 0.49}{0.6}$$
>
> As ra√≠zes s√£o:
> $z_1 \approx \frac{1.2 + 0.49}{0.6} \approx 2.82$
> $z_2 \approx \frac{1.2 - 0.49}{0.6} \approx 1.18$
>
> Como $|z_1| > 1$ e $|z_2| > 1$, o processo √© estacion√°rio. No entanto, se tiv√©ssemos $\phi_1 = 0.7$ e $\phi_2 = 0.9$, ent√£o $\phi_1 + \phi_2 = 1.6 > 1$ e o processo n√£o seria estacion√°rio.

**Lema 1:**
The stationarity conditions can be derived by analyzing the roots of the characteristic equation.

*Proof:*
Let $z_1$ and $z_2$ be the roots of the characteristic equation $1 - \phi_1 z - \phi_2 z^2 = 0$.  The process is stationary if $|z_1| > 1$ and $|z_2| > 1$. This implies that the roots must lie outside the unit circle in the complex plane.  Transforming the equation to $\phi_2 z^2 + \phi_1 z - 1 = 0$, we have the roots

$$z_{1,2} = \frac{-\phi_1 \pm \sqrt{\phi_1^2 + 4\phi_2}}{2\phi_2}.$$

For stationarity, we require $|z_1| > 1$ and $|z_2| > 1$.
The conditions $\phi_1 + \phi_2 < 1$, $\phi_2 - \phi_1 < 1$, and $-1 < \phi_2 < 1$ are equivalent to $|z_1| > 1$ and $|z_2| > 1$.

**Invertibilidade:**

Analogous to stationarity, invertibility is another important property of time series models. An AR(2) process is invertible if it can be represented as an infinite-order moving average (MA($\infty$)) process. The conditions for invertibility are related to the roots of a polynomial similar to the characteristic equation, but with the coefficients in reverse order.

**Teorema 1**
An AR(2) process is invertible if the roots of the polynomial

$$\phi_2 - \phi_1 z + z^2 = 0$$

lie outside the unit circle.

*Proof:* The invertibility condition ensures that the AR(2) process can be expressed as an infinite moving average process with convergent coefficients. This is equivalent to requiring that the roots of the polynomial above are outside the unit circle.

The invertibility conditions can also be expressed in terms of $\phi_1$ and $\phi_2$ as:

$$ \phi_1 - \phi_2 < 1 $$
$$ -\phi_2 - \phi_1 < 1 $$
$$ -1 < \phi_2 < 1 $$
Note that for an AR(2) process, the stationarity and invertibility regions in the $(\phi_1, \phi_2)$ plane are identical. This means that an AR(2) process is stationary if and only if it is invertible.

> üí° **Exemplo Num√©rico:**
> Usando $\phi_1 = 0.5$ e $\phi_2 = 0.3$ novamente, vamos verificar a invertibilidade:
>
> $\phi_1 - \phi_2 = 0.5 - 0.3 = 0.2 < 1$
> $-\phi_2 - \phi_1 = -0.3 - 0.5 = -0.8 < 1$
> $-1 < \phi_2 = 0.3 < 1$
>
> Todas as condi√ß√µes s√£o satisfeitas, e o processo √© invert√≠vel.
>
> Para o caso de $\phi_1 = 1.2$ e $\phi_2 = -0.3$:
>
> $\phi_1 - \phi_2 = 1.2 - (-0.3) = 1.5 > 1$, o processo n√£o √© invert√≠vel.

**Autocovari√¢ncias:**

As autocovari√¢ncias de um processo AR(2) descrevem a depend√™ncia entre os valores da s√©rie temporal em diferentes pontos no tempo [^45]. A *j*-√©sima autocovari√¢ncia, denotada por $\gamma_j$, √© definida como [^45]:

$$\gamma_j = E[(Y_t - \mu)(Y_{t-j} - \mu)]$$ [^45]

Para um processo AR(2) estacion√°rio, as autocovari√¢ncias satisfazem a seguinte equa√ß√£o de diferen√ßa de segunda ordem [^57]:

$$\gamma_j = \phi_1 \gamma_{j-1} + \phi_2 \gamma_{j-2} \quad \text{para } j = 1, 2, ...$$ [^57]

As primeiras autocovari√¢ncias ($\gamma_0$, $\gamma_1$, e $\gamma_2$) podem ser calculadas resolvendo um sistema de equa√ß√µes. Multiplicando ambos os lados da equa√ß√£o AR(2) por $(Y_t - \mu)$ e tomando as expectativas, obtemos [^58]:

$$E[(Y_t - \mu)^2] = \phi_1 E[(Y_{t-1} - \mu)(Y_t - \mu)] + \phi_2 E[(Y_{t-2} - \mu)(Y_t - \mu)] + E[\epsilon_t(Y_t - \mu)]$$ [^58]

$$\gamma_0 = \phi_1 \gamma_1 + \phi_2 \gamma_2 + \sigma^2$$ [^58]

Para $j = 1$ e $j = 2$, obtemos [^57]:

$$\gamma_1 = \phi_1 \gamma_0 + \phi_2 \gamma_1$$ [^57]
$$\gamma_2 = \phi_1 \gamma_1 + \phi_2 \gamma_0$$ [^57]

Estas equa√ß√µes podem ser resolvidas para encontrar $\gamma_0$, $\gamma_1$ e $\gamma_2$ em termos de $\phi_1$, $\phi_2$ e $\sigma^2$ [^58]. Solving this system of equations yields:

$$ \gamma_0 = \frac{(1 - \phi_2)\sigma^2}{(1+\phi_2)((1-\phi_2)^2 - \phi_1^2)} $$
$$ \gamma_1 = \frac{\phi_1 \sigma^2}{(1+\phi_2)((1-\phi_2)^2 - \phi_1^2)} $$
$$ \gamma_2 = \frac{(\phi_1^2 + \phi_2 - \phi_2^2)\sigma^2}{(1+\phi_2)((1-\phi_2)^2 - \phi_1^2)} $$

> üí° **Exemplo Num√©rico:**
> Vamos calcular as autocovari√¢ncias para um processo AR(2) com $\phi_1 = 0.5$, $\phi_2 = 0.3$ e $\sigma^2 = 1$.
>
> $\gamma_0 = \frac{(1 - 0.3)(1)}{(1+0.3)((1-0.3)^2 - 0.5^2)} = \frac{0.7}{1.3(0.49 - 0.25)} = \frac{0.7}{1.3(0.24)} = \frac{0.7}{0.312} \approx 2.2449$
>
> $\gamma_1 = \frac{0.5(1)}{1.3(0.24)} = \frac{0.5}{0.312} \approx 1.6026$
>
> $\gamma_2 = \frac{(0.5^2 + 0.3 - 0.3^2)(1)}{1.3(0.24)} = \frac{(0.25 + 0.3 - 0.09)}{0.312} = \frac{0.46}{0.312} \approx 1.4744$
>
> As autocovari√¢ncias s√£o $\gamma_0 \approx 2.2449$, $\gamma_1 \approx 1.6026$ e $\gamma_2 \approx 1.4744$.

As autocorrela√ß√µes, denotadas por $\rho_j$, s√£o definidas como as autocovari√¢ncias normalizadas pela vari√¢ncia [^49]:

$$\rho_j = \frac{\gamma_j}{\gamma_0}$$ [^49]

As autocorrela√ß√µes tamb√©m seguem a mesma equa√ß√£o de diferen√ßa de segunda ordem [^57]:

$$\rho_j = \phi_1 \rho_{j-1} + \phi_2 \rho_{j-2} \quad \text{para } j = 1, 2, ...$$ [^57]

O padr√£o de decaimento das autocorrela√ß√µes pode ser usado para identificar um processo AR(2). As autocorrela√ß√µes podem ser a soma de duas fun√ß√µes exponenciais de decaimento, ou uma fun√ß√£o senoidal amortecida [^58]. The behavior of the autocorrelations depends on the roots of the characteristic equation. If the roots are real, the autocorrelations will decay exponentially. If the roots are complex, the autocorrelations will exhibit a damped sinusoidal pattern.

> üí° **Exemplo Num√©rico:**
> Usando as autocovari√¢ncias calculadas anteriormente: $\gamma_0 \approx 2.2449$, $\gamma_1 \approx 1.6026$ e $\gamma_2 \approx 1.4744$.
>
> $\rho_1 = \frac{\gamma_1}{\gamma_0} = \frac{1.6026}{2.2449} \approx 0.7139$
>
> $\rho_2 = \frac{\gamma_2}{\gamma_0} = \frac{1.4744}{2.2449} \approx 0.6568$
>
> Agora, podemos calcular $\rho_3$ usando a equa√ß√£o de diferen√ßa:
>
> $\rho_3 = \phi_1 \rho_2 + \phi_2 \rho_1 = 0.5(0.6568) + 0.3(0.7139) = 0.3284 + 0.21417 = 0.54257 \approx 0.5426$

**Teorema 1.1**
The nature of the roots of the characteristic equation dictates the behavior of the autocorrelation function. Specifically:

1.  If the roots $r_1$ and $r_2$ are real and distinct, then $\rho_j = A r_1^j + B r_2^j$, where $A$ and $B$ are constants. This corresponds to a sum of two decaying exponentials.

2.  If the roots are real and equal (i.e., $r_1 = r_2 = r$), then $\rho_j = (A + Bj)r^j$, where $A$ and $B$ are constants.

3.  If the roots are complex conjugates, i.e., $r_{1,2} = \alpha \pm i\beta$, then $\rho_j = R^j (A \cos(j\theta) + B \sin(j\theta))$, where $R = \sqrt{\alpha^2 + \beta^2}$, $\theta = \arctan(\beta/\alpha)$, and $A$ and $B$ are constants. This corresponds to a damped sinusoidal pattern.

*Proof:*
The proof relies on the general solution of second-order linear difference equations. The characteristic equation is given by $1 - \phi_1 z - \phi_2 z^2 = 0$. The roots $z_1$ and $z_2$ of this equation determine the form of the general solution for $\rho_j$.

1.  If $z_1 \neq z_2$ and both are real, then the general solution is of the form $\rho_j = A z_1^{-j} + B z_2^{-j}$. Letting $r_1 = 1/z_1$ and $r_2 = 1/z_2$, we have $\rho_j = A r_1^j + B r_2^j$.

2.  If $z_1 = z_2 = z$ and both are real, the general solution is $\rho_j = (A + Bj) z^{-j}$. Letting $r = 1/z$, we have $\rho_j = (A + Bj) r^j$.

3.  If $z_1$ and $z_2$ are complex conjugates, they can be written as $z_{1,2} = R e^{\pm i\theta}$, where $R$ is the modulus and $\theta$ is the argument. The general solution is then of the form $\rho_j = A (R e^{i\theta})^{-j} + B (R e^{-ij\theta})^{-j} = R^{-j} (A e^{-ij\theta} + B e^{ij\theta})$.
    Using Euler's formula, we can rewrite this as $\rho_j = R^{-j} (A' \cos(j\theta) + B' \sin(j\theta))$, where $A'$ and $B'$ are new constants. Since $R = \sqrt{\alpha^2 + \beta^2}$ and $r_1 = 1/z_1$ and $r_2 = 1/z_2$, then $R = \sqrt{r_1 r_2}$. If the roots are outside the unit circle, $|r_1| > 1$ and $|r_2| > 1$, implying $|R| > 1$. Therefore, the autocorrelations will decay as $j$ increases if the process is stationary.

**Proposi√ß√£o 1**
The autocorrelations of an AR(2) process can be expressed as:

$$\rho_j = A r_1^j + B r_2^j$$

where $r_1$ and $r_2$ are the roots of the characteristic equation, and A and B are constants determined by the initial conditions $\rho_0 = 1$ and $\rho_1 = \frac{\phi_1}{1-\phi_2}$.

*Proof:* This follows directly from the theory of linear difference equations. The general solution to the difference equation for $\rho_j$ is a linear combination of terms involving the roots of the characteristic equation raised to the power of $j$.

**Prova da Deriva√ß√£o de Œ≥‚ÇÄ, Œ≥‚ÇÅ, e Œ≥‚ÇÇ:**
Podemos verificar as solu√ß√µes apresentadas para $\gamma_0$, $\gamma_1$, e $\gamma_2$.

I.  Come√ßamos com o sistema de equa√ß√µes:
    $$\gamma_0 = \phi_1 \gamma_1 + \phi_2 \gamma_2 + \sigma^2$$
    $$\gamma_1 = \phi_1 \gamma_0 + \phi_2 \gamma_1$$
    $$\gamma_2 = \phi_1 \gamma_1 + \phi_2 \gamma_0$$

II. Da segunda equa√ß√£o, podemos expressar $\gamma_1$ em termos de $\gamma_0$:
    $$\gamma_1 = \phi_1 \gamma_0 + \phi_2 \gamma_1 \implies \gamma_1(1-\phi_2) = \phi_1 \gamma_0 \implies \gamma_1 = \frac{\phi_1 \gamma_0}{1-\phi_2}$$

III. Substitu√≠mos essa express√£o de $\gamma_1$ na terceira equa√ß√£o:
    $$\gamma_2 = \phi_1 \left(\frac{\phi_1 \gamma_0}{1-\phi_2}\right) + \phi_2 \gamma_0 = \gamma_0 \left(\frac{\phi_1^2}{1-\phi_2} + \phi_2\right) = \gamma_0 \left(\frac{\phi_1^2 + \phi_2 - \phi_2^2}{1-\phi_2}\right)$$

IV. Agora, substitu√≠mos as express√µes de $\gamma_1$ e $\gamma_2$ na primeira equa√ß√£o:
    $$\gamma_0 = \phi_1 \left(\frac{\phi_1 \gamma_0}{1-\phi_2}\right) + \phi_2 \left(\gamma_0 \left(\frac{\phi_1^2 + \phi_2 - \phi_2^2}{1-\phi_2}\right)\right) + \sigma^2$$

V. Isolamos $\gamma_0$:
    $$\gamma_0 \left(1 - \frac{\phi_1^2}{1-\phi_2} - \frac{\phi_2(\phi_1^2 + \phi_2 - \phi_2^2)}{1-\phi_2}\right) = \sigma^2$$
    $$\gamma_0 \left(\frac{1-\phi_2 - \phi_1^2 - \phi_2\phi_1^2 - \phi_2^2 + \phi_2^3}{1-\phi_2}\right) = \sigma^2$$
    $$\gamma_0 \left(\frac{1 - \phi_2 - \phi_1^2 - \phi_2^2 + \phi_2^3 - \phi_2 \phi_1^2}{1-\phi_2}\right) = \sigma^2$$
    $$\gamma_0 = \frac{(1-\phi_2)\sigma^2}{1-\phi_2 - \phi_1^2 - \phi_2^2 + \phi_2^3 - \phi_2 \phi_1^2} = \frac{(1-\phi_2)\sigma^2}{(1+\phi_2)((1-\phi_2)^2 - \phi_1^2)}$$

VI. Encontramos $\gamma_1$:
    $$\gamma_1 = \frac{\phi_1 \gamma_0}{1-\phi_2} = \frac{\phi_1}{1-\phi_2} \cdot \frac{(1-\phi_2)\sigma^2}{(1+\phi_2)((1-\phi_2)^2 - \phi_1^2)} = \frac{\phi_1 \sigma^2}{(1+\phi_2)((1-\phi_2)^2 - \phi_1^2)}$$

VII. E encontramos $\gamma_2$:
     $$\gamma_2 = \gamma_0 \left(\frac{\phi_1^2 + \phi_2 - \phi_2^2}{1-\phi_2}\right) = \frac{(1-\phi_2)\sigma^2}{(1+\phi_2)((1-\phi_2)^2 - \phi_1^2)} \cdot \left(\frac{\phi_1^2 + \phi_2 - \phi_2^2}{1-\phi_2}\right) = \frac{(\phi_1^2 + \phi_2 - \phi_2^2)\sigma^2}{(1+\phi_2)((1-\phi_2)^2 - \phi_1^2)}$$

VIII. Portanto, demonstramos que:
    $$\gamma_0 = \frac{(1-\phi_2)\sigma^2}{(1+\phi_2)((1-\phi_2)^2 - \phi_1^2)}$$
    $$\gamma_1 = \frac{\phi_1 \sigma^2}{(1+\phi_2)((1-\phi_2)^2 - \phi_1^2)}$$
    $$\gamma_2 = \frac{(\phi_1^2 + \phi_2 - \phi_2^2)\sigma^2}{(1+\phi_2)((1-\phi_2)^2 - \phi_1^2)}$$ ‚ñ†

### Conclus√£o
O processo AR(2) oferece uma estrutura flex√≠vel para modelar s√©ries temporais com depend√™ncia de duas observa√ß√µes anteriores. A estacionariedade do processo √© garantida se as ra√≠zes da equa√ß√£o caracter√≠stica associada estiverem fora do c√≠rculo unit√°rio. O comportamento das autocovari√¢ncias fornece *insights* sobre a estrutura de depend√™ncia temporal da s√©rie. A an√°lise das autocorrela√ß√µes e autocovari√¢ncias √© fundamental para entender o comportamento da s√©rie temporal e escolher o modelo apropriado. Invertibility, which is equivalent to stationarity for AR(2) processes, is also crucial for model interpretation. The explicit formulas for autocovariances and the representation of autocorrelations in terms of the roots of the characteristic equation provide powerful tools for analyzing and understanding AR(2) processes.

### Refer√™ncias
[^45]: Defini√ß√£o de *covariance-stationary* e autocovari√¢ncias.
[^47]: Defini√ß√£o do termo de erro (ru√≠do branco).
[^48]: Propriedades do ru√≠do branco.
[^49]: Autocorrela√ß√µes.
[^53]: Introdu√ß√£o aos processos autorregressivos AR(1).
[^56]: Defini√ß√£o de um processo autorregressivo de segunda ordem AR(2).
[^57]: Estacionariedade de um processo AR(2) e a equa√ß√£o de diferen√ßa das autocovari√¢ncias.
[^58]: Como calcular as primeiras autocovari√¢ncias.
<!-- END -->