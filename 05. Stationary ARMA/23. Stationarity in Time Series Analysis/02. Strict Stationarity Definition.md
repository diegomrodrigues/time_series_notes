## Estacionariedade Estrita em An√°lise de S√©ries Temporais

### Introdu√ß√£o
Expandindo o conceito de estacionariedade em s√©ries temporais, este cap√≠tulo aprofunda-se na **estacionariedade estrita** (*strict stationarity*). Como vimos anteriormente, a *covariance stationarity* garante que a m√©dia e as autocovari√¢ncias de uma s√©rie temporal sejam invariantes no tempo. A *strict stationarity*, por outro lado, imp√µe uma condi√ß√£o mais forte, exigindo que a distribui√ß√£o conjunta de qualquer conjunto de observa√ß√µes na s√©rie temporal seja invariante no tempo. Este cap√≠tulo explora a defini√ß√£o formal, implica√ß√µes te√≥ricas e exemplos de estacionariedade estrita.

### Conceitos Fundamentais
Uma s√©rie temporal $\{Y_t\}$ √© dita **strictly stationary** se a distribui√ß√£o conjunta de $(Y_{t}, Y_{t+j_1}, ..., Y_{t+j_n})$ depende apenas dos intervalos separando as datas ($j_1, j_2, ..., j_n$) e n√£o da data $t$ [^3]. Formalmente, para qualquer $t$, $k$, e qualquer conjunto de inteiros $j_1, j_2, \ldots, j_n$,

$$F(Y_{t+k}, Y_{t+k+j_1}, \ldots, Y_{t+k+j_n}) = F(Y_t, Y_{t+j_1}, \ldots, Y_{t+j_n})$$

onde $F$ denota a fun√ß√£o de distribui√ß√£o conjunta. Em ess√™ncia, isto significa que a forma da distribui√ß√£o da s√©rie temporal n√£o muda com o tempo; a s√©rie exibe propriedades estat√≠sticas id√™nticas em qualquer janela de tempo.

#### Implica√ß√µes da Estacionariedade Estrita
1. **Invari√¢ncia da Distribui√ß√£o:** A estacionariedade estrita implica que todos os momentos da distribui√ß√£o (n√£o apenas a m√©dia e a vari√¢ncia) s√£o constantes no tempo [^3]. Isto inclui assimetria (*skewness*), curtose (*kurtosis*) e outros momentos de ordem superior.

> üí° **Exemplo Num√©rico:** Considere uma s√©rie temporal de retornos de a√ß√µes. Se for *strictly stationary*, a assimetria da distribui√ß√£o dos retornos (que indica a tend√™ncia de grandes quedas ou aumentos) ser√° constante ao longo do tempo. Se observarmos consistentemente uma assimetria negativa, isso significa que grandes quedas s√£o mais frequentes do que grandes aumentos, e essa caracter√≠stica se mant√©m constante.

2. **Propriedades Ergodicas:** Sob certas condi√ß√µes, a estacionariedade estrita implica *ergodicity*, que permite a infer√™ncia de propriedades estat√≠sticas da s√©rie a partir de uma √∫nica realiza√ß√£o observada. Este conceito ser√° explorado em detalhes em cap√≠tulos subsequentes.

3. **Rela√ß√£o com Covariance Stationarity:** Como mencionado anteriormente, se um processo √© *strictly stationary* e tem momentos de segunda ordem finitos, ent√£o ele √© *covariance-stationary* [^3]. No entanto, o inverso nem sempre √© verdadeiro.

> üí° **Exemplo Num√©rico:** Se temos uma s√©rie temporal que √© *strictly stationary* e tem vari√¢ncia finita, podemos calcular a m√©dia amostral dessa s√©rie e ela convergir√° para a m√©dia verdadeira da s√©rie √† medida que o tamanho da amostra aumenta. A *covariance stationarity* √© uma condi√ß√£o necess√°ria para isso.

4. **Fun√ß√£o de Distribui√ß√£o Invariante no Tempo:** Se $\{Y_t\}$ √© strictly stationary, a fun√ß√£o de distribui√ß√£o cumulativa (CDF) de $Y_t$ √© id√™ntica para todo $t$.
Seja $F_t(y)$ a CDF de $Y_t$, ent√£o $F_t(y) = P(Y_t \leq y)$. Se $\{Y_t\}$ √© strictly stationary, ent√£o $F_t(y) = F(y)$ para todo $t$, onde $F(y)$ √© uma fun√ß√£o de distribui√ß√£o fixa.

**Proposi√ß√£o 2** Se $\{Y_t\}$ √© strictly stationary, ent√£o $E[g(Y_t)] = E[g(Y_{t+k})]$ para qualquer fun√ß√£o mensur√°vel $g$ e qualquer inteiro $k$.

*Proof:* Seja $g$ uma fun√ß√£o mensur√°vel. Ent√£o $g(Y_t)$ √© uma vari√°vel aleat√≥ria. Se $\{Y_t\}$ √© strictly stationary, ent√£o a distribui√ß√£o de $Y_t$ √© a mesma que a distribui√ß√£o de $Y_{t+k}$ para qualquer inteiro $k$. Portanto, $E[g(Y_t)] = \int g(y) \, dF_t(y) = \int g(y) \, dF_{t+k}(y) = E[g(Y_{t+k})]$. $\blacksquare$

> üí° **Exemplo Num√©rico:** Suponha que a s√©rie temporal represente retornos di√°rios de um ativo financeiro. Se a s√©rie for *strictly stationary*, ent√£o a probabilidade de observar um retorno superior a 2% em qualquer dia √© constante ao longo do tempo.

> üí° **Exemplo Num√©rico:** Considere $g(x) = x^2$. Se $\{Y_t\}$ √© *strictly stationary*, ent√£o $E[Y_t^2] = E[Y_{t+k}^2]$ para todo $t$ e $k$. Isso significa que a m√©dia dos quadrados dos valores da s√©rie temporal √© constante ao longo do tempo.

#### Exemplos e Contraexemplos de Estacionariedade Estrita
1.  **Ru√≠do Branco Independente e Identicamente Distribu√≠do (IID):** Seja $\{\epsilon_t\}$ uma sequ√™ncia de vari√°veis aleat√≥rias IID com m√©dia zero e vari√¢ncia finita. Este √© um exemplo de um processo *strictly stationary*. A distribui√ß√£o conjunta de qualquer conjunto de $\epsilon_t$s depende apenas da distribui√ß√£o individual, que √© invariante no tempo.

    *Proof:* Suponha que $\epsilon_t \sim F_{\epsilon}$ para todo $t$, onde $F_{\epsilon}$ √© uma fun√ß√£o de distribui√ß√£o fixa. Ent√£o, a distribui√ß√£o conjunta de $(\epsilon_t, \epsilon_{t+j_1}, \ldots, \epsilon_{t+j_n})$ √© dada por $F_{\epsilon}(\epsilon_t)F_{\epsilon}(\epsilon_{t+j_1}) \ldots F_{\epsilon}(\epsilon_{t+j_n})$. Essa distribui√ß√£o conjunta √© a mesma para qualquer tempo $t$ porque as vari√°veis s√£o IID e, portanto, a distribui√ß√£o do processo depende apenas dos intervalos separando as datas ($j_1, j_2, ..., j_n$) e n√£o da data $t$ em si, cumprindo a condi√ß√£o de *strict stationarity*. $\blacksquare$

> üí° **Exemplo Num√©rico:** Suponha que $\{\epsilon_t\}$ seja uma sequ√™ncia de vari√°veis aleat√≥rias independentes e identicamente distribu√≠das (IID) seguindo uma distribui√ß√£o normal padr√£o, ou seja, $\epsilon_t \sim N(0, 1)$ para todo $t$. Para qualquer conjunto de tempos $t_1, t_2, ..., t_n$, a distribui√ß√£o conjunta de $(\epsilon_{t_1}, \epsilon_{t_2}, ..., \epsilon_{t_n})$ √© o produto das densidades normais padr√£o, que n√£o dependem do tempo $t$.

2.  **Processo Bernoulli Estacion√°rio:** Considere uma sequ√™ncia de lan√ßamentos de uma moeda justa, onde $Y_t = 1$ se o lan√ßamento $t$ resultar em cara e $Y_t = 0$ se resultar em coroa. Se a probabilidade de cara e coroa for constante ao longo do tempo, o processo √© *strictly stationary*.

    **Proposi√ß√£o 1** Um processo de Bernoulli estacion√°rio $\{Y_t\}$ com probabilidade $p$ de sucesso √© strictly stationary.

    *Proof:* Seja $Y_t$ uma vari√°vel aleat√≥ria de Bernoulli com $P(Y_t = 1) = p$ e $P(Y_t = 0) = 1-p$ para todo $t$. Como os lan√ßamentos s√£o independentes, a distribui√ß√£o conjunta de $(Y_{t}, Y_{t+j_1}, ..., Y_{t+j_n})$ √© dada por $P(Y_{t})P(Y_{t+j_1}) \ldots P(Y_{t+j_n})$. Como $P(Y_t = 1) = p$ e $P(Y_t = 0) = 1-p$ para todo $t$, a distribui√ß√£o conjunta √© independente de $t$ e depende apenas dos intervalos separando as datas ($j_1, j_2, ..., j_n$), satisfazendo a condi√ß√£o de strict stationarity. $\blacksquare$

> üí° **Exemplo Num√©rico:** Se a moeda √© justa, $p = 0.5$. Ent√£o a probabilidade de observar uma sequ√™ncia espec√≠fica de lan√ßamentos, digamos (cara, coroa, cara) nos tempos $t, t+1, t+2$, √© $(0.5)(0.5)(0.5) = 0.125$. Essa probabilidade √© a mesma para qualquer conjunto de tr√™s tempos consecutivos, indicando *strict stationarity*.

3.  **Caminhada Aleat√≥ria Simples:** Seja $Y_t = Y_{t-1} + \epsilon_t$, onde $\epsilon_t$ √© ru√≠do branco IID e $Y_0 = 0$. Este processo n√£o √© *strictly stationary*. Embora a distribui√ß√£o de $\epsilon_t$ seja invariante no tempo, a distribui√ß√£o de $Y_t$ varia com o tempo porque sua vari√¢ncia aumenta linearmente com $t$.

    *Proof:* A distribui√ß√£o conjunta de $Y_1, Y_2, \ldots, Y_n$ depende de $Y_0$, que √© uma constante. No entanto, a distribui√ß√£o de $Y_t$ muda com $t$. Por exemplo, $Var(Y_t) = Var(\sum_{i=1}^{t} \epsilon_i) = \sum_{i=1}^{t} Var(\epsilon_i) = t\sigma^2$. Assim, a vari√¢ncia de $Y_t$ aumenta com $t$. Portanto, a distribui√ß√£o de $Y_t$ muda com $t$, e o processo n√£o √© strictly stationary. $\blacksquare$

    > üí° **Exemplo Num√©rico:** Considere uma caminhada aleat√≥ria onde $Y_t = Y_{t-1} + \epsilon_t$ com $Y_0 = 0$ e $\epsilon_t$ sendo ru√≠do branco com m√©dia zero e vari√¢ncia 1. A vari√¢ncia de $Y_t$ ser√° igual a $t$, crescendo linearmente com o tempo. Isso significa que, √† medida que $t$ aumenta, a dispers√£o dos valores poss√≠veis de $Y_t$ tamb√©m aumenta, indicando que a distribui√ß√£o de $Y_t$ n√£o √© a mesma para todos os $t$.

> üí° **Exemplo Num√©rico:**  Simulando uma caminhada aleat√≥ria com $\epsilon_t \sim N(0,1)$ e $Y_0 = 0$ para $t = 1, 2, ..., 100$, podemos observar que a vari√¢ncia de $Y_t$ aumenta com o tempo. Para $t=10$, a vari√¢ncia amostral de $Y_{10}$ seria pr√≥xima de 10, enquanto para $t=50$, a vari√¢ncia amostral de $Y_{50}$ seria pr√≥xima de 50. Isso demonstra visualmente que a distribui√ß√£o de $Y_t$ n√£o √© constante ao longo do tempo, violando a *strict stationarity*.

### Rela√ß√£o entre Covariance-Stationary e Strictly Stationary
Conforme mencionado anteriormente, a estacionariedade estrita √© uma condi√ß√£o mais forte que a estacionariedade em covari√¢ncia. Se uma s√©rie temporal √© *strictly stationary* e possui momentos de segunda ordem finitos, ent√£o ela √© *covariance-stationary* [^3]. No entanto, o inverso n√£o √© sempre verdadeiro. Uma s√©rie temporal pode ser *covariance-stationary*, mas n√£o *strictly stationary*.

**Proposi√ß√£o 3** Se $\{Y_t\}$ √© strictly stationary e $E[Y_t^2] < \infty$, ent√£o $\{Y_t\}$ √© covariance-stationary.

*Proof:* Se $\{Y_t\}$ √© strictly stationary, ent√£o $E(Y_t) = \mu$ para todo $t$. Al√©m disso, $E(Y_t Y_{t+j}) = \gamma_j$ para todo $t$, onde $\gamma_j$ depende apenas de $j$ e n√£o de $t$. Portanto, $Cov(Y_t, Y_{t+j}) = E(Y_t Y_{t+j}) - E(Y_t)E(Y_{t+j}) = \gamma_j - \mu^2$, que depende apenas de $j$. Como a m√©dia e autocovari√¢ncia s√£o independentes de $t$, $\{Y_t\}$ √© covariance-stationary. $\blacksquare$

**Exemplo 1:** Considere uma s√©rie temporal onde $Y_t = \epsilon_t$ para $t$ par e $Y_t = -\epsilon_t$ para $t$ √≠mpar, onde $\epsilon_t$ √© ru√≠do branco com m√©dia zero e vari√¢ncia 1. Neste caso, $E(Y_t) = 0$ para todo $t$, e $Cov(Y_t, Y_{t+j}) = E(Y_t Y_{t+j}) = 0$ para $j \neq 0$. Assim, a s√©rie √© covariance-stationary. No entanto, a distribui√ß√£o de $Y_t$ depende da paridade de $t$, de modo que a s√©rie n√£o √© strictly stationary.

> üí° **Exemplo Num√©rico:** Para essa s√©rie temporal espec√≠fica, $Y_1 = -\epsilon_1$, $Y_2 = \epsilon_2$, $Y_3 = -\epsilon_3$, e assim por diante. Se $\epsilon_t$ segue uma distribui√ß√£o normal padr√£o, ent√£o $Y_t$ tamb√©m segue uma distribui√ß√£o normal com m√©dia zero e vari√¢ncia 1, mas com sinal alternado. A m√©dia de $Y_t$ √© sempre 0 e a covari√¢ncia entre $Y_t$ e $Y_{t+j}$ √© sempre 0 para $j \neq 0$, satisfazendo as condi√ß√µes de *covariance stationarity*. No entanto, a distribui√ß√£o de $Y_t$ muda dependendo se $t$ √© par ou √≠mpar ($Y_t$ √© negativo para $t$ √≠mpar e positivo para $t$ par), ent√£o n√£o √© *strictly stationary*.

**Lema 2** Se $\{Y_t\}$ √© uma s√©rie temporal Gaussiana covariance-stationary, ent√£o $\{Y_t\}$ √© tamb√©m strictly stationary.

*Proof:* Para uma s√©rie temporal Gaussiana, a distribui√ß√£o conjunta √© completamente determinada pela sua m√©dia e fun√ß√£o de autocovari√¢ncia. Se a s√©rie √© covariance-stationary, a m√©dia √© constante e a autocovari√¢ncia depende apenas da defasagem. Portanto, a distribui√ß√£o conjunta de $(Y_{t_1}, Y_{t_2}, \ldots, Y_{t_n})$ √© a mesma que a distribui√ß√£o conjunta de $(Y_{t_1+k}, Y_{t_2+k}, \ldots, Y_{t_n+k})$ para qualquer $k$, o que implica strict stationarity. $\blacksquare$

> üí° **Exemplo Num√©rico:** Uma s√©rie temporal gerada a partir de uma distribui√ß√£o normal com m√©dia constante e vari√¢ncia constante √© um exemplo de uma s√©rie que √© ao mesmo tempo covariance-stationary e strictly stationary.

> üí° **Exemplo Num√©rico:** Considere $Y_t \sim N(\mu, \sigma^2)$ para todo $t$, com $\mu = 5$ e $\sigma^2 = 2$. A autocovari√¢ncia entre $Y_t$ e $Y_{t+j}$ √© zero para $j \neq 0$.  A distribui√ß√£o conjunta de qualquer conjunto de observa√ß√µes $(Y_{t_1}, Y_{t_2}, ..., Y_{t_n})$ √© uma distribui√ß√£o normal multivariada com vetor de m√©dias $[\mu, \mu, ..., \mu]$ e matriz de covari√¢ncia diagonal com $\sigma^2$ na diagonal. Essa distribui√ß√£o conjunta √© a mesma para qualquer conjunto de tempos $t_1, t_2, ..., t_n$, indicando tanto *covariance stationarity* quanto *strict stationarity*.

**Lema 2.1** Seja $\{Y_t\}$ uma s√©rie temporal tal que $(Y_{t_1}, \ldots, Y_{t_n})$ segue uma distribui√ß√£o normal multivariada com vetor de m√©dias $\mu$ e matriz de covari√¢ncia $\Sigma$. Se $\mu$ √© constante e $\Sigma_{ij}$ depende apenas de $|t_i - t_j|$, ent√£o $\{Y_t\}$ √© strictly stationary.

*Proof:*  Se $\{Y_t\}$ √© uma s√©rie temporal Gaussiana covariance-stationary, ent√£o, por defini√ß√£o, o vetor de m√©dias $\mu$ √© constante e a matriz de covari√¢ncia $\Sigma$ depende apenas da defasagem entre os pontos no tempo. Especificamente, $\Sigma_{ij} = Cov(Y_{t_i}, Y_{t_j}) = \gamma_{|t_i - t_j|}$.  Portanto, a distribui√ß√£o conjunta de $(Y_{t_1}, \ldots, Y_{t_n})$ √© completamente determinada pela sua m√©dia constante e pela matriz de covari√¢ncia que depende apenas das defasagens. Agora, considere o vetor $(Y_{t_1+k}, \ldots, Y_{t_n+k})$. A sua m√©dia tamb√©m √© $\mu$ e a sua matriz de covari√¢ncia √© dada por $Cov(Y_{t_i+k}, Y_{t_j+k}) = \gamma_{|(t_i+k) - (t_j+k)|} = \gamma_{|t_i - t_j|}$, que √© a mesma que a matriz de covari√¢ncia de $(Y_{t_1}, \ldots, Y_{t_n})$. Portanto, a distribui√ß√£o conjunta de $(Y_{t_1}, \ldots, Y_{t_n})$ √© a mesma que a distribui√ß√£o conjunta de $(Y_{t_1+k}, \ldots, Y_{t_n+k})$ para qualquer $k$, o que implica strict stationarity. $\blacksquare$

**Teorema 4** Se $\{Y_t\}$ √© uma s√©rie temporal IID, ent√£o √© strictly stationary.

*Proof:* Como $\{Y_t\}$ √© IID, a distribui√ß√£o conjunta de $(Y_{t}, Y_{t+j_1}, ..., Y_{t+j_n})$ √© dada por $F(Y_{t})F(Y_{t+j_1}) \ldots F(Y_{t+j_n})$, onde $F$ √© a fun√ß√£o de distribui√ß√£o comum. Como as vari√°veis s√£o independentes e identicamente distribu√≠das, a distribui√ß√£o conjunta n√£o depende de $t$. Portanto, para qualquer $k$, a distribui√ß√£o conjunta de $(Y_{t+k}, Y_{t+k+j_1}, ..., Y_{t+k+j_n})$ √© a mesma que a distribui√ß√£o conjunta de $(Y_{t}, Y_{t+j_1}, ..., Y_{t+j_n})$, o que implica que a s√©rie √© strictly stationary. $\blacksquare$

**Corol√°rio 4.1** Ru√≠do branco √© strictly stationary.

*Proof:* Ru√≠do branco √© uma sequ√™ncia de vari√°veis aleat√≥rias IID com m√©dia zero e vari√¢ncia constante. Pelo Teorema 4, uma s√©rie temporal IID √© strictly stationary. Portanto, ru√≠do branco √© strictly stationary. $\blacksquare$

### Conclus√£o
A estacionariedade estrita √© um conceito fundamental na an√°lise de s√©ries temporais, que exige que a distribui√ß√£o conjunta da s√©rie temporal seja invariante no tempo. Embora seja uma condi√ß√£o mais forte que a estacionariedade em covari√¢ncia, a estacionariedade estrita garante que todas as propriedades estat√≠sticas da s√©rie temporal sejam consistentes ao longo do tempo. A distin√ß√£o entre estacionariedade estrita e covariance-stationary √© crucial para selecionar o modelo apropriado e interpretar os resultados da an√°lise de s√©ries temporais.
<!-- END -->