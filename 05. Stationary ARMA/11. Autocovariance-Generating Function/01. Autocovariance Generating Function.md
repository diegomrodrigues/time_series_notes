## The Autocovariance-Generating Function

### IntroduÃ§Ã£o

No estudo de processos estocÃ¡sticos e sÃ©ries temporais, uma ferramenta fundamental para a anÃ¡lise das dependÃªncias temporais Ã© a **funÃ§Ã£o geradora de autocovariÃ¢ncia** (Autocovariance-Generating Function - ACGF). Esta funÃ§Ã£o, denotada por $g_Y(z)$, oferece uma representaÃ§Ã£o concisa de todas as autocovariÃ¢ncias de um processo estacionÃ¡rio em covariÃ¢ncia, resumindo-as em uma Ãºnica funÃ§Ã£o escalar. Neste capÃ­tulo, exploraremos a definiÃ§Ã£o e as propriedades da ACGF, sua relaÃ§Ã£o com a estrutura de autocovariÃ¢ncia do processo e como ela pode ser utilizada para analisar e comparar diferentes processos estocÃ¡sticos. O conceito de autocovariÃ¢ncia foi previamente introduzido [^44, ^45], onde foi definido como a covariÃ¢ncia entre $Y_t$ e seus valores defasados $Y_{t-j}$. Este capÃ­tulo aprofunda a anÃ¡lise ao introduzir uma funÃ§Ã£o que encapsula todas essas autocovariÃ¢ncias.

### Conceitos Fundamentais

A **autocovariÃ¢ncia-geradora funÃ§Ã£o** (ACGF) $g_Y(z)$ para um processo $Y_t$ covariance-stationary Ã© definida como [^61]:

$$g_Y(z) = \sum_{j=-\infty}^{\infty} \gamma_j z^j$$

onde:
*   $\gamma_j$ representa a *j-Ã©sima autocovariÃ¢ncia* do processo $Y_t$, definida como $E[(Y_t - \mu)(Y_{t-j} - \mu)]$ [^45], com $\mu$ sendo a mÃ©dia do processo.
*   $z$ Ã© uma *variÃ¡vel complexa*.

A ACGF pode ser vista como uma *transformaÃ§Ã£o* da sequÃªncia de autocovariÃ¢ncias $\{\gamma_j\}$ para o domÃ­nio complexo, fornecendo uma representaÃ§Ã£o alternativa da estrutura de dependÃªncia temporal do processo.

**InterpretaÃ§Ã£o e propriedades:**

1.  **Resumo das autocovariÃ¢ncias:** A ACGF condensa todas as autocovariÃ¢ncias do processo em uma Ãºnica funÃ§Ã£o, facilitando a anÃ¡lise e comparaÃ§Ã£o entre diferentes processos.

    > ðŸ’¡ **Exemplo NumÃ©rico:**
    > Suponha que temos um processo com autocovariÃ¢ncias $\gamma_0 = 2$, $\gamma_1 = 1$, $\gamma_2 = 0.5$, e $\gamma_j = 0$ para $|j| > 2$. A ACGF seria:
    > $g_Y(z) = \ldots + 0.5z^{-2} + 1z^{-1} + 2 + 1z + 0.5z^2 + \ldots = 0.5z^{-2} + z^{-1} + 2 + z + 0.5z^2$
    > Esta Ãºnica funÃ§Ã£o resume toda a estrutura de autocovariÃ¢ncia do processo.

2.  **Simetria:** Para um processo real, a autocovariÃ¢ncia Ã© simÃ©trica, ou seja, $\gamma_j = \gamma_{-j}$. Assim, a ACGF pode ser reescrita como:
    $$g_Y(z) = \gamma_0 + \sum_{j=1}^{\infty} \gamma_j (z^j + z^{-j})$$

    **Prova da Simetria da ACGF:**
    Provaremos que se $\gamma_j = \gamma_{-j}$, entÃ£o $g_Y(z) = \gamma_0 + \sum_{j=1}^{\infty} \gamma_j (z^j + z^{-j})$.

    I.  ComeÃ§amos com a definiÃ§Ã£o da ACGF: $g_Y(z) = \sum_{j=-\infty}^{\infty} \gamma_j z^j$.

    II. Separamos a soma em trÃªs partes: $g_Y(z) = \gamma_0 + \sum_{j=1}^{\infty} \gamma_j z^j + \sum_{j=-\infty}^{-1} \gamma_j z^j$.

    III. Realizamos uma mudanÃ§a de Ã­ndice na terceira soma, fazendo $k = -j$: $\sum_{j=-\infty}^{-1} \gamma_j z^j = \sum_{k=1}^{\infty} \gamma_{-k} z^{-k}$.

    IV. Usamos a propriedade de simetria $\gamma_j = \gamma_{-j}$: $\sum_{k=1}^{\infty} \gamma_{-k} z^{-k} = \sum_{k=1}^{\infty} \gamma_{k} z^{-k}$.

    V.  SubstituÃ­mos de volta na expressÃ£o original: $g_Y(z) = \gamma_0 + \sum_{j=1}^{\infty} \gamma_j z^j + \sum_{j=1}^{\infty} \gamma_{j} z^{-j}$.

    VI. Combinamos as somas: $g_Y(z) = \gamma_0 + \sum_{j=1}^{\infty} \gamma_j (z^j + z^{-j})$.

    Portanto, demonstramos que $g_Y(z) = \gamma_0 + \sum_{j=1}^{\infty} \gamma_j (z^j + z^{-j})$ â– 

    **ObservaÃ§Ã£o:** A simetria da ACGF implica que ela Ã© uma funÃ§Ã£o real para valores reais de $z$. Esta propriedade simplifica a anÃ¡lise em muitos casos prÃ¡ticos.

    > ðŸ’¡ **Exemplo NumÃ©rico:**
    > Usando o exemplo anterior com $\gamma_0 = 2$, $\gamma_1 = 1$, $\gamma_2 = 0.5$, a ACGF simplificada devido Ã  simetria torna-se:
    > $g_Y(z) = 2 + 1(z + z^{-1}) + 0.5(z^2 + z^{-2})$. Note que para qualquer valor real de *z*, *g<sub>Y</sub>(z)* resultarÃ¡ em um nÃºmero real.  Por exemplo, se *z* = 2:
    > $g_Y(2) = 2 + 1(2 + 0.5) + 0.5(4 + 0.25) = 2 + 2.5 + 2.125 = 6.625$

3.  **Espectro de potÃªncia:** Avaliando a ACGF no cÃ­rculo unitÃ¡rio complexo, ou seja, substituindo $z = e^{-i\omega}$, onde $i = \sqrt{-1}$ e $\omega$ Ã© a frequÃªncia em radianos, e dividindo por $2\pi$, obtemos o *espectro de potÃªncia* do processo [^61]:

    $$S_Y(\omega) = \frac{1}{2\pi} g_Y(e^{-i\omega}) = \frac{1}{2\pi} \sum_{j=-\infty}^{\infty} \gamma_j e^{-i\omega j}$$

    O espectro de potÃªncia descreve a distribuiÃ§Ã£o da variÃ¢ncia do processo em diferentes frequÃªncias, fornecendo informaÃ§Ãµes sobre os componentes cÃ­clicos ou periÃ³dicos presentes na sÃ©rie temporal.

    > ðŸ’¡ **Exemplo NumÃ©rico:**
    > Assumindo as autocovariÃ¢ncias do exemplo anterior ($\gamma_0 = 2$, $\gamma_1 = 1$, $\gamma_2 = 0.5$), o espectro de potÃªncia seria:
    > $S_Y(\omega) = \frac{1}{2\pi} (2 + e^{-i\omega} + e^{i\omega} + 0.5e^{-2i\omega} + 0.5e^{2i\omega})$
    > Usando a identidade de Euler $e^{ix} = \cos(x) + i\sin(x)$, temos $e^{ix} + e^{-ix} = 2\cos(x)$. Portanto:
    > $S_Y(\omega) = \frac{1}{2\pi} (2 + 2\cos(\omega) + \cos(2\omega))$
    > Este espectro de potÃªncia mostra como a variÃ¢ncia do processo Ã© distribuÃ­da em diferentes frequÃªncias. Podemos plotar $S_Y(\omega)$ contra $\omega$ para visualizar o espectro.

    **Teorema 1:** (RelaÃ§Ã£o entre ACGF e Densidade Espectral)
    Se o processo $Y_t$ tem uma ACGF $g_Y(z)$ e uma densidade espectral $S_Y(\omega)$, entÃ£o $g_Y(z)$ Ã© a transformada Z da sequÃªncia de autocovariÃ¢ncias $\{\gamma_j\}$, e $S_Y(\omega)$ Ã© a transformada de Fourier discreta da mesma sequÃªncia.

    *Proof:* A relaÃ§Ã£o entre $g_Y(z)$ e $\{\gamma_j\}$ Ã© a definiÃ§Ã£o da transformada Z. A relaÃ§Ã£o entre $S_Y(\omega)$ e $\{\gamma_j\}$ Ã© a definiÃ§Ã£o da transformada de Fourier discreta.

    **CorolÃ¡rio 1.1:** (Espectro de potÃªncia real)
    O espectro de potÃªncia $S_Y(\omega)$ Ã© uma funÃ§Ã£o real e nÃ£o negativa de $\omega$.

    *Proof:* Como $\gamma_j = \gamma_{-j}$ para processos reais, $S_Y(\omega)$ Ã© real. A nÃ£o negatividade segue do fato de que $S_Y(\omega)$ representa a distribuiÃ§Ã£o da variÃ¢ncia em diferentes frequÃªncias, e a variÃ¢ncia nÃ£o pode ser negativa.

4.  **Processos ARMA:** Para processos *Autoregressivos de MÃ©dias MÃ³veis* (ARMA), a ACGF possui uma forma especÃ­fica que facilita sua identificaÃ§Ã£o e anÃ¡lise. Por exemplo, para um processo MA(q) [^48, ^50], a ACGF Ã© dada por [^62]:
    $$g_Y(z) = \sigma^2 (1 + \theta_1 z + \theta_2 z^2 + \ldots + \theta_q z^q)(1 + \theta_1 z^{-1} + \theta_2 z^{-2} + \ldots + \theta_q z^{-q})$$
    onde $\sigma^2$ Ã© a variÃ¢ncia do ruÃ­do branco e $\theta_i$ sÃ£o os coeficientes do modelo MA.

    > ðŸ’¡ **Exemplo NumÃ©rico:**
    > Considere um processo MA(2) com $\sigma^2 = 1$, $\theta_1 = 0.5$, e $\theta_2 = 0.2$. A ACGF seria:
    > $g_Y(z) = (1 + 0.5z + 0.2z^2)(1 + 0.5z^{-1} + 0.2z^{-2})$
    > Expandindo, obtemos:
    > $g_Y(z) = 0.2z^2 + 0.5z + 1 + 0.5z^{-1} + 0.2z^{-2} + 0.1 + 0.25 + 0.1z^{-1} + 0.04$
    > $g_Y(z) = 0.2z^2 + 0.5z + 1.39 + 0.6z^{-1} + 0.2z^{-2}$.
    > Esta forma da ACGF facilita a identificaÃ§Ã£o dos parÃ¢metros do processo MA(2).

    **Teorema 1.1:** (ACGF de um processo AR(p))
    Para um processo Autoregressivo de ordem p (AR(p)) definido por $Y_t = \phi_1 Y_{t-1} + \phi_2 Y_{t-2} + \ldots + \phi_p Y_{t-p} + \varepsilon_t$, onde $\{\varepsilon_t\}$ Ã© ruÃ­do branco com variÃ¢ncia $\sigma^2$, a ACGF Ã© dada por:

    $$g_Y(z) = \frac{\sigma^2}{\Phi(z)\Phi(z^{-1})}$$

    onde $\Phi(z) = 1 - \phi_1 z - \phi_2 z^2 - \ldots - \phi_p z^p$ Ã© o polinÃ´mio autoregressivo.

    *Proof:* Este resultado segue da aplicaÃ§Ã£o da transformada Z Ã  equaÃ§Ã£o do processo AR(p) e utilizando as propriedades da funÃ§Ã£o geradora de autocovariÃ¢ncia. Ver [^63] para uma demonstraÃ§Ã£o detalhada.

    > ðŸ’¡ **Exemplo NumÃ©rico:**
    > Considere um processo AR(1) com $\phi_1 = 0.7$ e $\sigma^2 = 1$. EntÃ£o, $\Phi(z) = 1 - 0.7z$.  A ACGF Ã©:
    > $g_Y(z) = \frac{1}{(1 - 0.7z)(1 - 0.7z^{-1})} = \frac{1}{1 - 0.7z - 0.7z^{-1} + 0.49}$
    > $g_Y(z) = \frac{1}{1.49 - 0.7(z + z^{-1})}$
    > Esta funÃ§Ã£o representa a estrutura de autocovariÃ¢ncia do processo AR(1).

    **Teorema 1.2:** (ACGF de um processo ARMA(p,q))
    Para um processo ARMA(p,q) definido por $\Phi(B)Y_t = \Theta(B)\varepsilon_t$, onde $B$ Ã© o operador de retrocesso, $\Phi(z) = 1 - \phi_1 z - \phi_2 z^2 - \ldots - \phi_p z^p$ e $\Theta(z) = 1 + \theta_1 z + \theta_2 z^2 + \ldots + \theta_q z^q$, e $\{\varepsilon_t\}$ Ã© ruÃ­do branco com variÃ¢ncia $\sigma^2$, a ACGF Ã© dada por:

    $$g_Y(z) = \sigma^2 \frac{\Theta(z)\Theta(z^{-1})}{\Phi(z)\Phi(z^{-1})}$$

    *Proof:* Este resultado Ã© uma generalizaÃ§Ã£o do Teorema 1.1 e segue da aplicaÃ§Ã£o da transformada Z Ã  equaÃ§Ã£o do processo ARMA(p,q), utilizando as propriedades da funÃ§Ã£o geradora de autocovariÃ¢ncia.

5.  **Unicidade:** Se dois processos diferentes compartilham a mesma ACGF, entÃ£o eles exibem a mesma sequÃªncia de autocovariÃ¢ncias [^61]. Isso implica que a ACGF captura completamente a estrutura de dependÃªncia temporal do processo, pelo menos atÃ© a segunda ordem.

**Exemplo (MA(1)):**

Considere um processo MA(1) definido como $Y_t = \mu + \varepsilon_t + \theta \varepsilon_{t-1}$ [^48], onde $\{\varepsilon_t\}$ Ã© um ruÃ­do branco com variÃ¢ncia $\sigma^2$. As autocovariÃ¢ncias sÃ£o:

*   $\gamma_0 = (1 + \theta^2)\sigma^2$ [^48]
*   $\gamma_1 = \theta \sigma^2$ [^48]
*   $\gamma_j = 0$ para $|j| > 1$ [^48]

A ACGF para este processo Ã© [^62]:

$$g_Y(z) = \theta \sigma^2 z^{-1} + (1 + \theta^2)\sigma^2 + \theta \sigma^2 z = \sigma^2[\theta z^{-1} + (1 + \theta^2) + \theta z]$$
que pode ser fatorada como [^62]:

$$g_Y(z) = \sigma^2(1 + \theta z)(1 + \theta z^{-1})$$

> ðŸ’¡ **Exemplo NumÃ©rico:**
> Suponha que $\theta = 0.6$ e $\sigma^2 = 1$. EntÃ£o as autocovariÃ¢ncias sÃ£o:
> $\gamma_0 = (1 + 0.6^2) * 1 = 1.36$
> $\gamma_1 = 0.6 * 1 = 0.6$
> $\gamma_j = 0$ para $|j| > 1$
> A ACGF Ã©:
> $g_Y(z) = 0.6z^{-1} + 1.36 + 0.6z = (1)(0.6z^{-1} + 1.36 + 0.6z)$
> $g_Y(z) = (1 + 0.6z)(1 + 0.6z^{-1})$

**ProposiÃ§Ã£o 1:** (Inversibilidade do processo MA(1))
Um processo MA(1) Ã© invertÃ­vel se e somente se $|\theta| < 1$.

*Proof:* A invertibilidade do processo MA(1) requer que a raiz do polinÃ´mio $(1 + \theta z)$ esteja fora do cÃ­rculo unitÃ¡rio, i.e., $|z| > 1$. Resolvendo $1 + \theta z = 0$, temos $z = -1/\theta$. Portanto, a condiÃ§Ã£o de invertibilidade Ã© $|-1/\theta| > 1$, o que implica $|\theta| < 1$.

I. Dado o processo MA(1): $Y_t = \mu + \varepsilon_t + \theta \varepsilon_{t-1}$.

II. Para que o processo seja invertÃ­vel, ele deve ser expresso como uma representaÃ§Ã£o AR($\infty$).  Isso significa que podemos escrever $\varepsilon_t$ em termos dos valores passados de $Y_t$.

III. Formalmente, a condiÃ§Ã£o de invertibilidade Ã© que as raÃ­zes do polinÃ´mio MA, neste caso $(1 + \theta z)$, devem estar fora do cÃ­rculo unitÃ¡rio no plano complexo.

IV. Encontramos a raiz do polinÃ´mio MA resolvendo $(1 + \theta z) = 0$, que nos dÃ¡ $z = -1/\theta$.

V. Para que a raiz esteja fora do cÃ­rculo unitÃ¡rio, devemos ter $|z| > 1$, o que significa $|-1/\theta| > 1$.

VI. Simplificando, obtemos $1/|\theta| > 1$, o que implica $|\theta| < 1$.

Portanto, um processo MA(1) Ã© invertÃ­vel se e somente se $|\theta| < 1$. â– 

> ðŸ’¡ **Exemplo NumÃ©rico:**
> Se $\theta = 0.8$, o processo MA(1) Ã© invertÃ­vel porque $|0.8| < 1$. No entanto, se $\theta = 1.2$, o processo nÃ£o Ã© invertÃ­vel porque $|1.2| > 1$.

**ProposiÃ§Ã£o 2:** (RelaÃ§Ã£o entre a ACGF e a FunÃ§Ã£o de AutocorrelaÃ§Ã£o)
A ACGF pode ser normalizada para obter a funÃ§Ã£o geradora de autocorrelaÃ§Ã£o (ACF-GF). Se $\rho_j = \gamma_j / \gamma_0$ Ã© a j-Ã©sima autocorrelaÃ§Ã£o, entÃ£o a ACF-GF, $g_{\rho}(z)$, Ã© dada por:

$$g_{\rho}(z) = \sum_{j=-\infty}^{\infty} \rho_j z^j = \frac{g_Y(z)}{\gamma_0}$$

*Proof:* Esta proposiÃ§Ã£o decorre diretamente da definiÃ§Ã£o de autocorrelaÃ§Ã£o e da ACGF. Dividindo cada termo da ACGF por $\gamma_0$ resulta na funÃ§Ã£o geradora das autocorrelaÃ§Ãµes.

I. ComeÃ§amos com a definiÃ§Ã£o da funÃ§Ã£o geradora de autocorrelaÃ§Ã£o: $g_{\rho}(z) = \sum_{j=-\infty}^{\infty} \rho_j z^j$.

II. SubstituÃ­mos a definiÃ§Ã£o de $\rho_j = \gamma_j / \gamma_0$: $g_{\rho}(z) = \sum_{j=-\infty}^{\infty} (\gamma_j / \gamma_0) z^j$.

III. Fatoramos o termo constante $1/\gamma_0$ para fora da soma: $g_{\rho}(z) = (1/\gamma_0) \sum_{j=-\infty}^{\infty} \gamma_j z^j$.

IV. Reconhecemos que $\sum_{j=-\infty}^{\infty} \gamma_j z^j$ Ã© a definiÃ§Ã£o da ACGF, $g_Y(z)$: $g_{\rho}(z) = (1/\gamma_0) g_Y(z)$.

V. Portanto, $g_{\rho}(z) = \frac{g_Y(z)}{\gamma_0}$.

Assim, demonstramos que a funÃ§Ã£o geradora de autocorrelaÃ§Ã£o Ã© obtida dividindo a ACGF pela autocovariÃ¢ncia de ordem zero, $\gamma_0$. â– 

> ðŸ’¡ **Exemplo NumÃ©rico:**
> Usando o exemplo anterior do MA(1) com $\theta = 0.6$ e $\sigma^2 = 1$, temos $\gamma_0 = 1.36$ e $g_Y(z) = 0.6z^{-1} + 1.36 + 0.6z$.
> As autocorrelaÃ§Ãµes sÃ£o:
> $\rho_0 = \gamma_0 / \gamma_0 = 1$
> $\rho_1 = \gamma_1 / \gamma_0 = 0.6 / 1.36 \approx 0.441$
> A ACF-GF Ã©:
> $g_{\rho}(z) = g_Y(z) / \gamma_0 = (0.6z^{-1} + 1.36 + 0.6z) / 1.36 = 0.441z^{-1} + 1 + 0.441z$

### ConclusÃ£o

A funÃ§Ã£o geradora de autocovariÃ¢ncia Ã© uma ferramenta poderosa para analisar e caracterizar a estrutura de dependÃªncia temporal de processos estocÃ¡sticos estacionÃ¡rios. Ao resumir todas as autocovariÃ¢ncias em uma Ãºnica funÃ§Ã£o, ela facilita a comparaÃ§Ã£o entre diferentes processos e permite a identificaÃ§Ã£o de componentes cÃ­clicos atravÃ©s do espectro de potÃªncia. AlÃ©m disso, a ACGF desempenha um papel fundamental na anÃ¡lise de modelos ARMA e na compreensÃ£o de filtros aplicados a sÃ©ries temporais. Como veremos em capÃ­tulos posteriores, a ACGF Ã© uma ferramenta essencial para a anÃ¡lise espectral e para o desenvolvimento de modelos mais sofisticados de sÃ©ries temporais.

### ReferÃªncias
[^44]: PÃ¡gina 44 do contexto original
[^45]: PÃ¡gina 45 do contexto original
[^48]: PÃ¡gina 48 do contexto original
[^50]: PÃ¡gina 50 do contexto original
[^61]: PÃ¡gina 61 do contexto original
[^62]: PÃ¡gina 62 do contexto original
[^63]: Nova referÃªncia para a demonstraÃ§Ã£o detalhada do Teorema 1.1.

<!-- END -->