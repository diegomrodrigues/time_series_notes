## The Autocovariance-Generating Function

### Introdu√ß√£o

No estudo de processos estoc√°sticos e s√©ries temporais, uma ferramenta fundamental para a an√°lise das depend√™ncias temporais √© a **fun√ß√£o geradora de autocovari√¢ncia** (Autocovariance-Generating Function - ACGF). Esta fun√ß√£o, denotada por $g_Y(z)$, oferece uma representa√ß√£o concisa de todas as autocovari√¢ncias de um processo estacion√°rio em covari√¢ncia, resumindo-as em uma √∫nica fun√ß√£o escalar. Neste cap√≠tulo, exploraremos a defini√ß√£o e as propriedades da ACGF, sua rela√ß√£o com a estrutura de autocovari√¢ncia do processo e como ela pode ser utilizada para analisar e comparar diferentes processos estoc√°sticos. O conceito de autocovari√¢ncia foi previamente introduzido [^44, ^45], onde foi definido como a covari√¢ncia entre $Y_t$ e seus valores defasados $Y_{t-j}$. Este cap√≠tulo aprofunda a an√°lise ao introduzir uma fun√ß√£o que encapsula todas essas autocovari√¢ncias.

### Conceitos Fundamentais

A **autocovari√¢ncia-geradora fun√ß√£o** (ACGF) $g_Y(z)$ para um processo $Y_t$ covariance-stationary √© definida como [^61]:

$$g_Y(z) = \sum_{j=-\infty}^{\infty} \gamma_j z^j$$

onde:
*   $\gamma_j$ representa a *j-√©sima autocovari√¢ncia* do processo $Y_t$, definida como $E[(Y_t - \mu)(Y_{t-j} - \mu)]$ [^45], com $\mu$ sendo a m√©dia do processo.
*   $z$ √© uma *vari√°vel complexa*.

A ACGF pode ser vista como uma *transforma√ß√£o* da sequ√™ncia de autocovari√¢ncias $\{\gamma_j\}$ para o dom√≠nio complexo, fornecendo uma representa√ß√£o alternativa da estrutura de depend√™ncia temporal do processo.

**Interpreta√ß√£o e propriedades:**

1.  **Resumo das autocovari√¢ncias:** A ACGF condensa todas as autocovari√¢ncias do processo em uma √∫nica fun√ß√£o, facilitando a an√°lise e compara√ß√£o entre diferentes processos.

    > üí° **Exemplo Num√©rico:**
    > Suponha que temos um processo com autocovari√¢ncias $\gamma_0 = 2$, $\gamma_1 = 1$, $\gamma_2 = 0.5$, e $\gamma_j = 0$ para $|j| > 2$. A ACGF seria:
    > $g_Y(z) = \ldots + 0.5z^{-2} + 1z^{-1} + 2 + 1z + 0.5z^2 + \ldots = 0.5z^{-2} + z^{-1} + 2 + z + 0.5z^2$
    > Esta √∫nica fun√ß√£o resume toda a estrutura de autocovari√¢ncia do processo.

2.  **Simetria:** Para um processo real, a autocovari√¢ncia √© sim√©trica, ou seja, $\gamma_j = \gamma_{-j}$. Assim, a ACGF pode ser reescrita como:
    $$g_Y(z) = \gamma_0 + \sum_{j=1}^{\infty} \gamma_j (z^j + z^{-j})$$

    **Prova da Simetria da ACGF:**
    Provaremos que se $\gamma_j = \gamma_{-j}$, ent√£o $g_Y(z) = \gamma_0 + \sum_{j=1}^{\infty} \gamma_j (z^j + z^{-j})$.

    I.  Come√ßamos com a defini√ß√£o da ACGF: $g_Y(z) = \sum_{j=-\infty}^{\infty} \gamma_j z^j$.

    II. Separamos a soma em tr√™s partes: $g_Y(z) = \gamma_0 + \sum_{j=1}^{\infty} \gamma_j z^j + \sum_{j=-\infty}^{-1} \gamma_j z^j$.

    III. Realizamos uma mudan√ßa de √≠ndice na terceira soma, fazendo $k = -j$: $\sum_{j=-\infty}^{-1} \gamma_j z^j = \sum_{k=1}^{\infty} \gamma_{-k} z^{-k}$.

    IV. Usamos a propriedade de simetria $\gamma_j = \gamma_{-j}$: $\sum_{k=1}^{\infty} \gamma_{-k} z^{-k} = \sum_{k=1}^{\infty} \gamma_{k} z^{-k}$.

    V.  Substitu√≠mos de volta na express√£o original: $g_Y(z) = \gamma_0 + \sum_{j=1}^{\infty} \gamma_j z^j + \sum_{j=1}^{\infty} \gamma_{j} z^{-j}$.

    VI. Combinamos as somas: $g_Y(z) = \gamma_0 + \sum_{j=1}^{\infty} \gamma_j (z^j + z^{-j})$.

    Portanto, demonstramos que $g_Y(z) = \gamma_0 + \sum_{j=1}^{\infty} \gamma_j (z^j + z^{-j})$ ‚ñ†

    **Observa√ß√£o:** A simetria da ACGF implica que ela √© uma fun√ß√£o real para valores reais de $z$. Esta propriedade simplifica a an√°lise em muitos casos pr√°ticos.

    > üí° **Exemplo Num√©rico:**
    > Usando o exemplo anterior com $\gamma_0 = 2$, $\gamma_1 = 1$, $\gamma_2 = 0.5$, a ACGF simplificada devido √† simetria torna-se:
    > $g_Y(z) = 2 + 1(z + z^{-1}) + 0.5(z^2 + z^{-2})$. Note que para qualquer valor real de *z*, *g<sub>Y</sub>(z)* resultar√° em um n√∫mero real.  Por exemplo, se *z* = 2:
    > $g_Y(2) = 2 + 1(2 + 0.5) + 0.5(4 + 0.25) = 2 + 2.5 + 2.125 = 6.625$

3.  **Espectro de pot√™ncia:** Avaliando a ACGF no c√≠rculo unit√°rio complexo, ou seja, substituindo $z = e^{-i\omega}$, onde $i = \sqrt{-1}$ e $\omega$ √© a frequ√™ncia em radianos, e dividindo por $2\pi$, obtemos o *espectro de pot√™ncia* do processo [^61]:

    $$S_Y(\omega) = \frac{1}{2\pi} g_Y(e^{-i\omega}) = \frac{1}{2\pi} \sum_{j=-\infty}^{\infty} \gamma_j e^{-i\omega j}$$

    O espectro de pot√™ncia descreve a distribui√ß√£o da vari√¢ncia do processo em diferentes frequ√™ncias, fornecendo informa√ß√µes sobre os componentes c√≠clicos ou peri√≥dicos presentes na s√©rie temporal.

    > üí° **Exemplo Num√©rico:**
    > Assumindo as autocovari√¢ncias do exemplo anterior ($\gamma_0 = 2$, $\gamma_1 = 1$, $\gamma_2 = 0.5$), o espectro de pot√™ncia seria:
    > $S_Y(\omega) = \frac{1}{2\pi} (2 + e^{-i\omega} + e^{i\omega} + 0.5e^{-2i\omega} + 0.5e^{2i\omega})$
    > Usando a identidade de Euler $e^{ix} = \cos(x) + i\sin(x)$, temos $e^{ix} + e^{-ix} = 2\cos(x)$. Portanto:
    > $S_Y(\omega) = \frac{1}{2\pi} (2 + 2\cos(\omega) + \cos(2\omega))$
    > Este espectro de pot√™ncia mostra como a vari√¢ncia do processo √© distribu√≠da em diferentes frequ√™ncias. Podemos plotar $S_Y(\omega)$ contra $\omega$ para visualizar o espectro.

    **Teorema 1:** (Rela√ß√£o entre ACGF e Densidade Espectral)
    Se o processo $Y_t$ tem uma ACGF $g_Y(z)$ e uma densidade espectral $S_Y(\omega)$, ent√£o $g_Y(z)$ √© a transformada Z da sequ√™ncia de autocovari√¢ncias $\{\gamma_j\}$, e $S_Y(\omega)$ √© a transformada de Fourier discreta da mesma sequ√™ncia.

    *Proof:* A rela√ß√£o entre $g_Y(z)$ e $\{\gamma_j\}$ √© a defini√ß√£o da transformada Z. A rela√ß√£o entre $S_Y(\omega)$ e $\{\gamma_j\}$ √© a defini√ß√£o da transformada de Fourier discreta.

    **Corol√°rio 1.1:** (Espectro de pot√™ncia real)
    O espectro de pot√™ncia $S_Y(\omega)$ √© uma fun√ß√£o real e n√£o negativa de $\omega$.

    *Proof:* Como $\gamma_j = \gamma_{-j}$ para processos reais, $S_Y(\omega)$ √© real. A n√£o negatividade segue do fato de que $S_Y(\omega)$ representa a distribui√ß√£o da vari√¢ncia em diferentes frequ√™ncias, e a vari√¢ncia n√£o pode ser negativa.

4.  **Processos ARMA:** Para processos *Autoregressivos de M√©dias M√≥veis* (ARMA), a ACGF possui uma forma espec√≠fica que facilita sua identifica√ß√£o e an√°lise. Por exemplo, para um processo MA(q) [^48, ^50], a ACGF √© dada por [^62]:
    $$g_Y(z) = \sigma^2 (1 + \theta_1 z + \theta_2 z^2 + \ldots + \theta_q z^q)(1 + \theta_1 z^{-1} + \theta_2 z^{-2} + \ldots + \theta_q z^{-q})$$
    onde $\sigma^2$ √© a vari√¢ncia do ru√≠do branco e $\theta_i$ s√£o os coeficientes do modelo MA.

    > üí° **Exemplo Num√©rico:**
    > Considere um processo MA(2) com $\sigma^2 = 1$, $\theta_1 = 0.5$, e $\theta_2 = 0.2$. A ACGF seria:
    > $g_Y(z) = (1 + 0.5z + 0.2z^2)(1 + 0.5z^{-1} + 0.2z^{-2})$
    > Expandindo, obtemos:
    > $g_Y(z) = 0.2z^2 + 0.5z + 1 + 0.5z^{-1} + 0.2z^{-2} + 0.1 + 0.25 + 0.1z^{-1} + 0.04$
    > $g_Y(z) = 0.2z^2 + 0.5z + 1.39 + 0.6z^{-1} + 0.2z^{-2}$.
    > Esta forma da ACGF facilita a identifica√ß√£o dos par√¢metros do processo MA(2).

    **Teorema 1.1:** (ACGF de um processo AR(p))
    Para um processo Autoregressivo de ordem p (AR(p)) definido por $Y_t = \phi_1 Y_{t-1} + \phi_2 Y_{t-2} + \ldots + \phi_p Y_{t-p} + \varepsilon_t$, onde $\{\varepsilon_t\}$ √© ru√≠do branco com vari√¢ncia $\sigma^2$, a ACGF √© dada por:

    $$g_Y(z) = \frac{\sigma^2}{\Phi(z)\Phi(z^{-1})}$$

    onde $\Phi(z) = 1 - \phi_1 z - \phi_2 z^2 - \ldots - \phi_p z^p$ √© o polin√¥mio autoregressivo.

    *Proof:* Este resultado segue da aplica√ß√£o da transformada Z √† equa√ß√£o do processo AR(p) e utilizando as propriedades da fun√ß√£o geradora de autocovari√¢ncia. Ver [^63] para uma demonstra√ß√£o detalhada.

    > üí° **Exemplo Num√©rico:**
    > Considere um processo AR(1) com $\phi_1 = 0.7$ e $\sigma^2 = 1$. Ent√£o, $\Phi(z) = 1 - 0.7z$.  A ACGF √©:
    > $g_Y(z) = \frac{1}{(1 - 0.7z)(1 - 0.7z^{-1})} = \frac{1}{1 - 0.7z - 0.7z^{-1} + 0.49}$
    > $g_Y(z) = \frac{1}{1.49 - 0.7(z + z^{-1})}$
    > Esta fun√ß√£o representa a estrutura de autocovari√¢ncia do processo AR(1).

    **Teorema 1.2:** (ACGF de um processo ARMA(p,q))
    Para um processo ARMA(p,q) definido por $\Phi(B)Y_t = \Theta(B)\varepsilon_t$, onde $B$ √© o operador de retrocesso, $\Phi(z) = 1 - \phi_1 z - \phi_2 z^2 - \ldots - \phi_p z^p$ e $\Theta(z) = 1 + \theta_1 z + \theta_2 z^2 + \ldots + \theta_q z^q$, e $\{\varepsilon_t\}$ √© ru√≠do branco com vari√¢ncia $\sigma^2$, a ACGF √© dada por:

    $$g_Y(z) = \sigma^2 \frac{\Theta(z)\Theta(z^{-1})}{\Phi(z)\Phi(z^{-1})}$$

    *Proof:* Este resultado √© uma generaliza√ß√£o do Teorema 1.1 e segue da aplica√ß√£o da transformada Z √† equa√ß√£o do processo ARMA(p,q), utilizando as propriedades da fun√ß√£o geradora de autocovari√¢ncia.

5.  **Unicidade:** Se dois processos diferentes compartilham a mesma ACGF, ent√£o eles exibem a mesma sequ√™ncia de autocovari√¢ncias [^61]. Isso implica que a ACGF captura completamente a estrutura de depend√™ncia temporal do processo, pelo menos at√© a segunda ordem.

**Exemplo (MA(1)):**

Considere um processo MA(1) definido como $Y_t = \mu + \varepsilon_t + \theta \varepsilon_{t-1}$ [^48], onde $\{\varepsilon_t\}$ √© um ru√≠do branco com vari√¢ncia $\sigma^2$. As autocovari√¢ncias s√£o:

*   $\gamma_0 = (1 + \theta^2)\sigma^2$ [^48]
*   $\gamma_1 = \theta \sigma^2$ [^48]
*   $\gamma_j = 0$ para $|j| > 1$ [^48]

A ACGF para este processo √© [^62]:

$$g_Y(z) = \theta \sigma^2 z^{-1} + (1 + \theta^2)\sigma^2 + \theta \sigma^2 z = \sigma^2[\theta z^{-1} + (1 + \theta^2) + \theta z]$$
que pode ser fatorada como [^62]:

$$g_Y(z) = \sigma^2(1 + \theta z)(1 + \theta z^{-1})$$

> üí° **Exemplo Num√©rico:**
> Suponha que $\theta = 0.6$ e $\sigma^2 = 1$. Ent√£o as autocovari√¢ncias s√£o:
> $\gamma_0 = (1 + 0.6^2) * 1 = 1.36$
> $\gamma_1 = 0.6 * 1 = 0.6$
> $\gamma_j = 0$ para $|j| > 1$
> A ACGF √©:
> $g_Y(z) = 0.6z^{-1} + 1.36 + 0.6z = (1)(0.6z^{-1} + 1.36 + 0.6z)$
> $g_Y(z) = (1 + 0.6z)(1 + 0.6z^{-1})$

**Proposi√ß√£o 1:** (Inversibilidade do processo MA(1))
Um processo MA(1) √© invert√≠vel se e somente se $|\theta| < 1$.

*Proof:* A invertibilidade do processo MA(1) requer que a raiz do polin√¥mio $(1 + \theta z)$ esteja fora do c√≠rculo unit√°rio, i.e., $|z| > 1$. Resolvendo $1 + \theta z = 0$, temos $z = -1/\theta$. Portanto, a condi√ß√£o de invertibilidade √© $|-1/\theta| > 1$, o que implica $|\theta| < 1$.

I. Dado o processo MA(1): $Y_t = \mu + \varepsilon_t + \theta \varepsilon_{t-1}$.

II. Para que o processo seja invert√≠vel, ele deve ser expresso como uma representa√ß√£o AR($\infty$).  Isso significa que podemos escrever $\varepsilon_t$ em termos dos valores passados de $Y_t$.

III. Formalmente, a condi√ß√£o de invertibilidade √© que as ra√≠zes do polin√¥mio MA, neste caso $(1 + \theta z)$, devem estar fora do c√≠rculo unit√°rio no plano complexo.

IV. Encontramos a raiz do polin√¥mio MA resolvendo $(1 + \theta z) = 0$, que nos d√° $z = -1/\theta$.

V. Para que a raiz esteja fora do c√≠rculo unit√°rio, devemos ter $|z| > 1$, o que significa $|-1/\theta| > 1$.

VI. Simplificando, obtemos $1/|\theta| > 1$, o que implica $|\theta| < 1$.

Portanto, um processo MA(1) √© invert√≠vel se e somente se $|\theta| < 1$. ‚ñ†

> üí° **Exemplo Num√©rico:**
> Se $\theta = 0.8$, o processo MA(1) √© invert√≠vel porque $|0.8| < 1$. No entanto, se $\theta = 1.2$, o processo n√£o √© invert√≠vel porque $|1.2| > 1$.

**Proposi√ß√£o 2:** (Rela√ß√£o entre a ACGF e a Fun√ß√£o de Autocorrela√ß√£o)
A ACGF pode ser normalizada para obter a fun√ß√£o geradora de autocorrela√ß√£o (ACF-GF). Se $\rho_j = \gamma_j / \gamma_0$ √© a j-√©sima autocorrela√ß√£o, ent√£o a ACF-GF, $g_{\rho}(z)$, √© dada por:

$$g_{\rho}(z) = \sum_{j=-\infty}^{\infty} \rho_j z^j = \frac{g_Y(z)}{\gamma_0}$$

*Proof:* Esta proposi√ß√£o decorre diretamente da defini√ß√£o de autocorrela√ß√£o e da ACGF. Dividindo cada termo da ACGF por $\gamma_0$ resulta na fun√ß√£o geradora das autocorrela√ß√µes.

I. Come√ßamos com a defini√ß√£o da fun√ß√£o geradora de autocorrela√ß√£o: $g_{\rho}(z) = \sum_{j=-\infty}^{\infty} \rho_j z^j$.

II. Substitu√≠mos a defini√ß√£o de $\rho_j = \gamma_j / \gamma_0$: $g_{\rho}(z) = \sum_{j=-\infty}^{\infty} (\gamma_j / \gamma_0) z^j$.

III. Fatoramos o termo constante $1/\gamma_0$ para fora da soma: $g_{\rho}(z) = (1/\gamma_0) \sum_{j=-\infty}^{\infty} \gamma_j z^j$.

IV. Reconhecemos que $\sum_{j=-\infty}^{\infty} \gamma_j z^j$ √© a defini√ß√£o da ACGF, $g_Y(z)$: $g_{\rho}(z) = (1/\gamma_0) g_Y(z)$.

V. Portanto, $g_{\rho}(z) = \frac{g_Y(z)}{\gamma_0}$.

Assim, demonstramos que a fun√ß√£o geradora de autocorrela√ß√£o √© obtida dividindo a ACGF pela autocovari√¢ncia de ordem zero, $\gamma_0$. ‚ñ†

> üí° **Exemplo Num√©rico:**
> Usando o exemplo anterior do MA(1) com $\theta = 0.6$ e $\sigma^2 = 1$, temos $\gamma_0 = 1.36$ e $g_Y(z) = 0.6z^{-1} + 1.36 + 0.6z$.
> As autocorrela√ß√µes s√£o:
> $\rho_0 = \gamma_0 / \gamma_0 = 1$
> $\rho_1 = \gamma_1 / \gamma_0 = 0.6 / 1.36 \approx 0.441$
> A ACF-GF √©:
> $g_{\rho}(z) = g_Y(z) / \gamma_0 = (0.6z^{-1} + 1.36 + 0.6z) / 1.36 = 0.441z^{-1} + 1 + 0.441z$

### Conclus√£o

A fun√ß√£o geradora de autocovari√¢ncia √© uma ferramenta poderosa para analisar e caracterizar a estrutura de depend√™ncia temporal de processos estoc√°sticos estacion√°rios. Ao resumir todas as autocovari√¢ncias em uma √∫nica fun√ß√£o, ela facilita a compara√ß√£o entre diferentes processos e permite a identifica√ß√£o de componentes c√≠clicos atrav√©s do espectro de pot√™ncia. Al√©m disso, a ACGF desempenha um papel fundamental na an√°lise de modelos ARMA e na compreens√£o de filtros aplicados a s√©ries temporais. Como veremos em cap√≠tulos posteriores, a ACGF √© uma ferramenta essencial para a an√°lise espectral e para o desenvolvimento de modelos mais sofisticados de s√©ries temporais.

### Refer√™ncias
[^44]: P√°gina 44 do contexto original
[^45]: P√°gina 45 do contexto original
[^48]: P√°gina 48 do contexto original
[^50]: P√°gina 50 do contexto original
[^61]: P√°gina 61 do contexto original
[^62]: P√°gina 62 do contexto original
[^63]: Nova refer√™ncia para a demonstra√ß√£o detalhada do Teorema 1.1.

<!-- END -->