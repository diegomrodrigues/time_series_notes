## TÃ­tulo Conciso: AnÃ¡lise da DiferenciaÃ§Ã£o Aplicada a um Processo MA(1) via FGAC

### IntroduÃ§Ã£o

Em continuidade ao estudo da implementaÃ§Ã£o de tÃ©cnicas de filtragem via manipulaÃ§Ã£o da funÃ§Ã£o geradora de autocovariÃ¢ncia (FGAC) e construindo sobre os tÃ³picos anteriores [^63, 64], este capÃ­tulo explora um caso especÃ­fico: a aplicaÃ§Ã£o de um filtro de diferenciaÃ§Ã£o a dados originalmente gerados por um processo MA(1). Analisaremos como essa transformaÃ§Ã£o altera a estrutura de autocorrelaÃ§Ã£o da sÃ©rie temporal e como a funÃ§Ã£o geradora de autocovariÃ¢ncia (FGAC) pode ser utilizada para caracterizar essa mudanÃ§a, considerando a forma fatorada da FGAC resultante [^63].

### Conceitos Fundamentais

Revisitando os conceitos estabelecidos, uma sÃ©rie temporal $Y_t$ gerada por um processo MA(1) Ã© definida como [^63]:

$$Y_t = (1 + \theta L)\epsilon_t$$

onde $L$ Ã© o operador de *lag*, $\theta$ Ã© o coeficiente do processo MA(1) e $\epsilon_t$ Ã© um ruÃ­do branco com mÃ©dia zero e variÃ¢ncia $\sigma^2$ [^47, 3.2.1, 3.2.2, 3.2.3]. A FGAC correspondente Ã© dada por [^63]:

$$g_y(z) = \sigma^2(1 + \theta z)(1 + \theta z^{-1})$$

> ğŸ’¡ **Exemplo NumÃ©rico:**
>
> Seja $\theta = 0.7$ e $\sigma^2 = 2$.  EntÃ£o, a FGAC da sÃ©rie MA(1) Ã©:
>
> $g_y(z) = 2(1 + 0.7z)(1 + 0.7z^{-1}) = 2(1 + 0.7z + 0.7z^{-1} + 0.49)$.
>
> Isso representa a funÃ§Ã£o que, quando expandida em potÃªncias de $z$, fornece as autocovariÃ¢ncias da sÃ©rie $Y_t$. Especificamente, o termo constante Ã© a variÃ¢ncia, e os coeficientes de $z$ e $z^{-1}$ sÃ£o as autocovariÃ¢ncias de lag 1.

Agora, aplicamos um filtro de diferenciaÃ§Ã£o, definido como:

$$X_t = (1 - L)Y_t$$

Este filtro calcula a diferenÃ§a entre o valor atual e o valor anterior da sÃ©rie temporal, resultando em [^63]:

$$X_t = (1 - L)(1 + \theta L)\epsilon_t = [1 + (\theta - 1)L - \theta L^2]\epsilon_t = [1 + \theta_1 L + \theta_2 L^2]\epsilon_t$$

onde $\theta_1 = (\theta - 1)$ e $\theta_2 = -\theta$. A sÃ©rie temporal $X_t$ Ã© agora um processo MA(2).

**FGAC da SÃ©rie Diferenciada:**

A FGAC da sÃ©rie diferenciada $X_t$ pode ser expressa de duas formas [^63]:

1.  **Forma direta:** Calculada diretamente a partir dos coeficientes do MA(2):

    $$g_x(z) = \sigma^2(1 + \theta_1 z + \theta_2 z^2)(1 + \theta_1 z^{-1} + \theta_2 z^{-2})$$

2.  **Forma fatorada:** Expressa em termos da FGAC original e do filtro de diferenciaÃ§Ã£o:

    $$g_x(z) = (1 - z)(1 - z^{-1})g_y(z)$$

A forma fatorada Ã© particularmente Ãºtil para entender como o filtro de diferenciaÃ§Ã£o altera a estrutura de autocorrelaÃ§Ã£o da sÃ©rie original.

> ğŸ’¡ **Exemplo NumÃ©rico:**
>
> Usando o exemplo anterior com $\theta = 0.7$ e $\sigma^2 = 2$, temos $\theta_1 = 0.7 - 1 = -0.3$ e $\theta_2 = -0.7$. A forma direta da FGAC Ã©:
>
> $g_x(z) = 2(1 - 0.3z - 0.7z^2)(1 - 0.3z^{-1} - 0.7z^{-2})$.
>
> ExpansÃ£o dos termos nos dÃ¡ os coeficientes das autocovariÃ¢ncias para lags 0, 1 e 2.

**Teorema 6:** A forma fatorada da FGAC para a sÃ©rie diferenciada $X_t$ enfatiza o efeito do filtro de diferenciaÃ§Ã£o na remoÃ§Ã£o de tendÃªncias de baixa frequÃªncia presentes na sÃ©rie original $Y_t$.

*Prova:*
I. A forma fatorada da FGAC de $X_t$ Ã© dada por $g_x(z) = (1 - z)(1 - z^{-1})g_y(z)$.
II. O termo $(1 - z)(1 - z^{-1})$ corresponde Ã  funÃ§Ã£o de transferÃªncia do filtro de diferenciaÃ§Ã£o.
III. Avaliando essa funÃ§Ã£o de transferÃªncia em $z = e^{-i\omega}$, obtemos $|1 - e^{-i\omega}|^2 = (1 - \cos(\omega))^2 + \sin^2(\omega) = 2 - 2\cos(\omega) = 4\sin^2(\omega/2)$.
IV. Para frequÃªncias baixas ($\omega \approx 0$), $\sin(\omega/2) \approx \omega/2$, entÃ£o $|1 - e^{-i\omega}|^2 \approx \omega^2$.
V. Isso mostra que o filtro de diferenciaÃ§Ã£o atenua fortemente as frequÃªncias baixas, efetivamente removendo tendÃªncias ou componentes de baixa frequÃªncia presentes na sÃ©rie original $Y_t$. $\blacksquare$

> ğŸ’¡ **Exemplo NumÃ©rico:**
>
> Considere uma sÃ©rie temporal $Y_t = (1 + 0.5L)\epsilon_t$, onde $\theta = 0.5$ e $\epsilon_t$ Ã© ruÃ­do branco com variÃ¢ncia $\sigma^2 = 1$. A FGAC original Ã© $g_y(z) = (1 + 0.5z)(1 + 0.5z^{-1})$.
>
> Aplicamos o filtro de diferenciaÃ§Ã£o $X_t = (1 - L)Y_t$.  A forma fatorada da FGAC Ã© $g_x(z) = (1 - z)(1 - z^{-1})g_y(z)$.
>
> Para avaliar a resposta do filtro em frequÃªncias baixas, substituÃ­mos $z = e^{-i\omega}$ na funÃ§Ã£o de transferÃªncia do filtro de diferenciaÃ§Ã£o:
>
> $(1 - z)(1 - z^{-1}) = (1 - e^{-i\omega})(1 - e^{i\omega}) = (1 - (\cos(\omega) - i\sin(\omega)))(1 - (\cos(\omega) + i\sin(\omega)))$
>
> $= (1 - \cos(\omega) + i\sin(\omega))(1 - \cos(\omega) - i\sin(\omega)) = (1 - \cos(\omega))^2 + \sin^2(\omega) = 1 - 2\cos(\omega) + \cos^2(\omega) + \sin^2(\omega) = 2 - 2\cos(\omega)$
>
> Usando a identidade trigonomÃ©trica $\cos(\omega) = 1 - 2\sin^2(\omega/2)$, obtemos $2 - 2(1 - 2\sin^2(\omega/2)) = 4\sin^2(\omega/2)$.
>
> Para frequÃªncias baixas, $\sin(\omega/2) \approx \omega/2$, entÃ£o a resposta do filtro Ã© aproximadamente $4(\omega/2)^2 = \omega^2$. Isso demonstra que o filtro de diferenciaÃ§Ã£o atenua as frequÃªncias baixas.
>
> Em Python:
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
>
> # Define frequÃªncias
> omega = np.linspace(0, np.pi, 100)
>
> # Calcula a resposta em frequÃªncia
> response = 4 * np.sin(omega/2)**2
>
> # Plota a resposta em frequÃªncia
> plt.plot(omega, response)
> plt.xlabel('FrequÃªncia (omega)')
> plt.ylabel('Resposta do Filtro')
> plt.title('Resposta em FrequÃªncia do Filtro de DiferenciaÃ§Ã£o')
> plt.grid(True)
> plt.show()
> ```
>
> Este cÃ³digo plota a resposta em frequÃªncia, mostrando claramente a atenuaÃ§Ã£o das frequÃªncias baixas.

<!-- END_Teorema_6 -->

**CorolÃ¡rio 6.1:** Se a sÃ©rie original $Y_t$ possui uma tendÃªncia linear dada por $Y_t = a + bt + \epsilon_t$, onde $\epsilon_t$ Ã© ruÃ­do branco, a aplicaÃ§Ã£o do filtro de diferenciaÃ§Ã£o $X_t = (1 - L)Y_t$ resulta em uma sÃ©rie sem tendÃªncia.

*Prova:*
I. Aplicando o filtro de diferenciaÃ§Ã£o Ã  sÃ©rie $Y_t = a + bt + \epsilon_t$, obtemos $X_t = (1 - L)Y_t = Y_t - Y_{t-1} = (a + bt + \epsilon_t) - (a + b(t-1) + \epsilon_{t-1}) = b + \epsilon_t - \epsilon_{t-1}$.
II. A sÃ©rie resultante $X_t = b + \epsilon_t - \epsilon_{t-1}$ tem mÃ©dia constante $b$ e, portanto, nÃ£o possui tendÃªncia linear.
III. A forma fatorada da FGAC enfatiza que a sÃ©rie diferenciada nÃ£o tem a caracterÃ­stica de frequÃªncia zero (tendÃªncia linear). $\blacksquare$

> ğŸ’¡ **Exemplo NumÃ©rico:**
>
> Considere uma sÃ©rie temporal $Y_t = 2 + 3t + \epsilon_t$, onde $\epsilon_t$ Ã© ruÃ­do branco.
>
> Aplicando o filtro de diferenciaÃ§Ã£o, obtemos:
>
> $X_t = Y_t - Y_{t-1} = (2 + 3t + \epsilon_t) - (2 + 3(t-1) + \epsilon_{t-1}) = (2 + 3t + \epsilon_t) - (2 + 3t - 3 + \epsilon_{t-1}) = 3 + \epsilon_t - \epsilon_{t-1}$.
>
> A sÃ©rie resultante $X_t = 3 + \epsilon_t - \epsilon_{t-1}$ tem uma mÃ©dia constante de 3 e nÃ£o possui tendÃªncia linear.
>
> Suponha que $\epsilon_t$ seja gerado a partir de uma distribuiÃ§Ã£o normal com mÃ©dia 0 e desvio padrÃ£o 1. Podemos simular essa sÃ©rie em Python:
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
>
> # Define os parÃ¢metros
> a = 2
> b = 3
> sigma = 1
>
> # Gera ruÃ­do branco
> np.random.seed(42)  # para reprodutibilidade
> epsilon = np.random.normal(0, sigma, 100)
>
> # Gera a sÃ©rie com tendÃªncia
> t = np.arange(100)
> Y = a + b * t + epsilon
>
> # Aplica o filtro de diferenciaÃ§Ã£o
> X = Y[1:] - Y[:-1]
>
> # Plota as sÃ©ries
> plt.figure(figsize=(12, 6))
> plt.subplot(2, 1, 1)
> plt.plot(Y)
> plt.title('SÃ©rie Original com TendÃªncia Linear')
> plt.xlabel('Tempo')
> plt.ylabel('Valor')
>
> plt.subplot(2, 1, 2)
> plt.plot(X)
> plt.title('SÃ©rie Diferenciada (Sem TendÃªncia)')
> plt.xlabel('Tempo')
> plt.ylabel('Valor')
>
> plt.tight_layout()
> plt.show()
>
> # Calcula a mÃ©dia da sÃ©rie diferenciada
> media_X = np.mean(X)
> print(f"MÃ©dia da sÃ©rie diferenciada: {media_X}")
> ```
>
> O grÃ¡fico mostrarÃ¡ a sÃ©rie original com a tendÃªncia linear e a sÃ©rie diferenciada sem a tendÃªncia, flutuando em torno de uma mÃ©dia constante (aproximadamente 3). A impressÃ£o da mÃ©dia da sÃ©rie diferenciada confirmarÃ¡ que ela estÃ¡ prÃ³xima do valor esperado (b=3).

<!-- END_Corolario_6.1 -->

**AnÃ¡lise da Forma Fatorada da FGAC:**

A forma fatorada da FGAC, $g_x(z) = (1 - z)(1 - z^{-1})g_y(z)$, permite uma anÃ¡lise mais intuitiva das transformaÃ§Ãµes realizadas pelo filtro. O termo $(1 - z)(1 - z^{-1})$ atua como um *operador de anulaÃ§Ã£o* para frequÃªncias prÃ³ximas de zero. Para ver isso, substituÃ­mos $z = e^{-i\omega}$ na expressÃ£o:

$$(1 - z)(1 - z^{-1}) = (1 - e^{-i\omega})(1 - e^{i\omega}) = 2 - 2\cos(\omega) = 4\sin^2(\omega/2)$$

Quando $\omega$ se aproxima de zero, $4\sin^2(\omega/2)$ tambÃ©m se aproxima de zero. Isso significa que o filtro de diferenciaÃ§Ã£o atenua fortemente as componentes de baixa frequÃªncia na sÃ©rie original, o que Ã© tÃ­pico de filtros de alta passagem.

> ğŸ’¡ **Exemplo NumÃ©rico:**
>
> Para $\omega = 0.1$, temos $4\sin^2(0.1/2) \approx 4(0.05)^2 = 0.01$. Para $\omega = 1$, temos $4\sin^2(1/2) \approx 4(0.479)^2 = 0.918$. Isso demonstra que o filtro de diferenciaÃ§Ã£o atenua as frequÃªncias baixas e amplifica as altas.
>
> Podemos usar um grÃ¡fico para visualizar essa atenuaÃ§Ã£o:
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
>
> # Define as frequÃªncias
> omega = np.linspace(0, np.pi, 100)
>
> # Calcula a resposta em frequÃªncia
> response = 4 * np.sin(omega/2)**2
>
> # Plota a resposta em frequÃªncia
> plt.plot(omega, response)
> plt.xlabel('FrequÃªncia (omega)')
> plt.ylabel('AtenuaÃ§Ã£o')
> plt.title('AtenuaÃ§Ã£o de FrequÃªncias pelo Filtro de DiferenciaÃ§Ã£o')
> plt.grid(True)
> plt.show()
> ```
> O grÃ¡fico mostrarÃ¡ a atenuaÃ§Ã£o das frequÃªncias baixas e o aumento das frequÃªncias mais altas.

**BenefÃ­cios da Forma Fatorada:**

*   **InterpretaÃ§Ã£o:** A forma fatorada permite uma interpretaÃ§Ã£o mais direta do efeito do filtro em termos de componentes de frequÃªncia.
*   **CÃ¡lculo:** Em algumas situaÃ§Ãµes, a forma fatorada pode simplificar os cÃ¡lculos, especialmente ao analisar a combinaÃ§Ã£o de mÃºltiplos filtros [^63].
*   **Design de Filtros:** A forma fatorada facilita o design de filtros com caracterÃ­sticas especÃ­ficas de resposta em frequÃªncia [^63].

**ProposiÃ§Ã£o 6.1:** A aplicaÃ§Ã£o sucessiva de um filtro de diferenciaÃ§Ã£o e um filtro de mÃ©dia mÃ³vel a uma sÃ©rie temporal Ã© equivalente a um filtro combinado, cuja resposta em frequÃªncia Ã© o produto das respostas em frequÃªncia dos filtros individuais.

*Prova*:
I. Seja $Y_t$ a sÃ©rie temporal original.
II. Aplicamos um filtro de diferenciaÃ§Ã£o $h_1(L) = 1 - L$, resultando em $X_t = (1 - L)Y_t$.
III. Em seguida, aplicamos um filtro de mÃ©dia mÃ³vel $h_2(L)$ a $X_t$, resultando em $Z_t = h_2(L)X_t = h_2(L)(1 - L)Y_t$.
IV. A funÃ§Ã£o de transferÃªncia do filtro de diferenciaÃ§Ã£o Ã© $H_1(\omega) = 1 - e^{-i\omega}$, e a funÃ§Ã£o de transferÃªncia do filtro de mÃ©dia mÃ³vel Ã© $H_2(\omega)$.
V. A resposta em frequÃªncia do filtro combinado Ã© o produto das respostas em frequÃªncia dos filtros individuais: $H(\omega) = H_1(\omega)H_2(\omega)$.
VI. Portanto, a aplicaÃ§Ã£o sucessiva dos filtros Ã© equivalente a um Ãºnico filtro com resposta em frequÃªncia $H(\omega)$. $\blacksquare$

> ğŸ’¡ **Exemplo NumÃ©rico:**
> Seja $h_1(L) = 1 - L$ e $h_2(L) = 0.5 + 0.5L$ (filtro de mÃ©dia mÃ³vel de ordem 1). EntÃ£o,
> $H_1(\omega) = 1 - e^{-i\omega}$ e $H_2(\omega) = 0.5 + 0.5e^{-i\omega} = 0.5(1 + e^{-i\omega})$.
> A resposta em frequÃªncia combinada Ã©:
> $H(\omega) = H_1(\omega)H_2(\omega) = (1 - e^{-i\omega})(0.5 + 0.5e^{-i\omega}) = 0.5(1 - e^{-2i\omega})$.
>
> Podemos visualizar as respostas em frequÃªncia dos filtros individuais e do filtro combinado:
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
>
> # Define as frequÃªncias
> omega = np.linspace(0, np.pi, 100)
>
> # Calcula as respostas em frequÃªncia dos filtros individuais
> H1 = 1 - np.exp(-1j * omega)
> H2 = 0.5 + 0.5 * np.exp(-1j * omega)
>
> # Calcula a resposta em frequÃªncia do filtro combinado
> H = H1 * H2
>
> # Plota as respostas em frequÃªncia
> plt.figure(figsize=(12, 6))
> plt.subplot(3, 1, 1)
> plt.plot(omega, np.abs(H1))
> plt.title('Resposta em FrequÃªncia do Filtro de DiferenciaÃ§Ã£o')
> plt.xlabel('FrequÃªncia (omega)')
> plt.ylabel('Amplitude')
>
> plt.subplot(3, 1, 2)
> plt.plot(omega, np.abs(H2))
> plt.title('Resposta em FrequÃªncia do Filtro de MÃ©dia MÃ³vel')
> plt.xlabel('FrequÃªncia (omega)')
> plt.ylabel('Amplitude')
>
> plt.subplot(3, 1, 3)
> plt.plot(omega, np.abs(H))
> plt.title('Resposta em FrequÃªncia do Filtro Combinado')
> plt.xlabel('FrequÃªncia (omega)')
> plt.ylabel('Amplitude')
>
> plt.tight_layout()
> plt.show()
> ```
>
> Os grÃ¡ficos mostram como a combinaÃ§Ã£o dos filtros afeta a resposta em frequÃªncia geral.

<!-- END_ProposiÃ§Ã£o_6.1 -->

**Lema 6.1:** A autocovariÃ¢ncia de ordem $k$ da sÃ©rie diferenciada $X_t$ pode ser expressa em termos das autocovariÃ¢ncias da sÃ©rie original $Y_t$.

*Prova:*
I. Seja $\gamma_y(k)$ a autocovariÃ¢ncia de ordem $k$ da sÃ©rie $Y_t$, definida como $\gamma_y(k) = E[(Y_t - \mu_y)(Y_{t-k} - \mu_y)]$, onde $\mu_y$ Ã© a mÃ©dia de $Y_t$.
II. Seja $\gamma_x(k)$ a autocovariÃ¢ncia de ordem $k$ da sÃ©rie $X_t$, definida como $\gamma_x(k) = E[(X_t - \mu_x)(X_{t-k} - \mu_x)]$, onde $\mu_x$ Ã© a mÃ©dia de $X_t$.
III. Como $X_t = Y_t - Y_{t-1}$, temos $\mu_x = E[X_t] = E[Y_t - Y_{t-1}] = \mu_y - \mu_y = 0$ (assumindo que a mÃ©dia de $Y_t$ Ã© constante).
IV. EntÃ£o, $\gamma_x(k) = E[X_t X_{t-k}] = E[(Y_t - Y_{t-1})(Y_{t-k} - Y_{t-k-1})] = E[Y_t Y_{t-k} - Y_t Y_{t-k-1} - Y_{t-1} Y_{t-k} + Y_{t-1} Y_{t-k-1}]$.
V. Usando a definiÃ§Ã£o de autocovariÃ¢ncia, temos $\gamma_x(k) = \gamma_y(k) - \gamma_y(k+1) - \gamma_y(k-1) + \gamma_y(k)$.
VI. Portanto, $\gamma_x(k) = 2\gamma_y(k) - \gamma_y(k+1) - \gamma_y(k-1)$. $\blacksquare$

> ğŸ’¡ **Exemplo NumÃ©rico:**
>
> Suponha que a sÃ©rie $Y_t$ tenha as seguintes autocovariÃ¢ncias:
>
> $\gamma_y(0) = 4$, $\gamma_y(1) = 2$, $\gamma_y(2) = 1$, e $\gamma_y(k) = 0$ para $|k| > 2$.
>
> EntÃ£o, a autocovariÃ¢ncia de ordem 0 da sÃ©rie diferenciada $X_t$ Ã©:
>
> $\gamma_x(0) = 2\gamma_y(0) - \gamma_y(1) - \gamma_y(-1) = 2(4) - 2 - 2 = 8 - 4 = 4$.
>
> A autocovariÃ¢ncia de ordem 1 da sÃ©rie diferenciada $X_t$ Ã©:
>
> $\gamma_x(1) = 2\gamma_y(1) - \gamma_y(2) - \gamma_y(0) = 2(2) - 1 - 4 = 4 - 5 = -1$.
>
> A autocovariÃ¢ncia de ordem 2 da sÃ©rie diferenciada $X_t$ Ã©:
>
> $\gamma_x(2) = 2\gamma_y(2) - \gamma_y(3) - \gamma_y(1) = 2(1) - 0 - 2 = 2 - 2 = 0$.

<!-- END_Lema_6.1 -->

**Teorema 7:** A variÃ¢ncia da sÃ©rie diferenciada $X_t$ estÃ¡ relacionada Ã  variÃ¢ncia da sÃ©rie original $Y_t$ e ao parÃ¢metro $\theta$ do processo MA(1).

*Prova:*
I. Sabemos que $X_t = (1 - L)Y_t = (1 - L)(1 + \theta L)\epsilon_t = [1 + (\theta - 1)L - \theta L^2]\epsilon_t$.
II. A variÃ¢ncia de $X_t$ Ã© dada por $Var(X_t) = E[X_t^2] - E[X_t]^2$. Como $E[\epsilon_t] = 0$, entÃ£o $E[X_t] = 0$.
III. Portanto, $Var(X_t) = E[X_t^2] = E[(1 + (\theta - 1)L - \theta L^2)\epsilon_t]^2 = E[(\epsilon_t + (\theta - 1)\epsilon_{t-1} - \theta \epsilon_{t-2})^2]$.
IV. Expandindo e utilizando o fato de que $E[\epsilon_t \epsilon_s] = 0$ para $t \neq s$ e $E[\epsilon_t^2] = \sigma^2$, obtemos:
$Var(X_t) = E[\epsilon_t^2 + (\theta - 1)^2\epsilon_{t-1}^2 + \theta^2 \epsilon_{t-2}^2] = \sigma^2 + (\theta - 1)^2\sigma^2 + \theta^2\sigma^2 = \sigma^2(1 + (\theta - 1)^2 + \theta^2) = \sigma^2(1 + \theta^2 - 2\theta + 1 + \theta^2) = \sigma^2(2\theta^2 - 2\theta + 2) = 2\sigma^2(\theta^2 - \theta + 1)$.
V. A variÃ¢ncia da sÃ©rie original $Y_t$ Ã© $Var(Y_t) = \sigma^2(1 + \theta^2)$.
VI. Assim, $Var(X_t) = 2\sigma^2(\theta^2 - \theta + 1) = 2(Var(Y_t) - \sigma^2\theta + \sigma^2 - \sigma^2\theta^2) = 2(Var(Y_t) - \sigma^2\theta(1+\theta))$. Portanto, a variÃ¢ncia da sÃ©rie diferenciada depende da variÃ¢ncia da sÃ©rie original e do parÃ¢metro $\theta$. $\blacksquare$

> ğŸ’¡ **Exemplo NumÃ©rico:**
>
> Seja $\theta = 0.5$ e $\sigma^2 = 1$. EntÃ£o, a variÃ¢ncia da sÃ©rie original $Y_t$ Ã©:
>
> $Var(Y_t) = \sigma^2(1 + \theta^2) = 1(1 + 0.5^2) = 1 + 0.25 = 1.25$.
>
> A variÃ¢ncia da sÃ©rie diferenciada $X_t$ Ã©:
>
> $Var(X_t) = 2\sigma^2(\theta^2 - \theta + 1) = 2(1)(0.5^2 - 0.5 + 1) = 2(0.25 - 0.5 + 1) = 2(0.75) = 1.5$.
>
> Podemos verificar essa relaÃ§Ã£o usando simulaÃ§Ã£o:
>
> ```python
> import numpy as np
>
> # Define os parÃ¢metros
> theta = 0.5
> sigma = 1
>
> # Gera ruÃ­do branco
> np.random.seed(42)
> epsilon = np.random.normal(0, sigma, 1000)
>
> # Gera a sÃ©rie MA(1)
> Y = epsilon[1:] + theta * epsilon[:-1]
>
> # Aplica o filtro de diferenciaÃ§Ã£o
> X = Y[1:] - Y[:-1]
>
> # Calcula as variÃ¢ncias
> var_Y = np.var(Y)
> var_X = np.var(X)
>
> print(f"VariÃ¢ncia da sÃ©rie original Y: {var_Y}")
> print(f"VariÃ¢ncia da sÃ©rie diferenciada X: {var_X}")
> ```
>
> Os resultados da simulaÃ§Ã£o devem se aproximar dos valores calculados analiticamente.

**CorolÃ¡rio 7.1:** Se $\theta = 0$ (i.e., $Y_t = \epsilon_t$ Ã© um ruÃ­do branco), entÃ£o a variÃ¢ncia da sÃ©rie diferenciada $X_t$ Ã© $2\sigma^2$, onde $\sigma^2$ Ã© a variÃ¢ncia do ruÃ­do branco original.

*Prova:*
I. Se $\theta = 0$, entÃ£o $Y_t = \epsilon_t$ e $X_t = (1 - L)Y_t = \epsilon_t - \epsilon_{t-1}$.
II. $Var(X_t) = Var(\epsilon_t - \epsilon_{t-1}) = Var(\epsilon_t) + Var(\epsilon_{t-1}) = \sigma^2 + \sigma^2 = 2\sigma^2$. $\blacksquare$

> ğŸ’¡ **Exemplo NumÃ©rico:**
>
> Se $\theta = 0$ e $\sigma^2 = 1$, entÃ£o $Y_t = \epsilon_t$ Ã© um ruÃ­do branco com variÃ¢ncia 1. A sÃ©rie diferenciada Ã© $X_t = \epsilon_t - \epsilon_{t-1}$.
>
> A variÃ¢ncia de $X_t$ Ã© $Var(X_t) = 2\sigma^2 = 2(1) = 2$.
>
> SimulaÃ§Ã£o em Python:
>
> ```python
> import numpy as np
>
> # Define os parÃ¢metros
> sigma = 1
>
> # Gera ruÃ­do branco
> np.random.seed(42)
> epsilon = np.random.normal(0, sigma, 1000)
>
> # Aplica o filtro de diferenciaÃ§Ã£o
> X = epsilon[1:] - epsilon[:-1]
>
> # Calcula a variÃ¢ncia
> var_X = np.var(X)
>
> print(f"VariÃ¢ncia da sÃ©rie diferenciada X: {var_X}")
> ```
>
> O resultado da simulaÃ§Ã£o deve se aproximar do valor teÃ³rico de 2.

<!-- END_Teorema_7 -->

### ConclusÃ£o

A anÃ¡lise do impacto de um filtro de diferenciaÃ§Ã£o aplicado a um processo MA(1) atravÃ©s da funÃ§Ã£o geradora de autocovariÃ¢ncia (FGAC) demonstra a utilidade desta ferramenta para compreender as transformaÃ§Ãµes na estrutura de autocorrelaÃ§Ã£o de uma sÃ©rie temporal. A forma fatorada da FGAC oferece insights valiosos sobre o efeito de atenuaÃ§Ã£o de componentes de baixa frequÃªncia promovido pelo filtro de diferenciaÃ§Ã£o. A compreensÃ£o dessas tÃ©cnicas Ã© essencial para a aplicaÃ§Ã£o de filtros em diversas Ã¡reas da anÃ¡lise de sÃ©ries temporais, como processamento de sinais, anÃ¡lise econÃ´mica e previsÃµes.

### ReferÃªncias

[^45]: DefiniÃ§Ã£o de autocovariÃ¢ncia e estacionaridade em ARMA.
[^47]: DefiniÃ§Ã£o de ruÃ­do branco.
[^61]: DefiniÃ§Ã£o da funÃ§Ã£o geradora de autocovariÃ¢ncia.
[^63]: ExplicaÃ§Ã£o do impacto de filtros e o uso da funÃ§Ã£o geradora de autocovariÃ¢ncia.
[^64]: GeneralizaÃ§Ã£o do impacto dos filtros na funÃ§Ã£o geradora de autocovariÃ¢ncia.
<!-- END -->