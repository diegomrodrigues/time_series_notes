## Expectativa como Limite de Probabilidade da M√©dia do Ensemble

### Introdu√ß√£o

Este cap√≠tulo explora a interpreta√ß√£o da **expectativa** de uma s√©rie temporal como o limite de probabilidade da m√©dia do ensemble. Expandindo os conceitos introduzidos nos cap√≠tulos anteriores, detalharemos a rela√ß√£o entre a expectativa te√≥rica e a m√©dia calculada a partir de m√∫ltiplas realiza√ß√µes independentes da s√©rie temporal [^1]. Esta interpreta√ß√£o oferece uma ponte entre a defini√ß√£o matem√°tica da expectativa e sua aplica√ß√£o pr√°tica na an√°lise de dados.

### M√©dia do Ensemble e Limite de Probabilidade

A **m√©dia do ensemble** no instante *t* √© calculada como a m√©dia dos valores observados em *t* em um grande n√∫mero de realiza√ß√µes independentes da s√©rie temporal. Formalmente, se tivermos $I$ realiza√ß√µes independentes da s√©rie temporal, denotadas por $\{Y_t^{(i)}\}_{i=1}^{I}$, a m√©dia do ensemble no instante *t* √© definida como:

$$\bar{Y}_t^{(I)} = \frac{1}{I} \sum_{i=1}^{I} Y_t^{(i)}$$

Onde $Y_t^{(i)}$ representa o valor da *t*-√©sima observa√ß√£o na *i*-√©sima realiza√ß√£o da s√©rie temporal. A interpreta√ß√£o da expectativa como o **limite de probabilidade da m√©dia do ensemble** afirma que, √† medida que o n√∫mero de realiza√ß√µes $I$ tende ao infinito, a m√©dia do ensemble converge em probabilidade para a expectativa te√≥rica $E(Y_t)$. Matematicamente:

$$E(Y_t) = \text{plim}_{I \to \infty} \left( \frac{1}{I} \sum_{i=1}^{I} Y_t^{(i)} \right) = \text{plim}_{I \to \infty} \bar{Y}_t^{(I)}$$

Esta formula√ß√£o √© crucial, pois conecta a defini√ß√£o te√≥rica da expectativa, baseada na distribui√ß√£o de probabilidade, com uma interpreta√ß√£o pr√°tica que pode ser aproximada a partir de dados observados [^1].

**Defini√ß√£o 1** (Converg√™ncia em Probabilidade). Uma sequ√™ncia de vari√°veis aleat√≥rias $X_n$ converge em probabilidade para uma constante $c$ se, para todo $\epsilon > 0$,

$$\lim_{n \to \infty} P(|X_n - c| > \epsilon) = 0$$

*Teorema 1 (Lei Fraca dos Grandes N√∫meros):* Seja $X_1, X_2, \ldots, X_n$ uma sequ√™ncia de vari√°veis aleat√≥rias independentes e identicamente distribu√≠das (i.i.d.) com m√©dia $\mu$ e vari√¢ncia finita $\sigma^2$. Ent√£o, a m√©dia amostral $\bar{X}_n = \frac{1}{n} \sum_{i=1}^{n} X_i$ converge em probabilidade para $\mu$:

$$\text{plim}_{n \to \infty} \bar{X}_n = \mu$$

*Prova:*
I. Queremos mostrar que para todo $\epsilon > 0$, $\lim_{n \to \infty} P(|\bar{X}_n - \mu| > \epsilon) = 0$.

II. Pela desigualdade de Chebyshev, temos: $P(|\bar{X}_n - \mu| > \epsilon) \leq \frac{\text{Var}(\bar{X}_n)}{\epsilon^2}$.

III. A vari√¢ncia da m√©dia amostral √©: $\text{Var}(\bar{X}_n) = \text{Var}(\frac{1}{n} \sum_{i=1}^{n} X_i) = \frac{1}{n^2} \sum_{i=1}^{n} \text{Var}(X_i)$.

IV. Como as vari√°veis s√£o i.i.d., $\text{Var}(X_i) = \sigma^2$ para todo *i*. Portanto, $\text{Var}(\bar{X}_n) = \frac{1}{n^2} \sum_{i=1}^{n} \sigma^2 = \frac{n\sigma^2}{n^2} = \frac{\sigma^2}{n}$.

V. Substituindo na desigualdade de Chebyshev: $P(|\bar{X}_n - \mu| > \epsilon) \leq \frac{\sigma^2}{n\epsilon^2}$.

VI. Tomando o limite quando $n \to \infty$: $\lim_{n \to \infty} P(|\bar{X}_n - \mu| > \epsilon) \leq \lim_{n \to \infty} \frac{\sigma^2}{n\epsilon^2} = 0$.

VII. Portanto, $\text{plim}_{n \to \infty} \bar{X}_n = \mu$. $\blacksquare$

Este teorema, a Lei Fraca dos Grandes N√∫meros, formaliza a ideia intuitiva de que, ao aumentar o n√∫mero de amostras, a m√©dia amostral se aproxima da m√©dia populacional.

**Teorema 1.1 (Lei Forte dos Grandes N√∫meros):** Seja $X_1, X_2, \ldots, X_n$ uma sequ√™ncia de vari√°veis aleat√≥rias independentes e identicamente distribu√≠das (i.i.d.) com m√©dia $\mu$. Ent√£o, a m√©dia amostral $\bar{X}_n = \frac{1}{n} \sum_{i=1}^{n} X_i$ converge quase certamente para $\mu$:

$$P(\lim_{n \to \infty} \bar{X}_n = \mu) = 1$$

A Lei Forte dos Grandes N√∫meros implica que, com probabilidade 1, a sequ√™ncia das m√©dias amostrais converge para a m√©dia populacional, que √© uma forma mais forte de converg√™ncia do que a converg√™ncia em probabilidade garantida pela Lei Fraca dos Grandes N√∫meros.

> üí° **Exemplo Num√©rico:**
>
> Considere uma s√©rie temporal gerada por um processo de ru√≠do branco gaussiano com m√©dia $\mu = 5$ e vari√¢ncia $\sigma^2 = 4$. Vamos simular v√°rias realiza√ß√µes deste processo e calcular a m√©dia do ensemble para diferentes valores de *I*. Observaremos como a m√©dia do ensemble se aproxima de 5 √† medida que *I* aumenta. Al√©m disso, vamos calcular explicitamente a probabilidade de que a m√©dia do ensemble se desvie da m√©dia real (5) por mais de um certo valor $\epsilon$ e ver como essa probabilidade diminui com o aumento de *I*.
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
> from scipy.stats import norm
>
> # Par√¢metros
> mu = 5
> sigma = 2
> n_samples = 100
> n_realizations = [10, 100, 1000, 10000]
> epsilon = 0.1
>
> # Gera√ß√£o de dados
> np.random.seed(42)
> realizations = {}
> for I in n_realizations:
>     realizations[I] = np.random.normal(mu, sigma, size=(I, n_samples))
>
> # C√°lculo da m√©dia do ensemble
> ensemble_means = {}
> for I, data in realizations.items():
>     ensemble_means[I] = np.mean(data, axis=0)
>
> # C√°lculo da probabilidade P(|X_n - mu| > epsilon) usando simula√ß√£o
> probabilities = {}
> n_iterations = 1000  # N√∫mero de itera√ß√µes para estimar a probabilidade
> for I in n_realizations:
>     deviations = np.zeros(n_iterations)
>     for i in range(n_iterations):
>         # Simula I realiza√ß√µes e calcula a m√©dia do ensemble
>         ensemble_realization = np.random.normal(mu, sigma, size=(I, n_samples))
>         ensemble_mean = np.mean(ensemble_realization)
>         deviations[i] = abs(ensemble_mean - mu) > epsilon
>     probabilities[I] = np.mean(deviations)
>
> # Imprime as probabilidades estimadas
> for I, prob in probabilities.items():
>     print(f'P(|X_n - mu| > {epsilon}) para I={I}: {prob}')
>
> # Plotagem
> plt.figure(figsize=(12, 6))
> for I, mean in ensemble_means.items():
>     plt.plot(mean, label=f'M√©dia do Ensemble (I={I})')
> plt.axhline(y=mu, color='r', linestyle='--', label='Expectativa Te√≥rica (Œº={mu})')
> plt.title('M√©dia do Ensemble para Ru√≠do Branco Gaussiano')
> plt.xlabel('Tempo (t)')
> plt.ylabel('Valor')
> plt.legend()
> plt.grid(True)
> plt.show()
>
> # Plot da convergencia no tempo T = 50
> plt.figure(figsize=(12, 6))
> T = 50
> plt.plot(n_realizations, [np.mean(realizations[I][:, T]) for I in n_realizations], marker='o')
> plt.axhline(y=mu, color='r', linestyle='--', label='Expectativa Te√≥rica (Œº={mu})')
> plt.title(f'Converg√™ncia da M√©dia do Ensemble no tempo {T}')
> plt.xlabel('N√∫mero de Realiza√ß√µes (I)')
> plt.ylabel('Valor da M√©dia do Ensemble')
> plt.xscale('log')
> plt.xticks(n_realizations, n_realizations)
> plt.grid(True)
> plt.legend()
> plt.show()
>
> # Plot das probabilidades P(|X_n - mu| > epsilon)
> plt.figure(figsize=(12, 6))
> plt.plot(n_realizations, [probabilities[I] for I in n_realizations], marker='o')
> plt.title(f'Probabilidade de Desvio P(|X_n - mu| > {epsilon})')
> plt.xlabel('N√∫mero de Realiza√ß√µes (I)')
> plt.ylabel('Probabilidade')
> plt.xscale('log')
> plt.xticks(n_realizations, n_realizations)
> plt.grid(True)
> plt.show()
> ```
>
> Os gr√°ficos demonstrar√£o como as m√©dias do ensemble com um n√∫mero maior de realiza√ß√µes se aproximam da m√©dia te√≥rica de 5. A converg√™ncia √© visualizada tanto no tempo quanto no n√∫mero de realiza√ß√µes. Adicionalmente, o √∫ltimo gr√°fico mostrar√° como a probabilidade de desvio diminui √† medida que *I* aumenta, confirmando a converg√™ncia em probabilidade.

> üìù **Observa√ß√£o Importante:**
>
> A converg√™ncia em probabilidade implica que a probabilidade de a m√©dia do ensemble se desviar da expectativa te√≥rica por mais do que um valor arbitrariamente pequeno tende a zero √† medida que o n√∫mero de realiza√ß√µes aumenta. No entanto, *n√£o* garante que a m√©dia do ensemble ir√° *exatamente* igualar a expectativa te√≥rica em um n√∫mero finito de realiza√ß√µes.

### Implica√ß√µes para a An√°lise de S√©ries Temporais

A interpreta√ß√£o da expectativa como o limite de probabilidade da m√©dia do ensemble tem v√°rias implica√ß√µes importantes para a an√°lise de s√©ries temporais:

1.  **Valida√ß√£o de Modelos:** Ao simular m√∫ltiplas realiza√ß√µes de um modelo de s√©rie temporal, podemos calcular a m√©dia do ensemble e compar√°-la com a expectativa te√≥rica do modelo. Se as duas medidas convergirem √† medida que o n√∫mero de realiza√ß√µes aumenta, isso fornece evid√™ncias de que o modelo est√° bem especificado.
2.  **Estimativa de Expectativas:** Em situa√ß√µes onde a expectativa te√≥rica n√£o √© conhecida analiticamente, podemos estim√°-la numericamente atrav√©s do c√°lculo da m√©dia do ensemble a partir de um grande n√∫mero de realiza√ß√µes simuladas.
3.  **Compreens√£o do Comportamento M√©dio:** A m√©dia do ensemble oferece uma vis√£o do comportamento m√©dio da s√©rie temporal, suavizando as flutua√ß√µes aleat√≥rias presentes em uma √∫nica realiza√ß√£o.
4.  **Ergodicidade:** Este conceito est√° intimamente ligado √† interpretabilidade da expectativa como limite da m√©dia do ensemble. Se um processo √© erg√≥dico, as m√©dias temporais convergem para m√©dias do ensemble.

> üìù **Defini√ß√£o 1:**
> *Um processo estacion√°rio √© dito ser *erg√≥dico* se as m√©dias temporais convergem para as m√©dias do ensemble.*

*Teorema 2:** Em um processo estoc√°stico estacion√°rio, se a fun√ß√£o de autocovari√¢ncia converge para zero √† medida que o lapso de tempo aumenta, o processo √© erg√≥dico.

**Teorema 2.1:** Um processo Gaussiano estacion√°rio √© erg√≥dico se e somente se sua fun√ß√£o de autocovari√¢ncia $R(\tau)$ converge para zero quando $\tau \to \infty$.

*Prova:*
I. Suponha que $Y_t$ seja um processo Gaussiano estacion√°rio com fun√ß√£o de autocovari√¢ncia $R(\tau)$.

II. Para que o processo seja erg√≥dico, a m√©dia temporal deve convergir para a m√©dia do ensemble. Isso ocorre se
    $$\lim_{T \to \infty} \frac{1}{T} \int_0^T Y_t \, dt = E[Y_t]$$

III. A condi√ß√£o para ergodicidade em processos Gaussianos est√° relacionada com a converg√™ncia da integral da fun√ß√£o de autocovari√¢ncia:
    $$\lim_{T \to \infty} \frac{1}{T} \int_0^T R(\tau) \, d\tau = 0$$

IV. Se $R(\tau) \to 0$ quando $\tau \to \infty$, ent√£o a condi√ß√£o acima √© satisfeita, e o processo √© erg√≥dico. $\blacksquare$

> üí° **Exemplo de um Processo N√£o-Erg√≥dico:**
>
> Considere um processo onde $Y_t = A$, onde $A$ √© uma vari√°vel aleat√≥ria com distribui√ß√£o n√£o-degenerada. Neste caso, a m√©dia temporal de uma √∫nica realiza√ß√£o ser√° sempre igual ao valor de $A$ para aquela realiza√ß√£o, enquanto a m√©dia do ensemble ser√° a m√©dia de $A$ sobre todas as poss√≠veis realiza√ß√µes. Se a distribui√ß√£o de $A$ tiver uma vari√¢ncia n√£o-nula, as m√©dias temporais *n√£o* convergir√£o para a m√©dia do ensemble, e o processo n√£o ser√° erg√≥dico. Vamos simular este processo e visualizar a diferen√ßa entre a m√©dia temporal e a m√©dia do ensemble.
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
>
> # Par√¢metros
> n_samples = 100
> n_realizations = 100
> sigma_A = 2  # Desvio padr√£o de A
>
> # Gera√ß√£o de dados
> np.random.seed(42)
> A_values = np.random.normal(0, sigma_A, n_realizations)  # Valores de A para cada realiza√ß√£o
> realizations = np.tile(A_values, (n_samples, 1)).T  # Cada linha √© uma realiza√ß√£o com o mesmo valor de A
>
> # C√°lculo da m√©dia do ensemble
> ensemble_mean = np.mean(realizations, axis=0)
>
> # C√°lculo da m√©dia temporal de uma √∫nica realiza√ß√£o
> realization_index = 0  # Seleciona a primeira realiza√ß√£o como exemplo
> temporal_mean = np.mean(realizations[realization_index, :])
>
> # Plotagem
> plt.figure(figsize=(12, 6))
> plt.plot(ensemble_mean, label='M√©dia do Ensemble')
> plt.axhline(y=temporal_mean, color='r', linestyle='--', label='M√©dia Temporal (Realiza√ß√£o 0)')
> plt.title('Compara√ß√£o entre M√©dia do Ensemble e M√©dia Temporal (Processo N√£o-Erg√≥dico)')
> plt.xlabel('Tempo (t)')
> plt.ylabel('Valor')
> plt.legend()
> plt.grid(True)
> plt.show()
>
> print(f'M√©dia Temporal (Realiza√ß√£o 0): {temporal_mean}')
> print(f'M√©dia do Ensemble (M√©dia de A): {np.mean(A_values)}')
> ```
>
> O gr√°fico mostrar√° que a m√©dia temporal de uma √∫nica realiza√ß√£o permanece constante ao longo do tempo, igual ao valor de *A* para essa realiza√ß√£o. A m√©dia do ensemble, por outro lado, representa a m√©dia dos valores de *A* sobre todas as realiza√ß√µes. Como a distribui√ß√£o de *A* tem uma vari√¢ncia n√£o-nula, a m√©dia temporal n√£o converge para a m√©dia do ensemble, demonstrando a n√£o-ergodicidade do processo.

### Conclus√£o

A interpreta√ß√£o da expectativa como o limite de probabilidade da m√©dia do ensemble fornece uma ferramenta poderosa para conectar a teoria e a pr√°tica na an√°lise de s√©ries temporais. Ao simular m√∫ltiplas realiza√ß√µes de um modelo, podemos verificar se o comportamento m√©dio das realiza√ß√µes converge para a expectativa te√≥rica, validando assim o modelo. Al√©m disso, a m√©dia do ensemble oferece uma maneira de estimar numericamente a expectativa em casos onde o c√°lculo anal√≠tico √© dif√≠cil ou imposs√≠vel. Esta perspectiva refor√ßa a import√¢ncia da simula√ß√£o e da an√°lise de dados na compreens√£o do comportamento de s√©ries temporais.

### Refer√™ncias

[^1]: P√°gina 44 do texto original.
<!-- END -->