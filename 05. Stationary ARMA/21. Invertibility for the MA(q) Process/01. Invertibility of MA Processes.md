## Invertibilidade para o Processo MA(q)
### Introdu√ß√£o
Em continuidade √† an√°lise de processos *moving average* (MA) e sua representa√ß√£o, a **invertibilidade** surge como uma propriedade crucial para garantir a unicidade e a interpretabilidade dos modelos de s√©ries temporais [^65]. Anteriormente, vimos que um processo pode admitir m√∫ltiplas representa√ß√µes [^60], e a invertibilidade oferece um crit√©rio para selecionar a representa√ß√£o mais adequada, especialmente para fins de estima√ß√£o e previs√£o. Este cap√≠tulo explora em profundidade a condi√ß√£o de invertibilidade para processos MA(q), suas implica√ß√µes e o procedimento para obter uma representa√ß√£o invert√≠vel a partir de uma n√£o invert√≠vel.

### Conceitos Fundamentais
Um processo *moving average* de ordem *q*, denotado MA(q), √© definido como [^50]:
$$Y_t - \mu = (1 + \theta_1 L + \theta_2 L^2 + \dots + \theta_q L^q) \epsilon_t$$
onde $Y_t$ √© a s√©rie temporal no instante *t*, $\mu$ √© a m√©dia do processo, $\epsilon_t$ √© um ru√≠do branco com m√©dia zero e vari√¢ncia $\sigma^2$, e $L$ √© o operador de *lag*.

> üí° **Exemplo Num√©rico:** Suponha que temos uma s√©rie temporal de pre√ßos de a√ß√µes di√°rios e queremos model√°-la usando um processo MA(1) com m√©dia zero. A equa√ß√£o seria:
>
> $Y_t = \epsilon_t + 0.8\epsilon_{t-1}$
>
> Isso significa que o pre√ßo da a√ß√£o no dia *t* √© uma combina√ß√£o do ru√≠do branco (choque aleat√≥rio) no dia *t* e 80% do ru√≠do branco no dia anterior.

A **invertibilidade** de um processo MA(q) est√° intrinsecamente ligada √†s ra√≠zes do polin√¥mio em termos do operador de *lag*:
$$1 + \theta_1 z + \theta_2 z^2 + \dots + \theta_q z^q = 0$$
onde $z$ √© uma vari√°vel complexa [^67]. Um processo MA(q) √© considerado *invert√≠vel* se todas as ra√≠zes deste polin√¥mio estiverem fora do c√≠rculo unit√°rio no plano complexo [^67]. Em outras palavras, se as ra√≠zes $z_i$ satisfazem $|z_i| > 1$ para todo *i*, ent√£o o processo √© invert√≠vel.

> üí° **Exemplo Num√©rico:**
> Para um processo MA(2) com $\theta_1 = 0.5$ e $\theta_2 = 0.25$, o polin√¥mio √© $1 + 0.5z + 0.25z^2 = 0$. As ra√≠zes s√£o $z_1 = -1 + i$ e $z_2 = -1 - i$. O m√≥dulo das ra√≠zes √© $|z_1| = |z_2| = \sqrt{2} > 1$. Portanto, este processo MA(2) √© invert√≠vel.
>
> Para um processo MA(1) com $\theta = 2$, o polin√¥mio √© $1 + 2z = 0$. A raiz √© $z = -0.5$. O m√≥dulo da raiz √© $|z| = 0.5 < 1$. Portanto, este processo MA(1) n√£o √© invert√≠vel.

A import√¢ncia da invertibilidade reside no fato de que um processo MA(q) invert√≠vel pode ser expresso como um processo autorregressivo de ordem infinita, AR($\infty$) [^67]. Isso significa que podemos reescrever a equa√ß√£o original do MA(q) de forma que o valor atual da s√©rie temporal dependa linearmente de seus valores passados infinitos. Essa representa√ß√£o √© √∫til para an√°lise te√≥rica e para derivar previs√µes √≥timas [^67].

> üí° **Exemplo Num√©rico:** Considere um processo MA(1) invert√≠vel: $Y_t = \epsilon_t + 0.5\epsilon_{t-1}$. Podemos reescrev√™-lo como um AR($\infty$) da seguinte forma:
>
> $Y_t = \epsilon_t + 0.5\epsilon_{t-1}$
>
> $\epsilon_t = Y_t - 0.5\epsilon_{t-1}$
>
> $\epsilon_{t-1} = Y_{t-1} - 0.5\epsilon_{t-2}$
>
> Substituindo recursivamente:
>
> $Y_t = Y_t - 0.5(Y_{t-1} - 0.5\epsilon_{t-2})$
>
> $Y_t = -0.5Y_{t-1} + 0.25Y_{t-2} -0.125Y_{t-3} + \ldots + \epsilon_t$
>
> Esta √© uma representa√ß√£o AR($\infty$).

A condi√ß√£o de invertibilidade garante que o processo MA(q) tenha uma representa√ß√£o √∫nica. Caso contr√°rio, existir√£o m√∫ltiplas representa√ß√µes MA(q) que geram a mesma fun√ß√£o de autocovari√¢ncia [^65].

Para ilustrar a aplica√ß√£o da condi√ß√£o de invertibilidade, considere o seguinte exemplo:

**Exemplo:**
Considere um processo MA(1) dado por:
$$Y_t = \epsilon_t + \theta \epsilon_{t-1}$$
O polin√¥mio associado √© $1 + \theta z = 0$, cuja raiz √© $z = -\frac{1}{\theta}$. Para que o processo seja invert√≠vel, devemos ter $|z| > 1$, o que implica $|-\frac{1}{\theta}| > 1$, ou seja, $|\theta| < 1$. Portanto, um processo MA(1) √© invert√≠vel se e somente se $|\theta| < 1$.

> üí° **Exemplo Num√©rico:**
> Se $\theta = 0.8$, ent√£o $|z| = |-\frac{1}{0.8}| = 1.25 > 1$, e o processo √© invert√≠vel.
> Se $\theta = 1.2$, ent√£o $|z| = |-\frac{1}{1.2}| = 0.833 < 1$, e o processo n√£o √© invert√≠vel.

Agora, vamos formalizar a rela√ß√£o entre a invertibilidade e a representa√ß√£o AR($\infty$).

**Teorema 1:** *Um processo MA(q) invert√≠vel pode ser expresso como um processo AR($\infty$).*

**Demonstra√ß√£o (Esbo√ßo):**
Seja $\Theta(L) = 1 + \theta_1 L + \theta_2 L^2 + \dots + \theta_q L^q$ o polin√¥mio do operador de *lag* do processo MA(q). Se o processo √© invert√≠vel, ent√£o as ra√≠zes de $\Theta(z) = 0$ est√£o todas fora do c√≠rculo unit√°rio. Portanto, $\Theta(L)^{-1}$ pode ser expresso como uma s√©rie convergente em $L$, dada por $\Phi(L) = 1 + \phi_1 L + \phi_2 L^2 + \dots$, onde os coeficientes $\phi_i$ decaem √† medida que *i* aumenta. Assim, podemos escrever $Y_t - \mu = \Theta(L) \epsilon_t$ como $\Phi(L) (Y_t - \mu) = \epsilon_t$, ou seja, $Y_t - \mu = -\sum_{i=1}^{\infty} \phi_i (Y_{t-i} - \mu) + \epsilon_t$, que √© a representa√ß√£o AR($\infty$).

**Prova Detalhada do Teorema 1:**
I. Considere o processo MA(q): $Y_t - \mu = \Theta(L) \epsilon_t$, onde $\Theta(L) = 1 + \theta_1 L + \theta_2 L^2 + \dots + \theta_q L^q$.

II. Se o processo √© invert√≠vel, as ra√≠zes de $\Theta(z) = 0$ est√£o todas fora do c√≠rculo unit√°rio, ou seja, $|z_i| > 1$ para todas as ra√≠zes $z_i$.

III. Podemos expressar o inverso de $\Theta(L)$ como uma s√©rie infinita: $\Theta(L)^{-1} = \Phi(L) = 1 + \phi_1 L + \phi_2 L^2 + \dots$. Essa expans√£o √© v√°lida porque o processo √© invert√≠vel e, portanto, a s√©rie converge.

IV. Multiplicando ambos os lados da equa√ß√£o do processo MA(q) por $\Phi(L)$, obtemos: $\Phi(L) (Y_t - \mu) = \Phi(L) \Theta(L) \epsilon_t$.

V. Como $\Phi(L) = \Theta(L)^{-1}$, temos: $\Phi(L) \Theta(L) = 1$. Portanto, $\Phi(L) (Y_t - \mu) = \epsilon_t$.

VI. Expandindo $\Phi(L)$, obtemos: $(1 + \phi_1 L + \phi_2 L^2 + \dots) (Y_t - \mu) = \epsilon_t$.

VII. Rearranjando os termos, obtemos a representa√ß√£o AR($\infty$): $Y_t - \mu = -\sum_{i=1}^{\infty} \phi_i (Y_{t-i} - \mu) + \epsilon_t$.

VIII. Assim, demonstramos que um processo MA(q) invert√≠vel pode ser expresso como um processo AR($\infty$). ‚ñ†

**Lema 1:** *Seja $P(z) = 1 + a_1 z + \dots + a_q z^q$ um polin√¥mio de grau $q$. Se $z_1, \dots, z_q$ s√£o as ra√≠zes de $P(z)$, ent√£o $P(z) = \prod_{i=1}^q (1 - z/z_i)$.*

**Demonstra√ß√£o:** Este lema decorre diretamente da fatora√ß√£o de polin√¥mios em suas ra√≠zes.

**Prova do Lema 1:**
I. Seja $P(z)$ um polin√¥mio de grau $q$ dado por $P(z) = 1 + a_1 z + \dots + a_q z^q$.

II. Sejam $z_1, \dots, z_q$ as ra√≠zes de $P(z)$. Ent√£o, $P(z)$ pode ser fatorado como $P(z) = c(1 - z/z_1)(1 - z/z_2)\dots(1 - z/z_q)$, onde $c$ √© uma constante.

III. Para determinar a constante $c$, note que o termo constante de $P(z)$ √© 1. Quando expandimos o produto $\prod_{i=1}^q (1 - z/z_i)$, o termo constante √© 1. Assim, $c = 1$.

IV. Portanto, $P(z) = \prod_{i=1}^q (1 - z/z_i)$. ‚ñ†

**Teorema 2:** *Seja $Y_t = (1 + \theta_1 L + \dots + \theta_q L^q)\epsilon_t$ um processo MA(q) com ra√≠zes $z_1, \dots, z_q$.  Se alguma raiz $z_i$ tem $|z_i| < 1$, ent√£o o processo n√£o √© invert√≠vel.  A representa√ß√£o invert√≠vel correspondente √© obtida substituindo $z_i$ por $1/z_i$ para cada raiz dentro do c√≠rculo unit√°rio.*

**Demonstra√ß√£o:** Seja $\Theta(L) = 1 + \theta_1 L + \dots + \theta_q L^q$.  Pelo Lema 1, $\Theta(L) = \prod_{i=1}^q (1 - L/z_i)$. Se $|z_i| < 1$, ent√£o a raiz $z_i$ est√° dentro do c√≠rculo unit√°rio, e o processo n√£o √© invert√≠vel. Para obter a representa√ß√£o invert√≠vel, substitu√≠mos $z_i$ por $1/z_i$ sempre que $|z_i| < 1$.  Note que $|1/z_i| > 1$, garantindo que todas as ra√≠zes da nova representa√ß√£o estejam fora do c√≠rculo unit√°rio. A nova representa√ß√£o √© dada por $\Theta^*(L) = \prod_{i=1}^q (1 - L/z_i^*)$, onde $z_i^* = 1/z_i$ se $|z_i| < 1$ e $z_i^* = z_i$ caso contr√°rio.

**Prova Detalhada do Teorema 2:**
I. Considere o processo MA(q): $Y_t = \Theta(L) \epsilon_t$, onde $\Theta(L) = 1 + \theta_1 L + \dots + \theta_q L^q$.

II. Seja $z_1, \dots, z_q$ as ra√≠zes do polin√¥mio $\Theta(z) = 1 + \theta_1 z + \dots + \theta_q z^q$. Pelo Lema 1, podemos escrever $\Theta(L) = \prod_{i=1}^q (1 - L/z_i)$.

III. Se alguma raiz $z_i$ satisfaz $|z_i| < 1$, ent√£o o processo n√£o √© invert√≠vel. Isso ocorre porque a condi√ß√£o de invertibilidade exige que todas as ra√≠zes estejam fora do c√≠rculo unit√°rio.

IV. Para obter a representa√ß√£o invert√≠vel, definimos novas ra√≠zes $z_i^*$ da seguinte forma:
   $$
   z_i^* = \begin{cases}
   1/z_i & \text{se } |z_i| < 1 \\
   z_i & \text{se } |z_i| \geq 1
   \end{cases}
   $$

V. Seja $\Theta^*(L) = \prod_{i=1}^q (1 - L/z_i^*)$. Constru√≠mos um novo processo MA(q) usando $\Theta^*(L)$: $Y_t^* = \Theta^*(L) \epsilon_t$.

VI. Mostraremos que este novo processo √© invert√≠vel. Se $|z_i| < 1$, ent√£o $|z_i^*| = |1/z_i| > 1$. Se $|z_i| \geq 1$, ent√£o $|z_i^*| = |z_i| \geq 1$. Assim, todas as ra√≠zes de $\Theta^*(z)$ est√£o fora ou na borda do c√≠rculo unit√°rio.  Se alguma raiz estiver na borda, ent√£o o processo n√£o √© unicamente invert√≠vel.

VII. Portanto, o processo $Y_t^* = \Theta^*(L) \epsilon_t$ √© a representa√ß√£o invert√≠vel correspondente ao processo original $Y_t = \Theta(L) \epsilon_t$. ‚ñ†

**Representa√ß√£o N√£o Invert√≠vel:**
Um processo MA(q) n√£o invert√≠vel pode ser expresso como [^68]:

$$Y_t = \mu + \left[ \prod_{i=1}^{n} (1 - \lambda_i L) \right] \left[ \prod_{i=n+1}^{q} (1 - \lambda_i L) \right] \epsilon_t,$$

onde $|\lambda_i| < 1$ para $i = 1, 2, \dots, n$ e $|\lambda_i| > 1$ para $i = n+1, n+2, \dots, q$.

**Representa√ß√£o Invert√≠vel:**
A correspondente representa√ß√£o invert√≠vel √© [^68]:

$$Y_t = \mu + \left[ \prod_{i=1}^{n} (1 - \lambda_i L) \right] \left[ \prod_{i=n+1}^{q} (1 - \lambda_i^{-1} L) \right] \epsilon_t,$$

Para complementar o que foi exposto, vejamos um exemplo pr√°tico de como transformar uma representa√ß√£o n√£o invert√≠vel em uma invert√≠vel.

**Exemplo:**
Considere o processo MA(2) dado por $Y_t = \epsilon_t + 0.5\epsilon_{t-1} + 0.25\epsilon_{t-2}$. O polin√¥mio associado √© $1 + 0.5z + 0.25z^2 = 0$. As ra√≠zes s√£o $z_1 = -1 + i$ e $z_2 = -1 - i$. Calculando o m√≥dulo, $|z_1| = |z_2| = \sqrt{(-1)^2 + 1^2} = \sqrt{2} > 1$. Portanto, o processo j√° √© invert√≠vel.

Agora, considere o processo MA(1) dado por $Y_t = \epsilon_t + 2\epsilon_{t-1}$. O polin√¥mio associado √© $1 + 2z = 0$, cuja raiz √© $z = -0.5$. Como $|z| = 0.5 < 1$, o processo n√£o √© invert√≠vel. Para encontrar a representa√ß√£o invert√≠vel, substitu√≠mos $z$ por $1/z = -2$. Portanto, a representa√ß√£o invert√≠vel √© $Y_t = \epsilon_t + 0.5\epsilon_{t-1}$. Observe que $|\theta|=0.5<1$, satisfazendo a condi√ß√£o de invertibilidade para MA(1).

> üí° **Exemplo Num√©rico:**
> Seja $Y_t = \epsilon_t + 1.5\epsilon_{t-1}$. Aqui, $\theta = 1.5$, ent√£o a raiz √© $z = -\frac{1}{1.5} = -0.6667$. Como $|z| < 1$, n√£o √© invert√≠vel.
> Para torn√°-lo invert√≠vel, usamos $\theta^* = \frac{1}{\theta} = \frac{1}{1.5} = 0.6667$. Ent√£o, a representa√ß√£o invert√≠vel √© $Y_t = \epsilon_t + 0.6667\epsilon_{t-1}$. A raiz agora √© $z = -\frac{1}{0.6667} = -1.5$, e $|z| > 1$.

**Fun√ß√£o Autocovari√¢ncia e Invertibilidade:**

A fun√ß√£o de autocovari√¢ncia √© invariante sob transforma√ß√£o da representa√ß√£o n√£o invert√≠vel para a invert√≠vel, ou seja, ambas representa√ß√µes geram a mesma estrutura de autocorrela√ß√£o para a s√©rie temporal [^65].

**Proposi√ß√£o 1:** *Se $Y_t = (1 + \theta L)\epsilon_t$ √© um processo MA(1), ent√£o as fun√ß√µes de autocovari√¢ncia de $Y_t = (1 + \theta L)\epsilon_t$ e $Y_t = (1 + \frac{1}{\theta} L)\epsilon_t$ s√£o id√™nticas.*

**Demonstra√ß√£o:** Para o processo $Y_t = (1 + \theta L)\epsilon_t$, temos:
$\gamma_0 = Var(Y_t) = (1 + \theta^2)\sigma^2$
$\gamma_1 = Cov(Y_t, Y_{t-1}) = \theta \sigma^2$
$\gamma_k = 0$ para $k > 1$.

Para o processo $Y_t = (1 + \frac{1}{\theta} L)\epsilon_t$, temos:
$\gamma_0^* = Var(Y_t) = (1 + (\frac{1}{\theta})^2)\sigma^2 = (\frac{\theta^2 + 1}{\theta^2})\sigma^2$
$\gamma_1^* = Cov(Y_t, Y_{t-1}) = \frac{1}{\theta} \sigma^2$
$\gamma_k^* = 0$ para $k > 1$.

As fun√ß√µes de autocorrela√ß√£o s√£o dadas por $\rho_k = \frac{\gamma_k}{\gamma_0}$.
Para o primeiro processo, $\rho_1 = \frac{\theta}{1 + \theta^2}$.
Para o segundo processo, $\rho_1^* = \frac{\frac{1}{\theta}}{\frac{1 + \theta^2}{\theta^2}} = \frac{\theta}{1 + \theta^2}$.

Portanto, $\rho_1 = \rho_1^*$, mostrando que os processos t√™m a mesma estrutura de autocorrela√ß√£o. Note, entretanto, que as autocovari√¢ncias s√£o diferentes, apenas as autocorrela√ß√µes s√£o iguais.

**Prova Detalhada da Proposi√ß√£o 1:**

I.  Considere o processo MA(1): $Y_t = (1 + \theta L) \epsilon_t = \epsilon_t + \theta \epsilon_{t-1}$, onde $\epsilon_t$ √© um ru√≠do branco com m√©dia zero e vari√¢ncia $\sigma^2$.
II. Calcule a autocovari√¢ncia $\gamma_0 = Cov(Y_t, Y_t) = E[(Y_t - E[Y_t])(Y_t - E[Y_t])]$
   $E[Y_t] = E[\epsilon_t + \theta \epsilon_{t-1}] = E[\epsilon_t] + \theta E[\epsilon_{t-1}] = 0$.
   $\gamma_0 = E[(\epsilon_t + \theta \epsilon_{t-1})^2] = E[\epsilon_t^2 + 2\theta \epsilon_t \epsilon_{t-1} + \theta^2 \epsilon_{t-1}^2] = E[\epsilon_t^2] + 2\theta E[\epsilon_t \epsilon_{t-1}] + \theta^2 E[\epsilon_{t-1}^2] = \sigma^2 + 0 + \theta^2 \sigma^2 = (1 + \theta^2)\sigma^2$.
III. Calcule a autocovari√¢ncia $\gamma_1 = Cov(Y_t, Y_{t-1}) = E[(Y_t - E[Y_t])(Y_{t-1} - E[Y_{t-1}])]$
    $\gamma_1 = E[(\epsilon_t + \theta \epsilon_{t-1})(\epsilon_{t-1} + \theta \epsilon_{t-2})] = E[\epsilon_t \epsilon_{t-1} + \theta \epsilon_{t-1}^2 + \theta \epsilon_t \epsilon_{t-2} + \theta^2 \epsilon_{t-1} \epsilon_{t-2}] = 0 + \theta \sigma^2 + 0 + 0 = \theta \sigma^2$.
IV. Calcule a autocovari√¢ncia $\gamma_k = Cov(Y_t, Y_{t-k})$ para $k > 1$. Como $Y_t$ depende apenas de $\epsilon_t$ e $\epsilon_{t-1}$, $\gamma_k = 0$ para $k > 1$.
V. Agora, considere o processo "invertido" MA(1): $Y_t^* = (1 + \frac{1}{\theta} L) \epsilon_t = \epsilon_t + \frac{1}{\theta} \epsilon_{t-1}$.
VI. Calcule a autocovari√¢ncia $\gamma_0^* = Cov(Y_t^*, Y_t^*) = E[(Y_t^* - E[Y_t^*])(Y_t^* - E[Y_t^*])]$
    $E[Y_t^*] = E[\epsilon_t + \frac{1}{\theta} \epsilon_{t-1}] = 0$.
    $\gamma_0^* = E[(\epsilon_t + \frac{1}{\theta} \epsilon_{t-1})^2] = E[\epsilon_t^2 + 2\frac{1}{\theta} \epsilon_t \epsilon_{t-1} + \frac{1}{\theta^2} \epsilon_{t-1}^2] = \sigma^2 + 0 + \frac{1}{\theta^2} \sigma^2 = (1 + \frac{1}{\theta^2})\sigma^2 = (\frac{\theta^2 + 1}{\theta^2})\sigma^2$.
VII. Calcule a autocovari√¢ncia $\gamma_1^* = Cov(Y_t^*, Y_{t-1}^*) = E[(Y_t^* - E[Y_t^*])(Y_{t-1}^* - E[Y_{t-1}^*])]$
    $\gamma_1^* = E[(\epsilon_t + \frac{1}{\theta} \epsilon_{t-1})(\epsilon_{t-1} + \frac{1}{\theta} \epsilon_{t-2})] = E[\epsilon_t \epsilon_{t-1} + \frac{1}{\theta} \epsilon_{t-1}^2 + \frac{1}{\theta} \epsilon_t \epsilon_{t-2} + \frac{1}{\theta^2} \epsilon_{t-1} \epsilon_{t-2}] = 0 + \frac{1}{\theta} \sigma^2 + 0 + 0 = \frac{1}{\theta} \sigma^2$.
VIII. Calcule a autocovari√¢ncia $\gamma_k^* = Cov(Y_t^*, Y_{t-k}^*)$ para $k > 1$. Como $Y_t^*$ depende apenas de $\epsilon_t$ e $\epsilon_{t-1}$, $\gamma_k^* = 0$ para $k > 1$.
IX. Calcule as autocorrela√ß√µes $\rho_1 = \frac{\gamma_1}{\gamma_0} = \frac{\theta \sigma^2}{(1 + \theta^2)\sigma^2} = \frac{\theta}{1 + \theta^2}$ e $\rho_1^* = \frac{\gamma_1^*}{\gamma_0^*} = \frac{\frac{1}{\theta} \sigma^2}{(\frac{\theta^2 + 1}{\theta^2})\sigma^2} = \frac{\frac{1}{\theta}}{\frac{\theta^2 + 1}{\theta^2}} = \frac{\theta}{1 + \theta^2}$.
X. Portanto, $\rho_1 = \rho_1^*$, demonstrando que as fun√ß√µes de autocorrela√ß√£o dos processos $Y_t$ e $Y_t^*$ s√£o id√™nticas. ‚ñ†

**Observa√ß√£o:** A proposi√ß√£o acima demonstra explicitamente que, embora as fun√ß√µes de autocovari√¢ncia n√£o sejam id√™nticas, as fun√ß√µes de autocorrela√ß√£o de um processo MA(1) e sua vers√£o "invertida" s√£o as mesmas. Essa propriedade √© fundamental para entender porque a invertibilidade √© importante: ela permite identificar uma representa√ß√£o √∫nica para o processo, j√° que infinitas representa√ß√µes n√£o invert√≠veis geram a mesma estrutura de autocorrela√ß√£o.

> üí° **Exemplo Num√©rico:**
> Seja $\theta = 0.5$. Ent√£o, o processo √© $Y_t = \epsilon_t + 0.5\epsilon_{t-1}$.
>
> $\gamma_0 = (1 + 0.5^2)\sigma^2 = 1.25\sigma^2$
> $\gamma_1 = 0.5\sigma^2$
> $\rho_1 = \frac{0.5}{1.25} = 0.4$
>
> A representa√ß√£o "invertida" √© $Y_t = \epsilon_t + 2\epsilon_{t-1}$.
>
> $\gamma_0^* = (1 + 2^2)\sigma^2 = 5\sigma^2$
> $\gamma_1^* = 2\sigma^2$
> $\rho_1^* = \frac{2}{5} = 0.4$
>
> As autocorrela√ß√µes s√£o as mesmas, embora as autocovari√¢ncias sejam diferentes.

### Conclus√£o

A invertibilidade √© uma propriedade essencial para a an√°lise e modelagem de processos *moving average*. Garante a unicidade da representa√ß√£o, permitindo a express√£o do processo como um AR($\infty$), o que facilita a deriva√ß√£o de previs√µes e a interpreta√ß√£o do modelo. Embora representa√ß√µes n√£o invert√≠veis possam gerar a mesma estrutura de autocovari√¢ncia, a representa√ß√£o invert√≠vel √© prefer√≠vel devido √†s suas propriedades anal√≠ticas e √† possibilidade de estima√ß√£o consistente dos par√¢metros [^67]. A an√°lise da invertibilidade e a transforma√ß√£o para uma representa√ß√£o invert√≠vel s√£o passos cruciais na modelagem de s√©ries temporais utilizando processos MA(q).
### Refer√™ncias
[^50]: A defini√ß√£o do processo MA(q) √© dada na p√°gina 50.
[^60]: Discuss√£o sobre a potencial redund√¢ncia de par√¢metros em processos ARMA na p√°gina 60.
[^65]: Explica√ß√£o sobre a mesma fun√ß√£o autocovari√¢ncia para representa√ß√µes invert√≠veis e n√£o invert√≠veis, p√°gina 65.
[^67]: A invertibilidade permite escrever o MA(q) como um AR(‚àû) (p√°gina 67).
[^68]: As equa√ß√µes para representa√ß√µes invert√≠veis e n√£o invert√≠veis s√£o mencionadas nas p√°ginas 67 e 68.
<!-- END -->