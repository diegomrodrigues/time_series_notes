## Autocorrelação em Processos Estacionários: Uma Análise Detalhada

### Introdução
Este capítulo aprofunda a análise da **autocorrelação** em processos estocásticos estacionários, um conceito fundamental para a compreensão das dependências temporais em séries temporais. Como vimos anteriormente [^3.1.9], a **variância** de uma variável aleatória $Y_t$, denotada por $\gamma_0$, é um caso especial de **autocovariância**, onde o *lag* é zero. A **autocovariância** $\gamma_j$ quantifica a relação linear entre as observações $Y_t$ e $Y_{t-j}$, e a **autocorrelação** $\rho_j$ é a normalização dessa medida pela variância, fornecendo uma escala comparável e limitada entre -1 e 1. Em continuidade ao estudo das propriedades de processos estocásticos, exploraremos em detalhe como a autocorrelação se manifesta em diferentes modelos, como o **MA(1)**, e sua importância na análise e modelagem de séries temporais.

### Conceitos Fundamentais
A **autocorrelação** $\rho_j$ de um processo estacionário é formalmente definida como a razão entre a **autocovariância** $\gamma_j$ e a **variância** $\gamma_0$ [^3.3.6]:
$$ \rho_j = \frac{\gamma_j}{\gamma_0} $$
onde $\gamma_j = E[(Y_t - \mu)(Y_{t-j} - \mu)]$ [^3.1.12] e $\gamma_0 = E[(Y_t - \mu)^2]$ [^3.1.9] . A **autocovariância** $\gamma_j$ mede a relação linear entre as observações da série temporal $Y_t$ e as observações defasadas $Y_{t-j}$.

**Propriedades da Autocorrelação**
*   A autocorrelação é uma medida normalizada, variando entre -1 e 1, devido à desigualdade de Cauchy-Schwarz [^3.3.6], ou seja, $|\rho_j| \le 1$.
*   A autocorrelação para *lag* zero, $\rho_0$, é sempre igual a 1, pois $\rho_0 = \frac{\gamma_0}{\gamma_0} = 1$ [^3.3.6].
*   Para um processo estacionário, a autocorrelação $\rho_j$ depende apenas do *lag* $j$ e não do tempo $t$ [^3.1.12].
*  A autocorrelação entre $Y_t$ e $Y_{t-j}$ é igual à autocorrelação entre $Y_t$ e $Y_{t+j}$, ou seja, $\rho_j = \rho_{-j}$ [^3.1.13].

A **autocorrelação** fornece informações cruciais sobre a dependência temporal de uma série temporal. Valores positivos de $\rho_j$ indicam que observações separadas por $j$ períodos tendem a ter o mesmo sinal (ambas acima ou abaixo da média), enquanto valores negativos indicam que elas tendem a ter sinais opostos.

**Autocorrelação em um Processo MA(1)**

No contexto de um processo **MA(1)** [^3.3.1] definido como:
$$ Y_t = \mu + \epsilon_t + \theta \epsilon_{t-1} $$
onde $\{\epsilon_t\}$ é um processo de ruído branco, a autocorrelação de primeira ordem ($\rho_1$) é dada por [^3.3.7]:
$$ \rho_1 = \frac{\theta}{1+\theta^2} $$
Todas as outras autocorrelações ($\rho_j$ para $j>1$) são zero, visto que $\text{E}[(Y_t - \mu)(Y_{t-j} - \mu)] = 0$ para $j>1$ [^3.3.5]. Este resultado indica que em um processo **MA(1)**, a dependência temporal está limitada ao *lag* 1.

A análise da autocorrelação nos permite entender como diferentes especificações de $\theta$ afetam o padrão de dependência temporal da série. Valores positivos de $\theta$ induzem uma autocorrelação positiva, onde valores acima da média tendem a ser seguidos por valores também acima da média, enquanto valores negativos de $\theta$ induzem uma autocorrelação negativa, com valores acima da média tendendo a serem seguidos por valores abaixo da média [^3.3.7].

**Autocorrelação em Ruído Branco**

Em contraste, para um processo de **ruído branco**, as autocorrelações são nulas para todos os *lags* diferentes de zero, ou seja, $\rho_j = 0$ para $j \ne 0$, e $\rho_0 = 1$ [^3.3.6]. Isso reflete a ausência de dependência temporal nesse tipo de processo [^3.3.6].

### Conclusão
A **autocorrelação** $\rho_j$ é uma ferramenta indispensável na análise de séries temporais, quantificando a dependência linear entre observações defasadas por $j$ períodos. Sua normalização permite comparar a intensidade dessas dependências em diferentes séries, enquanto suas propriedades como $|\rho_j| \leq 1$ e $\rho_0 = 1$ fornecem um ponto de referência para a análise. Através da análise de processos como o **MA(1)** e ruído branco, compreendemos que a autocorrelação é uma medida crucial para entender e modelar a estrutura temporal das séries temporais.

### Referências
[^3.1.9]: *The variance of the random variable Yt (denoted you) is similarly defined as  γot = E(Yt - μt)² = ∫₋∞∞(yt − μt)² fYt(yt) dyt.*
[^3.1.12]: *If the process is covariance-stationary, the covariance between Yt and Yt-j depends only on j, the length of time separating the observations, and not on t, the date of the observation. It follows that for a covariance-stationary process, γj and γ-j would represent the same magnitude. To see this, recall the definition  γj = E(Yt − μ)(Yt−j − μ).*
[^3.1.13]: *Thus, for any covariance-stationary process, γj = γ−j  for all integers j.*
[^3.3.1]: *Let {εt} be white noise as in [3.2.1] through [3.2.3], and consider the process  Yt = μ + εt + θεt−1*
[^3.3.5]: *Higher autocovariances are all zero:  E(Yt − μ)(Yt−j − μ) = E(εt + θεt−1)(εt−j + θεt−j−1) = 0 for j > 1.*
[^3.3.6]: *The jth autocorrelation of a covariance-stationary process (denoted ρj) is defined as its jth autocovariance divided by the variance: ρj = γj/γ0  Again the terminology arises from the fact that ρj is the correlation between Yt and Yt-j: Corr(Yt, Yt−j) = Cov(Yt, Yt−j) / √Var(Yt)Var(Yt−j) = γj / √γ0 √γ0 = ρj  Since ρj is a correlation, |ρj| ≤ 1 for all j, by the Cauchy-Schwarz inequality. Notice also that the Oth autocorrelation ρ0 is equal to unity for any covariance-stationary process by definition.*
[^3.3.7]: *From [3.3.3] and [3.3.4], the first autocorrelation for an MA(1) process is given by  ρ1 = θσ² / (1+θ²)σ² = θ / (1+θ²)  Higher autocorrelations are all zero.*
<!-- END -->
