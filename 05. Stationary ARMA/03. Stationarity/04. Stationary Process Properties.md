## Rela√ß√£o entre Estacionaridade Estrita e Covari√¢ncia-Estacionaridade

### Introdu√ß√£o
Este cap√≠tulo explora a interconex√£o entre dois conceitos cruciais na an√°lise de s√©ries temporais: a **estacionaridade estrita** e a **covari√¢ncia-estacionaridade**. Como vimos anteriormente [^3], [^DIRECTORY_PLACEHOLDER], [^SECTION_PLACEHOLDER], um processo estoc√°stico pode exibir diferentes graus de estacionaridade, cada um impondo diferentes restri√ß√µes sobre as propriedades estat√≠sticas do processo ao longo do tempo. Aqui, nos aprofundaremos na rela√ß√£o hier√°rquica entre a estacionaridade estrita e a covari√¢ncia-estacionaridade, demonstrando que a estacionaridade estrita, combinada com a exist√™ncia de momentos de segunda ordem finitos, implica a covari√¢ncia-estacionaridade, mas o inverso nem sempre √© verdadeiro.

### Conceitos Fundamentais
Para recapitular, um processo estoc√°stico $\{Y_t\}$ √© dito ser **estritamente estacion√°rio** se a distribui√ß√£o conjunta de qualquer conjunto de vari√°veis aleat√≥rias $(Y_{t_1}, Y_{t_2}, ..., Y_{t_n})$ √© invariante a transla√ß√µes no tempo [^3], [^DIRECTORY_PLACEHOLDER], [^SECTION_PLACEHOLDER]. Formalmente, para qualquer $t, h, j_1, ..., j_n$:

$$F(Y_t, Y_{t+j_1}, \ldots, Y_{t+j_n}) = F(Y_{t+h}, Y_{t+j_1+h}, \ldots, Y_{t+j_n+h})$$

Por outro lado, um processo $\{Y_t\}$ √© **covari√¢ncia-estacion√°rio** (ou fracamente estacion√°rio) se sua m√©dia $E[Y_t] = \mu$ √© constante para todo $t$, e sua autocovari√¢ncia $E[(Y_t - \mu)(Y_{t-j} - \mu)] = \gamma_j$ depende apenas da defasagem $j$ e n√£o do tempo $t$ [^3], [^DIRECTORY_PLACEHOLDER], [^SECTION_PLACEHOLDER].

> üí° **Exemplo Num√©rico:** Considere uma s√©rie temporal de temperaturas di√°rias coletadas ao longo de v√°rios anos em uma cidade. Se a m√©dia da temperatura di√°ria permanece constante ao longo do tempo (por exemplo, a m√©dia da temperatura em janeiro √© consistentemente 5¬∞C a cada ano) e a autocovari√¢ncia entre as temperaturas em dias consecutivos (defasagem de 1) tamb√©m permanece constante ao longo do tempo, ent√£o a s√©rie temporal √© covari√¢ncia-estacion√°ria.

**Teorema Principal:** Se um processo √© estritamente estacion√°rio e possui momentos de segunda ordem finitos, ent√£o ele deve ser covari√¢ncia-estacion√°rio; entretanto, o inverso n√£o √© necessariamente verdadeiro.

**Prova:**
A prova consiste em duas partes:

1.  *Estacionaridade Estrita Implica M√©dia Constante:*

    Seja $\{Y_t\}$ um processo estritamente estacion√°rio com $E[Y_t] = \mu_t$. Como o processo √© estritamente estacion√°rio, a distribui√ß√£o de $Y_t$ √© a mesma para todo $t$. Portanto, a m√©dia $E[Y_t]$ √© a mesma para todo $t$. Assim, $\mu_t = \mu$, onde $\mu$ √© uma constante.

    Prova formal:

    I. Seja $\{Y_t\}$ um processo estritamente estacion√°rio.
    II. Pela defini√ß√£o de estacionaridade estrita, a distribui√ß√£o de $Y_t$ √© a mesma para todos os valores de $t$.
    III. Portanto, $E[Y_t] = E[Y_{t+h}]$ para todo $t$ e $h$.
    IV. Se definirmos $E[Y_t] = \mu_t$, ent√£o $\mu_t = \mu_{t+h}$ para todo $t$ e $h$.
    V. Isso implica que $\mu_t$ √© constante com rela√ß√£o a $t$, ou seja, $\mu_t = \mu$ para alguma constante $\mu$.
    Portanto, a estacionaridade estrita implica que a m√©dia √© constante. ‚ñ†

    > üí° **Exemplo Num√©rico:** Suponha que simulamos uma s√©rie temporal $\{Y_t\}$ de 1000 pontos a partir de uma distribui√ß√£o normal com m√©dia 5 e desvio padr√£o 2. Se a s√©rie √© estritamente estacion√°ria, ent√£o a m√©dia amostral calculada a partir de qualquer subconjunto da s√©rie temporal (por exemplo, os primeiros 500 pontos ou os √∫ltimos 500 pontos) deve ser aproximadamente igual √† m√©dia te√≥rica de 5.
    ```python
    import numpy as np
    import matplotlib.pyplot as plt

    # Gerar dados aleat√≥rios de uma distribui√ß√£o normal
    np.random.seed(42)  # Define a semente para reproducibilidade
    mu = 5
    sigma = 2
    n = 1000
    Y = np.random.normal(mu, sigma, n)

    # Calcular a m√©dia amostral
    media_amostral = np.mean(Y)

    # Calcular a m√©dia amostral dos primeiros 500 pontos
    media_amostral_primeiros_500 = np.mean(Y[:500])

    # Calcular a m√©dia amostral dos √∫ltimos 500 pontos
    media_amostral_ultimos_500 = np.mean(Y[500:])

    print(f"M√©dia te√≥rica: {mu}")
    print(f"M√©dia amostral: {media_amostral:.2f}")
    print(f"M√©dia amostral (primeiros 500): {media_amostral_primeiros_500:.2f}")
    print(f"M√©dia amostral (√∫ltimos 500): {media_amostral_ultimos_500:.2f}")

    plt.figure(figsize=(10, 6))
    plt.plot(Y)
    plt.axhline(mu, color='r', linestyle='--', label=f'M√©dia Te√≥rica ({mu})')
    plt.axhline(media_amostral, color='g', linestyle='-', label=f'M√©dia Amostral ({media_amostral:.2f})')
    plt.title("S√©rie Temporal Estritamente Estacion√°ria (Normal)")
    plt.xlabel("Tempo")
    plt.ylabel("Valor")
    plt.legend()
    plt.grid(True)
    plt.show()
    ```

2.  *Estacionaridade Estrita Implica Autocovari√¢ncia Dependente Apenas da Defasagem:*

    Considere a autocovari√¢ncia entre $Y_t$ e $Y_{t-j}$:
    $$\gamma_{t,j} = E[(Y_t - \mu)(Y_{t-j} - \mu)]$$
    Como o processo √© estritamente estacion√°rio, a distribui√ß√£o conjunta de $(Y_t, Y_{t-j})$ √© a mesma para todo $t$. Portanto, a autocovari√¢ncia $E[(Y_t - \mu)(Y_{t-j} - \mu)]$ depende apenas da defasagem $j$ e n√£o de $t$. Assim, $\gamma_{t,j} = \gamma_j$, onde $\gamma_j$ √© uma fun√ß√£o apenas de $j$.

    Prova formal:
    I. Seja $\{Y_t\}$ um processo estritamente estacion√°rio com m√©dia constante $\mu$.
    II. A autocovari√¢ncia entre $Y_t$ e $Y_{t-j}$ √© definida como $\gamma_{t,j} = E[(Y_t - \mu)(Y_{t-j} - \mu)]$.
    III. Pela defini√ß√£o de estacionaridade estrita, a distribui√ß√£o conjunta de $(Y_t, Y_{t-j})$ √© a mesma que a distribui√ß√£o conjunta de $(Y_{t+h}, Y_{t+h-j})$ para qualquer $h$.
    IV. Portanto, $E[g(Y_t, Y_{t-j})] = E[g(Y_{t+h}, Y_{t+h-j})]$ para qualquer fun√ß√£o $g$.
    V. Seja $g(Y_t, Y_{t-j}) = (Y_t - \mu)(Y_{t-j} - \mu)$. Ent√£o,
    $E[(Y_t - \mu)(Y_{t-j} - \mu)] = E[(Y_{t+h} - \mu)(Y_{t+h-j} - \mu)]$.
    VI. Escolhendo $h = -t$, obtemos $E[(Y_t - \mu)(Y_{t-j} - \mu)] = E[(Y_{0} - \mu)(Y_{-j} - \mu)]$, que √© uma fun√ß√£o apenas de $j$.
    VII. Portanto, $\gamma_{t,j} = \gamma_j$, onde $\gamma_j$ depende apenas da defasagem $j$.
    Assim, a estacionaridade estrita implica que a autocovari√¢ncia depende apenas da defasagem. ‚ñ†

    > üí° **Exemplo Num√©rico:** Considere uma s√©rie temporal estritamente estacion√°ria com m√©dia 0. Calculamos a autocovari√¢ncia para uma defasagem de 1 (j=1) nos primeiros 500 pontos e depois nos √∫ltimos 500 pontos. Se o processo for estritamente estacion√°rio, essas duas autocovari√¢ncias devem ser aproximadamente iguais.
    ```python
    import numpy as np
    import matplotlib.pyplot as plt

    # Gerar dados aleat√≥rios de uma distribui√ß√£o normal
    np.random.seed(42)  # Define a semente para reproducibilidade
    mu = 0
    sigma = 1
    n = 1000
    Y = np.random.normal(mu, sigma, n)

    # Calcular a autocovari√¢ncia para defasagem 1 nos primeiros 500 pontos
    def autocovariance(x, lag):
        n = len(x)
        x_mean = np.mean(x)
        sum_term = np.sum((x[:n-lag] - x_mean) * (x[lag:] - x_mean))
        return sum_term / n

    autocov_primeiros_500 = autocovariance(Y[:500], 1)

    # Calcular a autocovari√¢ncia para defasagem 1 nos √∫ltimos 500 pontos
    autocov_ultimos_500 = autocovariance(Y[500:], 1)

    print(f"Autocovari√¢ncia (primeiros 500, lag=1): {autocov_primeiros_500:.2f}")
    print(f"Autocovari√¢ncia (√∫ltimos 500, lag=1): {autocov_ultimos_500:.2f}")

    # Plotting the series
    plt.figure(figsize=(10, 6))
    plt.plot(Y)
    plt.title("S√©rie Temporal Estritamente Estacion√°ria (Normal) - Autocovari√¢ncia")
    plt.xlabel("Tempo")
    plt.ylabel("Valor")
    plt.grid(True)
    plt.show()
    ```

Portanto, se $\{Y_t\}$ √© estritamente estacion√°rio e tem momentos de segunda ordem finitos, ent√£o ele √© tamb√©m covari√¢ncia-estacion√°rio.

Agora, vamos mostrar que o inverso n√£o √© sempre verdadeiro. Ou seja, um processo pode ser covari√¢ncia-estacion√°rio sem ser estritamente estacion√°rio.

Para isso, considere um processo $\{Y_t\}$ onde:

*   $Y_t \sim N(0,1)$ para $t < T_0$
*   $Y_t \sim U(-\sqrt{3}, \sqrt{3})$ para $t \geq T_0$

onde $N(0,1)$ representa a distribui√ß√£o normal padr√£o e $U(-\sqrt{3}, \sqrt{3})$ representa a distribui√ß√£o uniforme no intervalo $(-\sqrt{3}, \sqrt{3})$. Note que ambas as distribui√ß√µes t√™m m√©dia 0 e vari√¢ncia 1.

Portanto, $E[Y_t] = 0$ e $Var[Y_t] = 1$ para todo $t$. Al√©m disso, se assumirmos que os $Y_t$'s s√£o independentes, ent√£o $Cov(Y_t, Y_{t-j}) = 0$ para $j \neq 0$. Assim, este processo √© covari√¢ncia-estacion√°rio.

No entanto, este processo n√£o √© estritamente estacion√°rio, pois a distribui√ß√£o de $Y_t$ muda em $t = T_0$. Especificamente, a distribui√ß√£o de $Y_t$ √© normal para $t < T_0$ e uniforme para $t \geq T_0$. Isso significa que a distribui√ß√£o conjunta de qualquer conjunto de vari√°veis $Y_{t_1}, Y_{t_2}, \ldots, Y_{t_n}$ depende de se os √≠ndices $t_1, t_2, \ldots, t_n$ s√£o todos menores que $T_0$, todos maiores ou iguais a $T_0$, ou uma mistura de ambos. Portanto, a distribui√ß√£o conjunta n√£o √© invariante a transla√ß√µes no tempo, e o processo n√£o √© estritamente estacion√°rio. $\blacksquare$

> üí° **Exemplo Num√©rico:**  Vamos simular a s√©rie temporal descrita acima com  $T_0 = 500$ e visualizar as distribui√ß√µes antes e depois de $T_0$.

```python
import numpy as np
import matplotlib.pyplot as plt
import scipy.stats as stats

# Par√¢metros
T0 = 500
n = 1000

# Gerar dados
np.random.seed(42)
Y = np.concatenate([np.random.normal(0, 1, T0), np.random.uniform(-np.sqrt(3), np.sqrt(3), n - T0)])

# Verificar m√©dia e vari√¢ncia
print(f"M√©dia da s√©rie: {np.mean(Y):.2f}")
print(f"Vari√¢ncia da s√©rie: {np.var(Y):.2f}")

# Plotar a s√©rie temporal
plt.figure(figsize=(12, 6))
plt.plot(Y)
plt.axvline(T0, color='r', linestyle='--', label='T0 = 500')
plt.title("S√©rie Temporal Covari√¢ncia-Estacion√°ria, N√£o Estritamente Estacion√°ria")
plt.xlabel("Tempo")
plt.ylabel("Valor")
plt.legend()
plt.grid(True)
plt.show()

# Plotar histogramas antes e depois de T0
plt.figure(figsize=(12, 6))
plt.hist(Y[:T0], bins=30, density=True, alpha=0.5, label='t < T0 (Normal)')
plt.hist(Y[T0:], bins=30, density=True, alpha=0.5, label='t >= T0 (Uniforme)')

# Sobrepor as fun√ß√µes de densidade de probabilidade te√≥ricas
x = np.linspace(-4, 4, 100)
plt.plot(x, stats.norm.pdf(x, 0, 1), color='blue', label='Normal(0, 1)')
x = np.linspace(-np.sqrt(3), np.sqrt(3), 100)
plt.plot(x, stats.uniform.pdf(x, -np.sqrt(3), 2*np.sqrt(3)), color='orange', label='Uniforme(-‚àö3, ‚àö3)')

plt.title("Distribui√ß√µes antes e depois de T0")
plt.xlabel("Valor")
plt.ylabel("Densidade")
plt.legend()
plt.grid(True)
plt.show()
```

**Observa√ß√£o Importante:** A exist√™ncia de momentos de segunda ordem finitos √© crucial para que a estacionaridade estrita implique a covari√¢ncia-estacionaridade. Se os momentos de segunda ordem n√£o existirem (por exemplo, para algumas distribui√ß√µes de cauda pesada), um processo estritamente estacion√°rio pode n√£o ser covari√¢ncia-estacion√°rio.

**Exemplo de um processo estritamente estacion√°rio que n√£o √© covari√¢ncia-estacion√°rio:** Considere uma sequ√™ncia de vari√°veis aleat√≥rias i.i.d. $\{X_t\}$, onde cada $X_t$ segue uma distribui√ß√£o de Cauchy centrada em 0, com fun√ß√£o de densidade de probabilidade dada por:

$$f(x) = \frac{1}{\pi(1 + x^2)}$$

A distribui√ß√£o de Cauchy √© sim√©trica em torno de 0, de modo que $E[X_t] = 0$ (no sentido de valor principal de Cauchy). No entanto, a distribui√ß√£o de Cauchy n√£o possui momentos finitos de ordem superior a 0. Em particular, a vari√¢ncia (e, portanto, o momento de segunda ordem) n√£o √© definida.

Como os $X_t$ s√£o i.i.d., a distribui√ß√£o conjunta de qualquer conjunto de $X_{t_1}, X_{t_2}, ..., X_{t_n}$ depende apenas da distribui√ß√£o marginal, e n√£o do tempo. Portanto, o processo √© estritamente estacion√°rio.

No entanto, como a vari√¢ncia n√£o existe, o processo n√£o pode ser covari√¢ncia-estacion√°rio. Portanto, este √© um exemplo de um processo estritamente estacion√°rio que n√£o √© covari√¢ncia-estacion√°rio.

> üí° **Exemplo Num√©rico:** A distribui√ß√£o de Cauchy √© sim√©trica em torno de 0, de modo que a m√©dia te√≥rica √© 0. No entanto, devido √†s caudas pesadas, as m√©dias amostrais podem variar amplamente, e a lei dos grandes n√∫meros n√£o se aplica da mesma forma que para distribui√ß√µes com momentos finitos de primeira e segunda ordem. Isso significa que, mesmo com um grande n√∫mero de amostras, a m√©dia amostral pode n√£o convergir para um valor fixo.

![Generated plot](./../images/plot_8.png)

**Processos Gaussianos: Uma Exce√ß√£o:**

Como mencionado anteriormente [^3], [^DIRECTORY_PLACEHOLDER], [^SECTION_PLACEHOLDER], para processos Gaussianos, a estacionaridade estrita e a covari√¢ncia-estacionaridade s√£o equivalentes. Isso ocorre porque a distribui√ß√£o normal multivariada √© completamente caracterizada por seu vetor de m√©dias e sua matriz de covari√¢ncia. Se a m√©dia e a matriz de covari√¢ncia s√£o constantes ao longo do tempo, ent√£o a distribui√ß√£o conjunta √© constante ao longo do tempo, e o processo √© estritamente estacion√°rio.

Para complementar a discuss√£o sobre processos Gaussianos, podemos considerar uma caracteriza√ß√£o mais geral.

**Teorema 1:** *Para processos el√≠pticos, a estacionaridade estrita implica covari√¢ncia estacion√°ria, e a covari√¢ncia estacion√°ria implica estacionaridade estrita se e somente se a fun√ß√£o caracter√≠stica √© completamente definida pelos primeiros dois momentos.*

**Prova:**

A prova segue diretamente da defini√ß√£o de processos el√≠pticos. Um processo el√≠ptico √© definido por sua m√©dia, matriz de covari√¢ncia e uma fun√ß√£o geradora. Se o processo √© estritamente estacion√°rio, ent√£o a distribui√ß√£o conjunta √© invariante ao tempo, implicando que a m√©dia e a matriz de covari√¢ncia s√£o constantes. Isso leva √† covari√¢ncia estacion√°ria. A implica√ß√£o inversa depende da fun√ß√£o geradora. Se a fun√ß√£o geradora √© completamente definida pelos dois primeiros momentos, ent√£o a covari√¢ncia estacion√°ria implica que a fun√ß√£o geradora √© constante ao longo do tempo, e portanto o processo √© estritamente estacion√°rio. $\blacksquare$

**Corol√°rio 1:** *Processos Gaussianos s√£o um caso especial de processos el√≠pticos onde a fun√ß√£o caracter√≠stica (e portanto a distribui√ß√£o) √© completamente definida pelos dois primeiros momentos, validando a equival√™ncia entre estacionaridade estrita e covari√¢ncia estacion√°ria para esses processos.*

**Import√¢ncia Pr√°tica:**

Na pr√°tica, a covari√¢ncia-estacionaridade √© uma condi√ß√£o suficiente para muitas aplica√ß√µes, especialmente quando se est√° interessado apenas em modelar a m√©dia e a autocovari√¢ncia da s√©rie temporal. No entanto, em situa√ß√µes onde se deseja modelar aspectos mais detalhados da distribui√ß√£o (por exemplo, a cauda da distribui√ß√£o para an√°lise de risco) ou onde se espera que mudan√ßas na distribui√ß√£o ao longo do tempo tenham um impacto significativo nos resultados, a estacionaridade estrita pode ser mais relevante.

Al√©m disso, √© importante notar que a verifica√ß√£o da estacionaridade estrita √©, em geral, muito mais dif√≠cil do que a verifica√ß√£o da covari√¢ncia-estacionaridade, pois requer examinar a invari√¢ncia temporal de toda a distribui√ß√£o conjunta, e n√£o apenas de seus dois primeiros momentos.

### Conclus√£o
Em resumo, a estacionaridade estrita √© uma condi√ß√£o mais forte do que a covari√¢ncia-estacionaridade. Se um processo √© estritamente estacion√°rio e possui momentos de segunda ordem finitos, ent√£o ele deve ser covari√¢ncia-estacion√°rio. No entanto, o inverso n√£o √© sempre verdadeiro. A equival√™ncia entre estacionaridade estrita e covari√¢ncia-estacionaridade se mant√©m para processos Gaussianos. A escolha entre assumir estacionaridade estrita ou covari√¢ncia-estacionaridade depende da aplica√ß√£o espec√≠fica e da disponibilidade de dados para verificar as suposi√ß√µes.

### Refer√™ncias
[^3]: Retomado dos conceitos abordados anteriormente.
[^DIRECTORY_PLACEHOLDER]: An√°lise Avan√ßada de S√©ries Temporais e Matem√°tica.
[^SECTION_PLACEHOLDER]: Estacionaridade.
<!-- END -->