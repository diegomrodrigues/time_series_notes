## Expectation of a Time Series

### Introdu√ß√£o
Este cap√≠tulo aborda em detalhes a **expectativa $E(Y_t)$** de uma s√©rie temporal, explorando sua defini√ß√£o, interpreta√ß√£o e relev√¢ncia no contexto de processos estoc√°sticos estacion√°rios e n√£o estacion√°rios. A expectativa, tamb√©m conhecida como **m√©dia incondicional** $\mu_t$, fornece uma medida central da s√©rie temporal em um determinado ponto no tempo e desempenha um papel fundamental na caracteriza√ß√£o do comportamento da s√©rie [^44].

### Conceitos Fundamentais

A **expectativa $E(Y_t)$** de uma s√©rie temporal representa o valor m√©dio da vari√°vel aleat√≥ria $Y_t$ no instante *t*, assumindo que sua distribui√ß√£o de probabilidade exista [^44]. Formalmente, a expectativa √© definida como a m√©dia da distribui√ß√£o de probabilidade da *t*-√©sima observa√ß√£o, calculada pela integra√ß√£o do produto dos valores poss√≠veis de $Y_t$ e sua fun√ß√£o de densidade de probabilidade $f_t(y_t)$ [^44]:

$$ E(Y_t) = \int_{-\infty}^{\infty} y_t f_t(y_t) dy_t $$

onde:

*   $Y_t$ representa a vari√°vel aleat√≥ria no instante *t*.
*   $f_t(y_t)$ √© a fun√ß√£o de densidade de probabilidade de $Y_t$.
*   $y_t$ representa os valores poss√≠veis da vari√°vel aleat√≥ria $Y_t$.

A expectativa $E(Y_t)$ tamb√©m √© conhecida como a **m√©dia incondicional** $\mu_t$ [^44]. √â importante notar que $\mu_t$ pode ser uma fun√ß√£o do tempo *t*, dependendo do processo estoc√°stico subjacente [^44].

> üí° **Exemplo Num√©rico:**
>
> Suponha que $Y_t$ seja uma vari√°vel aleat√≥ria que representa a temperatura di√°ria em uma cidade. Em um determinado dia *t*, a temperatura pode variar, e sua distribui√ß√£o de probabilidade $f_t(y_t)$ descreve essa varia√ß√£o. Se a distribui√ß√£o $f_t(y_t)$ for centrada em 25 graus Celsius, a expectativa $E(Y_t)$ ser√° aproximadamente 25 graus Celsius. Este valor representa a temperatura m√©dia esperada para esse dia.
>
> Para calcular isso numericamente, podemos discretizar a integral. Suponha que a temperatura possa assumir valores entre 20 e 30 graus Celsius, com incrementos de 1 grau. E suponha uma distribui√ß√£o discreta simplificada:
>
> | Temperatura (y_t) | Probabilidade (f_t(y_t)) |
> |--------------------|--------------------------|
> | 20                 | 0.05                     |
> | 21                 | 0.08                     |
> | 22                 | 0.10                     |
> | 23                 | 0.12                     |
> | 24                 | 0.15                     |
> | 25                 | 0.20                     |
> | 26                 | 0.15                     |
> | 27                 | 0.08                     |
> | 28                 | 0.05                     |
> | 29                 | 0.01                     |
> | 30                 | 0.01                     |
>
> Ent√£o, a expectativa seria calculada como:
>
> $E(Y_t) = \sum_{i=1}^{11} y_{t_i} f_t(y_{t_i})$
>
> $E(Y_t) = (20 \cdot 0.05) + (21 \cdot 0.08) + (22 \cdot 0.10) + (23 \cdot 0.12) + (24 \cdot 0.15) + (25 \cdot 0.20) + (26 \cdot 0.15) + (27 \cdot 0.08) + (28 \cdot 0.05) + (29 \cdot 0.01) + (30 \cdot 0.01) = 24.37$
>
> Neste exemplo discreto, a temperatura m√©dia esperada √© 24.37 graus Celsius.

Uma interpreta√ß√£o da expectativa $E(Y_t)$ √© como o **limite de probabilidade da m√©dia do conjunto (ensemble average)** [^44]:

$$ E(Y_t) = \text{plim}_{I \to \infty} (1/I) \sum_{i=1}^{I} Y_t^{(i)} $$

Aqui, imaginamos uma "bateria" de *I* computadores gerando sequ√™ncias ${y_t^{(1)}, y_t^{(2)}, \dots, y_t^{(I)}}$ e selecionamos a observa√ß√£o associada √† data *t* de cada sequ√™ncia [^44]. Essa m√©dia do conjunto converge em probabilidade para a expectativa $E(Y_t)$ conforme o n√∫mero de realiza√ß√µes *I* tende ao infinito [^44].

> üí° **Exemplo Num√©rico:**
>
> Considere a simula√ß√£o de um processo estoc√°stico. Suponha que tenhamos 5 computadores (*I* = 5), cada um simulando a evolu√ß√£o de um pre√ßo de a√ß√£o. No dia *t* = 10, os pre√ßos simulados pelos computadores s√£o:
>
> $Y_{10}^{(1)} = 105, Y_{10}^{(2)} = 110, Y_{10}^{(3)} = 102, Y_{10}^{(4)} = 108, Y_{10}^{(5)} = 115$
>
> A m√©dia do conjunto neste instante *t* √©:
>
> $(1/5) \sum_{i=1}^{5} Y_{10}^{(i)} = (1/5) (105 + 110 + 102 + 108 + 115) = (1/5) (540) = 108$
>
> Se aumentarmos o n√∫mero de computadores para *I* = 1000 e calcularmos a m√©dia do conjunto, esse valor se aproximar√° da expectativa te√≥rica $E(Y_{10})$. Por exemplo, se ap√≥s 1000 simula√ß√µes a m√©dia do conjunto for 107.5, podemos dizer que a expectativa $E(Y_{10})$ √© aproximadamente 107.5.
>
> ```python
> import numpy as np
>
> # Simula√ß√£o com I=5
> simulations_5 = np.array([105, 110, 102, 108, 115])
> ensemble_average_5 = np.mean(simulations_5)
> print(f"M√©dia do conjunto com I=5: {ensemble_average_5}")
>
> # Simula√ß√£o com I=1000 (valores hipot√©ticos)
> simulations_1000 = np.random.normal(loc=107.5, scale=5, size=1000) # Simula 1000 pre√ßos com m√©dia 107.5 e desvio padr√£o 5
> ensemble_average_1000 = np.mean(simulations_1000)
> print(f"M√©dia do conjunto com I=1000: {ensemble_average_1000}")
> ```

**Proposi√ß√£o 1**

Seja $Y_t$ uma s√©rie temporal. Se a fun√ß√£o de densidade de probabilidade $f_t(y_t)$ √© sim√©trica em torno de um ponto $c$ para todo $t$, ent√£o $E(Y_t) = c$, desde que a expectativa exista.

*Proof:*
Como $f_t(y_t)$ √© sim√©trica em torno de $c$, temos $f_t(c+x) = f_t(c-x)$ para todo $x$.  Ent√£o
$$E(Y_t) = \int_{-\infty}^{\infty} y_t f_t(y_t) dy_t = \int_{-\infty}^{\infty} (y_t - c + c) f_t(y_t) dy_t = \int_{-\infty}^{\infty} (y_t - c) f_t(y_t) dy_t + c \int_{-\infty}^{\infty} f_t(y_t) dy_t$$
Substituindo $x = y_t - c$, temos $y_t = x + c$, e $dy_t = dx$. Ent√£o
$$\int_{-\infty}^{\infty} x f_t(x+c) dx = \int_{-\infty}^{\infty} x f_t(c-x) dx$$
Usando a substitui√ß√£o $u = -x$, temos $x = -u$ e $dx = -du$, e os limites de integra√ß√£o se invertem:
$$\int_{\infty}^{-\infty} (-u) f_t(c+u) (-du) = - \int_{-\infty}^{\infty} u f_t(c+u) du = - \int_{-\infty}^{\infty} x f_t(x+c) dx$$
Portanto, $\int_{-\infty}^{\infty} x f_t(x+c) dx = 0$, e $E(Y_t) = c \int_{-\infty}^{\infty} f_t(y_t) dy_t = c$.

I.  Dado que $f_t(y_t)$ √© sim√©trica em torno de $c$, ent√£o $f_t(c+x) = f_t(c-x)$ para todo $x$.
II.  Podemos expressar a expectativa como: $E(Y_t) = \int_{-\infty}^{\infty} y_t f_t(y_t) dy_t$.
III. Reescrevemos $y_t$ como $(y_t - c) + c$, ent√£o: $E(Y_t) = \int_{-\infty}^{\infty} [(y_t - c) + c] f_t(y_t) dy_t$.
IV. Separamos a integral em duas partes: $E(Y_t) = \int_{-\infty}^{\infty} (y_t - c) f_t(y_t) dy_t + \int_{-\infty}^{\infty} c f_t(y_t) dy_t$.
V.  Fazemos a substitui√ß√£o $x = y_t - c$, ent√£o $y_t = x + c$ e $dy_t = dx$.
VI.  A primeira integral se torna: $\int_{-\infty}^{\infty} x f_t(x+c) dx$.
VII. Devido √† simetria, mostramos que $\int_{-\infty}^{\infty} x f_t(x+c) dx = 0$.
VIII. A segunda integral se torna: $c \int_{-\infty}^{\infty} f_t(y_t) dy_t = c \cdot 1 = c$, pois a integral da fun√ß√£o densidade de probabilidade sobre todo o seu dom√≠nio √© 1.
IX. Portanto, $E(Y_t) = 0 + c = c$. $\blacksquare$

> üí° **Exemplo Num√©rico:**
>
> Suponha que $Y_t$ siga uma distribui√ß√£o normal com m√©dia $c$ e desvio padr√£o $\sigma$, ou seja, $Y_t \sim N(c, \sigma^2)$. A fun√ß√£o de densidade de probabilidade normal √© sim√©trica em torno da m√©dia $c$. Portanto, de acordo com a proposi√ß√£o, $E(Y_t) = c$.
>
> Por exemplo, se $Y_t \sim N(10, 4)$, ent√£o $E(Y_t) = 10$. A distribui√ß√£o √© sim√©trica em torno de 10, o que significa que os valores acima e abaixo de 10 t√™m a mesma probabilidade de ocorrer.
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
> from scipy.stats import norm
>
> # Par√¢metros da distribui√ß√£o normal
> media = 10
> desvio_padrao = 2
>
> # Cria um intervalo de valores para x
> x = np.linspace(media - 4*desvio_padrao, media + 4*desvio_padrao, 100)
>
> # Calcula a fun√ß√£o de densidade de probabilidade (PDF)
> pdf = norm.pdf(x, media, desvio_padrao)
>
> # Plota a PDF
> plt.plot(x, pdf, label=f'N({media}, {desvio_padrao**2})')
> plt.xlabel('Y_t')
> plt.ylabel('Densidade de Probabilidade')
> plt.title('Distribui√ß√£o Normal Sim√©trica')
> plt.legend()
> plt.grid(True)
> plt.show()
>
> # Simula valores e calcula a m√©dia amostral
> amostra = np.random.normal(media, desvio_padrao, 1000)
> media_amostral = np.mean(amostra)
> print(f"M√©dia Amostral (aproxima√ß√£o de E(Y_t)): {media_amostral}")
> ```

**Exemplos:**

1.  Se a s√©rie temporal ${Y_t}$ representa a soma de uma constante $\mu$ e um processo de ru√≠do branco Gaussiano ${\epsilon_t}$ [^44]:

    $$Y_t = \mu + \epsilon_t$$

    ent√£o sua m√©dia √© [^44]:

    $$E(Y_t) = \mu + E(\epsilon_t) = \mu$$

    pois a expectativa do ru√≠do branco √© zero [^44].

    *Proof:*
    I. Dado que $Y_t = \mu + \epsilon_t$.
    II. Aplicamos a expectativa em ambos os lados: $E(Y_t) = E(\mu + \epsilon_t)$.
    III. Pela linearidade da expectativa: $E(Y_t) = E(\mu) + E(\epsilon_t)$.
    IV. Como $\mu$ √© uma constante, $E(\mu) = \mu$.
    V. Dado que $\epsilon_t$ √© ru√≠do branco, $E(\epsilon_t) = 0$.
    VI. Portanto, $E(Y_t) = \mu + 0 = \mu$. $\blacksquare$

    > üí° **Exemplo Num√©rico:**
    >
    > Seja $\mu = 5$ e $\epsilon_t$ um ru√≠do branco com m√©dia 0 e vari√¢ncia 1. Ent√£o, $Y_t = 5 + \epsilon_t$. A s√©rie temporal $Y_t$ flutuar√° em torno de 5.
    >
    > Para qualquer instante *t*, $E(Y_t) = E(5 + \epsilon_t) = E(5) + E(\epsilon_t) = 5 + 0 = 5$.
    >
    > ```python
    > import numpy as np
    >
    > # Par√¢metros
    > mu = 5
    > num_pontos = 100
    >
    > # Gera ru√≠do branco
    > ruido_branco = np.random.normal(0, 1, num_pontos)
    >
    > # Gera a s√©rie temporal
    > Y = mu + ruido_branco
    >
    > # Calcula a m√©dia amostral
    > media_amostral = np.mean(Y)
    >
    > print(f"M√©dia amostral de Y_t: {media_amostral}")
    > ```

2.  Se $Y_t$ representa uma tend√™ncia de tempo (time trend) mais um ru√≠do branco Gaussiano ${\epsilon_t}$ [^44]:

    $$Y_t = \beta t + \epsilon_t$$

    ent√£o sua m√©dia √© [^44]:

    $$E(Y_t) = \beta t$$

    Nesse caso, a m√©dia √© uma fun√ß√£o do tempo *t* [^44].

    *Proof:*
    I. Dado que $Y_t = \beta t + \epsilon_t$.
    II. Aplicamos a expectativa em ambos os lados: $E(Y_t) = E(\beta t + \epsilon_t)$.
    III. Pela linearidade da expectativa: $E(Y_t) = E(\beta t) + E(\epsilon_t)$.
    IV. Como $\beta$ √© uma constante e $t$ √© determin√≠stico, $E(\beta t) = \beta t$.
    V. Dado que $\epsilon_t$ √© ru√≠do branco, $E(\epsilon_t) = 0$.
    VI. Portanto, $E(Y_t) = \beta t + 0 = \beta t$. $\blacksquare$

    > üí° **Exemplo Num√©rico:**
    >
    > Seja $\beta = 0.5$ e $\epsilon_t$ um ru√≠do branco com m√©dia 0 e vari√¢ncia 1. Ent√£o, $Y_t = 0.5t + \epsilon_t$.
    >
    > Para *t* = 10, $E(Y_{10}) = 0.5 \cdot 10 = 5$.
    > Para *t* = 20, $E(Y_{20}) = 0.5 \cdot 20 = 10$.
    >
    > A m√©dia da s√©rie temporal aumenta linearmente com o tempo.
    >
    > ```python
    > import numpy as np
    > import matplotlib.pyplot as plt
    >
    > # Par√¢metros
    > beta = 0.5
    > num_pontos = 100
    > tempo = np.arange(1, num_pontos + 1)
    >
    > # Gera ru√≠do branco
    > ruido_branco = np.random.normal(0, 1, num_pontos)
    >
    > # Gera a s√©rie temporal
    > Y = beta * tempo + ruido_branco
    >
    > # Calcula a m√©dia te√≥rica
    > media_teorica = beta * tempo
    >
    > # Plota a s√©rie temporal e a m√©dia te√≥rica
    > plt.plot(tempo, Y, label='Y_t')
    > plt.plot(tempo, media_teorica, label='E(Y_t) = beta * t', color='red')
    > plt.xlabel('Tempo (t)')
    > plt.ylabel('Valor')
    > plt.title('S√©rie Temporal com Tend√™ncia')
    > plt.legend()
    > plt.grid(True)
    > plt.show()
    > ```

3. Para complementar os exemplos, considere um processo Auto-Regressivo de ordem 1 (AR(1)) dado por:
    $$Y_t = \phi Y_{t-1} + \epsilon_t$$
    onde $|\phi| < 1$ para garantir a estacionariedade, e $\epsilon_t$ √© um ru√≠do branco com m√©dia zero. Tomando a expectativa de ambos os lados da equa√ß√£o, obtemos:
    $$E(Y_t) = \phi E(Y_{t-1}) + E(\epsilon_t)$$
    Sob a condi√ß√£o de estacionariedade, $E(Y_t) = E(Y_{t-1}) = \mu$. Portanto:
    $$\mu = \phi \mu + 0$$
    $$\mu (1 - \phi) = 0$$
    Como $\phi \neq 1$, ent√£o $\mu = 0$. Assim, para um processo AR(1) estacion√°rio com ru√≠do branco de m√©dia zero, a m√©dia incondicional √© zero.

    > üí° **Exemplo Num√©rico:**
    >
    > Seja $\phi = 0.7$ e $\epsilon_t$ um ru√≠do branco com m√©dia 0 e vari√¢ncia 1. Ent√£o, $Y_t = 0.7 Y_{t-1} + \epsilon_t$.
    >
    > Para simular essa s√©rie temporal, precisamos de um valor inicial para $Y_0$. Vamos assumir $Y_0 = 0$.
    >
    > Ent√£o, $E(Y_t) = 0$ para todo *t*, pois a s√©rie √© estacion√°ria e o ru√≠do branco tem m√©dia zero.
    >
    > ```python
    > import numpy as np
    > import matplotlib.pyplot as plt
    >
    > # Par√¢metros
    > phi = 0.7
    > num_pontos = 100
    >
    > # Gera ru√≠do branco
    > ruido_branco = np.random.normal(0, 1, num_pontos)
    >
    > # Inicializa a s√©rie temporal
    > Y = np.zeros(num_pontos)
    > Y[0] = 0  # Valor inicial
    >
    > # Gera a s√©rie temporal AR(1)
    > for t in range(1, num_pontos):
    >     Y[t] = phi * Y[t-1] + ruido_branco[t]
    >
    > # Calcula a m√©dia amostral
    > media_amostral = np.mean(Y)
    >
    > print(f"M√©dia amostral de Y_t: {media_amostral}")
    >
    > # Plota a s√©rie temporal
    > plt.plot(Y, label='Y_t')
    > plt.xlabel('Tempo (t)')
    > plt.ylabel('Valor')
    > plt.title('S√©rie Temporal AR(1)')
    > plt.legend()
    > plt.grid(True)
    > plt.show()
    > ```

√â crucial observar que, enquanto a nota√ß√£o $\mu_t$ permite a generaliza√ß√£o de que a m√©dia pode variar ao longo do tempo, como demonstrado no processo com tend√™ncia temporal (time trend) [^44], em outros casos, como no processo constante mais ru√≠do branco Gaussiano, a m√©dia permanece constante e independente do tempo [^44].

**Teorema 1**
Sejam $Y_t$ e $X_t$ duas s√©ries temporais, e $a$ e $b$ constantes. Ent√£o,
$$E(aY_t + bX_t) = aE(Y_t) + bE(X_t)$$
*Proof:*
$$E(aY_t + bX_t) = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} (ay + bx) f_{Y_t, X_t}(y, x) dy dx$$
$$ = a \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} y f_{Y_t, X_t}(y, x) dy dx + b \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} x f_{Y_t, X_t}(y, x) dy dx$$
$$ = a \int_{-\infty}^{\infty} y f_{Y_t}(y) dy + b \int_{-\infty}^{\infty} x f_{X_t}(x) dx = aE(Y_t) + bE(X_t)$$

I.  Come√ßamos com a defini√ß√£o de esperan√ßa: $E(aY_t + bX_t) = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} (ay + bx) f_{Y_t, X_t}(y, x) dy dx$.
II. Pela propriedade da integral, separamos a integral dupla: $= a \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} y f_{Y_t, X_t}(y, x) dy dx + b \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} x f_{Y_t, X_t}(y, x) dy dx$.
III. Integramos sobre $x$ no primeiro termo e sobre $y$ no segundo termo: $= a \int_{-\infty}^{\infty} y f_{Y_t}(y) dy + b \int_{-\infty}^{\infty} x f_{X_t}(x) dx$.
IV. Reconhecemos as integrais como as esperan√ßas de $Y_t$ e $X_t$: $= aE(Y_t) + bE(X_t)$. $\blacksquare$

> üí° **Exemplo Num√©rico:**
>
> Sejam $Y_t$ a temperatura di√°ria em graus Celsius e $X_t$ a umidade relativa do ar. Suponha que $E(Y_t) = 25$ e $E(X_t) = 70$. Queremos calcular a expectativa de uma nova s√©rie temporal $Z_t = 2Y_t + 0.5X_t$.
>
> Usando o Teorema 1, temos:
>
> $E(Z_t) = E(2Y_t + 0.5X_t) = 2E(Y_t) + 0.5E(X_t) = 2 \cdot 25 + 0.5 \cdot 70 = 50 + 35 = 85$
>
> Portanto, $E(Z_t) = 85$.
>
> ```python
> # Dados
> EY = 25  # E(Y_t)
> EX = 70  # E(X_t)
> a = 2
> b = 0.5
>
> # Calcula E(Z_t)
> EZ = a * EY + b * EX
> print(f"E(Z_t) = {EZ}")
> ```

**Teorema 1.1**
Sejam $Y_t, X_t$ duas s√©ries temporais independentes e $g, h$ fun√ß√µes lineares. Ent√£o,
$$E[g(Y_t)h(X_t)] = E[g(Y_t)]E[h(X_t)]$$
*Proof:*
Se $Y_t$ e $X_t$ s√£o independentes, ent√£o $f_{Y_t, X_t}(y, x) = f_{Y_t}(y)f_{X_t}(x)$. Seja $g(Y_t)$ e $h(X_t)$ fun√ß√µes lineares de $Y_t$ e $X_t$ respectivamente.
$$E[g(Y_t)h(X_t)] = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} g(y)h(x) f_{Y_t, X_t}(y, x) dy dx = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} g(y)h(x) f_{Y_t}(y)f_{X_t}(x) dy dx$$
$$ = \int_{-\infty}^{\infty} g(y) f_{Y_t}(y) dy \int_{-\infty}^{\infty} h(x)f_{X_t}(x) dx = E[g(Y_t)]E[h(X_t)]$$

I.  Dado que $Y_t$ e $X_t$ s√£o independentes, suas fun√ß√µes de densidade conjunta podem ser fatoradas: $f_{Y_t, X_t}(y, x) = f_{Y_t}(y)f_{X_t}(x)$.
II. A expectativa do produto de fun√ß√µes de vari√°veis independentes √© dada por: $E[g(Y_t)h(X_t)] = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} g(y)h(x) f_{Y_t, X_t}(y, x) dy dx$.
III. Substituindo a fun√ß√£o de densidade conjunta: $E[g(Y_t)h(X_t)] = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} g(y)h(x) f_{Y_t}(y)f_{X_t}(x) dy dx$.
IV. Separamos as integrais, pois as vari√°veis s√£o independentes: $E[g(Y_t)h(X_t)] = \int_{-\infty}^{\infty} g(y) f_{Y_t}(y) dy \int_{-\infty}^{\infty} h(x)f_{X_t}(x) dx$.
V. Reconhecemos cada integral como a expectativa de uma fun√ß√£o da vari√°vel correspondente: $E[g(Y_t)h(X_t)] = E[g(Y_t)]E[h(X_t)]$. $\blacksquare$

> üí° **Exemplo Num√©rico:**
>
> Sejam $Y_t$ o retorno de uma a√ß√£o A e $X_t$ o retorno de uma a√ß√£o B. Assume que $Y_t$ e $X_t$ s√£o independentes. Seja $g(Y_t) = 1 + Y_t$ e $h(X_t) = 1 + X_t$, representando o retorno bruto de cada a√ß√£o (investimento inicial + retorno). Suponha que $E(Y_t) = 0.10$ (10%) e $E(X_t) = 0.05$ (5%).
>
> Queremos calcular a expectativa do produto dos retornos brutos: $E[(1 + Y_t)(1 + X_t)]$.
>
> Usando o Teorema 1.1, temos:
>
> $E[(1 + Y_t)(1 + X_t)] = E[1 + Y_t] \cdot E[1 + X_t] = (1 + E[Y_t]) \cdot (1 + E[X_t]) = (1 + 0.10) \cdot (1 + 0.05) = 1.10 \cdot 1.05 = 1.155$
>
> Portanto, a expectativa do produto dos retornos brutos √© 1.155, o que representa um retorno de 15.5% sobre o investimento combinado.
>
> ```python
> # Dados
> EY = 0.10
> EX = 0.05
>
> # Calcula E[(1 + Y_t)(1 + X_t)]
> EZ = (1 + EY) * (1 + EX)
> print(f"E[(1 + Y_t)(1 + X_t)] = {EZ}")
> ```

**Teorema 2**
Seja $Y_t$ uma s√©rie temporal estacion√°ria. Ent√£o $E(Y_t) = \mu$ para todo $t$, onde $\mu$ √© uma constante.
*Proof:*
Por defini√ß√£o, uma s√©rie temporal estacion√°ria tem uma distribui√ß√£o que n√£o muda com o tempo. Portanto, a fun√ß√£o de densidade de probabilidade $f_t(y_t)$ √© a mesma para todo $t$, ou seja, $f_t(y_t) = f(y)$ para alguma fun√ß√£o $f$. Ent√£o
$$E(Y_t) = \int_{-\infty}^{\infty} y_t f_t(y_t) dy_t = \int_{-\infty}^{\infty} y f(y) dy = \mu$$
onde $\mu$ √© uma constante que n√£o depende de $t$.

I.  Por defini√ß√£o, uma s√©rie temporal estacion√°ria tem uma distribui√ß√£o que n√£o muda com o tempo.
II. Isso implica que a fun√ß√£o de densidade de probabilidade $f_t(y_t)$ √© a mesma para todo $t$. Podemos denotar essa fun√ß√£o por $f(y)$.
III. A expectativa de $Y_t$ √© dada por $E(Y_t) = \int_{-\infty}^{\infty} y_t f_t(y_t) dy_t$.
IV. Substituindo $f_t(y_t)$ por $f(y)$, temos $E(Y_t) = \int_{-\infty}^{\infty} y f(y) dy$.
V.  Como a integral $\int_{-\infty}^{\infty} y f(y) dy$ n√£o depende de $t$ e representa um valor constante, podemos denot√°-la por $\mu$.
VI. Portanto, $E(Y_t) = \mu$ para todo $t$, onde $\mu$ √© uma constante. $\blacksquare$

> üí° **Exemplo Num√©rico:**
>
> Considere uma s√©rie temporal estacion√°ria que representa a taxa de juros de curto prazo em um pa√≠s. Se a s√©rie for estacion√°ria, isso significa que a distribui√ß√£o da taxa de juros n√£o muda com o tempo. Suponha que a m√©dia dessa taxa de juros seja de 2% ao ano.
>
> Ent√£o, de acordo com o Teorema 2, a expectativa da taxa de juros em qualquer ponto no tempo *t* ser√° sempre 2%, ou seja, $E(Y_t) = 0.02$ para todo *t*.
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
>
> # Par√¢metros
> mu = 0.02  # M√©dia (2%)
> num_pontos = 100
>
> # Gera uma s√©rie temporal estacion√°ria (ru√≠do branco com m√©dia 0.02)
> Y = np.random.normal(mu, 0.01, num_pontos) # Desvio padr√£o de 0.01
>
> # Calcula a m√©dia amostral
> media_amostral = np.mean(Y)
>
> print(f"M√©dia amostral de Y_t: {media_amostral}")
>
> # Plota a s√©rie temporal
> plt.plot(Y, label='Taxa de Juros (Y_t)')
> plt.axhline(y=mu, color='r', linestyle='-', label='E(Y_t) = 0.02')  # Linha horizontal na m√©dia
> plt.xlabel('Tempo (t)')
> plt.ylabel('Taxa de Juros')
> plt.title('S√©rie Temporal Estacion√°ria (Taxa de Juros)')
> plt.legend()
> plt.grid(True)
> plt.show()
> ```

### Conclus√£o

A expectativa $E(Y_t)$, ou m√©dia incondicional $\mu_t$, √© uma medida fundamental que descreve o valor m√©dio de uma s√©rie temporal em um determinado ponto no tempo [^44]. Sua depend√™ncia ou independ√™ncia do tempo *t* reflete as caracter√≠sticas do processo estoc√°stico subjacente, sendo crucial para a an√°lise e modelagem de s√©ries temporais [^44].

### Refer√™ncias
[^44]: P√°gina 44 do texto original.
<!-- END -->