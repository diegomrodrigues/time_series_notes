## Invertibility in Moving Average Processes: An In-Depth Analysis

### Introdu√ß√£o
Este cap√≠tulo se aprofunda no conceito de **invertibilidade** em processos de *Moving Average* (MA), crucial para a an√°lise e modelagem de s√©ries temporais. Expandindo os conceitos apresentados anteriormente sobre processos MA, este cap√≠tulo examina as condi√ß√µes sob as quais um processo MA pode ser expresso de forma equivalente como um processo autorregressivo de ordem infinita (AR(‚àû)). Em particular, focaremos na condi√ß√£o de invertibilidade para um processo MA(1), onde o valor absoluto do coeficiente MA, denotado como $|\theta|$, deve ser menor que 1 [^65]. A invertibilidade garante que o processo MA possa ser representado de forma √∫nica e est√°vel, permitindo previs√µes e an√°lises estat√≠sticas consistentes.

**Proposi√ß√£o 1** (Unicidade da Representa√ß√£o AR(‚àû)). Se um processo MA(q) √© invert√≠vel, ent√£o sua representa√ß√£o AR(‚àû) √© √∫nica.
*Prova*. Suponha que existam duas representa√ß√µes AR(‚àû) para o mesmo processo MA(q) invert√≠vel. A diferen√ßa entre essas duas representa√ß√µes deve ser zero, implicando que os coeficientes de ambas as representa√ß√µes devem ser id√™nticos. Portanto, a representa√ß√£o AR(‚àû) √© √∫nica.

I. Seja $Y_t = \sum_{i=0}^{\infty} \phi_i Y_{t-i} + \epsilon_t$ e $Y_t = \sum_{i=0}^{\infty} \psi_i Y_{t-i} + \epsilon_t$ duas representa√ß√µes AR(‚àû) do mesmo processo MA(q) invert√≠vel.

II. Subtraindo uma representa√ß√£o da outra, obtemos:
   $$0 = \sum_{i=0}^{\infty} (\phi_i - \psi_i) Y_{t-i}$$

III. Para que esta equa√ß√£o seja v√°lida para todo $t$, devemos ter $\phi_i - \psi_i = 0$ para todo $i$.

IV. Portanto, $\phi_i = \psi_i$ para todo $i$, o que significa que as duas representa√ß√µes AR(‚àû) s√£o id√™nticas.

V. Portanto, a representa√ß√£o AR(‚àû) √© √∫nica. ‚ñ†

> üí° **Exemplo Num√©rico:**
>
> Suponha que temos um processo MA(1) invert√≠vel, $Y_t = 0.5 \epsilon_{t-1} + \epsilon_t$. Uma representa√ß√£o AR(‚àû) poss√≠vel seria $Y_t = 0.5Y_{t-1} - 0.25Y_{t-2} + 0.125Y_{t-3} \ldots + \epsilon_t$. Se existisse uma outra representa√ß√£o AR(‚àû), digamos $Y_t = \psi_1Y_{t-1} + \psi_2Y_{t-2} + \psi_3Y_{t-3} \ldots + \epsilon_t$, a proposi√ß√£o afirma que necessariamente $\psi_1 = 0.5$, $\psi_2 = -0.25$, $\psi_3 = 0.125$ e assim por diante, garantindo a unicidade.

### Conceitos Fundamentais
**Invertibilidade** significa que um processo *Moving Average* (MA) pode ser reescrito como uma representa√ß√£o *Autoregressive* (AR(‚àû)) [^65]. Considere um processo MA(1) dado por:
$$Y_t = \mu + (1 + \theta L)\epsilon_t$$
onde $Y_t$ √© o valor da s√©rie temporal no tempo $t$, $\mu$ √© a m√©dia do processo, $\epsilon_t$ √© o erro de ru√≠do branco no tempo $t$, e $L$ √© o operador de defasagem (lag), tal que $L\epsilon_t = \epsilon_{t-1}$ [^5]. Para este processo MA(1) ser invert√≠vel, a condi√ß√£o necess√°ria e suficiente √© $|\theta| < 1$ [^65].

> üí° **Exemplo Num√©rico:**
>
> Seja $\mu = 10$ e $\theta = 0.5$. Ent√£o o processo MA(1) √© $Y_t = 10 + \epsilon_t + 0.5\epsilon_{t-1}$.  Este processo √© invert√≠vel pois $|\theta| = |0.5| < 1$.  Se $\theta = 1.5$, o processo $Y_t = 10 + \epsilon_t + 1.5\epsilon_{t-1}$ n√£o seria invert√≠vel, pois $|1.5| > 1$.

Se $|\theta| < 1$, podemos multiplicar ambos os lados da equa√ß√£o por $(1 + \theta L)^{-1}$ [^65]:
$$(1 + \theta L)^{-1}(Y_t - \mu) = \epsilon_t$$
Expandindo o termo $(1 + \theta L)^{-1}$ como uma s√©rie infinita [^65]:
$$(1 - \theta L + \theta^2 L^2 - \theta^3 L^3 + \ldots)(Y_t - \mu) = \epsilon_t$$
Esta √© uma representa√ß√£o AR(‚àû) do processo MA(1). A condi√ß√£o $|\theta| < 1$ garante que a s√©rie infinita convirja, tornando a representa√ß√£o AR(‚àû) bem definida e o processo MA(1) invert√≠vel [^65]. Se $|\theta| \geq 1$, a s√©rie AR(‚àû) n√£o converge, e o processo MA(1) n√£o √© invert√≠vel [^65].

> üí° **Exemplo Num√©rico:**
>
> Se $\theta = 0.5$, a expans√£o √© $(1 - 0.5L + 0.25L^2 - 0.125L^3 + \ldots)(Y_t - \mu) = \epsilon_t$. Os coeficientes decaem exponencialmente, garantindo a converg√™ncia. Se $\theta = 2$, a expans√£o √© $(1 - 2L + 4L^2 - 8L^3 + \ldots)(Y_t - \mu) = \epsilon_t$.  Neste caso, os coeficientes crescem exponencialmente, indicando n√£o invertibilidade.

Para ilustrar, considere o caso em que $|\theta| \geq 1$. A s√©rie $(1 - \theta L + \theta^2 L^2 - \theta^3 L^3 + \ldots)$ n√£o converge, e a representa√ß√£o AR(‚àû) torna-se inst√°vel. Isso implica que as observa√ß√µes passadas teriam um peso crescente na determina√ß√£o do valor atual, o que n√£o √© consistente com um processo estacion√°rio.

A invertibilidade est√° intimamente ligada √† **unicidade da representa√ß√£o** de um processo estoc√°stico. Para um determinado conjunto de autocovari√¢ncias, pode haver m√∫ltiplos processos MA que se ajustam aos dados. No entanto, apenas o processo invert√≠vel MA tem uma representa√ß√£o AR(‚àû) causal e est√°vel [^65].

Considere um processo MA(1) n√£o invert√≠vel:
$$Y_t = \mu + (1 + \tilde{\theta}L)\tilde{\epsilon}_t$$
onde $|\tilde{\theta}| > 1$. Podemos encontrar um processo MA(1) invert√≠vel equivalente [^65]:
$$Y_t = \mu + (1 + \theta L)\epsilon_t$$
onde $\theta = \tilde{\theta}^{-1}$ e $\epsilon_t = \tilde{\theta}\tilde{\epsilon}_t$. Ambos os processos t√™m as mesmas autocovari√¢ncias, mas apenas o √∫ltimo √© invert√≠vel.

> üí° **Exemplo Num√©rico:**
>
> Seja $\tilde{\theta} = 2$. Ent√£o o processo n√£o invert√≠vel √© $Y_t = \mu + (1 + 2L)\tilde{\epsilon}_t$. O processo invert√≠vel equivalente √© $Y_t = \mu + (1 + 0.5L)\epsilon_t$, onde $\theta = 0.5$ e $\epsilon_t = 2\tilde{\epsilon}_t$. Ambos os processos ter√£o as mesmas autocovari√¢ncias.

**Lema 1**. Se dois processos MA(1) t√™m as mesmas autocovari√¢ncias, ent√£o os seus par√¢metros Œ∏ est√£o relacionados por Œ∏‚ÇÅ = Œ∏‚ÇÇ ou Œ∏‚ÇÅ = 1/Œ∏‚ÇÇ.

*Prova*. Seja Œ≥‚ÇÄ, Œ≥‚ÇÅ as autocovari√¢ncias de um processo MA(1). Ent√£o, Œ≥‚ÇÄ = œÉ¬≤(1 + Œ∏¬≤) e Œ≥‚ÇÅ = œÉ¬≤Œ∏.  Se dois processos MA(1) t√™m as mesmas autocovari√¢ncias, ent√£o œÉ‚ÇÅ¬≤(1 + Œ∏‚ÇÅ¬≤) = œÉ‚ÇÇ¬≤(1 + Œ∏‚ÇÇ¬≤) e œÉ‚ÇÅ¬≤Œ∏‚ÇÅ = œÉ‚ÇÇ¬≤Œ∏‚ÇÇ.  Dividindo a segunda equa√ß√£o pela primeira, obtemos Œ∏‚ÇÅ/(1 + Œ∏‚ÇÅ¬≤) = Œ∏‚ÇÇ/(1 + Œ∏‚ÇÇ¬≤).  Resolvendo para Œ∏‚ÇÅ, temos Œ∏‚ÇÅ = Œ∏‚ÇÇ ou Œ∏‚ÇÅ = 1/Œ∏‚ÇÇ.

I. Seja $Y_t = \mu + (1 + \theta_1 L)\epsilon_{1t}$ e $Y_t = \mu + (1 + \theta_2 L)\epsilon_{2t}$ dois processos MA(1) com as mesmas autocovari√¢ncias.
II. As autocovari√¢ncias para o primeiro processo s√£o $\gamma_{0}^{(1)} = \sigma_1^2 (1 + \theta_1^2)$ e $\gamma_{1}^{(1)} = \sigma_1^2 \theta_1$.
III. As autocovari√¢ncias para o segundo processo s√£o $\gamma_{0}^{(2)} = \sigma_2^2 (1 + \theta_2^2)$ e $\gamma_{1}^{(2)} = \sigma_2^2 \theta_2$.
IV. Como os processos t√™m as mesmas autocovari√¢ncias, temos $\gamma_{0}^{(1)} = \gamma_{0}^{(2)}$ e $\gamma_{1}^{(1)} = \gamma_{1}^{(2)}$.
V. Portanto, $\sigma_1^2 (1 + \theta_1^2) = \sigma_2^2 (1 + \theta_2^2)$ e $\sigma_1^2 \theta_1 = \sigma_2^2 \theta_2$.
VI. Dividindo a segunda equa√ß√£o pela primeira, obtemos:
    $$\frac{\theta_1}{1 + \theta_1^2} = \frac{\theta_2}{1 + \theta_2^2}$$
VII. Multiplicando cruzado, temos:
    $$\theta_1 + \theta_1 \theta_2^2 = \theta_2 + \theta_2 \theta_1^2$$
VIII. Reorganizando, temos:
     $$\theta_1 - \theta_2 + \theta_1 \theta_2^2 - \theta_2 \theta_1^2 = 0$$
IX. Fatorando, temos:
    $$(\theta_1 - \theta_2) - \theta_1 \theta_2 (\theta_1 - \theta_2) = 0$$
X. Fatorando novamente, temos:
   $$(\theta_1 - \theta_2)(1 - \theta_1 \theta_2) = 0$$
XI. Portanto, ou $\theta_1 - \theta_2 = 0$ ou $1 - \theta_1 \theta_2 = 0$.
XII. Se $\theta_1 - \theta_2 = 0$, ent√£o $\theta_1 = \theta_2$.
XIII. Se $1 - \theta_1 \theta_2 = 0$, ent√£o $\theta_1 \theta_2 = 1$, o que implica $\theta_1 = \frac{1}{\theta_2}$.
XIV. Portanto, $\theta_1 = \theta_2$ ou $\theta_1 = \frac{1}{\theta_2}$. ‚ñ†

> üí° **Exemplo Num√©rico:**
>
> Considere dois processos MA(1):
>
> 1.  $Y_t = \epsilon_{1t} + 0.5 \epsilon_{1,t-1}$ com $\theta_1 = 0.5$ e $\sigma_1^2 = 1$
> 2.  $Y_t = \epsilon_{2t} + 2 \epsilon_{2,t-1}$ com $\theta_2 = 2$ e $\sigma_2^2 = 0.25$
>
> Para o primeiro processo, $\gamma_0^{(1)} = 1(1 + 0.5^2) = 1.25$ e $\gamma_1^{(1)} = 1(0.5) = 0.5$.
>
> Para o segundo processo, $\gamma_0^{(2)} = 0.25(1 + 2^2) = 1.25$ e $\gamma_1^{(2)} = 0.25(2) = 0.5$.
>
> Os dois processos t√™m as mesmas autocovari√¢ncias. Note que $\theta_1 = 0.5$ e $\theta_2 = 2$, e $0.5 = 1/2$, o que demonstra o lema.

A **fun√ß√£o geradora de autocovari√¢ncia** para um processo MA(1) √© dada por [^65]:
$$g_Y(z) = \sigma^2(1 + \theta z)(1 + \theta z^{-1})$$
onde $z$ √© uma vari√°vel complexa. Para o processo MA(1) n√£o invert√≠vel, a fun√ß√£o geradora de autocovari√¢ncia √© [^65]:
$$g_{\tilde{Y}}(z) = \tilde{\sigma}^2(1 + \tilde{\theta} z)(1 + \tilde{\theta} z^{-1})$$
Se $\theta = \tilde{\theta}^{-1}$ e $\tilde{\sigma}^2 = \theta^2\sigma^2$, ent√£o $g_Y(z) = g_{\tilde{Y}}(z)$, demonstrando que ambos os processos t√™m as mesmas autocovari√¢ncias, mas apenas o primeiro √© invert√≠vel.

**Teorema 1**. Um processo MA(q) √© invert√≠vel se e somente se todas as ra√≠zes do polin√¥mio (1 + Œ∏‚ÇÅz + ... + Œ∏_q z^q) est√£o fora do c√≠rculo unit√°rio.

*Prova*. (Adapta√ß√£o da demonstra√ß√£o para MA(1)).  A condi√ß√£o de invertibilidade para um MA(q) garante que existe uma representa√ß√£o AR(‚àû) convergente.  Isso ocorre se e somente se as ra√≠zes do polin√¥mio caracter√≠stico do MA(q) estiverem fora do c√≠rculo unit√°rio.

I. Considere um processo MA(q) dado por $Y_t = \epsilon_t + \theta_1 \epsilon_{t-1} + \ldots + \theta_q \epsilon_{t-q}$, onde $\epsilon_t$ √© um ru√≠do branco com vari√¢ncia $\sigma^2$.

II. O polin√¥mio caracter√≠stico do processo MA(q) √© dado por $\Theta(z) = 1 + \theta_1 z + \ldots + \theta_q z^q$.

III. Para que o processo MA(q) seja invert√≠vel, ele deve ter uma representa√ß√£o AR(‚àû) convergente, ou seja, deve existir uma sequ√™ncia de coeficientes $\pi_i$ tal que $\epsilon_t = Y_t + \pi_1 Y_{t-1} + \pi_2 Y_{t-2} + \ldots$.

IV. A condi√ß√£o para que esta representa√ß√£o AR(‚àû) convirja √© que as ra√≠zes do polin√¥mio caracter√≠stico $\Theta(z)$ estejam fora do c√≠rculo unit√°rio, isto √©, $|z_i| > 1$ para todas as ra√≠zes $z_i$ de $\Theta(z)$.

V. Se todas as ra√≠zes de $\Theta(z)$ estiverem fora do c√≠rculo unit√°rio, ent√£o existe uma expans√£o em s√©rie de pot√™ncias convergente para $\frac{1}{\Theta(z)}$, que fornece os coeficientes $\pi_i$ da representa√ß√£o AR(‚àû).

VI. Reciprocamente, se alguma raiz de $\Theta(z)$ estiver dentro ou sobre o c√≠rculo unit√°rio, ent√£o a expans√£o em s√©rie de pot√™ncias de $\frac{1}{\Theta(z)}$ n√£o converge, e o processo MA(q) n√£o √© invert√≠vel.

VII. Portanto, um processo MA(q) √© invert√≠vel se e somente se todas as ra√≠zes do polin√¥mio (1 + Œ∏‚ÇÅz + ... + Œ∏_q z^q) est√£o fora do c√≠rculo unit√°rio. ‚ñ†

> üí° **Exemplo Num√©rico:**
>
> Considere um processo MA(2): $Y_t = \epsilon_t + 0.5\epsilon_{t-1} + 0.25\epsilon_{t-2}$.
>
> O polin√¥mio caracter√≠stico √© $\Theta(z) = 1 + 0.5z + 0.25z^2$.
>
> As ra√≠zes deste polin√¥mio podem ser encontradas usando a f√≥rmula quadr√°tica:
>
> $z = \frac{-b \pm \sqrt{b^2 - 4ac}}{2a} = \frac{-0.5 \pm \sqrt{0.5^2 - 4(0.25)(1)}}{2(0.25)} = \frac{-0.5 \pm \sqrt{0.25 - 1}}{0.5} = \frac{-0.5 \pm \sqrt{-0.75}}{0.5} = -1 \pm i\sqrt{3}$.
>
> O m√≥dulo das ra√≠zes √© $|z| = \sqrt{(-1)^2 + (\sqrt{3})^2} = \sqrt{1 + 3} = \sqrt{4} = 2$.
>
> Como $|z| = 2 > 1$, ambas as ra√≠zes est√£o fora do c√≠rculo unit√°rio, e o processo MA(2) √© invert√≠vel.
>
> Agora, considere um processo MA(2) n√£o invert√≠vel: $Y_t = \epsilon_t + 2\epsilon_{t-1} + \epsilon_{t-2}$.
>
> O polin√¥mio caracter√≠stico √© $\Theta(z) = 1 + 2z + z^2 = (1+z)^2$.
>
> A raiz deste polin√¥mio √© $z = -1$.
>
> O m√≥dulo da raiz √© $|z| = |-1| = 1$.
>
> Como $|z| = 1$, a raiz est√° sobre o c√≠rculo unit√°rio, e o processo MA(2) n√£o √© invert√≠vel.

Dado que o Teorema 1 estabelece a condi√ß√£o geral de invertibilidade para MA(q) processos, podemos formular um corol√°rio que relaciona diretamente a invertibilidade com a converg√™ncia da representa√ß√£o AR(‚àû).

**Corol√°rio 1.1**. Um processo MA(q) √© invert√≠vel se e somente se a sua representa√ß√£o AR(‚àû) converge.
*Prova*. O Teorema 1 estabelece que um processo MA(q) √© invert√≠vel se e somente se as ra√≠zes do polin√¥mio (1 + Œ∏‚ÇÅz + ... + Œ∏_q z^q) est√£o fora do c√≠rculo unit√°rio. Esta condi√ß√£o √© equivalente √† converg√™ncia da representa√ß√£o AR(‚àû), pois garante que os coeficientes da representa√ß√£o AR(‚àû) decaiam √† medida que o lag aumenta. Portanto, a invertibilidade √© uma condi√ß√£o necess√°ria e suficiente para a converg√™ncia da representa√ß√£o AR(‚àû).

I. Seja um processo MA(q) invert√≠vel. Pelo Teorema 1, todas as ra√≠zes do polin√¥mio caracter√≠stico est√£o fora do c√≠rculo unit√°rio.
II. Isso implica que a fun√ß√£o de transfer√™ncia do processo, que √© o inverso do polin√¥mio caracter√≠stico, tem uma expans√£o em s√©rie de pot√™ncias convergente.
III. Essa expans√£o em s√©rie de pot√™ncias corresponde √† representa√ß√£o AR(‚àû) do processo MA(q).
IV. Portanto, se o processo MA(q) √© invert√≠vel, sua representa√ß√£o AR(‚àû) converge.
V. Agora, suponha que a representa√ß√£o AR(‚àû) de um processo MA(q) converge.
VI. Isso implica que a fun√ß√£o de transfer√™ncia do processo tem uma expans√£o em s√©rie de pot√™ncias convergente.
VII. Portanto, todas as ra√≠zes do polin√¥mio caracter√≠stico devem estar fora do c√≠rculo unit√°rio.
VIII. Pelo Teorema 1, isso significa que o processo MA(q) √© invert√≠vel.
IX. Portanto, um processo MA(q) √© invert√≠vel se e somente se sua representa√ß√£o AR(‚àû) converge. ‚ñ†

Al√©m disso, podemos examinar como a invertibilidade afeta a fun√ß√£o de autocorrela√ß√£o (ACF) do processo MA.

**Proposi√ß√£o 2**. Para um processo MA(1), a fun√ß√£o de autocorrela√ß√£o (ACF) √© id√™ntica tanto para o processo invert√≠vel quanto para o n√£o invert√≠vel correspondente.

*Prova*. A ACF de um processo MA(1) √© dada por $\rho_1 = \frac{\theta}{1 + \theta^2}$ para o lag 1 e $\rho_k = 0$ para $k > 1$. Como demonstrado no Lema 1, tanto Œ∏ quanto 1/Œ∏ resultam nas mesmas autocovari√¢ncias e, portanto, na mesma ACF. Portanto, a ACF n√£o pode ser usada para distinguir entre um processo MA(1) invert√≠vel e seu correspondente n√£o invert√≠vel.

I. Considere um processo MA(1) invert√≠vel $Y_t = \epsilon_t + \theta \epsilon_{t-1}$ e um processo MA(1) n√£o invert√≠vel $Y_t = \tilde{\epsilon}_t + \tilde{\theta} \tilde{\epsilon}_{t-1}$, onde $\theta = 1/\tilde{\theta}$.
II. A autocovari√¢ncia no lag 0 para o processo invert√≠vel √© $\gamma_0 = Var(Y_t) = E[(Y_t)^2] = E[(\epsilon_t + \theta \epsilon_{t-1})^2] = E[\epsilon_t^2 + 2\theta \epsilon_t \epsilon_{t-1} + \theta^2 \epsilon_{t-1}^2] = \sigma^2 (1 + \theta^2)$, onde $\sigma^2 = Var(\epsilon_t)$.
III. A autocovari√¢ncia no lag 1 para o processo invert√≠vel √© $\gamma_1 = Cov(Y_t, Y_{t-1}) = E[Y_t Y_{t-1}] = E[(\epsilon_t + \theta \epsilon_{t-1})(\epsilon_{t-1} + \theta \epsilon_{t-2})] = E[\epsilon_t \epsilon_{t-1} + \theta \epsilon_{t-1}^2 + \theta \epsilon_t \epsilon_{t-2} + \theta^2 \epsilon_{t-1} \epsilon_{t-2}] = \theta \sigma^2$.
IV. Portanto, a autocorrela√ß√£o no lag 1 para o processo invert√≠vel √© $\rho_1 = \frac{\gamma_1}{\gamma_0} = \frac{\theta \sigma^2}{\sigma^2 (1 + \theta^2)} = \frac{\theta}{1 + \theta^2}$.
V. Similarmente, a autocovari√¢ncia no lag 0 para o processo n√£o invert√≠vel √© $\tilde{\gamma}_0 = \tilde{\sigma}^2 (1 + \tilde{\theta}^2)$, onde $\tilde{\sigma}^2 = Var(\tilde{\epsilon}_t)$.
VI. A autocovari√¢ncia no lag 1 para o processo n√£o invert√≠vel √© $\tilde{\gamma}_1 = \tilde{\theta} \tilde{\sigma}^2$.
VII. A autocorrela√ß√£o no lag 1 para o processo n√£o invert√≠vel √© $\tilde{\rho}_1 = \frac{\tilde{\gamma}_1}{\tilde{\gamma}_0} = \frac{\tilde{\theta}}{1 + \tilde{\theta}^2}$.
VIII. Substituindo $\tilde{\theta} = 1/\theta$, temos $\tilde{\rho}_1 = \frac{1/\theta}{1 + (1/\theta)^2} = \frac{1/\theta}{1 + 1/\theta^2} = \frac{1/\theta}{(\theta^2 + 1)/\theta^2} = \frac{1}{\theta} \cdot \frac{\theta^2}{\theta^2 + 1} = \frac{\theta}{1 + \theta^2}$.
IX. Portanto, $\rho_1 = \tilde{\rho}_1$, o que significa que a ACF √© id√™ntica para ambos os processos.
X. Para lags k > 1, a autocorrela√ß√£o √© 0 para ambos os processos, pois $Cov(Y_t, Y_{t-k}) = 0$ para $k > 1$.
XI. Assim, a fun√ß√£o de autocorrela√ß√£o (ACF) √© id√™ntica tanto para o processo invert√≠vel quanto para o n√£o invert√≠vel correspondente. ‚ñ†

> üí° **Exemplo Num√©rico:**
>
> Seja $\theta = 0.5$. Ent√£o, $\rho_1 = \frac{0.5}{1 + 0.5^2} = \frac{0.5}{1.25} = 0.4$.
>
> Agora, seja $\tilde{\theta} = 1/\theta = 2$. Ent√£o, $\tilde{\rho}_1 = \frac{2}{1 + 2^2} = \frac{2}{5} = 0.4$.
>
> A ACF no lag 1 √© a mesma para ambos os processos.

Considerando a import√¢ncia da representa√ß√£o AR(‚àû), podemos detalhar como os coeficientes dessa representa√ß√£o s√£o obtidos para um processo MA(1).

**Lema 2**. Para um processo MA(1) invert√≠vel, $Y_t = \mu + (1 + \theta L)\epsilon_t$ com $|\theta| < 1$, os coeficientes œÄ_j na representa√ß√£o AR(‚àû), $Y_t = \mu + \sum_{j=0}^{\infty} \pi_j Y_{t-j} + \epsilon_t$, s√£o dados por œÄ_j = -(-Œ∏)^j para j ‚â• 1.

*Prova*. J√° demonstramos que $(1 + \theta L)^{-1}(Y_t - \mu) = \epsilon_t$ pode ser expandido para $(1 - \theta L + \theta^2 L^2 - \theta^3 L^3 + \ldots)(Y_t - \mu) = \epsilon_t$. Rearranjando, temos $Y_t - \mu = \theta (Y_{t-1} - \mu) - \theta^2(Y_{t-2} - \mu) + \theta^3 (Y_{t-3} - \mu) - \ldots + \epsilon_t$.  Portanto, os coeficientes œÄ_j s√£o dados por œÄ_j = -(-Œ∏)^j.

I. Dado o processo MA(1) invert√≠vel $Y_t = \mu + \epsilon_t + \theta \epsilon_{t-1}$, onde $|\theta| < 1$.

II. Queremos expressar $Y_t$ na forma AR(‚àû): $Y_t - \mu = \sum_{j=1}^{\infty} \pi_j (Y_{t-j} - \mu) + \epsilon_t$.

III. Reescrevendo a equa√ß√£o MA(1) como $\epsilon_t = Y_t - \mu - \theta \epsilon_{t-1}$.

IV. Usando o operador de defasagem $L$, podemos escrever $\epsilon_{t-1} = (Y_{t-1} - \mu) - \theta \epsilon_{t-2}$.

V. Substituindo $\epsilon_{t-1}$ na equa√ß√£o de $\epsilon_t$, temos $\epsilon_t = (Y_t - \mu) - \theta [(Y_{t-1} - \mu) - \theta \epsilon_{t-2}] = (Y_t - \mu) - \theta (Y_{t-1} - \mu) + \theta^2 \epsilon_{t-2}$.

VI. Continuando a substitui√ß√£o recursivamente, obtemos: $\epsilon_t = (Y_t - \mu) - \theta (Y_{t-1} - \mu) + \theta^2 (Y_{t-2} - \mu) - \theta^3 (Y_{t-3} - \mu) + \ldots = (Y_t - \mu) + \sum_{j=1}^{\infty} (-\theta)^j (Y_{t-j} - \mu)$.

VII. Comparando esta equa√ß√£o com a representa√ß√£o AR(‚àû) $Y_t - \mu = \sum_{j=1}^{\infty} \pi_j (Y_{t-j} - \mu) + \epsilon_t$, temos:
$Y_t - \mu - \sum_{j=1}^{\infty} \pi_j (Y_{t-j} - \mu) = \epsilon_t$
$Y_t - \mu = \sum_{j=1}^{\infty} -\pi_j (Y_{t-j} - \mu) + \epsilon_t$.

VIII. Identificando os coeficientes, obtemos $-\pi_j = (-\theta)^j$, o que implica $\pi_j = - (-\theta)^j$ para $j \geq 1$.

IX. Portanto, os coeficientes $\pi_j$ na representa√ß√£o AR(‚àû) s√£o dados por $\pi_j = - (-\theta)^j$ para $j \geq 1$. ‚ñ†

> üí° **Exemplo Num√©rico:**
>
> Seja $\theta = 0.5$. Ent√£o:
>
> $\pi_1 = -(-0.5)^1 = 0.5$
>
> $\pi_2 = -(-0.5)^2 = -0.25$
>
> $\pi_3 = -(-0.5)^3 = 0.125$
>
> $\pi_4 = -(-0.5)^4 = -0.0625$
>
> Assim, a representa√ß√£o AR(‚àû) √© $Y_t = \mu + 0.5(Y_{t-1} - \mu) - 0.25(Y_{t-2} - \mu) + 0.125(Y_{t-3} - \mu) - 0.0625(Y_{t-4} - \mu) + \ldots + \epsilon_t$.

### Conclus√£o
A invertibilidade √© uma propriedade essencial dos processos *Moving Average* (MA) que garante uma representa√ß√£o √∫nica e est√°vel do processo. Para um processo MA(1), a condi√ß√£o de invertibilidade √© $|\theta| < 1$, que garante que o processo possa ser expresso como um processo AR(‚àû) convergente. A n√£o invertibilidade leva a ambiguidades na representa√ß√£o do processo e pode resultar em dificuldades na estimativa de par√¢metros e na previs√£o. Portanto, ao modelar s√©ries temporais usando processos MA, √© crucial verificar a condi√ß√£o de invertibilidade para garantir a validade e a interpretabilidade do modelo.

### Refer√™ncias
[^5]: Y‚ÇÅ = Œº + Œµ, + Œ∏Œµ,-1,
[^65]: Provided that |0| < 1, both sides of [3.7.1] can be multiplied by (1 + 8L) 1 to obtain
<!-- END -->