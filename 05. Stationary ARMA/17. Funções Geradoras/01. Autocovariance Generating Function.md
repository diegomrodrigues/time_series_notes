## A Função Geradora de Autocovariância

### Introdução

Em continuidade ao estudo de processos estocásticos estacionários, exploraremos agora a **função geradora de autocovariância**, uma ferramenta poderosa para analisar as propriedades de séries temporais. Como vimos anteriormente, as autocovariâncias descrevem a dependência entre observações em diferentes instantes de tempo [^3.10]. A função geradora de autocovariância, por sua vez, fornece uma representação condensada e manipulável dessas informações, facilitando análises e cálculos subsequentes, como a obtenção do espectro populacional da série temporal. Este capítulo visa detalhar a definição, propriedades e aplicação dessa função, com enfoque especial em sua forma para processos Moving Average (MA).

### Conceitos Fundamentais

A **função geradora de autocovariância** $g_Y(z)$ de uma série temporal $\{Y_t\}$ é definida como uma soma infinita das autocovariâncias $\gamma_j$ multiplicadas por potências de um número complexo *z*:

$$g_Y(z) = \sum_{j=-\infty}^{\infty} \gamma_j z^j$$ [^3.6.1]

Onde:

*   $\gamma_j$ representa a autocovariância de ordem *j*, dada por $E[(Y_t - \mu)(Y_{t-j} - \mu)]$, que mede a correlação entre observações defasadas em *j* períodos [^3.10].
*   *z* é um número complexo.

Essa função transforma a sequência de autocovariâncias $\{\gamma_j\}$, que é uma representação no domínio do tempo, em uma função no domínio *z*. Esta transformação é útil por várias razões:

1.  **Representação Compacta:** A função geradora codifica todas as autocovariâncias em uma única expressão analítica.
2.  **Manipulação Facilitada:** As operações sobre a sequência de autocovariâncias podem ser simplificadas através de operações sobre a função geradora.
3.  **Espectro Populacional:** A função geradora permite calcular o espectro populacional da série temporal, uma descrição de como a variância da série é distribuída em diferentes frequências [^3.6.1].

É importante ressaltar que a existência da função geradora de autocovariância é garantida se a sequência de autocovariâncias for absolutamente somável. Ou seja, $\sum_{j=-\infty}^{\infty} |\gamma_j| < \infty$ [^3.14].

#### Função Geradora para Processos MA(q)

Para um processo **Moving Average (MA)** de ordem *q*, a função geradora de autocovariância tem uma forma particular, que pode ser derivada a partir da representação do processo [^3.3.8]. Recordando que um processo MA(q) é dado por:

$$Y_t = \mu + \epsilon_t + \theta_1\epsilon_{t-1} + \theta_2\epsilon_{t-2} + \ldots + \theta_q\epsilon_{t-q}$$

onde $\{\epsilon_t\}$ é um ruído branco com média zero e variância $\sigma^2$, a função geradora de autocovariância $g_Y(z)$ é dada por:

$$g_Y(z) = \sigma^2 (1 + \theta_1 z + \theta_2 z^2 + \ldots + \theta_q z^q)(1 + \theta_1 z^{-1} + \theta_2 z^{-2} + \ldots + \theta_q z^{-q})$$ [^3.6.2, 3.6.3]

Esta expressão pode ser interpretada como o produto de dois polinômios, um em potências positivas de *z* e outro em potências negativas de *z*. O termo $\sigma^2$ representa a variância do ruído branco. As autocovariâncias do processo MA(q) podem ser obtidas a partir dos coeficientes dessa função [^3.6.4].

Para um processo MA(1) específico, onde $Y_t = \mu + \epsilon_t + \theta\epsilon_{t-1}$, a função geradora de autocovariância se reduz a:

$$g_Y(z) = \sigma^2(1 + \theta z)(1 + \theta z^{-1})$$
que também pode ser escrita como
$$g_Y(z) = \sigma^2[\theta z^{-1} + (1+\theta^2) + \theta z]$$

Essa expressão revela que para o processo MA(1) , as autocovariâncias são:

*   $\gamma_0 = \sigma^2 (1+\theta^2)$
*   $\gamma_1 = \gamma_{-1} = \sigma^2\theta$
*   $\gamma_j = 0$, para $|j| > 1$

#### Derivação da Função Geradora

A equação para $g_Y(z)$ de um MA(q) pode ser derivada usando a propriedade que permite calcular a função geradora de um processo, dado que esse é um filtro linear aplicado a um ruído branco. Um processo MA(q) pode ser escrito como $Y_t = \mu + \Psi(L)\epsilon_t$, onde $L$ é o operador de defasagem e $\Psi(L) = 1 + \theta_1 L + \ldots + \theta_q L^q$ é um polinômio em *L*. A função geradora de um processo é dada por $g_Y(z) = \sigma^2 \Psi(z)\Psi(z^{-1})$. No caso de um MA(q), temos que:

$$ \Psi(z) =  1 + \theta_1 z + \ldots + \theta_q z^q $$
$$ \Psi(z^{-1}) = 1 + \theta_1 z^{-1} + \ldots + \theta_q z^{-q} $$

Assim, ao multiplicar  $\Psi(z)$ e  $\Psi(z^{-1})$ e multiplicar pela variância do ruído branco ($\sigma^2$), obtemos a expressão para  $g_Y(z)$ para o MA(q) apresentada anteriormente.

### Conclusão

A função geradora de autocovariância $g_Y(z)$ é uma ferramenta analítica indispensável no estudo de séries temporais estacionárias. Ela oferece uma maneira eficiente e compacta de representar as autocovariâncias de um processo estocástico, permitindo manipular as relações temporais através de funções e calcular o espectro populacional da série [^3.6.1]. Para processos MA(q), a função geradora possui uma forma polinomial que facilita a análise de suas propriedades. A capacidade de expressar processos temporais na forma de funções no domínio *z* possibilita uma análise mais profunda e simplificada das suas características. As próximas seções explorarão outras aplicações dessa ferramenta em contextos mais complexos de séries temporais.

### Referências

[^3.6.1]:  *This function is constructed by taking the jth autocovariance and multiplying it by some number z raised to the jth power, and then summing over all the possible values of j. The argument of this function (z) is taken to be a complex scalar.*
[^3.10]:  *From this distribution we can calculate the jth autocovariance of Yt (denoted $\gamma_{jt}$):*
[^3.3.8]: *A qth-order moving average process, denoted MA(q), is characterized by
$Y_t = \mu + \epsilon_t + \theta_1\epsilon_{t-1} + \theta_2\epsilon_{t-2} + \ldots + \theta_q\epsilon_{t-q}$*
[^3.6.2]: *$g_Y(z) = \sigma^2(1 + \theta z)(1 + \theta z^{-1})$.*
[^3.6.3]: *$g_Y(z) = \sigma^2(1 + \theta_1 z + \theta_2 z^2 + \ldots + \theta_q z^q)
\times (1 + \theta_1 z^{-1} + \theta_2 z^{-2} + \ldots + \theta_q z^{-q})$.*
[^3.6.4]: *This conjecture can be verified by carrying out the multiplication in [3.6.3] and
collecting terms by powers of z:
$(1 + \theta_1 z + \theta_2 z^2 + \ldots + \theta_q z^q) \times (1 + \theta_1 z^{-1} + \theta_2 z^{-2} + \ldots + \theta_q z^{-q})
= (\theta_q)^2 z^q + (\theta_{q-1} + \theta_q\theta_1)z^{(q-1)} + (\theta_{q-2} + \theta_{q-1}\theta_1 + \theta_q\theta_2)z^{(q-2)}
+ \ldots + (\theta_1 + \theta_2\theta_1 + \theta_3\theta_2 + \ldots + \theta_q\theta_{q-1}) z
+ (1 + \theta_1^2 + \theta_2^2 + \ldots + \theta_q^2)
+ (\theta_1 + \theta_2\theta_1 + \theta_3\theta_2 + \ldots + \theta_q\theta_{q-1})z^{-1} + \ldots + (\theta_q)z^{-q}$.*
[^3.14]: *A sequence of numbers $\{\gamma_j\}_{j=-\infty}^\infty$ satisfying [3.3.14] is said to be square summable, whereas a sequence satisfying [3.3.15] is said to be absolutely summable. Absolute summability implies square-summability, but the converse does not hold-there
are examples of square-summable sequences that are not absolutely summable
(again, see Appendix 3.A).*
<!-- END -->
