## Invertibilidade em Processos MA(q)

### IntroduÃ§Ã£o
Este capÃ­tulo explora o conceito de **invertibilidade** em processos Moving Average (MA) de ordem *q*. A invertibilidade estÃ¡ intrinsecamente ligada Ã  representaÃ§Ã£o de um processo MA(q) como um processo Autoregressivo (AR) de ordem infinita [^3.7.12]. Investigaremos as condiÃ§Ãµes sob as quais um processo MA(q) pode ser invertido, com foco na localizaÃ§Ã£o das raÃ­zes do polinÃ´mio caracterÃ­stico associado. AlÃ©m disso, discutiremos as implicaÃ§Ãµes da nÃ£o invertibilidade e as alternativas para modelar processos MA(q) nÃ£o invertÃ­veis.

### Conceitos Fundamentais

Um processo MA(q) Ã© definido como [^3.7.12]:

$$ (Y_t - \mu) = (1 + \theta_1L + \theta_2L^2 + \ldots + \theta_qL^q)\epsilon_t $$

onde $Y_t$ Ã© a sÃ©rie temporal, $\mu$ Ã© a mÃ©dia, $\theta_i$ sÃ£o os coeficientes do processo MA(q), $L$ Ã© o operador de *lag*, e $\epsilon_t$ Ã© um ruÃ­do branco com mÃ©dia zero e variÃ¢ncia $\sigma^2$, ou seja, $E(\epsilon_t\epsilon_\tau) = \sigma^2$ se $t = \tau$ e $0$ caso contrÃ¡rio.

> ğŸ’¡ **Exemplo NumÃ©rico:** Considere um processo MA(1) com $\mu = 0$, $\theta_1 = 0.7$ e $\sigma^2 = 1$. EntÃ£o, $Y_t = \epsilon_t + 0.7\epsilon_{t-1}$.  Se $\epsilon_t$ sÃ£o valores aleatÃ³rios extraÃ­dos de uma distribuiÃ§Ã£o normal padrÃ£o, podemos simular os valores de $Y_t$.

A **invertibilidade** de um processo MA(q) significa que ele pode ser expresso como um processo AR(âˆ) [^3.7.12]:

$$ (1 + \eta_1L + \eta_2L^2 + \eta_3L^3 + \ldots)(Y_t - \mu) = \epsilon_t $$

onde $\eta_i$ sÃ£o os coeficientes do processo AR(âˆ).

Para que a representaÃ§Ã£o AR(âˆ) seja vÃ¡lida e bem definida, o operador MA deve ser invertÃ­vel. Isso requer que as **raÃ­zes** da equaÃ§Ã£o caracterÃ­stica do processo MA [^3.7.13]:

$$ (1 + \theta_1z + \theta_2z^2 + \ldots + \theta_qz^q) = 0 $$

estejam *fora* do cÃ­rculo unitÃ¡rio no plano complexo [^3.7.13]. Em outras palavras, se $z_i$ for uma raiz da equaÃ§Ã£o, entÃ£o $|z_i| > 1$ para todo $i$.

> ğŸ’¡ **Exemplo NumÃ©rico:**  Considere novamente o processo MA(1) com $\theta_1 = 0.7$. A equaÃ§Ã£o caracterÃ­stica Ã© $1 + 0.7z = 0$, entÃ£o $z = -1/0.7 \approx -1.43$. Como $|-1.43| > 1$, a condiÃ§Ã£o de invertibilidade Ã© satisfeita.  Agora, se $\theta_1 = 2$, entÃ£o $z = -1/2 = -0.5$, e $|-0.5| < 1$, o que significa que o processo nÃ£o Ã© invertÃ­vel.

Se todas as raÃ­zes estiverem fora do cÃ­rculo unitÃ¡rio, entÃ£o a representaÃ§Ã£o MA(q) Ã© invertÃ­vel, e podemos encontrar os coeficientes $\eta_i$ da representaÃ§Ã£o AR(âˆ). Caso contrÃ¡rio, a representaÃ§Ã£o MA(q) nÃ£o Ã© invertÃ­vel [^3.7.13].

Podemos fatorar o operador MA como [^3.7.14]:

$$ (1 + \theta_1L + \theta_2L^2 + \ldots + \theta_qL^q) = (1 - \lambda_1L)(1 - \lambda_2L)\ldots(1 - \lambda_qL) $$

onde $\lambda_i$ sÃ£o as raÃ­zes inversas da equaÃ§Ã£o caracterÃ­stica (ou seja, $\lambda_i = 1/z_i$). A condiÃ§Ã£o de invertibilidade Ã© entÃ£o equivalente a $|\lambda_i| < 1$ para todo $i$ [^3.7.14].

> ğŸ’¡ **Exemplo NumÃ©rico:** Retomando o exemplo do MA(1) com $\theta_1 = 0.7$, a raiz inversa Ã© $\lambda = -1/\theta_1 = -1/0.7 \approx -1.43$.  No entanto, devemos considerar $\lambda_i = 1/z_i$, entÃ£o $\lambda = 1/(-1/0.7) = -0.7$. Como $|-0.7| < 1$, a condiÃ§Ã£o de invertibilidade Ã© satisfeita. Se $\theta_1 = 2$, entÃ£o $\lambda = -0.5$, e $|-0.5| < 1$, o que *ainda* satisfaz a condiÃ§Ã£o de invertibilidade *na definiÃ§Ã£o com as raÃ­zes inversas*.  Portanto, Ã© importante lembrar que a condiÃ§Ã£o $|\lambda_i| < 1$ se refere Ã s *raÃ­zes inversas*.

**ProposiÃ§Ã£o 1**
Seja $\Theta(L) = (1 + \theta_1L + \theta_2L^2 + \ldots + \theta_qL^q)$ um operador MA(q). EntÃ£o, o processo MA(q) definido por $\Theta(L)\epsilon_t$ Ã© invertÃ­vel se e somente se $|\lambda_i| < 1$ para todo $i$, onde $\lambda_i$ sÃ£o as raÃ­zes inversas de $\Theta(z) = 0$.

Se alguns dos $|\lambda_i| > 1$, o processo nÃ£o Ã© invertÃ­vel. Hansen e Sargent (1981) propuseram um procedimento para encontrar uma representaÃ§Ã£o invertÃ­vel neste caso, substituindo as raÃ­zes $\lambda_i$ que estÃ£o fora do cÃ­rculo unitÃ¡rio por seus inversos $1/\lambda_i$ [^3.7.15].

O processo de substituiÃ§Ã£o das raÃ­zes externas pelo seus inversos resulta em uma nova representaÃ§Ã£o do MA(q) que Ã© invertÃ­vel e tem a mesma funÃ§Ã£o geradora de autocovariÃ¢ncia que a representaÃ§Ã£o original nÃ£o invertÃ­vel [^3.7.15]. Portanto, os primeiros dois momentos do processo (mÃ©dia e autocovariÃ¢ncias) permanecem inalterados [^3.7.3, 3.7.5].

**Teorema 1**
Seja $Y_t = (1 + \theta_1L + \theta_2L^2 + \ldots + \theta_qL^q)\epsilon_t$ um processo MA(q) com funÃ§Ã£o geradora de autocovariÃ¢ncia $g_Y(z)$. Se algumas raÃ­zes inversas $\lambda_i$ do polinÃ´mio caracterÃ­stico satisfazem $|\lambda_i| > 1$, entÃ£o existe um processo invertÃ­vel $\tilde{Y}_t = (1 + \tilde{\theta}_1L + \tilde{\theta}_2L^2 + \ldots + \tilde{\theta}_qL^q)\tilde{\epsilon}_t$ com funÃ§Ã£o geradora de autocovariÃ¢ncia $g_{\tilde{Y}}(z) = g_Y(z)$.

*DemonstraÃ§Ã£o:* (EsboÃ§o) A demonstraÃ§Ã£o segue o procedimento de Hansen e Sargent (1981), substituindo as raÃ­zes inversas $\lambda_i$ tais que $|\lambda_i| > 1$ por $1/\lambda_i$. Ajustando a variÃ¢ncia do ruÃ­do branco, obtÃ©m-se um processo com a mesma funÃ§Ã£o geradora de autocovariÃ¢ncia.

**Prova do Teorema 1:**
Para simplificar, vamos considerar um processo MA(1), mas a lÃ³gica pode ser estendida para MA(q).
I. Seja $Y_t = (1 + \theta L)\epsilon_t$ um processo MA(1), onde $\epsilon_t$ Ã© ruÃ­do branco com variÃ¢ncia $\sigma^2$.

II. A raiz inversa do polinÃ´mio caracterÃ­stico Ã© $\lambda = -\frac{1}{\theta}$. Se $|\lambda| > 1$, entÃ£o $|\theta| < 1$ (o processo jÃ¡ Ã© invertÃ­vel). Consideremos o caso onde $|\lambda| < 1$, entÃ£o $|\theta| > 1$.

> ğŸ’¡ **Exemplo NumÃ©rico:** Se $\theta = 2$, entÃ£o $\lambda = -1/2 = -0.5$, e $|\lambda| = 0.5 < 1$, o que indica que o processo *nÃ£o* Ã© invertÃ­vel na formulaÃ§Ã£o original, ou seja, para expressÃ¡-lo como uma combinaÃ§Ã£o *passada* do ruÃ­do branco.

III. Seguindo Hansen e Sargent, construÃ­mos um novo processo $\tilde{Y}_t = (1 + \tilde{\theta} L)\tilde{\epsilon}_t$ com $\tilde{\theta} = \frac{1}{\theta}$.  Agora $|\tilde{\theta}| < 1$, garantindo a invertibilidade.

> ğŸ’¡ **Exemplo NumÃ©rico:** Se $\theta = 2$, entÃ£o $\tilde{\theta} = 1/2 = 0.5$, e $|\tilde{\theta}| = 0.5 < 1$. Isso significa que o processo transformado Ã© invertÃ­vel.

IV. Precisamos mostrar que a funÃ§Ã£o geradora de autocovariÃ¢ncia de $\tilde{Y}_t$ Ã© a mesma que a de $Y_t$. A funÃ§Ã£o geradora de autocovariÃ¢ncia de $Y_t$ Ã©:
$$g_Y(z) = \sigma^2 (1 + \theta z)(1 + \theta z^{-1}) = \sigma^2 (1 + \theta z + \theta z^{-1} + \theta^2)$$

V. A funÃ§Ã£o geradora de autocovariÃ¢ncia de $\tilde{Y}_t$ Ã©:
$$g_{\tilde{Y}}(z) = \tilde{\sigma}^2 (1 + \tilde{\theta} z)(1 + \tilde{\theta} z^{-1}) = \tilde{\sigma}^2 (1 + \frac{1}{\theta} z)(1 + \frac{1}{\theta} z^{-1}) = \tilde{\sigma}^2 (1 + \frac{1}{\theta} z + \frac{1}{\theta} z^{-1} + \frac{1}{\theta^2})$$

VI. Para que $g_Y(z) = g_{\tilde{Y}}(z)$, precisamos que:
$$ \sigma^2 (1 + \theta z + \theta z^{-1} + \theta^2) = \tilde{\sigma}^2 (1 + \frac{1}{\theta} z + \frac{1}{\theta} z^{-1} + \frac{1}{\theta^2})$$
Isto Ã© satisfeito se $\tilde{\sigma}^2 = \theta^2 \sigma^2$.

> ğŸ’¡ **Exemplo NumÃ©rico:** Se $\theta = 2$ e $\sigma^2 = 1$, entÃ£o $\tilde{\sigma}^2 = 2^2 * 1 = 4$. Portanto, o processo invertÃ­vel Ã© $\tilde{Y}_t = (1 + 0.5L)\tilde{\epsilon}_t$, onde $\tilde{\epsilon}_t$ tem variÃ¢ncia 4.

VII. Portanto, o processo invertÃ­vel $\tilde{Y}_t = (1 + \frac{1}{\theta} L)\tilde{\epsilon}_t$ com $\tilde{\sigma}^2 = \theta^2 \sigma^2$ tem a mesma funÃ§Ã£o geradora de autocovariÃ¢ncia que o processo original $Y_t$. â– 

**CorolÃ¡rio 1**
Para um processo MA(q), a funÃ§Ã£o de autocorrelaÃ§Ã£o (ACF) Ã© a mesma para a representaÃ§Ã£o invertÃ­vel e nÃ£o invertÃ­vel obtidas pelo procedimento de Hansen e Sargent.

**Prova do CorolÃ¡rio 1:**
I. A funÃ§Ã£o de autocorrelaÃ§Ã£o (ACF) Ã© definida como a autocovariÃ¢ncia dividida pela variÃ¢ncia: $\rho(k) = \frac{\gamma(k)}{\gamma(0)}$.

II. Pelo Teorema 1, as representaÃ§Ãµes invertÃ­vel e nÃ£o invertÃ­vel tÃªm a mesma funÃ§Ã£o de autocovariÃ¢ncia, $g_Y(z) = g_{\tilde{Y}}(z)$. Isso implica que as autocovariÃ¢ncias $\gamma(k)$ sÃ£o as mesmas para ambas as representaÃ§Ãµes.

III. A variÃ¢ncia Ã© um caso especial da autocovariÃ¢ncia quando $k=0$, ou seja, $\gamma(0)$. Como as autocovariÃ¢ncias sÃ£o as mesmas, as variÃ¢ncias tambÃ©m sÃ£o as mesmas.

IV. Portanto, como a ACF Ã© a autocovariÃ¢ncia dividida pela variÃ¢ncia, e ambas as representaÃ§Ãµes tÃªm a mesma autocovariÃ¢ncia e variÃ¢ncia, suas ACFs sÃ£o idÃªnticas. â– 

**Lema 1**
Seja $Y_t$ um processo MA(q) com coeficientes $\theta_1, \ldots, \theta_q$. A funÃ§Ã£o de autocovariÃ¢ncia $\gamma(k) = Cov(Y_t, Y_{t-k})$ Ã© dada por:

$$ \gamma(k) = \begin{cases}
\sigma^2 \sum_{i=0}^{q-k} \theta_i \theta_{i+k}, & 0 \leq k \leq q \\
0, & k > q
\end{cases}
$$
onde $\theta_0 = 1$.

*DemonstraÃ§Ã£o:* (EsboÃ§o) A demonstraÃ§Ã£o segue da definiÃ§Ã£o do processo MA(q) e das propriedades do ruÃ­do branco.

**Prova do Lema 1:**
I. Considere o processo MA(q): $Y_t = \mu + \epsilon_t + \theta_1\epsilon_{t-1} + \theta_2\epsilon_{t-2} + \ldots + \theta_q\epsilon_{t-q}$. Para simplificar, vamos assumir $\mu = 0$.

II. Queremos calcular a autocovariÃ¢ncia $\gamma(k) = E[(Y_t)(Y_{t-k})]$.

III. Substituindo a definiÃ§Ã£o de $Y_t$:
$$ \gamma(k) = E[(\epsilon_t + \theta_1\epsilon_{t-1} + \ldots + \theta_q\epsilon_{t-q})(\epsilon_{t-k} + \theta_1\epsilon_{t-k-1} + \ldots + \theta_q\epsilon_{t-k-q})] $$

IV. Expandindo e usando o fato de que $E[\epsilon_t \epsilon_{t-k}] = \sigma^2$ se $t = t-k$ (ou seja, $k=0$) e $0$ caso contrÃ¡rio:

V. Para $0 \leq k \leq q$:
$$ \gamma(k) = E[\epsilon_t \epsilon_{t-k} + \theta_1 \epsilon_{t-1} \epsilon_{t-k} + \ldots + \theta_{q-k} \epsilon_{t-q+k} \epsilon_{t-k} + \ldots + \theta_q \epsilon_{t-q} \epsilon_{t-k}] $$
$$+ E[\theta_1 \epsilon_{t-1} \epsilon_{t-k} + \theta_1\theta_1 \epsilon_{t-1} \epsilon_{t-k-1} + \ldots ] + \ldots$$
$$ \gamma(k) = \sigma^2 (\theta_k + \theta_1\theta_{k+1} + \theta_2\theta_{k+2} + \ldots + \theta_{q-k}\theta_q) = \sigma^2 \sum_{i=0}^{q-k} \theta_i \theta_{i+k}$$
Onde $\theta_0 = 1$.

> ğŸ’¡ **Exemplo NumÃ©rico:** Para um MA(1) com $\theta_1 = 0.7$ e $\sigma^2 = 1$, as autocovariÃ¢ncias sÃ£o:
> *   $\gamma(0) = \sigma^2 (1 + \theta_1^2) = 1 * (1 + 0.7^2) = 1.49$
> *   $\gamma(1) = \sigma^2 * \theta_1 = 1 * 0.7 = 0.7$
> *   $\gamma(k) = 0$ para $k > 1$
>
> Para um MA(2) com $\theta_1 = 0.5$, $\theta_2 = 0.3$ e $\sigma^2 = 1$, as autocovariÃ¢ncias sÃ£o:
> *   $\gamma(0) = \sigma^2 (1 + \theta_1^2 + \theta_2^2) = 1 * (1 + 0.5^2 + 0.3^2) = 1.34$
> *   $\gamma(1) = \sigma^2 (\theta_1 + \theta_1\theta_2) = 1 * (0.5 + 0.5 * 0.3) = 0.65$
> *   $\gamma(2) = \sigma^2 * \theta_2 = 1 * 0.3 = 0.3$
> *   $\gamma(k) = 0$ para $k > 2$

VI. Para $k > q$, nÃ£o hÃ¡ termos coincidentes, entÃ£o $\gamma(k) = 0$.

VII. Combinando os casos, obtemos:
$$ \gamma(k) = \begin{cases}
\sigma^2 \sum_{i=0}^{q-k} \theta_i \theta_{i+k}, & 0 \leq k \leq q \\
0, & k > q
\end{cases}
$$ â– 

**ObservaÃ§Ã£o:** A invertibilidade garante a unicidade da representaÃ§Ã£o AR(âˆ). Se o processo nÃ£o Ã© invertÃ­vel, existem mÃºltiplas representaÃ§Ãµes MA(q) com a mesma funÃ§Ã£o de autocovariÃ¢ncia.

**Exemplo**

Considere o processo MA(1) [^3.7.1, 3.7.4]:
$$ Y_t = \mu + (1 + \theta L)\epsilon_t $$
A condiÃ§Ã£o para invertibilidade Ã© $|\theta| < 1$. Se $|\theta| > 1$, podemos encontrar um processo nÃ£o invertÃ­vel
$$ \tilde{Y_t} = \mu + (1 + \tilde{\theta} L)\tilde{\epsilon_t} $$
com $\tilde{\theta} = 1/\theta$ e $\tilde{\sigma}^2 = \theta^2 \sigma^2$ [^3.7.6, 3.7.7], que terÃ¡ a mesma funÃ§Ã£o geradora de autocovariÃ¢ncia que o processo original [^3.7.5]:

$$g_Y(z) = \sigma^2 (1 + \theta z)(1 + \theta z^{-1})$$
$$g_{\tilde{Y}}(z) = \tilde{\sigma}^2 (1 + \tilde{\theta} z)(1 + \tilde{\theta} z^{-1}) = \theta^2 \sigma^2 (1 + \theta^{-1} z)(1 + \theta^{-1} z^{-1}) = \sigma^2(1 + \theta z)(1 + \theta z^{-1})$$

Apesar de terem os mesmos momentos de primeira e segunda ordem, o processo invertÃ­vel e o nÃ£o invertÃ­vel sÃ£o distintos [^3.7.15]. No entanto, se o objetivo for apenas modelar a dependÃªncia de primeira e segunda ordem, ambas as representaÃ§Ãµes sÃ£o igualmente vÃ¡lidas [^3.7.15].

> ğŸ’¡ **Exemplo NumÃ©rico:** Seja $\theta = 2$ e $\sigma^2 = 1$.  O processo original Ã© $Y_t = \epsilon_t + 2\epsilon_{t-1}$, que nÃ£o Ã© invertÃ­vel. O processo invertÃ­vel correspondente Ã© $\tilde{Y}_t = \tilde{\epsilon}_t + 0.5\tilde{\epsilon}_{t-1}$, onde $\tilde{\sigma}^2 = 4$.  As autocovariÃ¢ncias para o processo original sÃ£o $\gamma_0 = 5$ e $\gamma_1 = 2$. As autocovariÃ¢ncias para o processo invertÃ­vel sÃ£o $\gamma_0 = 4(1 + 0.5^2) = 5$ e $\gamma_1 = 4(0.5) = 2$.  Como esperado, as autocovariÃ¢ncias sÃ£o as mesmas.

### ConclusÃ£o
A invertibilidade Ã© uma propriedade crucial de processos MA(q), garantindo que eles possam ser expressos como processos AR(âˆ) [^3.7.12]. A condiÃ§Ã£o de invertibilidade Ã© satisfeita quando as raÃ­zes do polinÃ´mio caracterÃ­stico estÃ£o fora do cÃ­rculo unitÃ¡rio [^3.7.13]. Se um processo MA(q) nÃ£o for invertÃ­vel, podemos encontrar uma representaÃ§Ã£o invertÃ­vel que compartilhe a mesma funÃ§Ã£o de geraÃ§Ã£o de autocovariÃ¢ncia [^3.7.15]. No entanto, Ã© importante notar que o processo invertÃ­vel Ã© distinto do processo original nÃ£o invertÃ­vel, e a escolha entre os dois pode depender dos objetivos da anÃ¡lise, especialmente se for necessÃ¡rio calcular os valores presentes do ruÃ­do a partir de valores futuros da sÃ©rie [^3.7.11]. A compreensÃ£o da invertibilidade Ã© essencial para a correta especificaÃ§Ã£o e interpretaÃ§Ã£o de modelos MA(q).

### ReferÃªncias
[^3.7.1]: Yâ‚ = Î¼ + (1 + Î¸L)Îµ,,
[^3.7.3]: gy(z) = ÏƒÂ²(1 + Î¸z)(1 + Î¸z-1).
[^3.7.4]: á»¸, - Î¼ = (1 + 0L)á»….
[^3.7.5]: g(z) = 2(1 + z)(1 + -1).
[^3.7.6]:  0 = 6-1
[^3.7.7]:  2 = 0262.
[^3.7.11]: á¼”â‚ = Î¸(Y1+1 â€“ Î¼) â€“ Î¸Â² (Y1+2 â€“ Î¼) + 03 (Y1+3 - Î¼) -Â·Â·Â·,
[^3.7.12]: (Î¥, â€“ Î¼) = (1 + 0â‚L + 02LÂ² + Â·Â·Â· + Î¸Î±LÂº)Îµ,,
[^3.7.13]: (1 + O + O22Â² + Â·Â·Â· + 029) = 0
[^3.7.14]: (1 + 0â‚L + 0â‚‚LÂ² + + Oâ€LÂº) = (1 - 1)(1 â€“ AL)Â·Â·Â· (1 â€“ AL).
[^3.7.15]: gy(z) = ÏƒÂ². {(1 â€“ Î»â‚z)(1 â€“ Î»â‚‚z)Â·Â·Â· (1 â€“ Î»Ä…z)} Ã— {(1 â€“ Î»â‚z-1)(1 - Î»â‚‚z-1)Â·Â·Â· (1 â€“ AzÂ¯Â¹)}.
<!-- END -->