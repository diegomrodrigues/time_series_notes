## Invertibilidade em Processos MA(q)

### Introdu√ß√£o
Este cap√≠tulo explora o conceito de **invertibilidade** em processos Moving Average (MA) de ordem *q*. A invertibilidade est√° intrinsecamente ligada √† representa√ß√£o de um processo MA(q) como um processo Autoregressivo (AR) de ordem infinita [^3.7.12]. Investigaremos as condi√ß√µes sob as quais um processo MA(q) pode ser invertido, com foco na localiza√ß√£o das ra√≠zes do polin√¥mio caracter√≠stico associado. Al√©m disso, discutiremos as implica√ß√µes da n√£o invertibilidade e as alternativas para modelar processos MA(q) n√£o invert√≠veis.

### Conceitos Fundamentais

Um processo MA(q) √© definido como [^3.7.12]:

$$ (Y_t - \mu) = (1 + \theta_1L + \theta_2L^2 + \ldots + \theta_qL^q)\epsilon_t $$

onde $Y_t$ √© a s√©rie temporal, $\mu$ √© a m√©dia, $\theta_i$ s√£o os coeficientes do processo MA(q), $L$ √© o operador de *lag*, e $\epsilon_t$ √© um ru√≠do branco com m√©dia zero e vari√¢ncia $\sigma^2$, ou seja, $E(\epsilon_t\epsilon_\tau) = \sigma^2$ se $t = \tau$ e $0$ caso contr√°rio.

> üí° **Exemplo Num√©rico:** Considere um processo MA(1) com $\mu = 0$, $\theta_1 = 0.7$ e $\sigma^2 = 1$. Ent√£o, $Y_t = \epsilon_t + 0.7\epsilon_{t-1}$.  Se $\epsilon_t$ s√£o valores aleat√≥rios extra√≠dos de uma distribui√ß√£o normal padr√£o, podemos simular os valores de $Y_t$.

A **invertibilidade** de um processo MA(q) significa que ele pode ser expresso como um processo AR(‚àû) [^3.7.12]:

$$ (1 + \eta_1L + \eta_2L^2 + \eta_3L^3 + \ldots)(Y_t - \mu) = \epsilon_t $$

onde $\eta_i$ s√£o os coeficientes do processo AR(‚àû).

Para que a representa√ß√£o AR(‚àû) seja v√°lida e bem definida, o operador MA deve ser invert√≠vel. Isso requer que as **ra√≠zes** da equa√ß√£o caracter√≠stica do processo MA [^3.7.13]:

$$ (1 + \theta_1z + \theta_2z^2 + \ldots + \theta_qz^q) = 0 $$

estejam *fora* do c√≠rculo unit√°rio no plano complexo [^3.7.13]. Em outras palavras, se $z_i$ for uma raiz da equa√ß√£o, ent√£o $|z_i| > 1$ para todo $i$.

> üí° **Exemplo Num√©rico:**  Considere novamente o processo MA(1) com $\theta_1 = 0.7$. A equa√ß√£o caracter√≠stica √© $1 + 0.7z = 0$, ent√£o $z = -1/0.7 \approx -1.43$. Como $|-1.43| > 1$, a condi√ß√£o de invertibilidade √© satisfeita.  Agora, se $\theta_1 = 2$, ent√£o $z = -1/2 = -0.5$, e $|-0.5| < 1$, o que significa que o processo n√£o √© invert√≠vel.

Se todas as ra√≠zes estiverem fora do c√≠rculo unit√°rio, ent√£o a representa√ß√£o MA(q) √© invert√≠vel, e podemos encontrar os coeficientes $\eta_i$ da representa√ß√£o AR(‚àû). Caso contr√°rio, a representa√ß√£o MA(q) n√£o √© invert√≠vel [^3.7.13].

Podemos fatorar o operador MA como [^3.7.14]:

$$ (1 + \theta_1L + \theta_2L^2 + \ldots + \theta_qL^q) = (1 - \lambda_1L)(1 - \lambda_2L)\ldots(1 - \lambda_qL) $$

onde $\lambda_i$ s√£o as ra√≠zes inversas da equa√ß√£o caracter√≠stica (ou seja, $\lambda_i = 1/z_i$). A condi√ß√£o de invertibilidade √© ent√£o equivalente a $|\lambda_i| < 1$ para todo $i$ [^3.7.14].

> üí° **Exemplo Num√©rico:** Retomando o exemplo do MA(1) com $\theta_1 = 0.7$, a raiz inversa √© $\lambda = -1/\theta_1 = -1/0.7 \approx -1.43$.  No entanto, devemos considerar $\lambda_i = 1/z_i$, ent√£o $\lambda = 1/(-1/0.7) = -0.7$. Como $|-0.7| < 1$, a condi√ß√£o de invertibilidade √© satisfeita. Se $\theta_1 = 2$, ent√£o $\lambda = -0.5$, e $|-0.5| < 1$, o que *ainda* satisfaz a condi√ß√£o de invertibilidade *na defini√ß√£o com as ra√≠zes inversas*.  Portanto, √© importante lembrar que a condi√ß√£o $|\lambda_i| < 1$ se refere √†s *ra√≠zes inversas*.

**Proposi√ß√£o 1**
Seja $\Theta(L) = (1 + \theta_1L + \theta_2L^2 + \ldots + \theta_qL^q)$ um operador MA(q). Ent√£o, o processo MA(q) definido por $\Theta(L)\epsilon_t$ √© invert√≠vel se e somente se $|\lambda_i| < 1$ para todo $i$, onde $\lambda_i$ s√£o as ra√≠zes inversas de $\Theta(z) = 0$.

Se alguns dos $|\lambda_i| > 1$, o processo n√£o √© invert√≠vel. Hansen e Sargent (1981) propuseram um procedimento para encontrar uma representa√ß√£o invert√≠vel neste caso, substituindo as ra√≠zes $\lambda_i$ que est√£o fora do c√≠rculo unit√°rio por seus inversos $1/\lambda_i$ [^3.7.15].

O processo de substitui√ß√£o das ra√≠zes externas pelo seus inversos resulta em uma nova representa√ß√£o do MA(q) que √© invert√≠vel e tem a mesma fun√ß√£o geradora de autocovari√¢ncia que a representa√ß√£o original n√£o invert√≠vel [^3.7.15]. Portanto, os primeiros dois momentos do processo (m√©dia e autocovari√¢ncias) permanecem inalterados [^3.7.3, 3.7.5].

**Teorema 1**
Seja $Y_t = (1 + \theta_1L + \theta_2L^2 + \ldots + \theta_qL^q)\epsilon_t$ um processo MA(q) com fun√ß√£o geradora de autocovari√¢ncia $g_Y(z)$. Se algumas ra√≠zes inversas $\lambda_i$ do polin√¥mio caracter√≠stico satisfazem $|\lambda_i| > 1$, ent√£o existe um processo invert√≠vel $\tilde{Y}_t = (1 + \tilde{\theta}_1L + \tilde{\theta}_2L^2 + \ldots + \tilde{\theta}_qL^q)\tilde{\epsilon}_t$ com fun√ß√£o geradora de autocovari√¢ncia $g_{\tilde{Y}}(z) = g_Y(z)$.

*Demonstra√ß√£o:* (Esbo√ßo) A demonstra√ß√£o segue o procedimento de Hansen e Sargent (1981), substituindo as ra√≠zes inversas $\lambda_i$ tais que $|\lambda_i| > 1$ por $1/\lambda_i$. Ajustando a vari√¢ncia do ru√≠do branco, obt√©m-se um processo com a mesma fun√ß√£o geradora de autocovari√¢ncia.

**Prova do Teorema 1:**
Para simplificar, vamos considerar um processo MA(1), mas a l√≥gica pode ser estendida para MA(q).
I. Seja $Y_t = (1 + \theta L)\epsilon_t$ um processo MA(1), onde $\epsilon_t$ √© ru√≠do branco com vari√¢ncia $\sigma^2$.

II. A raiz inversa do polin√¥mio caracter√≠stico √© $\lambda = -\frac{1}{\theta}$. Se $|\lambda| > 1$, ent√£o $|\theta| < 1$ (o processo j√° √© invert√≠vel). Consideremos o caso onde $|\lambda| < 1$, ent√£o $|\theta| > 1$.

> üí° **Exemplo Num√©rico:** Se $\theta = 2$, ent√£o $\lambda = -1/2 = -0.5$, e $|\lambda| = 0.5 < 1$, o que indica que o processo *n√£o* √© invert√≠vel na formula√ß√£o original, ou seja, para express√°-lo como uma combina√ß√£o *passada* do ru√≠do branco.

III. Seguindo Hansen e Sargent, constru√≠mos um novo processo $\tilde{Y}_t = (1 + \tilde{\theta} L)\tilde{\epsilon}_t$ com $\tilde{\theta} = \frac{1}{\theta}$.  Agora $|\tilde{\theta}| < 1$, garantindo a invertibilidade.

> üí° **Exemplo Num√©rico:** Se $\theta = 2$, ent√£o $\tilde{\theta} = 1/2 = 0.5$, e $|\tilde{\theta}| = 0.5 < 1$. Isso significa que o processo transformado √© invert√≠vel.

IV. Precisamos mostrar que a fun√ß√£o geradora de autocovari√¢ncia de $\tilde{Y}_t$ √© a mesma que a de $Y_t$. A fun√ß√£o geradora de autocovari√¢ncia de $Y_t$ √©:
$$g_Y(z) = \sigma^2 (1 + \theta z)(1 + \theta z^{-1}) = \sigma^2 (1 + \theta z + \theta z^{-1} + \theta^2)$$

V. A fun√ß√£o geradora de autocovari√¢ncia de $\tilde{Y}_t$ √©:
$$g_{\tilde{Y}}(z) = \tilde{\sigma}^2 (1 + \tilde{\theta} z)(1 + \tilde{\theta} z^{-1}) = \tilde{\sigma}^2 (1 + \frac{1}{\theta} z)(1 + \frac{1}{\theta} z^{-1}) = \tilde{\sigma}^2 (1 + \frac{1}{\theta} z + \frac{1}{\theta} z^{-1} + \frac{1}{\theta^2})$$

VI. Para que $g_Y(z) = g_{\tilde{Y}}(z)$, precisamos que:
$$ \sigma^2 (1 + \theta z + \theta z^{-1} + \theta^2) = \tilde{\sigma}^2 (1 + \frac{1}{\theta} z + \frac{1}{\theta} z^{-1} + \frac{1}{\theta^2})$$
Isto √© satisfeito se $\tilde{\sigma}^2 = \theta^2 \sigma^2$.

> üí° **Exemplo Num√©rico:** Se $\theta = 2$ e $\sigma^2 = 1$, ent√£o $\tilde{\sigma}^2 = 2^2 * 1 = 4$. Portanto, o processo invert√≠vel √© $\tilde{Y}_t = (1 + 0.5L)\tilde{\epsilon}_t$, onde $\tilde{\epsilon}_t$ tem vari√¢ncia 4.

VII. Portanto, o processo invert√≠vel $\tilde{Y}_t = (1 + \frac{1}{\theta} L)\tilde{\epsilon}_t$ com $\tilde{\sigma}^2 = \theta^2 \sigma^2$ tem a mesma fun√ß√£o geradora de autocovari√¢ncia que o processo original $Y_t$. ‚ñ†

**Corol√°rio 1**
Para um processo MA(q), a fun√ß√£o de autocorrela√ß√£o (ACF) √© a mesma para a representa√ß√£o invert√≠vel e n√£o invert√≠vel obtidas pelo procedimento de Hansen e Sargent.

**Prova do Corol√°rio 1:**
I. A fun√ß√£o de autocorrela√ß√£o (ACF) √© definida como a autocovari√¢ncia dividida pela vari√¢ncia: $\rho(k) = \frac{\gamma(k)}{\gamma(0)}$.

II. Pelo Teorema 1, as representa√ß√µes invert√≠vel e n√£o invert√≠vel t√™m a mesma fun√ß√£o de autocovari√¢ncia, $g_Y(z) = g_{\tilde{Y}}(z)$. Isso implica que as autocovari√¢ncias $\gamma(k)$ s√£o as mesmas para ambas as representa√ß√µes.

III. A vari√¢ncia √© um caso especial da autocovari√¢ncia quando $k=0$, ou seja, $\gamma(0)$. Como as autocovari√¢ncias s√£o as mesmas, as vari√¢ncias tamb√©m s√£o as mesmas.

IV. Portanto, como a ACF √© a autocovari√¢ncia dividida pela vari√¢ncia, e ambas as representa√ß√µes t√™m a mesma autocovari√¢ncia e vari√¢ncia, suas ACFs s√£o id√™nticas. ‚ñ†

**Lema 1**
Seja $Y_t$ um processo MA(q) com coeficientes $\theta_1, \ldots, \theta_q$. A fun√ß√£o de autocovari√¢ncia $\gamma(k) = Cov(Y_t, Y_{t-k})$ √© dada por:

$$ \gamma(k) = \begin{cases}
\sigma^2 \sum_{i=0}^{q-k} \theta_i \theta_{i+k}, & 0 \leq k \leq q \\
0, & k > q
\end{cases}
$$
onde $\theta_0 = 1$.

*Demonstra√ß√£o:* (Esbo√ßo) A demonstra√ß√£o segue da defini√ß√£o do processo MA(q) e das propriedades do ru√≠do branco.

**Prova do Lema 1:**
I. Considere o processo MA(q): $Y_t = \mu + \epsilon_t + \theta_1\epsilon_{t-1} + \theta_2\epsilon_{t-2} + \ldots + \theta_q\epsilon_{t-q}$. Para simplificar, vamos assumir $\mu = 0$.

II. Queremos calcular a autocovari√¢ncia $\gamma(k) = E[(Y_t)(Y_{t-k})]$.

III. Substituindo a defini√ß√£o de $Y_t$:
$$ \gamma(k) = E[(\epsilon_t + \theta_1\epsilon_{t-1} + \ldots + \theta_q\epsilon_{t-q})(\epsilon_{t-k} + \theta_1\epsilon_{t-k-1} + \ldots + \theta_q\epsilon_{t-k-q})] $$

IV. Expandindo e usando o fato de que $E[\epsilon_t \epsilon_{t-k}] = \sigma^2$ se $t = t-k$ (ou seja, $k=0$) e $0$ caso contr√°rio:

V. Para $0 \leq k \leq q$:
$$ \gamma(k) = E[\epsilon_t \epsilon_{t-k} + \theta_1 \epsilon_{t-1} \epsilon_{t-k} + \ldots + \theta_{q-k} \epsilon_{t-q+k} \epsilon_{t-k} + \ldots + \theta_q \epsilon_{t-q} \epsilon_{t-k}] $$
$$+ E[\theta_1 \epsilon_{t-1} \epsilon_{t-k} + \theta_1\theta_1 \epsilon_{t-1} \epsilon_{t-k-1} + \ldots ] + \ldots$$
$$ \gamma(k) = \sigma^2 (\theta_k + \theta_1\theta_{k+1} + \theta_2\theta_{k+2} + \ldots + \theta_{q-k}\theta_q) = \sigma^2 \sum_{i=0}^{q-k} \theta_i \theta_{i+k}$$
Onde $\theta_0 = 1$.

> üí° **Exemplo Num√©rico:** Para um MA(1) com $\theta_1 = 0.7$ e $\sigma^2 = 1$, as autocovari√¢ncias s√£o:
> *   $\gamma(0) = \sigma^2 (1 + \theta_1^2) = 1 * (1 + 0.7^2) = 1.49$
> *   $\gamma(1) = \sigma^2 * \theta_1 = 1 * 0.7 = 0.7$
> *   $\gamma(k) = 0$ para $k > 1$
>
> Para um MA(2) com $\theta_1 = 0.5$, $\theta_2 = 0.3$ e $\sigma^2 = 1$, as autocovari√¢ncias s√£o:
> *   $\gamma(0) = \sigma^2 (1 + \theta_1^2 + \theta_2^2) = 1 * (1 + 0.5^2 + 0.3^2) = 1.34$
> *   $\gamma(1) = \sigma^2 (\theta_1 + \theta_1\theta_2) = 1 * (0.5 + 0.5 * 0.3) = 0.65$
> *   $\gamma(2) = \sigma^2 * \theta_2 = 1 * 0.3 = 0.3$
> *   $\gamma(k) = 0$ para $k > 2$

VI. Para $k > q$, n√£o h√° termos coincidentes, ent√£o $\gamma(k) = 0$.

VII. Combinando os casos, obtemos:
$$ \gamma(k) = \begin{cases}
\sigma^2 \sum_{i=0}^{q-k} \theta_i \theta_{i+k}, & 0 \leq k \leq q \\
0, & k > q
\end{cases}
$$ ‚ñ†

**Observa√ß√£o:** A invertibilidade garante a unicidade da representa√ß√£o AR(‚àû). Se o processo n√£o √© invert√≠vel, existem m√∫ltiplas representa√ß√µes MA(q) com a mesma fun√ß√£o de autocovari√¢ncia.

**Exemplo**

Considere o processo MA(1) [^3.7.1, 3.7.4]:
$$ Y_t = \mu + (1 + \theta L)\epsilon_t $$
A condi√ß√£o para invertibilidade √© $|\theta| < 1$. Se $|\theta| > 1$, podemos encontrar um processo n√£o invert√≠vel
$$ \tilde{Y_t} = \mu + (1 + \tilde{\theta} L)\tilde{\epsilon_t} $$
com $\tilde{\theta} = 1/\theta$ e $\tilde{\sigma}^2 = \theta^2 \sigma^2$ [^3.7.6, 3.7.7], que ter√° a mesma fun√ß√£o geradora de autocovari√¢ncia que o processo original [^3.7.5]:

$$g_Y(z) = \sigma^2 (1 + \theta z)(1 + \theta z^{-1})$$
$$g_{\tilde{Y}}(z) = \tilde{\sigma}^2 (1 + \tilde{\theta} z)(1 + \tilde{\theta} z^{-1}) = \theta^2 \sigma^2 (1 + \theta^{-1} z)(1 + \theta^{-1} z^{-1}) = \sigma^2(1 + \theta z)(1 + \theta z^{-1})$$

Apesar de terem os mesmos momentos de primeira e segunda ordem, o processo invert√≠vel e o n√£o invert√≠vel s√£o distintos [^3.7.15]. No entanto, se o objetivo for apenas modelar a depend√™ncia de primeira e segunda ordem, ambas as representa√ß√µes s√£o igualmente v√°lidas [^3.7.15].

> üí° **Exemplo Num√©rico:** Seja $\theta = 2$ e $\sigma^2 = 1$.  O processo original √© $Y_t = \epsilon_t + 2\epsilon_{t-1}$, que n√£o √© invert√≠vel. O processo invert√≠vel correspondente √© $\tilde{Y}_t = \tilde{\epsilon}_t + 0.5\tilde{\epsilon}_{t-1}$, onde $\tilde{\sigma}^2 = 4$.  As autocovari√¢ncias para o processo original s√£o $\gamma_0 = 5$ e $\gamma_1 = 2$. As autocovari√¢ncias para o processo invert√≠vel s√£o $\gamma_0 = 4(1 + 0.5^2) = 5$ e $\gamma_1 = 4(0.5) = 2$.  Como esperado, as autocovari√¢ncias s√£o as mesmas.

### Conclus√£o
A invertibilidade √© uma propriedade crucial de processos MA(q), garantindo que eles possam ser expressos como processos AR(‚àû) [^3.7.12]. A condi√ß√£o de invertibilidade √© satisfeita quando as ra√≠zes do polin√¥mio caracter√≠stico est√£o fora do c√≠rculo unit√°rio [^3.7.13]. Se um processo MA(q) n√£o for invert√≠vel, podemos encontrar uma representa√ß√£o invert√≠vel que compartilhe a mesma fun√ß√£o de gera√ß√£o de autocovari√¢ncia [^3.7.15]. No entanto, √© importante notar que o processo invert√≠vel √© distinto do processo original n√£o invert√≠vel, e a escolha entre os dois pode depender dos objetivos da an√°lise, especialmente se for necess√°rio calcular os valores presentes do ru√≠do a partir de valores futuros da s√©rie [^3.7.11]. A compreens√£o da invertibilidade √© essencial para a correta especifica√ß√£o e interpreta√ß√£o de modelos MA(q).

### Refer√™ncias
[^3.7.1]: Y‚ÇÅ = Œº + (1 + Œ∏L)Œµ,,
[^3.7.3]: gy(z) = œÉ¬≤(1 + Œ∏z)(1 + Œ∏z-1).
[^3.7.4]: ·ª∏, - Œº = (1 + 0L)·ªÖ.
[^3.7.5]: g(z) = 2(1 + z)(1 + -1).
[^3.7.6]:  0 = 6-1
[^3.7.7]:  2 = 0262.
[^3.7.11]: ·ºî‚ÇÅ = Œ∏(Y1+1 ‚Äì Œº) ‚Äì Œ∏¬≤ (Y1+2 ‚Äì Œº) + 03 (Y1+3 - Œº) -¬∑¬∑¬∑,
[^3.7.12]: (Œ•, ‚Äì Œº) = (1 + 0‚ÇÅL + 02L¬≤ + ¬∑¬∑¬∑ + Œ∏Œ±L¬∫)Œµ,,
[^3.7.13]: (1 + O + O22¬≤ + ¬∑¬∑¬∑ + 029) = 0
[^3.7.14]: (1 + 0‚ÇÅL + 0‚ÇÇL¬≤ + + O‚ÄûL¬∫) = (1 - 1)(1 ‚Äì AL)¬∑¬∑¬∑ (1 ‚Äì AL).
[^3.7.15]: gy(z) = œÉ¬≤. {(1 ‚Äì Œª‚ÇÅz)(1 ‚Äì Œª‚ÇÇz)¬∑¬∑¬∑ (1 ‚Äì ŒªƒÖz)} √ó {(1 ‚Äì Œª‚ÇÅz-1)(1 - Œª‚ÇÇz-1)¬∑¬∑¬∑ (1 ‚Äì Az¬Ø¬π)}.
<!-- END -->