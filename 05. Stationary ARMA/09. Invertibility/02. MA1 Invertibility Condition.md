## Invertibilidade em Processos MA(1)

### Introdu√ß√£o
Em continuidade ao estudo da invertibilidade de processos Moving Average (MA), este cap√≠tulo se aprofunda nas condi√ß√µes espec√≠ficas para que um processo MA de ordem 1 (MA(1)) seja invert√≠vel. Como vimos anteriormente [^An MA(q) process is invertible if it can be rewritten as an AR(‚àû) representation. This requires the roots of (1 + Œ∏1z + Œ∏2z¬≤ + ... + Œ∏qz^q) = 0 to lie outside the unit circle. ---], a invertibilidade √© crucial para a representa√ß√£o de um processo MA(q) como um processo Autoregressivo (AR) de ordem infinita. Analisaremos detalhadamente o caso MA(1), demonstrando que a condi√ß√£o necess√°ria e suficiente para a invertibilidade √© que o valor absoluto do coeficiente MA, denotado por $\theta$, seja menor que 1, ou seja, $|\theta| < 1$ [^For an MA(1) process, invertibility requires |Œ∏| < 1.]. Exploraremos as implica√ß√µes dessa condi√ß√£o e forneceremos exemplos ilustrativos.

### Conceitos Fundamentais

Um processo MA(1) √© definido como [^3.7.1]:

$$Y_t = \mu + \epsilon_t + \theta \epsilon_{t-1}$$

onde $Y_t$ √© a s√©rie temporal, $\mu$ √© a m√©dia, $\theta$ √© o coeficiente MA(1), e $\epsilon_t$ √© um ru√≠do branco com m√©dia zero e vari√¢ncia $\sigma^2$, ou seja, $E(\epsilon_t\epsilon_\tau) = \sigma^2$ se $t = \tau$ e $0$ caso contr√°rio.

> üí° **Exemplo Num√©rico:** Considere um processo MA(1) com $\mu = 0$, $\theta = 0.5$ e $\sigma^2 = 1$. Ent√£o, $Y_t = \epsilon_t + 0.5\epsilon_{t-1}$.  Se $\epsilon_t$ s√£o valores aleat√≥rios extra√≠dos de uma distribui√ß√£o normal padr√£o, podemos simular os valores de $Y_t$.

A **invertibilidade** de um processo MA(1) implica que podemos reescrever o processo na forma AR(‚àû):

$$Y_t - \mu = \epsilon_t + \theta\epsilon_{t-1}$$
$$\epsilon_t = (Y_t - \mu) - \theta \epsilon_{t-1}$$
Iterando recursivamente:
$$\epsilon_t = (Y_t - \mu) - \theta(Y_{t-1} - \mu) + \theta^2(Y_{t-2} - \mu) - \theta^3(Y_{t-3} - \mu) + \ldots$$

$$Y_t - \mu = \sum_{i=0}^{\infty} (-\theta)^i(Y_{t-i} - \mu)$$

Para que esta representa√ß√£o seja v√°lida, a sequ√™ncia $\sum_{i=0}^{\infty} (-\theta)^i$ deve convergir. Isso ocorre se e somente se $|\theta| < 1$.

**Teorema 2:** Um processo MA(1) $Y_t = \mu + \epsilon_t + \theta \epsilon_{t-1}$ √© invert√≠vel se e somente se $|\theta| < 1$.

*Demonstra√ß√£o:*

I. Assumindo que $|\theta| < 1$, podemos reescrever o processo MA(1) na forma AR(‚àû):

$$(1 + \theta L)\epsilon_t = (Y_t - \mu)$$
$$\epsilon_t = (1 + \theta L)^{-1}(Y_t - \mu)$$

II. Usando a expans√£o da s√©rie geom√©trica, temos:

$$(1 + \theta L)^{-1} = 1 - \theta L + \theta^2 L^2 - \theta^3 L^3 + \ldots = \sum_{i=0}^{\infty} (-\theta L)^i$$
Nota:  Esta expans√£o √© v√°lida apenas se $|-\theta L| < 1$, o que √© equivalente a $|\theta| < 1$.  $L$ √© o operador de defasagem.

III. Portanto:

$$\epsilon_t = (Y_t - \mu) - \theta(Y_{t-1} - \mu) + \theta^2(Y_{t-2} - \mu) - \theta^3(Y_{t-3} - \mu) + \ldots = \sum_{i=0}^{\infty} (-\theta)^i(Y_{t-i} - \mu)$$

Como $|\theta| < 1$, a s√©rie converge absolutamente, e a representa√ß√£o AR(‚àû) √© v√°lida.

IV. Agora, suponha que $|\theta| \geq 1$.  Neste caso, a expans√£o da s√©rie geom√©trica $\sum_{i=0}^{\infty} (-\theta)^i$ diverge. Isso significa que a representa√ß√£o AR(‚àû) n√£o converge, e o processo MA(1) n√£o √© invert√≠vel.

Portanto, um processo MA(1) √© invert√≠vel se e somente se $|\theta| < 1$. $\blacksquare$

> üí° **Exemplo Num√©rico:**  Considere o processo $Y_t = \epsilon_t + 0.8 \epsilon_{t-1}$. Como $|\theta| = |0.8| < 1$, o processo √© invert√≠vel.  A representa√ß√£o AR(‚àû) √©:
>
> $$\epsilon_t = (Y_t - \mu) - 0.8(Y_{t-1} - \mu) + 0.8^2(Y_{t-2} - \mu) - 0.8^3(Y_{t-3} - \mu) + \ldots$$
>
> Agora, considere o processo $Y_t = \epsilon_t + 1.2 \epsilon_{t-1}$. Como $|\theta| = |1.2| > 1$, o processo n√£o √© invert√≠vel. A expans√£o da s√©rie AR(‚àû) divergir√°, tornando a representa√ß√£o inv√°lida.
> ```python
> import numpy as np
>
> # Exemplo de converg√™ncia vs diverg√™ncia
> theta_invertivel = 0.8
> theta_nao_invertivel = 1.2
>
> # Calculando os primeiros termos da expans√£o AR(inf) para ambos os casos
> termos_invertivel = [(-theta_invertivel)**i for i in range(10)]
> termos_nao_invertivel = [(-theta_nao_invertivel)**i for i in range(10)]
>
> # Imprimindo os resultados
> print("Termos da expans√£o para theta = 0.8 (invert√≠vel):", termos_invertivel)
> print("Termos da expans√£o para theta = 1.2 (n√£o invert√≠vel):", termos_nao_invertivel)
>
> # Calculando as somas parciais
> soma_parcial_invertivel = np.cumsum(termos_invertivel)
> soma_parcial_nao_invertivel = np.cumsum(termos_nao_invertivel)
>
> # Imprimindo as somas parciais
> print("Somas parciais para theta = 0.8 (invert√≠vel):", soma_parcial_invertivel)
> print("Somas parciais para theta = 1.2 (n√£o invert√≠vel):", soma_parcial_nao_invertivel)
>
> # A soma parcial para theta = 0.8 tende a convergir, enquanto a soma para theta = 1.2 diverge
> ```

**Teorema 2.1:** Dado um processo MA(1) n√£o invert√≠vel $Y_t = \mu + \epsilon_t + \theta \epsilon_{t-1}$ com $|\theta| > 1$, existe um processo MA(1) invert√≠vel equivalente $\tilde{Y}_t = \mu + \tilde{\epsilon}_t + \tilde{\theta} \tilde{\epsilon}_{t-1}$ onde $\tilde{\theta} = \frac{1}{\theta}$ e $Var(\tilde{\epsilon}_t) = \theta^2 Var(\epsilon_t)$, tal que ambos os processos possuem a mesma fun√ß√£o de autocovari√¢ncia.

*Demonstra√ß√£o:*

I. Seja $Y_t = \mu + \epsilon_t + \theta \epsilon_{t-1}$. A fun√ß√£o de autocovari√¢ncia para este processo √©:
$\gamma_0 = (1 + \theta^2)\sigma^2$
$\gamma_1 = \theta \sigma^2$
$\gamma_k = 0$, para $|k| > 1$.

II. Agora, considere o processo $\tilde{Y}_t = \mu + \tilde{\epsilon}_t + \tilde{\theta} \tilde{\epsilon}_{t-1}$, onde $\tilde{\theta} = \frac{1}{\theta}$ e $Var(\tilde{\epsilon}_t) = \tilde{\sigma}^2 = \theta^2 \sigma^2$. A fun√ß√£o de autocovari√¢ncia para este processo √©:
$\tilde{\gamma}_0 = (1 + \tilde{\theta}^2)\tilde{\sigma}^2 = (1 + \frac{1}{\theta^2})\theta^2 \sigma^2 = (\theta^2 + 1)\sigma^2 = \gamma_0$
$\tilde{\gamma}_1 = \tilde{\theta} \tilde{\sigma}^2 = \frac{1}{\theta} \theta^2 \sigma^2 = \theta \sigma^2 = \gamma_1$
$\tilde{\gamma}_k = 0$, para $|k| > 1$.

III. Portanto, os dois processos possuem a mesma fun√ß√£o de autocovari√¢ncia. Al√©m disso, como $|\theta| > 1$, ent√£o $|\tilde{\theta}| = |\frac{1}{\theta}| < 1$, o que implica que $\tilde{Y}_t$ √© invert√≠vel. $\blacksquare$

> üí° **Exemplo Num√©rico:**  Seja $Y_t = \epsilon_t + 2 \epsilon_{t-1}$, onde $\sigma^2 = Var(\epsilon_t) = 1$.  Ent√£o $\theta = 2$.
> $\gamma_0 = (1 + 2^2)(1) = 5$
> $\gamma_1 = 2(1) = 2$
>
> Agora, considere o processo invert√≠vel equivalente: $\tilde{Y}_t = \tilde{\epsilon}_t + 0.5 \tilde{\epsilon}_{t-1}$, onde $Var(\tilde{\epsilon}_t) = \tilde{\sigma}^2 = 2^2 (1) = 4$.  Ent√£o $\tilde{\theta} = 0.5$.
> $\tilde{\gamma}_0 = (1 + 0.5^2)(4) = (1 + 0.25)(4) = 5$
> $\tilde{\gamma}_1 = 0.5(4) = 2$
>
> Observe que $\gamma_0 = \tilde{\gamma}_0$ e $\gamma_1 = \tilde{\gamma}_1$, demonstrando que ambos os processos possuem a mesma fun√ß√£o de autocovari√¢ncia.

No caso em que $|\theta| > 1$, podemos sempre encontrar uma representa√ß√£o invert√≠vel equivalente, como demonstrado anteriormente [^3.7.6, 3.7.7].

### Implica√ß√µes da N√£o Invertibilidade

Quando um processo MA(1) n√£o √© invert√≠vel (ou seja, $|\theta| \geq 1$), a representa√ß√£o AR(‚àû) n√£o converge, e o processo n√£o pode ser expresso como uma fun√ß√£o linear ponderada das suas pr√≥prias *defasagens*. Isso tem implica√ß√µes pr√°ticas na estima√ß√£o e previs√£o do processo [^3.7.15].

Embora um processo MA(1) n√£o invert√≠vel compartilhe a mesma fun√ß√£o geradora de autocovari√¢ncia com um processo MA(1) invert√≠vel, como vimos na se√ß√£o anterior, √© fundamental reconhecer que as implica√ß√µes pr√°ticas s√£o diferentes [^3.7.15].

**Exemplo:**

Considere um processo gerado por $Y_t = \epsilon_t + 2\epsilon_{t-1}$, que n√£o √© invert√≠vel (j√° que $|\theta| = 2 > 1$). Podemos encontrar um processo invert√≠vel correspondente:
$$\tilde{Y_t} = \tilde{\epsilon_t} + 0.5 \tilde{\epsilon_{t-1}}$$
Onde $E[\tilde{\epsilon_t}^2] = \tilde{\sigma}^2 = 4 \sigma^2$.

Se quisermos calcular o valor de $\epsilon_t$ dado um n√∫mero infinito de observa√ß√µes *passadas* de $Y_t$, s√≥ podemos faz√™-lo usando a representa√ß√£o invert√≠vel, pois a representa√ß√£o n√£o invert√≠vel levar√° a uma s√©rie divergente.  Por outro lado, se tiv√©ssemos acesso a um n√∫mero infinito de observa√ß√µes *futuras* de $Y_t$, poder√≠amos construir o ru√≠do a partir da representa√ß√£o n√£o invert√≠vel.

Al√©m disso, a estimativa de par√¢metros para modelos MA(1) n√£o invert√≠veis pode ser problem√°tica. M√©todos de estima√ß√£o como m√°xima verossimilhan√ßa podem ter dificuldades em convergir ou podem levar a estimativas inst√°veis.

> üí° **Exemplo Num√©rico:** Simula√ß√£o de m√°xima verossimilhan√ßa para modelos invert√≠veis e n√£o invert√≠veis.
> ```python
> import numpy as np
> import statsmodels.api as sm
> from statsmodels.tsa.arima.model import ARIMA
>
> # Simula√ß√£o de dados MA(1)
> def simulate_ma1(theta, sigma, n):
>     epsilon = np.random.normal(0, sigma, n)
>     Y = np.zeros(n)
>     Y[0] = epsilon[0]
>     for t in range(1, n):
>         Y[t] = epsilon[t] + theta * epsilon[t-1]
>     return Y
>
> # Par√¢metros
> n = 200
> sigma = 1
>
> # Caso invert√≠vel
> theta_invertible = 0.5
> Y_invertible = simulate_ma1(theta_invertible, sigma, n)
>
> # Caso n√£o invert√≠vel
> theta_non_invertible = 1.5
> Y_non_invertible = simulate_ma1(theta_non_invertible, sigma, n)
>
> # Estima√ß√£o por m√°xima verossimilhan√ßa
> # Modelo invert√≠vel
> model_invertible = ARIMA(Y_invertible, order=(0, 0, 1)) # MA(1)
> results_invertible = model_invertible.fit()
>
> # Modelo n√£o invert√≠vel
> model_non_invertible = ARIMA(Y_non_invertible, order=(0, 0, 1)) # MA(1)
> results_non_invertible = model_non_invertible.fit()
>
> # Resultados
> print("Resultados para o modelo invert√≠vel (theta = 0.5):")
> print(results_invertible.summary())
>
> print("\nResultados para o modelo n√£o invert√≠vel (theta = 1.5):")
> print(results_non_invertible.summary())
>
> # An√°lise: Observar os erros padr√£o dos coeficientes e a signific√¢ncia estat√≠stica.
> # Problemas de converg√™ncia e estimativas inst√°veis podem ser observadas no modelo n√£o invert√≠vel
> ```
> Este c√≥digo simula dados de processos MA(1) invert√≠veis e n√£o invert√≠veis e, em seguida, ajusta um modelo ARIMA (que inclui MA) aos dados usando m√°xima verossimilhan√ßa. Ao examinar os resultados do resumo, preste aten√ß√£o aos erros padr√£o dos coeficientes e aos n√≠veis de signific√¢ncia. Em alguns casos, o modelo n√£o invert√≠vel pode encontrar dificuldades de converg√™ncia ou produzir estimativas de par√¢metros inst√°veis.

### Conclus√£o

A invertibilidade √© uma propriedade crucial de processos MA(1), determinada pela condi√ß√£o $|\theta| < 1$. Essa condi√ß√£o garante que o processo possa ser expresso como um processo AR(‚àû) convergente, permitindo a estimativa e previs√£o do processo [^3.7.15]. Quando um processo MA(1) n√£o √© invert√≠vel, podemos encontrar uma representa√ß√£o invert√≠vel equivalente que compartilhe a mesma fun√ß√£o geradora de autocovari√¢ncia, mas √© fundamental reconhecer as diferen√ßas pr√°ticas e implica√ß√µes da n√£o invertibilidade.
<!-- END -->