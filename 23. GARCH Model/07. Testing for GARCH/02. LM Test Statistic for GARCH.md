## O Teste LM para Efeitos GARCH: Detalhes da Estat√≠stica do Teste

### Introdu√ß√£o
Em continuidade √† discuss√£o sobre testes para efeitos GARCH (Generalized Autoregressive Conditional Heteroskedasticity), e aprofundando o conceito do Teste de Multiplicador de Lagrange (LM) introduzido no t√≥pico anterior, este cap√≠tulo se concentrar√° na estat√≠stica do teste LM propriamente dita, especificamente a estat√≠stica $\xi_{LM} = f_0'Z_0(Z_0'Z_0)^{-1}Z_0'f_0$ [^1]. Ser√£o detalhadas as componentes da estat√≠stica, sua deriva√ß√£o e interpreta√ß√£o, ressaltando as nuances e implica√ß√µes pr√°ticas para a modelagem de s√©ries temporais.

### Conceitos Fundamentais

Como estabelecido, o teste LM oferece uma abordagem formal para verificar a presen√ßa de efeitos GARCH, complementando ferramentas informais [^1]. A estat√≠stica do teste, $\xi_{LM}$, quantifica a signific√¢ncia da inclus√£o de par√¢metros GARCH em um modelo condicionalmente heterosced√°stico.

A estat√≠stica do teste LM para a hip√≥tese nula $H_0: \omega_2 = 0$, onde $\omega_2$ representa os par√¢metros GARCH que estamos testando, √© definida como [^1]:

$$
\xi_{LM} = f_0'Z_0(Z_0'Z_0)^{-1}Z_0'f_0
$$

Vamos analisar cada componente desta estat√≠stica:

1.  **O Vetor** $f_0$:

    Este vetor, $f_0 = (\epsilon_1^2h_1^{-1} - 1, ..., \epsilon_T^2h_T^{-1} - 1)'$, captura os desvios dos erros quadr√°ticos normalizados em rela√ß√£o ao valor esperado sob a hip√≥tese nula [^1]. Cada elemento deste vetor quantifica a diferen√ßa entre o erro quadr√°tico normalizado observado ($\epsilon_t^2h_t^{-1}$) e o valor esperado sob a hip√≥tese nula, que √© 1. Em outras palavras, $f_{0,t} = \epsilon_t^2h_t^{-1} - 1$ mede o qu√£o bem a vari√¢ncia condicional estimada sob a hip√≥tese nula ($h_t$) se alinha com o erro quadr√°tico observado ($\epsilon_t^2$). Se os valores de $f_{0,t}$ forem consistentemente grandes (em valor absoluto), isso sugere que a hip√≥tese nula de aus√™ncia de efeitos GARCH pode ser falsa, e que a vari√¢ncia condicional verdadeira pode ter uma din√¢mica n√£o capturada pelo modelo sob a hip√≥tese nula.

    Sob a hip√≥tese nula, $\mathbb{E}[\epsilon_t^2| \psi_{t-1}] = h_t$, e portanto, $\mathbb{E}[\epsilon_t^2h_t^{-1}| \psi_{t-1}] = 1$. Assim, se a hip√≥tese nula for verdadeira, o vetor $f_0$ deve ter uma m√©dia pr√≥xima de zero.

    > üí° **Exemplo Num√©rico:** Para ilustrar, considere uma s√©rie temporal com $T = 3$. Suponha que sob a hip√≥tese nula (e.g., um modelo ARCH(0) ou aus√™ncia de efeitos ARCH), estimamos $h_t = \hat{\alpha}_0 = 1.0$ para todos os *t*. Se observarmos $\epsilon_1^2 = 1.5$, $\epsilon_2^2 = 0.8$, e $\epsilon_3^2 = 1.2$, ent√£o o vetor $f_0$ seria:
    >
    > $f_0 = (1.5/1.0 - 1, 0.8/1.0 - 1, 1.2/1.0 - 1)' = (0.5, -0.2, 0.2)'$.
    >
    > Este exemplo quantifica como os desvios dos erros quadr√°ticos normalizados em rela√ß√£o √† sua esperan√ßa s√£o calculados, formando a base para o c√°lculo da estat√≠stica LM. Valores maiores (em magnitude) dos elementos de $f_0$ sugerem evid√™ncias contra a hip√≥tese nula.
    >
    > ```python
    > import numpy as np
    >
    > # Dados do exemplo
    > T = 3
    > h_t_hat = np.array([1.0, 1.0, 1.0])
    > epsilon_squared = np.array([1.5, 0.8, 1.2])
    >
    > # Calcula f_0
    > f_0 = (epsilon_squared / h_t_hat) - 1
    >
    > print("Vetor f_0:", f_0)
    > ```

2.  **A Matriz** $Z_0$:

    A matriz $Z_0$ √© definida como $Z_0 = (\frac{\partial h_1}{\partial \omega}, \frac{\partial h_2}{\partial \omega}, \ldots, \frac{\partial h_T}{\partial \omega})'$ [^1], onde cada coluna representa as derivadas parciais da vari√¢ncia condicional $h_t$ em rela√ß√£o aos par√¢metros $\omega$, avaliadas sob a hip√≥tese nula. Estas derivadas quantificam como a vari√¢ncia condicional responde a pequenas mudan√ßas nos par√¢metros sob a hip√≥tese nula. Em outras palavras, $Z_0$ representa a sensibilidade da vari√¢ncia condicional aos par√¢metros do modelo sob a hip√≥tese nula. A transposta $Z_0'$ ent√£o organiza estas derivadas por per√≠odo *t*, formando uma matriz *T x k*, onde *k* √© o n√∫mero de par√¢metros em $\omega$.

    > üí° **Exemplo Num√©rico:** Para um modelo ARCH(1), a vari√¢ncia condicional √© $h_t = \alpha_0 + \alpha_1 \epsilon_{t-1}^2$, e $\omega = (\alpha_0, \alpha_1)'$. As derivadas parciais s√£o:
    >
    > $\frac{\partial h_t}{\partial \alpha_0} = 1$
    >
    > $\frac{\partial h_t}{\partial \alpha_1} = \epsilon_{t-1}^2$
    >
    > Sob a hip√≥tese nula de aus√™ncia de efeitos ARCH(1) (ou seja, $\alpha_1 = 0$), temos $\omega = \alpha_0$ e $h_t = \alpha_0$. Neste caso, $Z_0$ seria uma matriz de dimens√µes *T x 1* (assumindo que estamos avaliando a derivada em rela√ß√£o a $\alpha_0$), com todos os elementos iguais a 1, $Z_0 = (1, 1, ..., 1)'$.
    >
    > Assim, a matriz $Z_0$ captura a sensibilidade da vari√¢ncia condicional aos par√¢metros do modelo sob a hip√≥tese nula.
    >
    > ```python
    > import numpy as np
    >
    > # Dados do exemplo
    > T = 3
    >
    > # Z_0 para ARCH(1) sob H0: alpha_1 = 0
    > Z_0 = np.ones((T, 1))
    >
    > print("Matriz Z_0:\n", Z_0)
    > ```
    >
    > üí° **Exemplo Num√©rico Estendido:** Considere um modelo GARCH(1,1) da forma $h_t = \alpha_0 + \alpha_1 \epsilon_{t-1}^2 + \beta_1 h_{t-1}$. Sob a hip√≥tese nula de que $\alpha_1 = \beta_1 = 0$, temos $h_t = \alpha_0$. O vetor de par√¢metros √© $\omega = (\alpha_0, \alpha_1, \beta_1)'$. As derivadas parciais s√£o:
    >
    > $\frac{\partial h_t}{\partial \alpha_0} = 1$
    >
    > $\frac{\partial h_t}{\partial \alpha_1} = \epsilon_{t-1}^2$
    >
    > $\frac{\partial h_t}{\partial \beta_1} = h_{t-1}$
    >
    > Sob a hip√≥tese nula, $\alpha_1 = 0$ e $\beta_1 = 0$, portanto as derivadas parciais em rela√ß√£o a $\alpha_1$ e $\beta_1$ s√£o 0. Logo, $Z_0$ √© uma matriz *T x 1* (assumindo que estamos avaliando a derivada em rela√ß√£o a $\alpha_0$), com todos os elementos iguais a 1, $Z_0 = (1, 1, ..., 1)'$.
    > ```python
    > import numpy as np
    >
    > # Dados do exemplo
    > T = 3
    >
    > # Z_0 para GARCH(1,1) sob H0: alpha_1 = beta_1 = 0
    > Z_0 = np.ones((T, 1))
    >
    > print("Matriz Z_0:\n", Z_0)
    > ```

    **Proposi√ß√£o 1:** Para um modelo GARCH(p,q), a matriz $Z_0$ pode ser constru√≠da iterativamente utilizando as derivadas parciais da vari√¢ncia condicional em rela√ß√£o aos par√¢metros do modelo, avaliadas sob a hip√≥tese nula de aus√™ncia de efeitos GARCH.

    *Estrat√©gia da Prova:* A prova envolve a aplica√ß√£o da regra da cadeia para calcular as derivadas parciais da vari√¢ncia condicional em rela√ß√£o a cada par√¢metro do modelo GARCH(p,q). Sob a hip√≥tese nula, os par√¢metros GARCH s√£o iguais a zero, simplificando as derivadas e permitindo a constru√ß√£o iterativa da matriz $Z_0$.

    **Prova da Proposi√ß√£o 1:**
    I. Considere um modelo GARCH(p,q) geral:
    $$h_t = \alpha_0 + \sum_{i=1}^{q} \alpha_i \epsilon_{t-i}^2 + \sum_{j=1}^{p} \beta_j h_{t-j}$$
    Onde $\alpha_i$ s√£o os coeficientes ARCH e $\beta_j$ s√£o os coeficientes GARCH.  O vetor de par√¢metros √© $\omega = (\alpha_0, \alpha_1, \ldots, \alpha_q, \beta_1, \ldots, \beta_p)'$.

    II. Sob a hip√≥tese nula de aus√™ncia de efeitos GARCH, temos $\alpha_1 = \ldots = \alpha_q = \beta_1 = \ldots = \beta_p = 0$.  Portanto, $h_t = \alpha_0$ para todo $t$.

    III. Calcule as derivadas parciais de $h_t$ em rela√ß√£o a cada par√¢metro em $\omega$:
    $$\frac{\partial h_t}{\partial \alpha_0} = 1$$
    $$\frac{\partial h_t}{\partial \alpha_i} = 0, \quad \text{para } i = 1, \ldots, q$$
    $$\frac{\partial h_t}{\partial \beta_j} = 0, \quad \text{para } j = 1, \ldots, p$$

    IV. Construa a matriz $Z_0$. Cada linha de $Z_0$ corresponde a um tempo $t$, e cada coluna corresponde √† derivada parcial de $h_t$ em rela√ß√£o a um elemento de $\omega$, avaliada sob a hip√≥tese nula.  Assim, $Z_0$ √© uma matriz $T \times (1+p+q)$.

    V. Devido √† hip√≥tese nula, as derivadas parciais em rela√ß√£o a $\alpha_i$ e $\beta_j$ s√£o zero.  Portanto, a matriz $Z_0$ ter√° a seguinte forma:
    $$Z_0 = \begin{bmatrix}
    1 & 0 & \cdots & 0 \\
    1 & 0 & \cdots & 0 \\
    \vdots & \vdots & \ddots & \vdots \\
    1 & 0 & \cdots & 0
    \end{bmatrix}$$
    Esta √© uma matriz $T \times (1+p+q)$ onde a primeira coluna √© composta por 1s e as demais colunas s√£o compostas por 0s.

    VI. Podemos construir $Z_0$ iterativamente. Inicialize $Z_0$ como uma matriz de zeros de dimens√£o $T \times (1+p+q)$.  Em seguida, defina a primeira coluna de $Z_0$ como um vetor de 1s.
    Portanto, para um modelo GARCH(p,q) sob a hip√≥tese nula, a matriz $Z_0$ √© constru√≠da iterativamente, e as derivadas parciais da vari√¢ncia condicional em rela√ß√£o aos par√¢metros do modelo, avaliadas sob a hip√≥tese nula de aus√™ncia de efeitos GARCH, s√£o utilizadas. ‚ñ†

3.  **A Matriz** $(Z_0'Z_0)^{-1}$:

    Esta √© a inversa da matriz $Z_0'Z_0$. Esta matriz √© crucial para o teste LM pois fornece uma estimativa da matriz de covari√¢ncia dos par√¢metros sob a hip√≥tese nula [^1]. A inversa de $Z_0'Z_0$ √© usada para ajustar a estat√≠stica do teste pela variabilidade dos par√¢metros estimados sob a hip√≥tese nula. Matrizes de covari√¢ncia menores indicam estimativas mais precisas dos par√¢metros e, portanto, um teste mais poderoso.

    > üí° **Exemplo Num√©rico:** No exemplo anterior com $Z_0 = (1, 1, ..., 1)'$, a matriz $Z_0'Z_0$ seria a soma dos quadrados dos elementos de $Z_0$, que √© simplesmente o n√∫mero de observa√ß√µes *T*. Portanto, $(Z_0'Z_0)^{-1} = 1/T$.
    >
    > Este exemplo demonstra como a matriz $(Z_0'Z_0)^{-1}$ est√° relacionada √† precis√£o das estimativas sob a hip√≥tese nula.
    >
    > ```python
    > import numpy as np
    >
    > # Dados do exemplo
    > T = 3
    > Z_0 = np.ones((T, 1))
    >
    > # Calcula Z_0'Z_0
    > Z_0_transpose_Z_0 = np.transpose(Z_0) @ Z_0
    >
    > # Calcula (Z_0'Z_0)^{-1}
    > Z_0_transpose_Z_0_inv = 1 / Z_0_transpose_Z_0
    >
    > print("(Z_0'Z_0)^{-1}:", Z_0_transpose_Z_0_inv)
    > ```

4.  **A Estat√≠stica** $\xi_{LM}$:

    A estat√≠stica $\xi_{LM} = f_0'Z_0(Z_0'Z_0)^{-1}Z_0'f_0$ combina as informa√ß√µes dos desvios dos erros quadr√°ticos normalizados ($f_0$) com a sensibilidade da vari√¢ncia condicional aos par√¢metros sob a hip√≥tese nula ($Z_0$) e ajusta para a variabilidade dos par√¢metros estimados ($(Z_0'Z_0)^{-1}$). A estat√≠stica $\xi_{LM}$ quantifica a signific√¢ncia da inclus√£o de par√¢metros GARCH em um modelo condicionalmente heterosced√°stico [^1]. Sob a hip√≥tese nula, $\xi_{LM}$ segue uma distribui√ß√£o qui-quadrado com *r* graus de liberdade, onde *r* √© o n√∫mero de par√¢metros em $\omega_2$ [^1].

    Um valor alto da estat√≠stica $\xi_{LM}$ indica que os desvios dos erros quadr√°ticos normalizados ($f_0$) s√£o sistematicamente relacionados com as derivadas da vari√¢ncia condicional em rela√ß√£o aos par√¢metros ($Z_0$), e que essa rela√ß√£o √© estatisticamente significativa ap√≥s ajustar pela variabilidade dos par√¢metros estimados ($(Z_0'Z_0)^{-1}$). Neste caso, rejeitar√≠amos a hip√≥tese nula de aus√™ncia de efeitos GARCH.

    > üí° **Exemplo Num√©rico:** Para um modelo ARCH(1) sob a hip√≥tese nula $\alpha_1 = 0$, temos que $f_0$ mede o desvio dos erros quadr√°ticos normalizados e $Z_0$ representa a sensibilidade da vari√¢ncia condicional ao par√¢metro $\alpha_0$. Se a estat√≠stica $\xi_{LM}$ for alta, isso indica que os desvios dos erros quadr√°ticos normalizados est√£o relacionados com a sensibilidade da vari√¢ncia condicional a $\alpha_0$, e que essa rela√ß√£o √© estatisticamente significativa.
    >
    > ```python
    > import numpy as np
    > from scipy.stats import chi2
    >
    > # Dados dos exemplos anteriores
    > T = 3
    > h_t_hat = np.array([1.0, 1.0, 1.0])
    > epsilon_squared = np.array([1.5, 0.8, 1.2])
    > f_0 = (epsilon_squared / h_t_hat) - 1
    > Z_0 = np.ones((T, 1))
    > Z_0_transpose_Z_0_inv = 1 / T
    >
    > # Calcula a estat√≠stica LM
    > xi_LM = f_0.T @ Z_0 @ Z_0_transpose_Z_0_inv @ Z_0.T @ f_0
    >
    > # Calcula o p-valor
    > r = 1  # Graus de liberdade (n√∫mero de par√¢metros restritos)
    > p_value = 1 - chi2.cdf(xi_LM, r)
    >
    > print("Estat√≠stica LM:", xi_LM)
    > print("P-valor:", p_value)
    >
    > # Interpreta√ß√£o
    > alpha = 0.05  # N√≠vel de signific√¢ncia
    > if p_value < alpha:
    >     print("Rejeitamos a hip√≥tese nula de aus√™ncia de efeitos ARCH.")
    > else:
    >     print("N√£o rejeitamos a hip√≥tese nula de aus√™ncia de efeitos ARCH.")
    > ```

    **Teorema 1:** A estat√≠stica do Teste LM, $\xi_{LM}$, √© assintoticamente equivalente √† estat√≠stica do teste da raz√£o de verossimilhan√ßas (LR) para a hip√≥tese nula de aus√™ncia de efeitos GARCH.

    *Estrat√©gia da Prova:* A prova envolve expandir a fun√ß√£o de log-verossimilhan√ßa sob a hip√≥tese alternativa (com efeitos GARCH) em torno das estimativas sob a hip√≥tese nula (sem efeitos GARCH) usando uma expans√£o de Taylor de segunda ordem. Mostra-se que a estat√≠stica LR resultante √© assintoticamente igual a $\xi_{LM}$.

   **Prova do Teorema 1:**

    I. Seja $L(\theta)$ a fun√ß√£o de log-verossimilhan√ßa do modelo GARCH, onde $\theta = (\theta_1, \theta_2)$ √© o vetor de par√¢metros, com $\theta_1$ representando os par√¢metros estimados sob a hip√≥tese nula e $\theta_2$ os par√¢metros GARCH que estamos testando (e que s√£o restritos a zero sob a hip√≥tese nula).

    II. A estat√≠stica do teste da raz√£o de verossimilhan√ßas (LR) √© dada por:
    $$LR = 2[L(\hat{\theta}) - L(\tilde{\theta})]$$
    Onde $\hat{\theta}$ s√£o as estimativas de m√°xima verossimilhan√ßa sob a hip√≥tese alternativa (sem restri√ß√µes) e $\tilde{\theta}$ s√£o as estimativas sob a hip√≥tese nula ($\theta_2 = 0$).

    III. Expanda $L(\hat{\theta})$ em torno de $\tilde{\theta}$ usando uma expans√£o de Taylor de segunda ordem:
    $$L(\hat{\theta}) \approx L(\tilde{\theta}) + (\hat{\theta} - \tilde{\theta})' \nabla L(\tilde{\theta}) + \frac{1}{2} (\hat{\theta} - \tilde{\theta})' \nabla^2 L(\tilde{\theta}) (\hat{\theta} - \tilde{\theta})$$
    Onde $\nabla L(\tilde{\theta})$ √© o vetor gradiente (primeira derivada) e $\nabla^2 L(\tilde{\theta})$ √© a matriz Hessiana (segunda derivada) da fun√ß√£o de log-verossimilhan√ßa, ambos avaliados em $\tilde{\theta}$.

    IV. Sob a hip√≥tese nula, o vetor gradiente para os par√¢metros restritos $\theta_2$ √© zero no ponto de m√°ximo (pelas condi√ß√µes de primeira ordem): $\nabla_{\theta_2} L(\tilde{\theta}) = 0$. Portanto, o termo linear na expans√£o de Taylor se anula.

    V. A estat√≠stica LR se torna:
    $$LR = 2[L(\hat{\theta}) - L(\tilde{\theta})] \approx (\hat{\theta} - \tilde{\theta})' [-\nabla^2 L(\tilde{\theta})] (\hat{\theta} - \tilde{\theta})$$
    Observe que $-\nabla^2 L(\tilde{\theta})$ √© a matriz de informa√ß√£o de Fisher, que denotamos por $I(\tilde{\theta})$.

    VI. Particionando a matriz de informa√ß√£o de Fisher e o vetor de par√¢metros, temos:
    $$I(\tilde{\theta}) = \begin{bmatrix}
    I_{11} & I_{12} \\
    I_{21} & I_{22}
    \end{bmatrix}, \quad (\hat{\theta} - \tilde{\theta}) = \begin{bmatrix}
    \hat{\theta}_1 - \tilde{\theta}_1 \\
    \hat{\theta}_2 - 0
    \end{bmatrix}$$
    Onde $I_{ij}$ s√£o os blocos da matriz de informa√ß√£o correspondentes aos par√¢metros $\theta_i$ e $\theta_j$.

    VII. Sob a hip√≥tese nula, a estimativa de m√°xima verossimilhan√ßa de $\theta_2$ √© assintoticamente:
    $$\hat{\theta}_2 \approx I_{22}^{-1} \nabla_{\theta_2} L(\tilde{\theta})$$
    Como $\nabla_{\theta_2} L(\tilde{\theta})$ √© o vetor $f_0$ e $I_{22}$ est√° relacionado a $Z_0'Z_0$, podemos escrever a estat√≠stica LR como:
    $$LR \approx f_0'Z_0(Z_0'Z_0)^{-1}Z_0'f_0 = \xi_{LM}$$

    VIII. Portanto, a estat√≠stica do Teste LR √© assintoticamente equivalente √† estat√≠stica do Teste LM:
    $$LR \approx \xi_{LM}$$
    Isso completa a prova. ‚ñ†

A estat√≠stica do teste LM tamb√©m pode ser expressa como $\xi_{LM} = T \cdot R^2$, onde $R^2$ √© o coeficiente de correla√ß√£o m√∫ltipla ao quadrado entre $f_0$ e $Z_0$ [^1]. Esta formula√ß√£o oferece uma interpreta√ß√£o intuitiva: a estat√≠stica do teste √© proporcional √† quantidade de varia√ß√£o em $f_0$ que √© explicada por $Z_0$.

### Conclus√£o

Em conclus√£o, a estat√≠stica do teste LM, $\xi_{LM} = f_0'Z_0(Z_0'Z_0)^{-1}Z_0'f_0$, √© uma ferramenta fundamental para testar a presen√ßa de efeitos GARCH em modelos de s√©ries temporais. Compreender suas componentes e sua deriva√ß√£o √© essencial para interpretar corretamente os resultados do teste e tomar decis√µes informadas sobre a adequa√ß√£o do modelo [^1]. A estat√≠stica $\xi_{LM}$ quantifica a signific√¢ncia da inclus√£o de par√¢metros GARCH em um modelo condicionalmente heterosced√°stico, considerando os desvios dos erros quadr√°ticos normalizados, a sensibilidade da vari√¢ncia condicional aos par√¢metros sob a hip√≥tese nula, e a variabilidade dos par√¢metros estimados.

### Refer√™ncias

[^1]: Bollerslev, T. (1986). Generalized autoregressive conditional heteroskedasticity. *Journal of Econometrics, 31*(3), 307-327.
<!-- END -->