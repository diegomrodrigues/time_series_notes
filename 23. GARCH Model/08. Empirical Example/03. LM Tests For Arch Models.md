Aufbauend auf der vorherigen Diskussion √ºber die Modellierung der Inflationsunsicherheit mit GARCH-Modellen, konzentrieren wir uns nun detaillierter auf die Lagrange-Multiplikator (LM) Tests f√ºr das Vorhandensein von ARCH-Effekten. Wie im vorherigen Kapitel dargelegt, deutet die Signifikanz der Autokorrelationen und partiellen Autokorrelationen von $\epsilon_t^2$ auf eine bedingte Heteroskedastizit√§t hin, was die Anwendung von ARCH- oder GARCH-Modellen rechtfertigt [^1]. Dieser Abschnitt vertieft dieses Konzept, indem er die spezifischen LM Tests f√ºr ARCH(1), ARCH(4) und ARCH(8) untersucht [^1].

### LM-Test f√ºr ARCH-Effekte

Der Lagrange-Multiplikator (LM) Test ist ein statistischer Test, der verwendet wird, um das Vorhandensein von ARCH-Effekten in den Residuen eines Zeitreihenmodells zu √ºberpr√ºfen [^1]. Der Test basiert auf der Idee, zu untersuchen, ob die quadrierten Residuen mit ihren vergangenen Werten korreliert sind [^1]. Wenn die Residuen mit ihren vergangenen Werten korreliert sind, deutet dies darauf hin, dass die Varianz der Residuen √ºber die Zeit nicht konstant ist, was auf ARCH-Effekte hindeutet [^1].

> üí° **Zusammenfassung:** Der LM-Test pr√ºft, ob vergangene quadrierte Residuen die aktuelle Varianz beeinflussen, und wird so zum Nachweis von ARCH-Effekten eingesetzt.

Um den LM-Test durchzuf√ºhren, wird die folgende Hilfsregression gesch√§tzt:

$$
\epsilon_t^2 = \gamma_0 + \gamma_1 \epsilon_{t-1}^2 + \gamma_2 \epsilon_{t-2}^2 + \dots + \gamma_q \epsilon_{t-q}^2 + v_t
$$

wobei:
*   $\epsilon_t^2$ die quadrierten Residuen des urspr√ºnglichen Regressionsmodells sind,
*   $\epsilon_{t-i}^2$ die verz√∂gerten quadrierten Residuen sind,
*   $\gamma_i$ die zu sch√§tzenden Parameter sind,
*   $q$ die Anzahl der Verz√∂gerungen ist, und
*   $v_t$ der Fehlerterm ist.

Die Nullhypothese des LM-Tests ist, dass alle Koeffizienten der verz√∂gerten quadrierten Residuen Null sind, d. h. $H_0: \gamma_1 = \gamma_2 = \dots = \gamma_q = 0$. Die alternative Hypothese ist, dass mindestens einer der Koeffizienten ungleich Null ist, d. h. $H_1: \gamma_i \neq 0$ f√ºr mindestens ein $i$.

Die Teststatistik des LM-Tests ist gegeben durch:

$$
LM = T \cdot R^2
$$

wobei:
*   $T$ die Anzahl der Beobachtungen ist, und
*   $R^2$ das Bestimmtheitsma√ü aus der Hilfsregression ist.

Die Teststatistik folgt asymptotisch einer Chi-Quadrat-Verteilung mit $q$ Freiheitsgraden unter der Nullhypothese. Wenn die Teststatistik gr√∂√üer ist als der kritische Wert der Chi-Quadrat-Verteilung auf einem bestimmten Signifikanzniveau, wird die Nullhypothese verworfen, was auf das Vorhandensein von ARCH-Effekten hindeutet.

> üí° **Exemplo Num√©rico:** Betrachten wir ein Modell mit zwei Verz√∂gerungen $(q=2)$:
>
> $\epsilon_t^2 = \gamma_0 + \gamma_1 \epsilon_{t-1}^2 + \gamma_2 \epsilon_{t-2}^2 + v_t$
>
> Nehmen wir an, dass nach der Sch√§tzung dieser Regression mit unseren Daten $(T=143)$, das $R^2 = 0.15$ betr√§gt. Dann ist die LM-Statistik:
>
> $LM = 143 \cdot 0.15 = 21.45$
>
> Der kritische Wert der Chi-Quadrat-Verteilung mit 2 Freiheitsgraden auf dem 5 % Signifikanzniveau betr√§gt 5.99. Da $21.45 > 5.99$, verwerfen wir die Nullhypothese und schlie√üen, dass ARCH-Effekte vorliegen.

**Lema 1 (Bedeutung der Lag-L√§nge im LM-Test):** Die Wahl der Lag-L√§nge $q$ in der Hilfsregression ist entscheidend. Eine zu kleine Lag-L√§nge k√∂nnte wichtige ARCH-Effekte √ºbersehen, w√§hrend eine zu lange Lag-L√§nge die Testst√§rke verringern k√∂nnte. Informationskriterien oder eine visuelle Inspektion der Autokorrelationsfunktion der quadrierten Residuen k√∂nnen verwendet werden, um eine geeignete Lag-L√§nge zu w√§hlen.

> üí° **Exemplo Num√©rico:** Angenommen, wir haben monatliche Inflationsdaten √ºber einen Zeitraum von 10 Jahren ($T = 120$). Wir analysieren die Autokorrelationsfunktion (ACF) der quadrierten Residuen und beobachten signifikante Autokorrelationen bis zu Lag 6. Dies deutet darauf hin, dass eine Lag-L√§nge von $q=6$ angemessen sein k√∂nnte. Um die Robustheit zu gew√§hrleisten, k√∂nnten wir auch $q=4$ und $q=8$ testen. Der LM-Test w√ºrde dann dreimal mit jeweils unterschiedlichen Verz√∂gerungen durchgef√ºhrt.
> ```python
> import numpy as np
> import statsmodels.api as sm
> from statsmodels.stats.diagnostic import het_arch
>
> # Generiere Beispieldaten (quadrierte Residuen)
> np.random.seed(0)
> residuals_squared = np.random.randn(120)**2
>
> # F√ºhre den LM-Test f√ºr verschiedene Lag-L√§ngen durch
> lag_lengths = [4, 6, 8]
>
> for q in lag_lengths:
>     lm_test = het_arch(residuals_squared, nlags=q)
>     print(f"LM-Test f√ºr ARCH({q}):")
>     print(f"  LM-Statistik: {lm_test[0]:.4f}")
>     print(f"  P-Wert: {lm_test[1]:.4f}")
>     if lm_test[1] < 0.05:
>         print("  Signifikante ARCH-Effekte gefunden.")
>     else:
>         print("  Keine signifikanten ARCH-Effekte gefunden.")
>     print("-" * 30)
> ```

Um die praktische Anwendung des LM-Tests zu erleichtern, ist es hilfreich, die Berechnung des p-Werts explizit darzustellen.

**Lema 1.1 (P-Wert-Berechnung im LM-Test):** Der p-Wert des LM-Tests gibt die Wahrscheinlichkeit an, eine Teststatistik zu erhalten, die mindestens so extrem ist wie die beobachtete, unter der Annahme, dass die Nullhypothese wahr ist. Er wird berechnet als:

$$
p \text{-Wert} = P(\chi^2_q > LM)
$$

wobei $\chi^2_q$ eine Chi-Quadrat-verteilte Zufallsvariable mit $q$ Freiheitsgraden ist und $LM$ die berechnete LM-Teststatistik ist. Ein kleiner p-Wert (typischerweise unterhalb eines Signifikanzniveaus von 0.05) liefert Evidenz gegen die Nullhypothese und deutet auf das Vorhandensein von ARCH-Effekten hin.

**Corol√°rio 1.1 (Entscheidungsregel basierend auf dem p-Wert):**  Verwerfen Sie die Nullhypothese (keine ARCH-Effekte), wenn der p-Wert kleiner als das gew√§hlte Signifikaniveau $\alpha$ ist. Andernfalls kann die Nullhypothese nicht verworfen werden.

**Testen f√ºr ARCH(1), ARCH(4) und ARCH(8)**

Im spezifischen Kontext der Analyse von Engle und Kraft (1983) werden LM-Tests f√ºr ARCH(1), ARCH(4) und ARCH(8) durchgef√ºhrt [^1]. Dies bedeutet, dass separate Hilfsregressionen mit 1, 4 bzw. 8 Verz√∂gerungen der quadrierten Residuen gesch√§tzt werden [^1]. Die entsprechenden Teststatistiken werden berechnet und mit den kritischen Werten der Chi-Quadrat-Verteilung mit 1, 4 bzw. 8 Freiheitsgraden verglichen.

> üí° **Exemplo Num√©rico:**
>
> *   **ARCH(1):** $\epsilon_t^2 = \gamma_0 + \gamma_1 \epsilon_{t-1}^2 + v_t$
> *   **ARCH(4):** $\epsilon_t^2 = \gamma_0 + \gamma_1 \epsilon_{t-1}^2 + \gamma_2 \epsilon_{t-2}^2 + \gamma_3 \epsilon_{t-3}^2 + \gamma_4 \epsilon_{t-4}^2 + v_t$
> *   **ARCH(8):** $\epsilon_t^2 = \gamma_0 + \gamma_1 \epsilon_{t-1}^2 + \gamma_2 \epsilon_{t-2}^2 + \gamma_3 \epsilon_{t-3}^2 + \gamma_4 \epsilon_{t-4}^2 + \gamma_5 \epsilon_{t-5}^2 + \gamma_6 \epsilon_{t-6}^2 + \gamma_7 \epsilon_{t-7}^2 + \gamma_8 \epsilon_{t-8}^2 + v_t$
>
> Nehmen wir an, die Ergebnisse des LM-Tests sind wie folgt:
>
> *   ARCH(1): LM = 8.5, p-Wert = 0.004
> *   ARCH(4): LM = 15.2, p-Wert = 0.004
> *   ARCH(8): LM = 22.1, p-Wert = 0.005
>
> Da alle p-Werte unter 0.05 liegen, w√ºrden wir die Nullhypothese in allen drei F√§llen verwerfen und schlie√üen, dass ARCH-Effekte vorliegen. Je h√∂her die Lag-Ordnung des ARCH-Tests ist, desto breiter ist der Zeitraum, √ºber den das Modell pr√ºft, ob vergangene Schocks in den Daten einen Einfluss haben. Die hochsignifikanten p-Werte deuten darauf hin, dass die Heteroskedastizit√§t der quadrierten Residuen bis zu den getesteten Lags erhalten bleibt.
>
> ```python
> import numpy as np
> from scipy.stats import chi2
>
> # Ergebnisse der LM-Tests
> lm_statistics = np.array([8.5, 15.2, 22.1])
> degrees_of_freedom = np.array([1, 4, 8])
>
> # Signifikanzniveau
> alpha = 0.05
>
> # Kritische Werte berechnen
> critical_values = chi2.ppf(1 - alpha, degrees_of_freedom)
>
> # P-Werte berechnen
> p_values = 1 - chi2.cdf(lm_statistics, degrees_of_freedom)
>
> # Ergebnisse ausgeben
> for i in range(len(lm_statistics)):
>     print(f"ARCH({degrees_of_freedom[i]}): LM = {lm_statistics[i]:.2f}, p-Wert = {p_values[i]:.3f}")
>     if p_values[i] < alpha:
>         print("Nullhypothese verwerfen: ARCH-Effekte vorhanden")
>     else:
>         print("Nullhypothese nicht verwerfen: Keine signifikanten ARCH-Effekte")
>     print("-" * 40)
> ```

### Interpretation der Ergebnisse

Die Signifikanz der LM-Tests f√ºr ARCH(1), ARCH(4) und ARCH(8) deutet darauf hin, dass das urspr√ºngliche Modell, das von Engle und Kraft (1983) gesch√§tzt wurde, eine bedingte Heteroskedastizit√§t aufweist [^1]. Dies bedeutet, dass die Varianz der Residuen √ºber die Zeit nicht konstant ist, sondern von den vergangenen Werten der quadrierten Residuen abh√§ngt [^1]. Diese Erkenntnis motiviert die Verwendung von ARCH- oder GARCH-Modellen, um die Dynamik der Varianz explizit zu modellieren [^1].

Die Wahl zwischen einem ARCH- und einem GARCH-Modell h√§ngt von den spezifischen Eigenschaften der Daten ab [^1]. ARCH-Modelle modellieren die Varianz als Funktion der vergangenen quadrierten Residuen, w√§hrend GARCH-Modelle zus√§tzlich verz√∂gerte Werte der Varianz selbst einbeziehen [^1]. GARCH-Modelle sind im Allgemeinen flexibler und in der Lage, persistente Volatilit√§tscluster zu erfassen, die h√§ufig in Finanzzeitreihen zu finden sind [^1].

> üí° **Exemplo Num√©rico:** Um den Unterschied zwischen ARCH- und GARCH-Modellen zu verdeutlichen, betrachten wir zwei Szenarien:
>
> 1.  **ARCH(1)-Szenario:** Angenommen, die quadrierte Residuen eines Tages beeinflussen die Varianz des n√§chsten Tages, aber danach gibt es keinen signifikanten Einfluss mehr.  In diesem Fall w√§re ein einfaches ARCH(1)-Modell ausreichend. Zum Beispiel:
>     $\sigma_t^2 = \alpha_0 + \alpha_1 \epsilon_{t-1}^2$, wobei $\alpha_1$ signifikant ist und die nachfolgenden $\epsilon_{t-i}^2$ keinen Einfluss haben.
> 2.  **GARCH(1,1)-Szenario:** Angenommen, ein Schock am heutigen Tag beeinflusst nicht nur die Varianz des n√§chsten Tages, sondern hat auch einen anhaltenden Einfluss auf die zuk√ºnftige Varianz.  In diesem Fall w√§re ein GARCH(1,1)-Modell besser geeignet:
>     $\sigma_t^2 = \alpha_0 + \alpha_1 \epsilon_{t-1}^2 + \beta_1 \sigma_{t-1}^2$, wobei sowohl $\alpha_1$ als auch $\beta_1$ signifikant sind. $\beta_1$ f√§ngt die Persistenz der Volatilit√§t ein. Ein Wert von $\beta_1$ nahe 1 deutet auf eine hohe Persistenz hin.
>
> Die Wahl zwischen ARCH und GARCH kann auch durch Informationskriterien wie AIC und BIC unterst√ºtzt werden, die die Modellkomplexit√§t ber√ºcksichtigen.

**Proposi√ß√£o 1 (Implikationen f√ºr die Modellierung):** Die Signifikanz der ARCH-LM-Tests erfordert die Verwendung von Modellen, die bedingte Heteroskedastizit√§t explizit ber√ºcksichtigen. ARCH- und GARCH-Modelle sind geeignete Wahlm√∂glichkeiten, um die zeitliche Ver√§nderung der Volatilit√§t zu erfassen.

**Proposi√ß√£o 1.1 (Modellauswahlkriterien):**  Neben den ARCH-LM-Tests sollten auch Informationskriterien wie das Akaike Information Criterion (AIC) oder das Bayesian Information Criterion (BIC) verwendet werden, um die beste Lag-L√§nge und die geeignetste Modellfamilie (ARCH oder GARCH) auszuw√§hlen.  Diese Kriterien ber√ºcksichtigen sowohl die Anpassungsg√ºte als auch die Modellkomplexit√§t, um eine √úberanpassung zu vermeiden.

Um zu zeigen, dass die LM-Statistik asymptotisch einer Chi-Quadrat-Verteilung folgt, k√∂nnen wir Folgendes beweisen:

**Beweis (Asymptotische Verteilung der LM-Statistik):**

Wir werden beweisen, dass unter der Nullhypothese $H_0: \gamma_1 = \gamma_2 = \dots = \gamma_q = 0$, die LM-Statistik $LM = T \cdot R^2$ asymptotisch einer Chi-Quadrat-Verteilung mit $q$ Freiheitsgraden folgt.

I. Betrachten Sie die Hilfsregression:
$$\epsilon_t^2 = \gamma_0 + \gamma_1 \epsilon_{t-1}^2 + \gamma_2 \epsilon_{t-2}^2 + \dots + \gamma_q \epsilon_{t-q}^2 + v_t$$

II. Unter der Nullhypothese $H_0$, ist das wahre Modell:
$$\epsilon_t^2 = \gamma_0 + v_t$$

III. Die LM-Statistik kann als Test der Restriktionen in einem uneingeschr√§nkten Modell im Vergleich zu einem eingeschr√§nkten Modell interpretiert werden.  Im Wesentlichen testet es, ob das Hinzuf√ºgen der verz√∂gerten quadrierten Residuen die erkl√§rte Varianz signifikant erh√∂ht.

IV. Die LM-Statistik ist √§quivalent zu $n$ mal der erkl√§rten Varianz ($R^2$) aus der Regression von $\epsilon_t^2$ auf $\epsilon_{t-1}^2, \epsilon_{t-2}^2, \dots, \epsilon_{t-q}^2$.

V. Unter Regularit√§tsbedingungen (wie endlichen Momenten und Ergodizit√§t) und unter der Nullhypothese, die besagt, dass die $\gamma_i$ gleich null sind, konvergiert die LM-Statistik in der Verteilung zu einer Chi-Quadrat-Verteilung mit $q$ Freiheitsgraden:
$$LM = T \cdot R^2 \xrightarrow{d} \chi^2(q)$$

VI. Die Freiheitsgrade $q$ entsprechen der Anzahl der Restriktionen, die unter der Nullhypothese auferlegt werden (d. h. die Anzahl der auf Null gesetzten verz√∂gerten Koeffizienten).

Somit haben wir bewiesen, dass $LM = T \cdot R^2$ asymptotisch einer Chi-Quadrat-Verteilung mit $q$ Freiheitsgraden folgt. ‚ñ†

> üí° **√úberblick:** Die LM-Tests liefern einen formalen Rahmen f√ºr die Beurteilung, ob ARCH-Effekte vorliegen. Wenn diese Effekte signifikant sind, ist es notwendig, diese durch fortschrittlichere Methoden wie die GARCH-Modellierung zu ber√ºcksichtigen.

### Zusammenfassung

Dieser Abschnitt hat die LM-Tests f√ºr ARCH-Effekte detailliert beschrieben und ihre Anwendung im Kontext der Analyse von Engle und Kraft (1983) erl√§utert [^1]. Die Signifikanz der LM-Tests f√ºr ARCH(1), ARCH(4) und ARCH(8) deutet auf das Vorhandensein einer bedingten Heteroskedastizit√§t hin, was die Verwendung von ARCH- oder GARCH-Modellen zur Modellierung der Inflationsunsicherheit rechtfertigt [^1].

### Referenzen
[^1]: Tim Bollerslev, *Generalized Autoregressive Conditional Heteroskedasticity*
<!-- END -->