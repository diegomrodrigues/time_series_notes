Empirische Anwendung: GARCH Modellierung der Inflationsunsicherheit

### EinfÃ¼hrung
In diesem Kapitel untersuchen wir eine empirische Anwendung des GARCH-Modells, die auf der Arbeit von Engle und Kraft (1983) basiert [^1]. Diese Anwendung konzentriert sich auf die Modellierung der Unsicherheit der Inflation in den Vereinigten Staaten mithilfe des GARCH-Modells, wobei die Wachstumsrate des impliziten GNP-Deflators in den USA durch seine eigene Vergangenheit erklÃ¤rt wird. Die Unsicherheit der Inflation ist eine Ã¶konomisch wichtige Variable, die nicht direkt beobachtet werden kann, und wurde bereits in mehreren ARCH-Modellen untersucht [^1].

### Modellspezifikation
Die Studie von Engle und Kraft (1983) wird hier nÃ¤her betrachtet, wobei die Wachstumsrate des impliziten GNP-Deflators in den USA durch ihre eigene Vergangenheit erklÃ¤rt wird [^1].

Definiere $\pi_t = 100 \cdot \ln(GD_t/GD_{t-1})$, wobei $GD_t$ den impliziten Preisdeflator fÃ¼r das GNP darstellt [^1]. Standardunivariate Zeitreihenmethoden fÃ¼hren zur Identifizierung des folgenden Modells fÃ¼r $\pi_t$:

$$
\pi_t = 0.240 + 0.552\pi_{t-1} + 0.177\pi_{t-2} + 0.232\pi_{t-3} - 0.209\pi_{t-4} + \epsilon_t, \quad h_t = 0.282
$$

Die Werte in Klammern geben die Standardfehler an [^1]. Das Modell wird anhand vierteljÃ¤hrlicher Daten von 1948.2 bis 1983.4 geschÃ¤tzt, was insgesamt 143 Beobachtungen entspricht [^1]. Die SchÃ¤tzung erfolgt mittels Ordinary Least Squares (OLS).

> ğŸ’¡ **Exemplo NumÃ©rico:** Nehmen wir an, wir haben die folgenden ersten fÃ¼nf Werte fÃ¼r $\pi_t$: 2.5, 1.8, 2.1, 1.9, 2.3. Die Gleichung fÃ¼r $\pi_5$ wÃ¤re dann:
>
> $\pi_5 = 0.240 + 0.552(2.3) + 0.177(1.9) + 0.232(2.1) - 0.209(1.8) + \epsilon_5$
>
> $\pi_5 = 0.240 + 1.2696 + 0.3363 + 0.4872 - 0.3762 + \epsilon_5$
>
> $\pi_5 = 1.957 + \epsilon_5$
>
> Wenn wir annehmen, dass der tatsÃ¤chliche Wert von $\pi_5$ 2.3 war, dann wÃ¤re $\epsilon_5 = 2.3 - 1.957 = 0.343$. Das Modell schÃ¤tzt also den Inflationswert fÃ¼r das fÃ¼nfte Quartal basierend auf den vorherigen vier Quartalen und einem Fehlerterm. Die konstante Varianz des Fehlers betrÃ¤gt 0.282.

### Analyse der Residuen

Das Modell ist stationÃ¤r, und keine der ersten zehn Autokorrelationen oder partiellen Autokorrelationen fÃ¼r $\epsilon_t$ ist auf dem 5%-Niveau signifikant [^1]. Jedoch Ã¼berschreiten die Autokorrelationen fÃ¼r $\epsilon_t^2$ fÃ¼r die 1., 3., 7., 9. und 10. VerzÃ¶gerung alle zwei asymptotischen Standardfehler. Ã„hnliche Ergebnisse gelten fÃ¼r die partiellen Autokorrelationen fÃ¼r $\epsilon_t^2$. Der LM-Test fÃ¼r ARCH(1), ARCH(4) und ARCH(8) ist ebenfalls auf jedem vernÃ¼nftigen Niveau hochsignifikant [^1].

**ProposiÃ§Ã£o 1.** Die Signifikanz der Autokorrelationen und partiellen Autokorrelationen von $\epsilon_t^2$ deutet auf eine bedingte HeteroskedastizitÃ¤t hin, was die Anwendung von ARCH- oder GARCH-Modellen rechtfertigt.

*Beweis.* Die Definition von ARCH- und GARCH-Modellen beinhaltet explizit die Modellierung der Varianz als Funktion vergangener Fehlerquadrate. Signifikante Autokorrelationen in den quadrierten Residuen sind ein starker Hinweis darauf, dass die Varianz nicht konstant ist, sondern von vergangenen Schocks abhÃ¤ngt. Die Signifikanz des LM-Tests bestÃ¤tigt dies zusÃ¤tzlich.

I. Signifikante Autokorrelationen und partielle Autokorrelationen in $\epsilon_t^2$ implizieren, dass die Varianz der Residuen nicht konstant Ã¼ber die Zeit ist.
II. ARCH- und GARCH-Modelle sind speziell dafÃ¼r entwickelt, solche zeitabhÃ¤ngigen Varianzen zu modellieren.
III. Daher ist die Anwendung von ARCH- oder GARCH-Modellen gerechtfertigt, um die bedingte HeteroskedastizitÃ¤t in den Daten zu berÃ¼cksichtigen. â– 

> ğŸ’¡ **Exemplo NumÃ©rico:** Nehmen wir an, wir berechnen die Autokorrelationen der quadrierten Residuen $\epsilon_t^2$ und finden:
>
> $\text{Autokorrelation}(\epsilon_t^2, \epsilon_{t-1}^2) = 0.35$
>
> $\text{Autokorrelation}(\epsilon_t^2, \epsilon_{t-3}^2) = 0.28$
>
> $\text{Autokorrelation}(\epsilon_t^2, \epsilon_{t-7}^2) = 0.42$
>
> $\text{Autokorrelation}(\epsilon_t^2, \epsilon_{t-9}^2) = 0.31$
>
> $\text{Autokorrelation}(\epsilon_t^2, \epsilon_{t-10}^2) = 0.25$
>
> Der asymptotische Standardfehler ist ungefÃ¤hr $1/\sqrt{T} = 1/\sqrt{143} \approx 0.084$. Zwei asymptotische Standardfehler wÃ¤ren also etwa 0.168. Da die oben genannten Autokorrelationen alle grÃ¶ÃŸer als 0.168 sind, sind sie signifikant. Dies deutet darauf hin, dass groÃŸe (oder kleine) Quadrate von Residuen dazu neigen, von groÃŸen (oder kleinen) Quadraten von Residuen in den angegebenen VerzÃ¶gerungen gefolgt zu werden, was auf eine bedingte HeteroskedastizitÃ¤t hindeutet.
>
> Der LM-Test fÃ¼r ARCH(1) ergibt einen p-Wert von 0.02, fÃ¼r ARCH(4) einen p-Wert von 0.001 und fÃ¼r ARCH(8) einen p-Wert von 0.0005. Da diese p-Werte alle unter 0.05 liegen, lehnen wir die Nullhypothese ab, dass keine ARCH-Effekte vorliegen, was die Notwendigkeit eines ARCH- oder GARCH-Modells weiter unterstÃ¼tzt.

### ARCH-Modell nach Engle und Kraft
Diese Ergebnisse veranlassen Engle und Kraft (1983), die folgende Spezifikation vorzuschlagen:

$$
\pi_t = 0.138 + 0.423\pi_{t-1} + 0.222\pi_{t-2} + 0.377\pi_{t-3} - 0.175\pi_{t-4} + \epsilon_t, \quad h_t = 0.058 + 0.802 \sum_{i=1}^{8} (9-i)/36 \epsilon_{t-i}^2
$$

Die SchÃ¤tzungen sind Maximum-Likelihood-SchÃ¤tzungen mit heteroskedastie-konsistenten Standardfehlern in Klammern. Die Wahl der linearen Struktur mit abnehmender VerzÃ¶gerung achter Ordnung ist eher ad hoc, wird aber durch das lange GedÃ¤chtnis in der bedingten Varianzgleichung motiviert.

> ğŸ’¡ **Exemplo NumÃ©rico:** Nehmen wir an, wir haben die folgenden Werte fÃ¼r die quadrierten Residuen in den letzten 8 Perioden: $\epsilon_{t-1}^2 = 0.09, \epsilon_{t-2}^2 = 0.16, \epsilon_{t-3}^2 = 0.04, \epsilon_{t-4}^2 = 0.25, \epsilon_{t-5}^2 = 0.01, \epsilon_{t-6}^2 = 0.36, \epsilon_{t-7}^2 = 0.10, \epsilon_{t-8}^2 = 0.05$. Dann berechnen wir $h_t$ wie folgt:
>
> $h_t = 0.058 + 0.802 \cdot [(8/36) \cdot 0.09 + (7/36) \cdot 0.16 + (6/36) \cdot 0.04 + (5/36) \cdot 0.25 + (4/36) \cdot 0.01 + (3/36) \cdot 0.36 + (2/36) \cdot 0.10 + (1/36) \cdot 0.05]$
>
> $h_t = 0.058 + 0.802 \cdot [0.02 + 0.031 + 0.007 + 0.035 + 0.001 + 0.03 + 0.006 + 0.001]$
>
> $h_t = 0.058 + 0.802 \cdot 0.131$
>
> $h_t = 0.058 + 0.105$
>
> $h_t = 0.163$
>
> Dies zeigt, wie die bedingte Varianz $h_t$ basierend auf vergangenen quadrierten Fehlern und einer abnehmenden VerzÃ¶gerungsstruktur berechnet wird.

### GARCH(1,1) Modell
Alternativ betrachten wir die folgende GARCH(1,1)-Spezifikation:

$$
\pi_t = 0.141 + 0.433\pi_{t-1} + 0.229\pi_{t-2} + 0.349\pi_{t-3} - 0.162\pi_{t-4} + \epsilon_t, \quad h_t = 0.007 + 0.135\epsilon_{t-1}^2 + 0.829h_{t-1}
$$

GemÃ¤ÃŸ Theorem 2 existiert das vierte Moment von $\epsilon_t$ [^1]. Keine der ersten zehn Autokorrelationen oder partiellen Autokorrelationen fÃ¼r $\epsilon_t h_t^{-1/2}$ Ã¼bersteigt zwei asymptotische Standardfehler. Der LM-Test fÃ¼r den Einschluss der linearen Struktur mit abnehmender VerzÃ¶gerung achter Ordnung ergibt 2.33, was dem 0.87-Fraktil in der $\chi_1^2$-Verteilung entspricht [^1]. Der LM-Test fÃ¼r GARCH(1,2) oder das lokal Ã¤quivalente GARCH(2,1) ergibt 3.80 und ist daher auf dem 5%-Niveau nicht signifikant. Die LM-Teststatistik fÃ¼r den Einschluss von $\epsilon_{t-1}^2, \dots, \epsilon_{t-5}^2$ nimmt den Wert 5.58 an, was dem 0.77-Fraktil in der $\chi_5^2$-Verteilung entspricht [^1].

> ğŸ’¡ **Exemplo NumÃ©rico:** Nehmen wir an, wir haben $\epsilon_{t-1} = 0.2$ und $h_{t-1} = 0.15$. Dann berechnen wir $h_t$ wie folgt:
>
> $h_t = 0.007 + 0.135(0.2)^2 + 0.829(0.15)$
>
> $h_t = 0.007 + 0.135(0.04) + 0.12435$
>
> $h_t = 0.007 + 0.0054 + 0.12435$
>
> $h_t = 0.13675$
>
> Dies veranschaulicht, wie die aktuelle bedingte Varianz $h_t$ im GARCH(1,1)-Modell aus dem quadrierten Fehler der vorherigen Periode und der bedingten Varianz der vorherigen Periode berechnet wird.
>
> Wir kÃ¶nnen auch ein Diagramm erstellen, um zu zeigen, wie sich die bedingte Varianz im Laufe der Zeit Ã¤ndert.
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
>
> # Parameterwerte
> omega = 0.007
> alpha = 0.135
> beta = 0.829
>
> # Anzahl der Perioden
> T = 100
>
> # Residuen simulieren (normalverteilt mit Mittelwert 0)
> np.random.seed(42)  # FÃ¼r Reproduzierbarkeit
> epsilon = np.random.normal(0, 1, T)
>
> # Bedingte Varianz initialisieren
> h = np.zeros(T)
> h[0] = omega / (1 - alpha - beta)  # Unbedingte Varianz als Startwert
>
> # GARCH(1,1) simulieren
> for t in range(1, T):
>     h[t] = omega + alpha * epsilon[t-1]**2 + beta * h[t-1]
>
> # Plot der bedingten Varianz
> plt.figure(figsize=(10, 6))
> plt.plot(h)
> plt.title("GARCH(1,1) Bedingte Varianz")
> plt.xlabel("Zeit")
> plt.ylabel("Bedingte Varianz")
> plt.grid(True)
> plt.show()
> ```

Um die GARCH(1,1)-Spezifikation weiter zu untersuchen, betrachten wir die StationaritÃ¤tsbedingung.

**Lema 1.** FÃ¼r das GARCH(1,1)-Modell, $h_t = \omega + \alpha \epsilon_{t-1}^2 + \beta h_{t-1}$, ist die StationaritÃ¤tsbedingung gegeben durch $\alpha + \beta < 1$.

*Beweis.* Die StationaritÃ¤tsbedingung ergibt sich aus der Forderung, dass die unbedingte Varianz von $\pi_t$ endlich ist. Diese Bedingung ist Ã¤quivalent zu $E[\log(\alpha \epsilon_{t-1}^2 + \beta h_{t-1})] < 0$. FÃ¼r ein GARCH(1,1) Modell vereinfacht sich diese Bedingung zu $\alpha + \beta < 1$.

I. Wir betrachten das GARCH(1,1)-Modell: $h_t = \omega + \alpha \epsilon_{t-1}^2 + \beta h_{t-1}$.
II. Die StationaritÃ¤tsbedingung fÃ¼r ein GARCH(1,1)-Modell ist gegeben durch: $E[\log(\alpha \epsilon_{t-1}^2 + \beta h_{t-1})] < 0$.
III. Durch Vereinfachung dieser Bedingung erhÃ¤lt man: $\alpha + \beta < 1$.
IV. Dies stellt sicher, dass die unbedingte Varianz des Prozesses endlich ist und der Prozess stationÃ¤r ist. â– 

**CorolÃ¡rio 1.** Im vorliegenden Fall, mit $\alpha = 0.135$ und $\beta = 0.829$, ist $\alpha + \beta = 0.135 + 0.829 = 0.964 < 1$. Somit erfÃ¼llt das geschÃ¤tzte GARCH(1,1)-Modell die StationaritÃ¤tsbedingung.

> ğŸ’¡ **Exemplo NumÃ©rico:** Angenommen, wir schÃ¤tzen ein anderes GARCH(1,1)-Modell und erhalten $\alpha = 0.2$ und $\beta = 0.9$. Dann ist $\alpha + \beta = 1.1 > 1$. Dieses Modell wÃ¤re nicht stationÃ¤r, was bedeutet, dass die Varianz mit der Zeit explodieren kÃ¶nnte, was es fÃ¼r die Prognose unbrauchbar macht.

### Koeffizienten der Kurtosis und Schiefe

Der Stichprobenkoeffizient der Kurtosis fÃ¼r $\epsilon_t h_t^{-1/2}$ aus Modell (31) betrÃ¤gt 3.81, was sich von dem "normalen" Wert von 3.00 um geringfÃ¼gig weniger als zwei asymptotische Standardfehler, $2\sqrt{24/T} = 0.82$, unterscheidet [^1]. FÃ¼r die Modelle (29) und (30) betrÃ¤gt der Koeffizient der Kurtosis 6.90 bzw. 4.07 [^1]. Die Stichprobenkoeffizienten der Schiefe fÃ¼r $\epsilon_t h_t^{-1/2}$ aus jedem der drei Modelle liegen alle innerhalb eines asymptotischen Standardfehlers, $\sqrt{6/T} = 0.20$ [^1].

> ğŸ’¡ **Exemplo NumÃ©rico:** Ein Kurtosis-Wert von 3.81 deutet darauf hin, dass die Verteilung der standardisierten Residuen leptokurtisch ist, d.h. sie hat schwerere RÃ¤nder und einen spitzeren Gipfel als eine Normalverteilung. Dies ist typisch fÃ¼r Finanzdaten. Ein Schiefe-Wert innerhalb von $\pm 0.20$ deutet darauf hin, dass die Verteilung ungefÃ¤hr symmetrisch ist.
>
> Wir kÃ¶nnen auch diese Werte mit denen einer Normalverteilung vergleichen. Die Kurtosis einer Normalverteilung betrÃ¤gt 3, und die Schiefe betrÃ¤gt 0.

### Interpretation der Lag-Struktur

Die mittlere und mediane VerzÃ¶gerung in der bedingten Varianzgleichung in (31) werden auf 5.848 bzw. 3.696 geschÃ¤tzt [^1]. Im Vergleich dazu wird in (30) die mittlere VerzÃ¶gerung auf $3\frac{1}{3}$ gezwungen, und die mediane VerzÃ¶gerung betrÃ¤gt $2\frac{1}{2}$ [^1]. Die VerzÃ¶gerungsstruktur im GARCH(1,1)-Modell kann durch eine Art adaptiven Lernmechanismus rationalisiert werden.

### Schlussfolgerung
Das GARCH(1,1)-Modell bietet eine etwas bessere Anpassung als das ARCH(8)-Modell von Engle und Kraft (1983) und weist auch eine vernÃ¼nftigere VerzÃ¶gerungsstruktur auf [^1].

### Referenzen
[^1]: Tim Bollerslev, *Generalized Autoregressive Conditional Heteroskedasticity*
<!-- END -->