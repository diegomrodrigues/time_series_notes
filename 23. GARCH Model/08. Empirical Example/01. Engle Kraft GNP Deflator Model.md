Empirische Anwendung: GARCH Modellierung der Inflationsunsicherheit

### Einf√ºhrung
In diesem Kapitel untersuchen wir eine empirische Anwendung des GARCH-Modells, die auf der Arbeit von Engle und Kraft (1983) basiert [^1]. Diese Anwendung konzentriert sich auf die Modellierung der Unsicherheit der Inflation in den Vereinigten Staaten mithilfe des GARCH-Modells, wobei die Wachstumsrate des impliziten GNP-Deflators in den USA durch seine eigene Vergangenheit erkl√§rt wird. Die Unsicherheit der Inflation ist eine √∂konomisch wichtige Variable, die nicht direkt beobachtet werden kann, und wurde bereits in mehreren ARCH-Modellen untersucht [^1].

### Modellspezifikation
Die Studie von Engle und Kraft (1983) wird hier n√§her betrachtet, wobei die Wachstumsrate des impliziten GNP-Deflators in den USA durch ihre eigene Vergangenheit erkl√§rt wird [^1].

Definiere $\pi_t = 100 \cdot \ln(GD_t/GD_{t-1})$, wobei $GD_t$ den impliziten Preisdeflator f√ºr das GNP darstellt [^1]. Standardunivariate Zeitreihenmethoden f√ºhren zur Identifizierung des folgenden Modells f√ºr $\pi_t$:

$$
\pi_t = 0.240 + 0.552\pi_{t-1} + 0.177\pi_{t-2} + 0.232\pi_{t-3} - 0.209\pi_{t-4} + \epsilon_t, \quad h_t = 0.282
$$

Die Werte in Klammern geben die Standardfehler an [^1]. Das Modell wird anhand viertelj√§hrlicher Daten von 1948.2 bis 1983.4 gesch√§tzt, was insgesamt 143 Beobachtungen entspricht [^1]. Die Sch√§tzung erfolgt mittels Ordinary Least Squares (OLS).

> üí° **Exemplo Num√©rico:** Nehmen wir an, wir haben die folgenden ersten f√ºnf Werte f√ºr $\pi_t$: 2.5, 1.8, 2.1, 1.9, 2.3. Die Gleichung f√ºr $\pi_5$ w√§re dann:
>
> $\pi_5 = 0.240 + 0.552(2.3) + 0.177(1.9) + 0.232(2.1) - 0.209(1.8) + \epsilon_5$
>
> $\pi_5 = 0.240 + 1.2696 + 0.3363 + 0.4872 - 0.3762 + \epsilon_5$
>
> $\pi_5 = 1.957 + \epsilon_5$
>
> Wenn wir annehmen, dass der tats√§chliche Wert von $\pi_5$ 2.3 war, dann w√§re $\epsilon_5 = 2.3 - 1.957 = 0.343$. Das Modell sch√§tzt also den Inflationswert f√ºr das f√ºnfte Quartal basierend auf den vorherigen vier Quartalen und einem Fehlerterm. Die konstante Varianz des Fehlers betr√§gt 0.282.

### Analyse der Residuen

Das Modell ist station√§r, und keine der ersten zehn Autokorrelationen oder partiellen Autokorrelationen f√ºr $\epsilon_t$ ist auf dem 5%-Niveau signifikant [^1]. Jedoch √ºberschreiten die Autokorrelationen f√ºr $\epsilon_t^2$ f√ºr die 1., 3., 7., 9. und 10. Verz√∂gerung alle zwei asymptotischen Standardfehler. √Ñhnliche Ergebnisse gelten f√ºr die partiellen Autokorrelationen f√ºr $\epsilon_t^2$. Der LM-Test f√ºr ARCH(1), ARCH(4) und ARCH(8) ist ebenfalls auf jedem vern√ºnftigen Niveau hochsignifikant [^1].

**Proposi√ß√£o 1.** Die Signifikanz der Autokorrelationen und partiellen Autokorrelationen von $\epsilon_t^2$ deutet auf eine bedingte Heteroskedastizit√§t hin, was die Anwendung von ARCH- oder GARCH-Modellen rechtfertigt.

*Beweis.* Die Definition von ARCH- und GARCH-Modellen beinhaltet explizit die Modellierung der Varianz als Funktion vergangener Fehlerquadrate. Signifikante Autokorrelationen in den quadrierten Residuen sind ein starker Hinweis darauf, dass die Varianz nicht konstant ist, sondern von vergangenen Schocks abh√§ngt. Die Signifikanz des LM-Tests best√§tigt dies zus√§tzlich.

I. Signifikante Autokorrelationen und partielle Autokorrelationen in $\epsilon_t^2$ implizieren, dass die Varianz der Residuen nicht konstant √ºber die Zeit ist.
II. ARCH- und GARCH-Modelle sind speziell daf√ºr entwickelt, solche zeitabh√§ngigen Varianzen zu modellieren.
III. Daher ist die Anwendung von ARCH- oder GARCH-Modellen gerechtfertigt, um die bedingte Heteroskedastizit√§t in den Daten zu ber√ºcksichtigen. ‚ñ†

> üí° **Exemplo Num√©rico:** Nehmen wir an, wir berechnen die Autokorrelationen der quadrierten Residuen $\epsilon_t^2$ und finden:
>
> $\text{Autokorrelation}(\epsilon_t^2, \epsilon_{t-1}^2) = 0.35$
>
> $\text{Autokorrelation}(\epsilon_t^2, \epsilon_{t-3}^2) = 0.28$
>
> $\text{Autokorrelation}(\epsilon_t^2, \epsilon_{t-7}^2) = 0.42$
>
> $\text{Autokorrelation}(\epsilon_t^2, \epsilon_{t-9}^2) = 0.31$
>
> $\text{Autokorrelation}(\epsilon_t^2, \epsilon_{t-10}^2) = 0.25$
>
> Der asymptotische Standardfehler ist ungef√§hr $1/\sqrt{T} = 1/\sqrt{143} \approx 0.084$. Zwei asymptotische Standardfehler w√§ren also etwa 0.168. Da die oben genannten Autokorrelationen alle gr√∂√üer als 0.168 sind, sind sie signifikant. Dies deutet darauf hin, dass gro√üe (oder kleine) Quadrate von Residuen dazu neigen, von gro√üen (oder kleinen) Quadraten von Residuen in den angegebenen Verz√∂gerungen gefolgt zu werden, was auf eine bedingte Heteroskedastizit√§t hindeutet.
>
> Der LM-Test f√ºr ARCH(1) ergibt einen p-Wert von 0.02, f√ºr ARCH(4) einen p-Wert von 0.001 und f√ºr ARCH(8) einen p-Wert von 0.0005. Da diese p-Werte alle unter 0.05 liegen, lehnen wir die Nullhypothese ab, dass keine ARCH-Effekte vorliegen, was die Notwendigkeit eines ARCH- oder GARCH-Modells weiter unterst√ºtzt.

### ARCH-Modell nach Engle und Kraft
Diese Ergebnisse veranlassen Engle und Kraft (1983), die folgende Spezifikation vorzuschlagen:

$$
\pi_t = 0.138 + 0.423\pi_{t-1} + 0.222\pi_{t-2} + 0.377\pi_{t-3} - 0.175\pi_{t-4} + \epsilon_t, \quad h_t = 0.058 + 0.802 \sum_{i=1}^{8} (9-i)/36 \epsilon_{t-i}^2
$$

Die Sch√§tzungen sind Maximum-Likelihood-Sch√§tzungen mit heteroskedastie-konsistenten Standardfehlern in Klammern. Die Wahl der linearen Struktur mit abnehmender Verz√∂gerung achter Ordnung ist eher ad hoc, wird aber durch das lange Ged√§chtnis in der bedingten Varianzgleichung motiviert.

> üí° **Exemplo Num√©rico:** Nehmen wir an, wir haben die folgenden Werte f√ºr die quadrierten Residuen in den letzten 8 Perioden: $\epsilon_{t-1}^2 = 0.09, \epsilon_{t-2}^2 = 0.16, \epsilon_{t-3}^2 = 0.04, \epsilon_{t-4}^2 = 0.25, \epsilon_{t-5}^2 = 0.01, \epsilon_{t-6}^2 = 0.36, \epsilon_{t-7}^2 = 0.10, \epsilon_{t-8}^2 = 0.05$. Dann berechnen wir $h_t$ wie folgt:
>
> $h_t = 0.058 + 0.802 \cdot [(8/36) \cdot 0.09 + (7/36) \cdot 0.16 + (6/36) \cdot 0.04 + (5/36) \cdot 0.25 + (4/36) \cdot 0.01 + (3/36) \cdot 0.36 + (2/36) \cdot 0.10 + (1/36) \cdot 0.05]$
>
> $h_t = 0.058 + 0.802 \cdot [0.02 + 0.031 + 0.007 + 0.035 + 0.001 + 0.03 + 0.006 + 0.001]$
>
> $h_t = 0.058 + 0.802 \cdot 0.131$
>
> $h_t = 0.058 + 0.105$
>
> $h_t = 0.163$
>
> Dies zeigt, wie die bedingte Varianz $h_t$ basierend auf vergangenen quadrierten Fehlern und einer abnehmenden Verz√∂gerungsstruktur berechnet wird.

### GARCH(1,1) Modell
Alternativ betrachten wir die folgende GARCH(1,1)-Spezifikation:

$$
\pi_t = 0.141 + 0.433\pi_{t-1} + 0.229\pi_{t-2} + 0.349\pi_{t-3} - 0.162\pi_{t-4} + \epsilon_t, \quad h_t = 0.007 + 0.135\epsilon_{t-1}^2 + 0.829h_{t-1}
$$

Gem√§√ü Theorem 2 existiert das vierte Moment von $\epsilon_t$ [^1]. Keine der ersten zehn Autokorrelationen oder partiellen Autokorrelationen f√ºr $\epsilon_t h_t^{-1/2}$ √ºbersteigt zwei asymptotische Standardfehler. Der LM-Test f√ºr den Einschluss der linearen Struktur mit abnehmender Verz√∂gerung achter Ordnung ergibt 2.33, was dem 0.87-Fraktil in der $\chi_1^2$-Verteilung entspricht [^1]. Der LM-Test f√ºr GARCH(1,2) oder das lokal √§quivalente GARCH(2,1) ergibt 3.80 und ist daher auf dem 5%-Niveau nicht signifikant. Die LM-Teststatistik f√ºr den Einschluss von $\epsilon_{t-1}^2, \dots, \epsilon_{t-5}^2$ nimmt den Wert 5.58 an, was dem 0.77-Fraktil in der $\chi_5^2$-Verteilung entspricht [^1].

> üí° **Exemplo Num√©rico:** Nehmen wir an, wir haben $\epsilon_{t-1} = 0.2$ und $h_{t-1} = 0.15$. Dann berechnen wir $h_t$ wie folgt:
>
> $h_t = 0.007 + 0.135(0.2)^2 + 0.829(0.15)$
>
> $h_t = 0.007 + 0.135(0.04) + 0.12435$
>
> $h_t = 0.007 + 0.0054 + 0.12435$
>
> $h_t = 0.13675$
>
> Dies veranschaulicht, wie die aktuelle bedingte Varianz $h_t$ im GARCH(1,1)-Modell aus dem quadrierten Fehler der vorherigen Periode und der bedingten Varianz der vorherigen Periode berechnet wird.
>
> Wir k√∂nnen auch ein Diagramm erstellen, um zu zeigen, wie sich die bedingte Varianz im Laufe der Zeit √§ndert.
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
>
> # Parameterwerte
> omega = 0.007
> alpha = 0.135
> beta = 0.829
>
> # Anzahl der Perioden
> T = 100
>
> # Residuen simulieren (normalverteilt mit Mittelwert 0)
> np.random.seed(42)  # F√ºr Reproduzierbarkeit
> epsilon = np.random.normal(0, 1, T)
>
> # Bedingte Varianz initialisieren
> h = np.zeros(T)
> h[0] = omega / (1 - alpha - beta)  # Unbedingte Varianz als Startwert
>
> # GARCH(1,1) simulieren
> for t in range(1, T):
>     h[t] = omega + alpha * epsilon[t-1]**2 + beta * h[t-1]
>
> # Plot der bedingten Varianz
> plt.figure(figsize=(10, 6))
> plt.plot(h)
> plt.title("GARCH(1,1) Bedingte Varianz")
> plt.xlabel("Zeit")
> plt.ylabel("Bedingte Varianz")
> plt.grid(True)
> plt.show()
> ```

Um die GARCH(1,1)-Spezifikation weiter zu untersuchen, betrachten wir die Stationarit√§tsbedingung.

**Lema 1.** F√ºr das GARCH(1,1)-Modell, $h_t = \omega + \alpha \epsilon_{t-1}^2 + \beta h_{t-1}$, ist die Stationarit√§tsbedingung gegeben durch $\alpha + \beta < 1$.

*Beweis.* Die Stationarit√§tsbedingung ergibt sich aus der Forderung, dass die unbedingte Varianz von $\pi_t$ endlich ist. Diese Bedingung ist √§quivalent zu $E[\log(\alpha \epsilon_{t-1}^2 + \beta h_{t-1})] < 0$. F√ºr ein GARCH(1,1) Modell vereinfacht sich diese Bedingung zu $\alpha + \beta < 1$.

I. Wir betrachten das GARCH(1,1)-Modell: $h_t = \omega + \alpha \epsilon_{t-1}^2 + \beta h_{t-1}$.
II. Die Stationarit√§tsbedingung f√ºr ein GARCH(1,1)-Modell ist gegeben durch: $E[\log(\alpha \epsilon_{t-1}^2 + \beta h_{t-1})] < 0$.
III. Durch Vereinfachung dieser Bedingung erh√§lt man: $\alpha + \beta < 1$.
IV. Dies stellt sicher, dass die unbedingte Varianz des Prozesses endlich ist und der Prozess station√§r ist. ‚ñ†

**Corol√°rio 1.** Im vorliegenden Fall, mit $\alpha = 0.135$ und $\beta = 0.829$, ist $\alpha + \beta = 0.135 + 0.829 = 0.964 < 1$. Somit erf√ºllt das gesch√§tzte GARCH(1,1)-Modell die Stationarit√§tsbedingung.

> üí° **Exemplo Num√©rico:** Angenommen, wir sch√§tzen ein anderes GARCH(1,1)-Modell und erhalten $\alpha = 0.2$ und $\beta = 0.9$. Dann ist $\alpha + \beta = 1.1 > 1$. Dieses Modell w√§re nicht station√§r, was bedeutet, dass die Varianz mit der Zeit explodieren k√∂nnte, was es f√ºr die Prognose unbrauchbar macht.

### Koeffizienten der Kurtosis und Schiefe

Der Stichprobenkoeffizient der Kurtosis f√ºr $\epsilon_t h_t^{-1/2}$ aus Modell (31) betr√§gt 3.81, was sich von dem "normalen" Wert von 3.00 um geringf√ºgig weniger als zwei asymptotische Standardfehler, $2\sqrt{24/T} = 0.82$, unterscheidet [^1]. F√ºr die Modelle (29) und (30) betr√§gt der Koeffizient der Kurtosis 6.90 bzw. 4.07 [^1]. Die Stichprobenkoeffizienten der Schiefe f√ºr $\epsilon_t h_t^{-1/2}$ aus jedem der drei Modelle liegen alle innerhalb eines asymptotischen Standardfehlers, $\sqrt{6/T} = 0.20$ [^1].

> üí° **Exemplo Num√©rico:** Ein Kurtosis-Wert von 3.81 deutet darauf hin, dass die Verteilung der standardisierten Residuen leptokurtisch ist, d.h. sie hat schwerere R√§nder und einen spitzeren Gipfel als eine Normalverteilung. Dies ist typisch f√ºr Finanzdaten. Ein Schiefe-Wert innerhalb von $\pm 0.20$ deutet darauf hin, dass die Verteilung ungef√§hr symmetrisch ist.
>
> Wir k√∂nnen auch diese Werte mit denen einer Normalverteilung vergleichen. Die Kurtosis einer Normalverteilung betr√§gt 3, und die Schiefe betr√§gt 0.

### Interpretation der Lag-Struktur

Die mittlere und mediane Verz√∂gerung in der bedingten Varianzgleichung in (31) werden auf 5.848 bzw. 3.696 gesch√§tzt [^1]. Im Vergleich dazu wird in (30) die mittlere Verz√∂gerung auf $3\frac{1}{3}$ gezwungen, und die mediane Verz√∂gerung betr√§gt $2\frac{1}{2}$ [^1]. Die Verz√∂gerungsstruktur im GARCH(1,1)-Modell kann durch eine Art adaptiven Lernmechanismus rationalisiert werden.

### Schlussfolgerung
Das GARCH(1,1)-Modell bietet eine etwas bessere Anpassung als das ARCH(8)-Modell von Engle und Kraft (1983) und weist auch eine vern√ºnftigere Verz√∂gerungsstruktur auf [^1].

### Referenzen
[^1]: Tim Bollerslev, *Generalized Autoregressive Conditional Heteroskedasticity*
<!-- END -->