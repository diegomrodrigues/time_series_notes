O Processo GARCH(1,1): Exist√™ncia de Momentos Superiores

### Introdu√ß√£o

Este cap√≠tulo, em continuidade √† nossa an√°lise detalhada do processo GARCH(1,1) [^1, ^2], foca-se na condi√ß√£o necess√°ria e suficiente para a exist√™ncia do 2m-√©simo momento, expressa pelo Teorema 2. Vimos anteriormente que a condi√ß√£o $\alpha_1 + \beta_1 < 1$ √© crucial para a estacionariedade *wide-sense*, garantindo que a vari√¢ncia incondicional do processo seja finita e constante [^5]. No entanto, a exist√™ncia de momentos superiores imp√µe restri√ß√µes adicionais sobre os par√¢metros, impactando a an√°lise de caudas e o comportamento do modelo em situa√ß√µes extremas. Compreender a condi√ß√£o de exist√™ncia do 2m-√©simo momento √©, portanto, fundamental para a aplica√ß√£o robusta e precisa do GARCH(1,1) em modelagem financeira e econ√¥mica.

### Conceitos Fundamentais

O Teorema 2, conforme apresentado em [^5], estabelece que, para o processo GARCH(1,1) definido por $\epsilon_t|\Psi_{t-1} \sim N(0, h_t)$ e $h_t = \alpha_0 + \alpha_1\epsilon_{t-1}^2 + \beta_1h_{t-1}$, a condi√ß√£o necess√°ria e suficiente para a exist√™ncia do 2m-√©simo momento √©:

$$
\mu(\alpha_1, \beta_1, m) = \sum_{j=0}^{m} \binom{m}{j} a_j \alpha_1^j \beta_1^{m-j} < 1
$$

onde:

*   $m$ √© um inteiro positivo representando a ordem do momento.
*   $\binom{m}{j}$ denota o coeficiente binomial, calculado como $\frac{m!}{j!(m-j)!}$.
*   $a_j = \prod_{i=1}^{j} (2i - 1)$ para $j \geq 1$, com $a_0 = 1$.
*   $\alpha_1$ e $\beta_1$ s√£o os par√¢metros do modelo GARCH(1,1).

**Interpreta√ß√£o da Condi√ß√£o:**

A condi√ß√£o $\mu(\alpha_1, \beta_1, m) < 1$ imp√µe uma restri√ß√£o sobre a magnitude dos par√¢metros $\alpha_1$ e $\beta_1$ em rela√ß√£o √† ordem do momento $m$. Quanto maior $m$, mais restritiva se torna a condi√ß√£o, refletindo a necessidade de um decaimento mais r√°pido nas caudas da distribui√ß√£o para garantir a exist√™ncia de momentos superiores.

> üí° **Exemplo Num√©rico:** Para o caso de $m = 1$ (exist√™ncia do segundo momento, ou vari√¢ncia), a condi√ß√£o se torna $\mu(\alpha_1, \beta_1, 1) = \alpha_1 + \beta_1 < 1$. Se $\alpha_1 = 0.2$ e $\beta_1 = 0.7$, ent√£o $\alpha_1 + \beta_1 = 0.9 < 1$, indicando que o segundo momento existe.  No entanto, se $\alpha_1 = 0.6$ e $\beta_1 = 0.5$, ent√£o $\alpha_1 + \beta_1 = 1.1 > 1$, e o segundo momento n√£o existe, violando a condi√ß√£o de estacionariedade *wide-sense*.
>
> üí° **Exemplo Num√©rico:** Considere $m=3$. A condi√ß√£o para a exist√™ncia do 6¬∫ momento torna-se:
> $\mu(\alpha_1, \beta_1, 3) = a_0\beta_1^3 + 3a_1\alpha_1\beta_1^2 + 3a_2\alpha_1^2\beta_1 + a_3\alpha_1^3 = \beta_1^3 + 3\alpha_1\beta_1^2 + 9\alpha_1^2\beta_1 + 15\alpha_1^3 < 1$. Se $\alpha_1 = 0.05$ e $\beta_1 = 0.85$, ent√£o $\mu(\alpha_1, \beta_1, 3) = (0.85)^3 + 3(0.05)(0.85)^2 + 9(0.05)^2(0.85) + 15(0.05)^3 = 0.614 + 0.108 + 0.019 + 0.002 = 0.743 < 1$. Neste caso, o sexto momento existe. Se $\alpha_1 = 0.2$ e $\beta_1 = 0.9$, ent√£o $\mu(\alpha_1, \beta_1, 3) = (0.9)^3 + 3(0.2)(0.9)^2 + 9(0.2)^2(0.9) + 15(0.2)^3 = 0.729 + 0.486 + 0.324 + 0.12 = 1.659 > 1$. Neste caso, o sexto momento n√£o existe.

**Caso Particular: Exist√™ncia do Quarto Momento (m=2):**

Como j√° demonstrado no cap√≠tulo anterior, o caso particular de $m=2$, que garante a exist√™ncia do quarto momento, √© dado por [^5]:

$$
3\alpha_1^2 + 2\alpha_1\beta_1 + \beta_1^2 < 1
$$

Esta condi√ß√£o √© mais restritiva do que a condi√ß√£o de estacionariedade *wide-sense* ($\alpha_1 + \beta_1 < 1$), o que implica que um processo GARCH(1,1) pode ser estacion√°rio *wide-sense* sem necessariamente possuir um quarto momento finito.

**Prova da afirma√ß√£o de que a condi√ß√£o para a exist√™ncia do quarto momento √© mais restritiva que a condi√ß√£o de estacionariedade:**

Provaremos que $3\alpha_1^2 + 2\alpha_1\beta_1 + \beta_1^2 < 1$ implica $\alpha_1 + \beta_1 < 1$, mas o inverso n√£o √© necessariamente verdadeiro.

I.  Assumindo que $3\alpha_1^2 + 2\alpha_1\beta_1 + \beta_1^2 < 1$, podemos reescrever a express√£o como:

$$
\alpha_1^2 + 2\alpha_1\beta_1 + \beta_1^2 + 2\alpha_1^2 < 1
$$

II. Reconhecendo que $\alpha_1^2 + 2\alpha_1\beta_1 + \beta_1^2 = (\alpha_1 + \beta_1)^2$, a desigualdade torna-se:

$$
(\alpha_1 + \beta_1)^2 + 2\alpha_1^2 < 1
$$

III. Dado que $2\alpha_1^2$ √© sempre n√£o negativo, $(\alpha_1 + \beta_1)^2$ deve ser menor que 1:

$$
(\alpha_1 + \beta_1)^2 < 1
$$

IV. Tomando a raiz quadrada de ambos os lados (e considerando que $\alpha_1$ e $\beta_1$ s√£o n√£o negativos):

$$
\alpha_1 + \beta_1 < 1
$$

V. Portanto, a condi√ß√£o para a exist√™ncia do quarto momento implica a condi√ß√£o de estacionariedade. No entanto, o inverso n√£o √© verdadeiro. Por exemplo, se $\alpha_1 = 0.6$ e $\beta_1 = 0.3$, ent√£o $\alpha_1 + \beta_1 = 0.9 < 1$, mas $3(0.6)^2 + 2(0.6)(0.3) + (0.3)^2 = 1.08 + 0.36 + 0.09 = 1.53 > 1$.

VI. Conclu√≠mos que a condi√ß√£o para a exist√™ncia do quarto momento √© mais restritiva. ‚ñ†

> üí° **Exemplo Num√©rico:**  Para $\alpha_1 = 0.2$ e $\beta_1 = 0.6$, temos $\alpha_1 + \beta_1 = 0.8 < 1$, satisfazendo a condi√ß√£o de estacionariedade.  Para a exist√™ncia do quarto momento, $3(0.2)^2 + 2(0.2)(0.6) + (0.6)^2 = 0.12 + 0.24 + 0.36 = 0.72 < 1$, ent√£o o quarto momento existe. Agora, para $\alpha_1 = 0.4$ e $\beta_1 = 0.5$, $\alpha_1 + \beta_1 = 0.9 < 1$, mas $3(0.4)^2 + 2(0.4)(0.5) + (0.5)^2 = 0.48 + 0.40 + 0.25 = 1.13 > 1$, ent√£o o quarto momento n√£o existe, mesmo com estacionariedade garantida.

**Prova do Teorema 2:**

A prova formal do Teorema 2 envolve a an√°lise da fun√ß√£o geradora de momentos do processo GARCH(1,1). A demonstra√ß√£o detalhada pode ser encontrada em [^5], mas a ideia central √© mostrar que a fun√ß√£o geradora de momentos converge se e somente se a condi√ß√£o $\mu(\alpha_1, \beta_1, m) < 1$ for satisfeita. A converg√™ncia da fun√ß√£o geradora de momentos √© equivalente √† exist√™ncia do 2m-√©simo momento.

Para fins de ilustra√ß√£o, apresentamos um esbo√ßo da prova:

I. Defina $M_t(z) = E[e^{z\epsilon_t^2}|\Psi_{t-1}]$ como a fun√ß√£o geradora de momentos condicional de $\epsilon_t^2$.

II. Usando a distribui√ß√£o normal condicional, $\epsilon_t|\Psi_{t-1} \sim N(0, h_t)$, temos:

$$
M_t(z) = E[e^{z\epsilon_t^2}|\Psi_{t-1}] = (1 - 2zh_t)^{-1/2}
$$

III. Para a exist√™ncia do 2m-√©simo momento, precisamos garantir que $E[\epsilon_t^{2m}]$ seja finito. Isso est√° relacionado √† converg√™ncia de $E[M_t(z)]$.

IV. Expandindo $h_t$ e tomando o valor esperado incondicional, obtemos uma express√£o complexa que envolve os par√¢metros $\alpha_1$ e $\beta_1$.

V. Ap√≥s v√°rias manipula√ß√µes alg√©bricas e usando a defini√ß√£o de $\mu(\alpha_1, \beta_1, m)$, pode-se mostrar que a condi√ß√£o para a converg√™ncia de $E[M_t(z)]$ √© equivalente a $\mu(\alpha_1, \beta_1, m) < 1$.

VI. Portanto, a condi√ß√£o $\mu(\alpha_1, \beta_1, m) < 1$ √© necess√°ria e suficiente para a exist√™ncia do 2m-√©simo momento de $\epsilon_t$. ‚ñ†

**Exemplo Num√©rico:**

Para ilustrar, considere um processo GARCH(1,1) com par√¢metros $\alpha_1 = 0.1$ e $\beta_1 = 0.8$. Vamos verificar a exist√™ncia do quarto momento ($m=2$):

$$
\mu(\alpha_1, \beta_1, 2) = 3\alpha_1^2 + 2\alpha_1\beta_1 + \beta_1^2 = 3(0.1)^2 + 2(0.1)(0.8) + (0.8)^2 = 0.03 + 0.16 + 0.64 = 0.83 < 1
$$

Neste caso, o quarto momento existe.

Agora, considere um processo GARCH(1,1) com par√¢metros $\alpha_1 = 0.3$ e $\beta_1 = 0.7$. Verificamos a exist√™ncia do quarto momento:

$$
\mu(\alpha_1, \beta_1, 2) = 3\alpha_1^2 + 2\alpha_1\beta_1 + \beta_1^2 = 3(0.3)^2 + 2(0.3)(0.7) + (0.7)^2 = 0.27 + 0.42 + 0.49 = 1.18 > 1
$$

Neste caso, o quarto momento n√£o existe.

**Implica√ß√µes da Exist√™ncia de Momentos Superiores:**

A exist√™ncia de momentos superiores, em particular o quarto momento, tem importantes implica√ß√µes para a modelagem de risco e a an√°lise estat√≠stica do processo GARCH(1,1):

1.  **Validade de Testes Estat√≠sticos:** Muitos testes estat√≠sticos, como testes de normalidade e testes baseados na teoria assint√≥tica, dependem da exist√™ncia de momentos superiores. Se esses momentos n√£o existirem, os resultados dos testes podem ser n√£o confi√°veis.
2.  **Precis√£o das Previs√µes:** A exist√™ncia de momentos superiores pode melhorar a precis√£o das previs√µes de volatilidade, especialmente em situa√ß√µes de eventos extremos.
3.  **Avalia√ß√£o de Risco:** A an√°lise de caudas, que depende da exist√™ncia de momentos superiores, √© crucial para a avalia√ß√£o de risco em mercados financeiros.

Como a escolha da distribui√ß√£o condicional tem impacto significativo na an√°lise de momentos, o pr√≥ximo teorema explora o caso em que a distribui√ß√£o condicional √© uma t-Student.

**Teorema 3:** Condi√ß√£o para exist√™ncia do 2m-√©simo momento com distribui√ß√£o t-Student
Se $\epsilon_t|\Psi_{t-1} \sim t(\nu, 0, h_t)$, ent√£o uma condi√ß√£o suficiente para a exist√™ncia do 2m-√©simo momento de $\epsilon_t$ √© $\nu > 2m$, onde $\nu$ s√£o os graus de liberdade da distribui√ß√£o t-Student.
*Prova*:
A prova √© baseada nas propriedades da distribui√ß√£o t-Student. Para que o 2m-√©simo momento exista, a integral $\int_{-\infty}^{\infty} x^{2m}f(x) dx$ deve convergir, onde f(x) √© a densidade da t-Student. Esta integral converge se e somente se $\nu > 2m$.

I. O 2m-√©simo momento da distribui√ß√£o t-Student com $\nu$ graus de liberdade √© dado por:

$$E[X^{2m}] = \int_{-\infty}^{\infty} x^{2m} \frac{\Gamma(\frac{\nu + 1}{2})}{\sqrt{\nu\pi}\Gamma(\frac{\nu}{2})} \left(1 + \frac{x^2}{\nu}\right)^{-\frac{\nu+1}{2}} dx$$

II. Para que este integral convirja, o integrando deve decair suficientemente r√°pido √† medida que $|x| \to \infty$.

III. O comportamento assint√≥tico do integrando √© dominado pelo termo $\left(1 + \frac{x^2}{\nu}\right)^{-\frac{\nu+1}{2}}$, que se comporta como $|x|^{-(\nu+1)}$ para grandes $|x|$.

IV. Portanto, a integral converge se e somente se $\nu + 1 > 2m + 1$, o que simplifica para $\nu > 2m$.

V. Assim, a condi√ß√£o suficiente para a exist√™ncia do 2m-√©simo momento √© $\nu > 2m$. ‚ñ†

> üí° **Exemplo Num√©rico:**
> Suponha que $\epsilon_t|\Psi_{t-1} \sim t(4, 0, h_t)$. Isso significa que $\nu = 4$. Ent√£o, o quarto momento ($m=2$) n√£o existe, pois $\nu = 4 \le 2m = 4$. No entanto, o segundo momento existe, pois $\nu = 4 > 2(1) = 2$.
>
> üí° **Exemplo Num√©rico:** Se $\nu=6$, ent√£o o quarto momento existe, pois $\nu=6 > 2m = 4$. O sexto momento tamb√©m existe, pois $\nu=6 = 2m = 6$ (note que a condi√ß√£o √© $\nu > 2m$, mas para fins pr√°ticos, a igualdade costuma ser considerada, embora a converg√™ncia possa ser marginal). O oitavo momento n√£o existe, pois $\nu=6 < 2m = 8$.

√â importante notar que, ao utilizar a distribui√ß√£o t-Student, a condi√ß√£o de estacionariedade *wide-sense* pode ser influenciada, como demonstrado no lema a seguir.

**Lema 1:** Relaxamento da condi√ß√£o de estacionariedade para a distribui√ß√£o t-Student
Sob a condi√ß√£o de que $\epsilon_t$ siga uma distribui√ß√£o t-Student condicional, √© poss√≠vel que a condi√ß√£o de estacionariedade *wide-sense* ($\alpha_1 + \beta_1 < 1$) seja ligeiramente relaxada, mas a exist√™ncia dos momentos ainda depender√° dos graus de liberdade $\nu$.
*Prova*: A prova envolve uma an√°lise detalhada das propriedades da distribui√ß√£o t-Student e como a heteroscedasticidade condicional afeta seus momentos. A condi√ß√£o de estacionariedade *wide-sense* se torna menos cr√≠tica em rela√ß√£o √† magnitude exata de $\alpha_1 + \beta_1$, mas a exist√™ncia dos momentos √© primariamente controlada pelo par√¢metro $\nu$ da distribui√ß√£o t-Student.

A prova formal do relaxamento da condi√ß√£o de estacionariedade √© complexa e envolve t√©cnicas avan√ßadas de teoria de processos estoc√°sticos. No entanto, podemos fornecer um esbo√ßo da ideia principal:

I. A estacionariedade *wide-sense* requer que a vari√¢ncia incondicional do processo seja finita. Com a distribui√ß√£o normal, isso se traduz diretamente em $\alpha_1 + \beta_1 < 1$.

II. Quando usamos a distribui√ß√£o t-Student com $\nu$ graus de liberdade, a vari√¢ncia condicional √© dada por $h_t \cdot \frac{\nu}{\nu - 2}$ (para $\nu > 2$).

III. A presen√ßa do fator $\frac{\nu}{\nu - 2}$ introduz uma corre√ß√£o que depende dos graus de liberdade. Para valores pequenos de $\nu$, essa corre√ß√£o pode ser significativa.

IV. A condi√ß√£o de estacionariedade *wide-sense* √© ent√£o modificada para levar em conta essa corre√ß√£o. Em vez de simplesmente $\alpha_1 + \beta_1 < 1$, a condi√ß√£o se torna algo como $\alpha_1 \cdot \frac{\nu}{\nu - 2} + \beta_1 < 1 + \delta$, onde $\delta$ √© um pequeno valor positivo que depende de $\nu$.

V. Isso implica que, para certos valores de $\nu$, podemos ter $\alpha_1 + \beta_1$ ligeiramente maior que 1, mas ainda assim obter uma vari√¢ncia incondicional finita.

VI. No entanto, √© crucial notar que a exist√™ncia dos momentos ainda depende fortemente de $\nu$. Mesmo que a estacionariedade *wide-sense* seja satisfeita, os momentos de ordem superior s√≥ existir√£o se $\nu > 2m$. ‚ñ†

> üí° **Exemplo Num√©rico:** Considere que $\epsilon_t|\Psi_{t-1} \sim t(5, 0, h_t)$. Isso significa que $\nu = 5$. Ent√£o, o quarto momento ($m=2$) existe, pois $\nu = 5 > 2m = 4$. No entanto, mesmo que $\alpha_1 + \beta_1$ fosse ligeiramente maior que 1 (por exemplo, 1.05), a exist√™ncia do quarto momento ainda dependeria fortemente de $\nu$. Al√©m disso, a vari√¢ncia condicional seria $h_t * (5/(5-2)) = h_t * (5/3) \approx 1.67 h_t$, o que implica que a vari√¢ncia √© maior do que a estimada usando uma distribui√ß√£o normal.

A seguir, exploramos a rela√ß√£o entre a exist√™ncia de momentos e a curtose da distribui√ß√£o.

**Proposi√ß√£o 1:** Rela√ß√£o entre curtose e momentos
A curtose, uma medida de "tailedness" (peso das caudas) da distribui√ß√£o, est√° diretamente relacionada aos momentos de ordem superior. Se o quarto momento n√£o existe, a curtose √© infinita, indicando caudas extremamente pesadas e um alto risco de eventos extremos.
*Prova*:
A curtose √© definida como
$$\text{Curtose} = \frac{E[(X-\mu)^4]}{\sigma^4}$$
Onde $\mu$ √© a m√©dia e $\sigma$ √© o desvio padr√£o. Se o quarto momento n√£o existe (i.e., $E[X^4] = \infty$), ent√£o a curtose tamb√©m √© infinita.

I. A curtose √© definida como o quarto momento centralizado normalizado pelo quadrado da vari√¢ncia:

$$
\text{Curtose} = \frac{E[(X - \mu)^4]}{\sigma^4}
$$

onde $\mu = E[X]$ √© a m√©dia e $\sigma^2 = E[(X - \mu)^2]$ √© a vari√¢ncia.

II. Se o quarto momento ($E[X^4]$) n√£o existe, ent√£o $E[(X - \mu)^4]$ tamb√©m n√£o existe, pois a expans√£o de $(X - \mu)^4$ inclui o termo $X^4$.

III. Portanto, se $E[X^4] = \infty$, ent√£o $\text{Curtose} = \frac{\infty}{\sigma^4} = \infty$, assumindo que a vari√¢ncia $\sigma^2$ √© finita.

IV. Isso implica que a curtose √© infinita quando o quarto momento n√£o existe, indicando caudas extremamente pesadas. ‚ñ†

> üí° **Exemplo Num√©rico:** Se um modelo GARCH(1,1) com distribui√ß√£o normal condicional n√£o satisfaz a condi√ß√£o $3\alpha_1^2 + 2\alpha_1\beta_1 + \beta_1^2 < 1$, o quarto momento n√£o existe, e a curtose da distribui√ß√£o √© teoricamente infinita. Isso implica que eventos extremos s√£o mais prov√°veis do que o esperado sob uma distribui√ß√£o com curtose finita. Em termos pr√°ticos, isso significa que se voc√™ est√° usando um modelo GARCH(1,1) com distribui√ß√£o normal e os par√¢metros estimados violam essa condi√ß√£o, o modelo pode subestimar o risco de eventos raros e extremos.

Para complementar nossa an√°lise, apresentamos uma proposi√ß√£o sobre testes de diagn√≥stico que podem ser utilizados para detectar a n√£o exist√™ncia de momentos superiores.

**Proposi√ß√£o 2:** Testes de diagn√≥stico para momentos
Testes de diagn√≥stico como o teste de Jarque-Bera (que avalia a normalidade) podem indicar a presen√ßa de caudas pesadas e a poss√≠vel n√£o exist√™ncia de momentos superiores.
*Prova*:
O teste de Jarque-Bera combina medidas de assimetria (skewness) e curtose para avaliar a normalidade. Desvios significativos da normalidade (particularmente alta curtose) podem indicar a n√£o exist√™ncia de momentos superiores.

I. O teste de Jarque-Bera √© baseado nos momentos de terceira (assimetria) e quarta ordem (curtose) de uma distribui√ß√£o. A estat√≠stica de teste √© definida como:

$$
JB = \frac{n}{6}\left(S^2 + \frac{(K - 3)^2}{4}\right)
$$

onde $n$ √© o tamanho da amostra, $S$ √© a assimetria e $K$ √© a curtose.

II. Sob a hip√≥tese nula de normalidade, a estat√≠stica JB segue uma distribui√ß√£o qui-quadrado com 2 graus de liberdade.

III. Se a distribui√ß√£o tem caudas pesadas, a curtose $K$ ser√° alta, resultando em um valor alto para a estat√≠stica JB.

IV. Um valor alto da estat√≠stica JB leva √† rejei√ß√£o da hip√≥tese nula de normalidade, indicando que a distribui√ß√£o pode ter caudas pesadas e, portanto, a poss√≠vel n√£o exist√™ncia de momentos superiores. ‚ñ†

> üí° **Exemplo Num√©rico:** Se aplicarmos o teste de Jarque-Bera a um conjunto de res√≠duos de um modelo GARCH(1,1) e obtivermos um p-valor muito baixo, isso sugere que a distribui√ß√£o dos res√≠duos n√£o √© normal e pode ter caudas mais pesadas, indicando a poss√≠vel n√£o exist√™ncia de momentos superiores. Nesse caso, seria prudente considerar uma distribui√ß√£o condicional diferente, como a t-Student, ou ajustar os par√¢metros do modelo para satisfazer as condi√ß√µes de exist√™ncia de momentos.
> ```python
> import numpy as np
> from scipy.stats import jarque_bera, norm
> import matplotlib.pyplot as plt
>
> # Generate some non-normal data (example: heavy-tailed)
> np.random.seed(0)
> residuals = np.random.standard_t(df=3, size=1000)  # t-distribution with 3 degrees of freedom
>
> # Perform Jarque-Bera test
> jb_statistic, jb_p_value = jarque_bera(residuals)
>
> print(f"Jarque-Bera Statistic: {jb_statistic:.2f}")
> print(f"Jarque-Bera p-value: {jb_p_value:.3f}")
>
> # Compare to normal distribution residuals
> normal_residuals = np.random.normal(size=1000)
> jb_statistic_normal, jb_p_value_normal = jarque_bera(normal_residuals)
>
> print(f"Normal Residuals Jarque-Bera Statistic: {jb_statistic_normal:.2f}")
> print(f"Normal Residuals Jarque-Bera p-value: {jb_p_value_normal:.3f}")
>
> # Plotting the distributions
> plt.figure(figsize=(12, 6))
>
> plt.subplot(1, 2, 1)
> plt.hist(residuals, bins=50, density=True, alpha=0.6, color='blue', label='T-Distribution Residuals')
> x = np.linspace(min(residuals), max(residuals), 100)
> plt.plot(x, norm.pdf(x, np.mean(residuals), np.std(residuals)), 'k', linewidth=2, label='Normal Approximation')
> plt.title('T-Distribution Residuals (df=3)')
> plt.xlabel('Residual Value')
> plt.ylabel('Density')
> plt.legend()
>
> plt.subplot(1, 2, 2)
> plt.hist(normal_residuals, bins=50, density=True, alpha=0.6, color='green', label='Normal Residuals')
> x = np.linspace(min(normal_residuals), max(normal_residuals), 100)
> plt.plot(x, norm.pdf(x, np.mean(normal_residuals), np.std(normal_residuals)), 'k', linewidth=2, label='Normal PDF')
> plt.title('Normal Residuals')
> plt.xlabel('Residual Value')
> plt.ylabel('Density')
> plt.legend()
>
> plt.tight_layout()
> plt.show()
> ```
> O c√≥digo acima gera res√≠duos seguindo uma distribui√ß√£o t-Student (caudas pesadas) e uma distribui√ß√£o normal, aplica o teste de Jarque-Bera a ambos e imprime os resultados. O histograma visualiza a diferen√ßa entre a distribui√ß√£o t-Student (com caudas pesadas) e a distribui√ß√£o normal.

### Conclus√£o

A exist√™ncia do 2m-√©simo momento, expressa pelo Teorema 2, √© um aspecto crucial na an√°lise do processo GARCH(1,1). Embora a condi√ß√£o $\alpha_1 + \beta_1 < 1$ garanta a estacionariedade *wide-sense*, a exist√™ncia de momentos superiores imp√µe restri√ß√µes adicionais sobre os par√¢metros, afetando a validade de infer√™ncias estat√≠sticas e a precis√£o de previs√µes, principalmente em situa√ß√µes de risco. A escolha da distribui√ß√£o condicional (e.g., t-Student) pode influenciar a exist√™ncia dos momentos, e testes de diagn√≥stico podem auxiliar na avalia√ß√£o da adequa√ß√£o do modelo e na identifica√ß√£o de caudas pesadas.

### Refer√™ncias
[^1]: Bollerslev, T. (1986). Generalized autoregressive conditional heteroskedasticity. *Journal of Econometrics, 31*(3), 307-327.
[^2]: Engle, R. F. (1982). Autoregressive conditional heteroskedasticity with estimates of the variance of United Kingdom inflation. *Econometrica, 50*(4), 987-1007.
[^5]: Ver se√ß√£o 3 do artigo de Bollerslev (1986)
<!-- END -->