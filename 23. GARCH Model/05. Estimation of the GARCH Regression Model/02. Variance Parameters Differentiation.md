Este cap√≠tulo aprofunda a estima√ß√£o de modelos de regress√£o GARCH por meio da **Estima√ß√£o de M√°xima Verossimilhan√ßa (MLE)**, com foco espec√≠fico na diferencia√ß√£o da fun√ß√£o de log-verossimilhan√ßa em rela√ß√£o aos par√¢metros de vari√¢ncia, denotados por $\omega$ [^1]. Este processo de diferencia√ß√£o √© essencial para a implementa√ß√£o de algoritmos de otimiza√ß√£o que visam encontrar os valores dos par√¢metros que melhor se ajustam aos dados observados. Construindo sobre os conceitos j√° estabelecidos de modelos GARCH e MLE, esta se√ß√£o fornecer√° uma an√°lise detalhada das equa√ß√µes derivadas e suas implica√ß√µes pr√°ticas.

### Conceitos Fundamentais

Como vimos anteriormente, a MLE √© uma t√©cnica fundamental para estimar os par√¢metros dos modelos GARCH [^1]. A fun√ß√£o de log-verossimilhan√ßa, $L_T(\theta)$, quantifica a probabilidade dos dados observados em fun√ß√£o dos par√¢metros do modelo, $\theta$ [^1]. No contexto dos modelos GARCH, $\theta$ inclui tanto os par√¢metros da m√©dia condicional ($b$) quanto os par√¢metros da vari√¢ncia condicional ($\omega$).

Para implementar a MLE, precisamos maximizar $L_T(\theta)$ com rela√ß√£o a $\theta$. Isso envolve calcular as derivadas parciais de $L_T(\theta)$ em rela√ß√£o aos diferentes par√¢metros e, em seguida, usar algoritmos de otimiza√ß√£o para encontrar os valores dos par√¢metros que tornam as derivadas iguais a zero (ou o mais pr√≥ximo poss√≠vel).

Nesta se√ß√£o, focaremos na diferencia√ß√£o da fun√ß√£o de log-verossimilhan√ßa em rela√ß√£o aos par√¢metros de vari√¢ncia, $\omega$. Usando a fun√ß√£o de log-verossimilhan√ßa definida em [^1]:

$$
l_t(\theta) = -\frac{1}{2} \log h_t - \frac{1}{2} \epsilon_t^2 h_t^{-1},
$$

e diferenciando com rela√ß√£o a $\omega$ [^9], obtemos:

$$
\frac{\partial l_t}{\partial \omega} = \left[-\frac{1}{2} + \frac{\epsilon_t^2}{2h_t}\right] \frac{\partial h_t}{\partial \omega} \frac{1}{h_t}
$$

Esta equa√ß√£o, extra√≠da diretamente do contexto [^9], pode ser reescrita como:

$$
\frac{\partial l_t}{\partial \omega} = 0.5 h_t^{-1} \frac{\partial h_t}{\partial \omega} (\epsilon_t^2 h_t^{-1} - 1)
$$

Esta equa√ß√£o [^9] √© crucial para a implementa√ß√£o da MLE em modelos GARCH. Ela fornece a dire√ß√£o do maior aumento na fun√ß√£o de log-verossimilhan√ßa com rela√ß√£o a uma pequena mudan√ßa nos par√¢metros de vari√¢ncia, $\omega$. O termo $\frac{\partial h_t}{\partial \omega}$ quantifica a sensibilidade da vari√¢ncia condicional, $h_t$, a mudan√ßas em $\omega$. O termo $(\epsilon_t^2 h_t^{-1} - 1)$ compara o erro quadrado ao seu valor esperado (vari√¢ncia condicional).

> üí° **Exemplo Num√©rico:**
>
> Suponha que temos um modelo GARCH(1,1) com os seguintes par√¢metros e valores:
>
> *   $\alpha_0 = 0.01$ (constante da vari√¢ncia)
> *   $\alpha_1 = 0.1$ (coeficiente do termo ARCH)
> *   $\beta_1 = 0.8$ (coeficiente do termo GARCH)
> *   $\epsilon_t = 0.02$ (erro no tempo *t*)
> *   $h_t = 0.03$ (vari√¢ncia condicional no tempo *t*)
>
> A fun√ß√£o de log-verossimilhan√ßa para uma observa√ß√£o √©:
>
> $l_t(\theta) = -\frac{1}{2} \log(0.03) - \frac{1}{2} (0.02)^2 (0.03)^{-1}$
>
> $l_t(\theta) = -\frac{1}{2} (-3.5066) - \frac{1}{2} (0.0004) (33.3333)$
>
> $l_t(\theta) = 1.7533 - 0.0067 = 1.7466$
>
> Agora, vamos calcular $\frac{\partial l_t}{\partial \alpha_0}$:
>
> Primeiro, precisamos de $\frac{\partial h_t}{\partial \alpha_0}$. Para um GARCH(1,1):
>
> $h_t = \alpha_0 + \alpha_1 \epsilon_{t-1}^2 + \beta_1 h_{t-1}$, ent√£o $\frac{\partial h_t}{\partial \alpha_0} = 1$
>
> Agora, usando a f√≥rmula derivada:
>
> $\frac{\partial l_t}{\partial \alpha_0} = 0.5 h_t^{-1} \frac{\partial h_t}{\partial \alpha_0} (\epsilon_t^2 h_t^{-1} - 1)$
>
> $\frac{\partial l_t}{\partial \alpha_0} = 0.5 (0.03)^{-1} (1) ((0.02)^2 (0.03)^{-1} - 1)$
>
> $\frac{\partial l_t}{\partial \alpha_0} = 0.5 (33.3333) (0.0004 * 33.3333 - 1)$
>
> $\frac{\partial l_t}{\partial \alpha_0} = 16.6667 (0.0133 - 1) = 16.6667 (-0.9867) = -16.4445$
>
> Este valor negativo indica que, para este ponto de dados, aumentar $\alpha_0$ diminuiria a log-verossimilhan√ßa. Portanto, um algoritmo de otimiza√ß√£o ajustaria $\alpha_0$ para baixo para aumentar a verossimilhan√ßa.

**Proposi√ß√£o 1** (Condi√ß√£o de Ortogonalidade): No ponto de m√°ximo da fun√ß√£o de log-verossimilhan√ßa, a derivada parcial de $l_t$ em rela√ß√£o a $\omega$ √© igual a zero. Ou seja,
$$
\frac{\partial l_t}{\partial \omega} = 0
$$
*Prova*: A condi√ß√£o de primeira ordem para maximizar a fun√ß√£o de log-verossimilhan√ßa exige que as derivadas parciais em rela√ß√£o a cada par√¢metro sejam iguais a zero. Isso garante que estamos em um ponto estacion√°rio, que pode ser um m√°ximo, m√≠nimo ou ponto de sela. No contexto da MLE para modelos GARCH, essa condi√ß√£o √© fundamental para encontrar os valores √≥timos dos par√¢metros de vari√¢ncia $\omega$.

I. A MLE busca maximizar a fun√ß√£o de log-verossimilhan√ßa $L_T(\theta)$ em rela√ß√£o aos par√¢metros $\theta$. Isso significa encontrar o valor de $\theta$ que torna a fun√ß√£o de log-verossimilhan√ßa a maior poss√≠vel.

II. Para encontrar este m√°ximo, calculamos a derivada da fun√ß√£o de log-verossimilhan√ßa em rela√ß√£o a cada par√¢metro e igualamos a zero.  Este √© um princ√≠pio fundamental do c√°lculo para encontrar m√°ximos e m√≠nimos de fun√ß√µes.

III. Especificamente, para o par√¢metro $\omega$, a condi√ß√£o de primeira ordem para um m√°ximo √©:
$$\frac{\partial L_T(\theta)}{\partial \omega} = 0$$

IV. Como $L_T(\theta)$ √© a soma das log-verossimilhan√ßas individuais $l_t(\theta)$, a derivada da soma √© a soma das derivadas:
$$\frac{\partial L_T(\theta)}{\partial \omega} = \sum_{t=1}^T \frac{\partial l_t(\theta)}{\partial \omega} = 0$$

V. Para que a soma seja zero, em um caso ideal (onde cada termo tem o mesmo sinal), cada termo individualmente deve ser zero:
$$\frac{\partial l_t(\theta)}{\partial \omega} = 0$$
Isto implica que no ponto de m√°ximo da fun√ß√£o de log-verossimilhan√ßa, a derivada parcial de $l_t$ em rela√ß√£o a $\omega$ √© igual a zero. ‚ñ†

> üí° **Exemplo Num√©rico:**
>
> Considere um modelo GARCH(1,1) com a seguinte especifica√ß√£o:
> $$
> h_t = \alpha_0 + \alpha_1 \epsilon_{t-1}^2 + \beta_1 h_{t-1}
> $$
> onde $\omega = (\alpha_0, \alpha_1, \beta_1)$ s√£o os par√¢metros de vari√¢ncia.
>
> Para derivar $\frac{\partial l_t}{\partial \omega}$, primeiro precisamos calcular $\frac{\partial h_t}{\partial \omega}$:
>
> $$
> \frac{\partial h_t}{\partial \alpha_0} = 1 \\
> \frac{\partial h_t}{\partial \alpha_1} = \epsilon_{t-1}^2 \\
> \frac{\partial h_t}{\partial \beta_1} = h_{t-1}
> $$
>
> Agora, substitu√≠mos esses resultados na equa√ß√£o para $\frac{\partial l_t}{\partial \omega}$:
>
> $$
> \frac{\partial l_t}{\partial \alpha_0} = 0.5 h_t^{-1} (1) (\epsilon_t^2 h_t^{-1} - 1) \\
> \frac{\partial l_t}{\partial \alpha_1} = 0.5 h_t^{-1} (\epsilon_{t-1}^2) (\epsilon_t^2 h_t^{-1} - 1) \\
> \frac{\partial l_t}{\partial \beta_1} = 0.5 h_t^{-1} (h_{t-1}) (\epsilon_t^2 h_t^{-1} - 1)
> $$
>
> Por exemplo, se tivermos as seguintes informa√ß√µes:
>
> $\alpha_0 = 0.1$, $\alpha_1 = 0.2$, $\beta_1 = 0.7$, $\epsilon_{t-1} = 0.5$, $h_{t-1} = 0.3$, $\epsilon_t = 0.2$
>
> Primeiro, calculamos $h_t$:
>
> $h_t = 0.1 + 0.2 (0.5)^2 + 0.7 (0.3) = 0.1 + 0.05 + 0.21 = 0.36$
>
> Agora, podemos calcular as derivadas parciais:
>
> $\frac{\partial l_t}{\partial \alpha_0} = 0.5 (0.36)^{-1} (1) ((0.2)^2 (0.36)^{-1} - 1) = 0.5 (2.78) (0.11 - 1) = 1.39 (-0.89) = -1.24$
> $\frac{\partial l_t}{\partial \alpha_1} = 0.5 (0.36)^{-1} (0.5)^2 ((0.2)^2 (0.36)^{-1} - 1) = 0.5 (2.78) (0.25) (0.11 - 1) = 0.35 (-0.89) = -0.31$
> $\frac{\partial l_t}{\partial \beta_1} = 0.5 (0.36)^{-1} (0.3) ((0.2)^2 (0.36)^{-1} - 1) = 0.5 (2.78) (0.3) (0.11 - 1) = 0.42 (-0.89) = -0.37$
>
> Esses valores representam a inclina√ß√£o da fun√ß√£o de log-verossimilhan√ßa em rela√ß√£o a cada par√¢metro. Durante a otimiza√ß√£o, os algoritmos usariam essas informa√ß√µes para ajustar os par√¢metros at√© que as derivadas se aproximem de zero, indicando um m√°ximo local da fun√ß√£o de log-verossimilhan√ßa.
>
> Al√©m disso, a condi√ß√£o de ortogonalidade implica que, no ponto de m√°ximo, pequenas mudan√ßas em $\alpha_0$, $\alpha_1$ ou $\beta_1$ n√£o afetar√£o a fun√ß√£o de log-verossimilhan√ßa, indicando que encontramos os valores √≥timos para esses par√¢metros.

Al√©m disso, a segunda derivada, fornecida por [^9]:

$$
\frac{\partial^2 l_t}{\partial \omega \partial \omega'} = \left[-\frac{1}{h_t}\right] \frac{\partial h_t}{\partial \omega} \frac{\partial h_t}{\partial \omega'} + \left[-\frac{1}{2} + \frac{\epsilon_t^2}{2h_t}\right] \left[-\frac{1}{h_t^2} \right] \frac{\partial h_t}{\partial \omega} \frac{\partial h_t}{\partial \omega'} + \left[-\frac{1}{2} + \frac{\epsilon_t^2}{2h_t}\right] \frac{1}{h_t} \frac{\partial^2 h_t}{\partial \omega \partial \omega'},
$$

√© usada para implementar m√©todos de otimiza√ß√£o de segunda ordem, como o m√©todo de Newton-Raphson. Essa derivada fornece informa√ß√µes sobre a curvatura da fun√ß√£o de log-verossimilhan√ßa e pode ajudar a acelerar a converg√™ncia do algoritmo de otimiza√ß√£o.

√â importante notar que o termo $\frac{\partial^2 h_t}{\partial \omega \partial \omega'}$ pode ser complexo de se calcular, especialmente para modelos GARCH de alta ordem. Em alguns casos, pode ser mais eficiente usar m√©todos de quase-Newton, que aproximam a Hessiana (matriz das segundas derivadas) usando apenas as primeiras derivadas.

**Proposi√ß√£o 2:** (Interpreta√ß√£o do Sinal da Derivada) O sinal da derivada $\frac{\partial l_t}{\partial \omega}$ indica a dire√ß√£o na qual a fun√ß√£o de log-verossimilhan√ßa aumenta em rela√ß√£o a uma mudan√ßa em $\omega$. Se $\frac{\partial l_t}{\partial \omega} > 0$, aumentar $\omega$ aumentar√° a log-verossimilhan√ßa. Se $\frac{\partial l_t}{\partial \omega} < 0$, diminuir $\omega$ aumentar√° a log-verossimilhan√ßa.

*Prova:* Esta proposi√ß√£o decorre diretamente da defini√ß√£o de derivada. A derivada representa a taxa de varia√ß√£o instant√¢nea de uma fun√ß√£o em rela√ß√£o a uma vari√°vel. No contexto da MLE, a derivada da fun√ß√£o de log-verossimilhan√ßa em rela√ß√£o aos par√¢metros indica como a probabilidade dos dados observados muda em resposta a pequenas altera√ß√µes nesses par√¢metros. Um sinal positivo indica que aumentar o par√¢metro aumenta a verossimilhan√ßa, enquanto um sinal negativo indica o oposto. Isso √© fundamental para direcionar os algoritmos de otimiza√ß√£o na busca pelos valores √≥timos dos par√¢metros.

I. Por defini√ß√£o, a derivada de uma fun√ß√£o, $f(x)$, em rela√ß√£o a uma vari√°vel, $x$, representa a taxa de varia√ß√£o instant√¢nea de $f(x)$ em rela√ß√£o a $x$. Matematicamente, isso √© expresso como:
$$\frac{df(x)}{dx} = \lim_{\Delta x \to 0} \frac{f(x + \Delta x) - f(x)}{\Delta x}$$

II. No nosso caso, $f(x)$ √© a fun√ß√£o de log-verossimilhan√ßa $l_t$ e $x$ √© o par√¢metro $\omega$. Portanto, $\frac{\partial l_t}{\partial \omega}$ representa a taxa de varia√ß√£o da fun√ß√£o de log-verossimilhan√ßa em rela√ß√£o a pequenas mudan√ßas em $\omega$.

III. Se $\frac{\partial l_t}{\partial \omega} > 0$, isso significa que um pequeno aumento em $\omega$ (ou seja, $\Delta \omega > 0$) resultar√° em um aumento em $l_t$ (ou seja, $l_t(\omega + \Delta \omega) > l_t(\omega)$).

IV. Por outro lado, se $\frac{\partial l_t}{\partial \omega} < 0$, isso significa que um pequeno aumento em $\omega$ (ou seja, $\Delta \omega > 0$) resultar√° em uma diminui√ß√£o em $l_t$ (ou seja, $l_t(\omega + \Delta \omega) < l_t(\omega)$). Consequentemente, uma *diminui√ß√£o* em $\omega$ levaria a um aumento em $l_t$.

V. Portanto, o sinal da derivada $\frac{\partial l_t}{\partial \omega}$ indica a dire√ß√£o na qual a fun√ß√£o de log-verossimilhan√ßa aumenta em rela√ß√£o a uma mudan√ßa em $\omega$. Se a derivada √© positiva, aumentar $\omega$ aumenta a log-verossimilhan√ßa; se a derivada √© negativa, diminuir $\omega$ aumenta a log-verossimilhan√ßa. ‚ñ†

> üí° **Exemplo Num√©rico:**
>
> Suponha que, ap√≥s algumas itera√ß√µes de um algoritmo de otimiza√ß√£o, temos os seguintes valores para um modelo GARCH(1,1):
>
> *   $\alpha_0 = 0.005$
> *   $\alpha_1 = 0.05$
> *   $\beta_1 = 0.9$
> *   $\epsilon_t = -0.01$
> *   $h_t = 0.02$
>
> Calculamos $\frac{\partial l_t}{\partial \alpha_0} = 2$. Isso significa que aumentar $\alpha_0$ aumentar√° a fun√ß√£o de log-verossimilhan√ßa. O algoritmo de otimiza√ß√£o ent√£o aumentaria $\alpha_0$ ligeiramente, digamos para 0.0055, e recalcularia a fun√ß√£o de log-verossimilhan√ßa e suas derivadas. Este processo continua at√© que as derivadas estejam pr√≥ximas de zero, indicando que encontramos um ponto m√°ximo (local).
>
> Vamos tamb√©m calcular $\frac{\partial l_t}{\partial \beta_1}$:
>
> $\frac{\partial h_t}{\partial \beta_1} = h_{t-1}$
> Assumindo $h_{t-1}=0.019$:
> $\frac{\partial l_t}{\partial \beta_1} = 0.5 (0.02)^{-1} (0.019) (((-0.01)^2) (0.02)^{-1} - 1)$
> $\frac{\partial l_t}{\partial \beta_1} = 0.5 (50) (0.019) ((0.0001) (50) - 1)$
> $\frac{\partial l_t}{\partial \beta_1} = 1.25 (0.005 - 1) = 1.25 (-0.995) = -1.24375$
>
> Neste caso, $\frac{\partial l_t}{\partial \beta_1} < 0$. Portanto, diminuir $\beta_1$ aumentaria a fun√ß√£o de log-verossimilhan√ßa.

### Conclus√£o

A diferencia√ß√£o da fun√ß√£o de log-verossimilhan√ßa em rela√ß√£o aos par√¢metros de vari√¢ncia √© um passo essencial na implementa√ß√£o da MLE para modelos de regress√£o GARCH [^1]. As equa√ß√µes derivadas, fornecidas neste cap√≠tulo, permitem a constru√ß√£o de algoritmos de otimiza√ß√£o que podem ser usados para estimar os par√¢metros do modelo. Compreender essas derivadas √© crucial para qualquer pesquisador ou profissional que trabalhe com modelos GARCH.

### Refer√™ncias

[^1]: Bollerslev, T. (1986). Generalized autoregressive conditional heteroskedasticity. *Journal of Econometrics*, *31*(3), 307-327.
[^9]: A discuss√£o sobre a estima√ß√£o da regress√£o GARCH e a fun√ß√£o de log-verossimilhan√ßa na p√°gina 315 do artigo de Bollerslev (1986).
<!-- END -->