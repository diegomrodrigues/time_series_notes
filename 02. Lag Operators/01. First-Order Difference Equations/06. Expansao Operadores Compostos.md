## ExpansÃ£o de Operadores Compostos e Complexidade Computacional em EquaÃ§Ãµes de DiferenÃ§a
### IntroduÃ§Ã£o
Nos capÃ­tulos anteriores, exploramos a representaÃ§Ã£o de equaÃ§Ãµes de diferenÃ§a de primeira ordem usando o operador de atraso ($L$). Vimos como expressÃµes como $(1 - \phi L)y_t = w_t$ [^2.2.2] podem ser manipuladas algebricamente para obter soluÃ§Ãµes na forma de sÃ©ries infinitas, por exemplo, $y_t = \sum_{k=0}^{\infty} \phi^k w_{t-k}$ [^2.2.9]. Este capÃ­tulo aprofunda a anÃ¡lise da expansÃ£o de operadores compostos na manipulaÃ§Ã£o de equaÃ§Ãµes de diferenÃ§a, explorando as complexidades computacionais inerentes e as tÃ©cnicas de simplificaÃ§Ã£o e otimizaÃ§Ã£o de cÃ³digo para manter um bom desempenho. Veremos que enquanto os operadores de atraso facilitam a representaÃ§Ã£o e a anÃ¡lise, a expansÃ£o de operadores compostos pode aumentar a complexidade computacional, exigindo estratÃ©gias para lidar com essa complexidade.

### ExpansÃ£o de Operadores Compostos
A representaÃ§Ã£o de equaÃ§Ãµes de diferenÃ§a com o operador de atraso permite a criaÃ§Ã£o de operadores compostos. Por exemplo, o operador inverso $(1 - \phi L)^{-1}$, fundamental na resoluÃ§Ã£o da equaÃ§Ã£o de primeira ordem, Ã© ele prÃ³prio um operador composto, que, quando expandido, se torna a sÃ©rie $1 + \phi L + \phi^2 L^2 + \phi^3 L^3 + \ldots$ [^2.2.8]. Em sistemas mais complexos, como aqueles com mÃºltiplas equaÃ§Ãµes de diferenÃ§a ou com dependÃªncias temporais de ordem superior, os operadores envolvidos podem ser ainda mais complexos.

A expansÃ£o desses operadores compostos Ã© uma tÃ©cnica para obter representaÃ§Ãµes explÃ­citas das equaÃ§Ãµes de diferenÃ§a. Ao aplicar esta tÃ©cnica, obtemos expressÃµes que relacionam diretamente as variÃ¡veis no tempo presente com seus valores passados, ou seja, Ã© uma ferramenta poderosa para anÃ¡lise. No entanto, esta expansÃ£o pode levar a expressÃµes com um grande nÃºmero de termos, aumentando a complexidade computacional.

*   **PolinÃ´mios no Operador de Atraso:** Operadores como $(1 - \phi_1 L - \phi_2 L^2)$ ou $(1 + a_1L + a_2L^2 + a_3L^3)$ sÃ£o polinÃ´mios no operador de atraso. Tais operadores podem aparecer como parte de uma equaÃ§Ã£o de diferenÃ§a, ou como resultado de uma manipulaÃ§Ã£o algÃ©brica. Expandir um operador inverso deste tipo significa encontrar a sÃ©rie infinita correspondente que quando aplicada na equaÃ§Ã£o de diferenÃ§a permite calcular os valores de $y_t$ em funÃ§Ã£o de $w_t$.
*   **Inversos de Operadores:** O inverso de um operador, como $(1-\phi L)^{-1}$, Ã© tambÃ©m um operador composto. A expansÃ£o deste tipo de operador se traduz na criaÃ§Ã£o de uma sÃ©rie infinita que descreve a influÃªncia de $w_t$ nos valores $y_t$.

> ðŸ’¡ **Exemplo NumÃ©rico:**
> Considere a equaÃ§Ã£o $(1 - 0.5L)(1 - 0.3L)y_t = w_t$. Podemos expandir o operador composto para:
>
> $(1 - 0.5L - 0.3L + 0.15L^2)y_t = w_t$
>
> $(1 - 0.8L + 0.15L^2)y_t = w_t$.
>
> Se quisermos expressar $y_t$ em termos de $w_t$, podemos multiplicar ambos os lados pelo inverso do operador:
>
> $y_t = (1 - 0.8L + 0.15L^2)^{-1}w_t$
>
> Expandir o operador inverso, neste caso, Ã© uma tarefa mais complexa. Se realizarmos a divisÃ£o de polinÃ´mios, obteremos
>
> $y_t = (1 + 0.8L + (0.8^2 - 0.15)L^2 + (0.8^3 - 2*0.15*0.8)L^3  + \ldots)w_t$
>
> $y_t = (1 + 0.8L + 0.49L^2 + 0.212L^3 + \ldots)w_t$
>
> Em termos de implementaÃ§Ã£o computacional, esta expansÃ£o infinita Ã© uma aproximaÃ§Ã£o que envolve truncar a sÃ©rie em algum ponto e acumular erros de aproximaÃ§Ã£o. Note que cada novo termo da sÃ©rie de operadores composto Ã© mais complexo que o anterior.
>
>  Vamos ilustrar o cÃ¡lculo dos primeiros termos desta expansÃ£o do operador inverso, passo a passo:
>
>   $\text{Passo 1: } (1 - 0.8L + 0.15L^2)^{-1} = 1 + a_1L + a_2L^2 + a_3L^3 + \ldots$
>
>   $\text{Passo 2: } (1 - 0.8L + 0.15L^2)(1 + a_1L + a_2L^2 + a_3L^3 + \ldots) = 1$
>
>   $\text{Passo 3: } \text{Expandindo o produto e igualando coeficientes a zero (exceto para o termo constante): }$
>
>   $\text{Termo em } L^0: 1 = 1$
>
>   $\text{Termo em } L^1: a_1 - 0.8 = 0 \Rightarrow a_1 = 0.8$
>
>  $\text{Termo em } L^2: a_2 - 0.8a_1 + 0.15 = 0 \Rightarrow a_2 = 0.8 * 0.8 - 0.15 = 0.49$
>
>   $\text{Termo em } L^3: a_3 - 0.8a_2 + 0.15a_1 = 0 \Rightarrow a_3 = 0.8*0.49 - 0.15*0.8 = 0.272$
>
>  O que leva a:
>
>  $y_t = (1 + 0.8L + 0.49L^2 + 0.272L^3 + \ldots)w_t$
>
>  Podemos observar que a expansÃ£o envolve um cÃ¡lculo recursivo para cada novo coeficiente, o que aumenta a complexidade.
>

**ProposiÃ§Ã£o 1:**
    O produto de dois operadores polinomiais no operador de atraso $p(L) = \sum_{i=0}^n a_i L^i$ e $q(L) = \sum_{j=0}^m b_j L^j$  Ã© um novo operador polinomial $r(L)= p(L)q(L)$ de grau $n+m$, onde os coeficientes de $r(L)$ sÃ£o dados por $c_k = \sum_{i=0}^k a_i b_{k-i}$ com $a_i = 0$ para $i > n$ e $b_j = 0$ para $j > m$.
  *   **Prova:**
         I.  Expandindo o produto, temos $r(L) = p(L)q(L) = (\sum_{i=0}^n a_i L^i)(\sum_{j=0}^m b_j L^j) =  \sum_{i=0}^n \sum_{j=0}^m a_i b_j L^{i+j}$.
         II. Agrupando os termos com potÃªncias iguais de $L$,  temos $r(L) = \sum_{k=0}^{n+m} c_k L^k$, onde $c_k = \sum_{i=0}^k a_i b_{k-i}$.
         III. O grau mÃ¡ximo de $L$ no operador $r(L)$ Ã© $n+m$ , e o coeficiente $c_k$ Ã© a soma de produtos dos coeficientes de $p(L)$ e $q(L)$.  â– 

**ProposiÃ§Ã£o 1.1:** A composiÃ§Ã£o de operadores polinomiais no operador de atraso Ã© associativa, ou seja,  $(p(L)q(L))s(L) = p(L)(q(L)s(L))$.
*   **Prova:**
    I.  Sejam $p(L)$, $q(L)$ e $s(L)$ trÃªs operadores polinomiais no operador de atraso.
    II. Pela ProposiÃ§Ã£o 1, o produto de dois operadores polinomiais Ã© um novo operador polinomial. Assim, $p(L)q(L)$ Ã© um operador polinomial, e $(p(L)q(L))s(L)$ tambÃ©m Ã© um operador polinomial.
    III. Similarmente, $q(L)s(L)$ Ã© um operador polinomial e $p(L)(q(L)s(L))$ tambÃ©m Ã© um operador polinomial.
    IV. O produto de operadores polinomiais Ã©, por definiÃ§Ã£o, associativo.
    V. Portanto $(p(L)q(L))s(L) = p(L)(q(L)s(L))$.  â– 

**ProposiÃ§Ã£o 1.2:** A multiplicaÃ§Ã£o de operadores polinomiais no operador de atraso Ã© comutativa, isto Ã©, $p(L)q(L) = q(L)p(L)$.
*   **Prova:**
    I. Seja $p(L) = \sum_{i=0}^n a_i L^i$ e $q(L) = \sum_{j=0}^m b_j L^j$.
    II. Pela ProposiÃ§Ã£o 1, $p(L)q(L) = \sum_{k=0}^{n+m} c_k L^k$ onde $c_k = \sum_{i=0}^k a_i b_{k-i}$.
    III. Analogamente, $q(L)p(L) = \sum_{k=0}^{n+m} d_k L^k$ onde $d_k = \sum_{j=0}^k b_j a_{k-j}$.
    IV. Note que, pela propriedade comutativa da multiplicaÃ§Ã£o de nÃºmeros reais, $a_i b_{k-i} = b_{k-i} a_i$.
    V. Portanto, $\sum_{i=0}^k a_i b_{k-i} = \sum_{j=0}^k b_j a_{k-j}$, o que implica que $c_k = d_k$ para todo $k$.
    VI. Consequentemente, $p(L)q(L) = q(L)p(L)$.  â– 

### Complexidade Computacional
A expansÃ£o de operadores compostos, embora Ãºtil para a anÃ¡lise teÃ³rica, pode aumentar a complexidade computacional. A principal razÃ£o Ã© que, em muitos casos, os operadores inversos resultam em sÃ©ries infinitas. Na prÃ¡tica, Ã© necessÃ¡rio truncar essas sÃ©ries em um nÃºmero finito de termos, o que leva a uma aproximaÃ§Ã£o da soluÃ§Ã£o.

AlÃ©m disso, quando temos sistemas de equaÃ§Ãµes, a manipulaÃ§Ã£o das matrizes de operadores de atraso e a expansÃ£o de seus inversos podem envolver um grande nÃºmero de cÃ¡lculos. A implementaÃ§Ã£o de tais operaÃ§Ãµes em um cÃ³digo computacional pode levar a um aumento significativo do tempo de execuÃ§Ã£o e uso de memÃ³ria, dependendo do tamanho das sequÃªncias de tempo, da ordem das equaÃ§Ãµes de diferenÃ§a e da complexidade dos operadores.

*   **CÃ¡lculo da SÃ©rie Infinita:** A expansÃ£o do operador inverso $(1 - \phi L)^{-1}$ requer o cÃ¡lculo de uma sÃ©rie infinita, que Ã© truncada em um certo ponto. Quanto mais termos forem incluÃ­dos na aproximaÃ§Ã£o da sÃ©rie, maior a precisÃ£o, mas maior tambÃ©m o custo computacional.
*  **OperaÃ§Ãµes com Operadores:** A aplicaÃ§Ã£o de um operador a uma sequÃªncia de tempo envolve operaÃ§Ãµes com os coeficientes do operador e os valores defasados da sequÃªncia. Ao aumentar o nÃºmero de termos do operador, o nÃºmero de operaÃ§Ãµes aritmÃ©ticas aumenta proporcionalmente.
*   **InversÃ£o de Matrizes de Operadores:** Em sistemas multivariados, a inversÃ£o de matrizes que contÃªm operadores de atraso Ã© um processo computacionalmente custoso. Em cada passo, Ã© necessÃ¡rio executar um nÃºmero elevado de operaÃ§Ãµes, e estas operaÃ§Ãµes, em geral, dependem do tamanho da matriz (i.e. do nÃºmero de variÃ¡veis e da ordem das equaÃ§Ãµes de diferenÃ§a).

   > ðŸ’¡ **Exemplo NumÃ©rico:**
   > Vamos considerar novamente a expansÃ£o do operador inverso:
   > $y_t = (1 - 0.5L)^{-1}w_t$.
   > Em um implementaÃ§Ã£o computacional, precisarÃ­amos aproximar a sÃ©rie infinita $1 + 0.5L + 0.25L^2 + 0.125L^3 + \ldots$ truncando a mesma. Por exemplo, se truncarmos a sÃ©rie apÃ³s o quinto termo,  a cada valor de $y_t$ em cada passo de tempo, seria necessÃ¡rio realizar cinco operaÃ§Ãµes de multiplicaÃ§Ã£o e quatro operaÃ§Ãµes de soma. Se a sequÃªncia de tempo tem um tamanho de 1000, isso significa a execuÃ§Ã£o de pelo menos $1000 \times 5$ operaÃ§Ãµes de multiplicaÃ§Ã£o e $1000 \times 4$ operaÃ§Ãµes de soma. Se o nÃºmero de termos da expansÃ£o fosse $n$, terÃ­amos $1000 \times n$ operaÃ§Ãµes de multiplicaÃ§Ã£o e $1000 \times (n-1)$ operaÃ§Ãµes de soma, um custo computacional diretamente proporcional ao nÃºmero de termos na aproximaÃ§Ã£o da expansÃ£o.
    >
    > Para ilustrar, se tivermos uma sequÃªncia $w_t = [1, 2, 3, 4, 5]$ e truncarmos o operador inverso $(1 - 0.5L)^{-1}$ apÃ³s 3 termos (i.e., $1 + 0.5L + 0.25L^2$), o cÃ¡lculo de $y_t$ seria:
    >
    > $\text{Passo 1: } y_1 = 1 \times w_1 = 1$
    >
    > $\text{Passo 2: } y_2 = 1 \times w_2 + 0.5 \times w_1 = 2 + 0.5 \times 1 = 2.5$
    >
    > $\text{Passo 3: } y_3 = 1 \times w_3 + 0.5 \times w_2 + 0.25 \times w_1 = 3 + 0.5 \times 2 + 0.25 \times 1 = 4.25$
    >
    > $\text{Passo 4: } y_4 = 1 \times w_4 + 0.5 \times w_3 + 0.25 \times w_2 = 4 + 0.5 \times 3 + 0.25 \times 2 = 5.5$
    >
    > $\text{Passo 5: } y_5 = 1 \times w_5 + 0.5 \times w_4 + 0.25 \times w_3 = 5 + 0.5 \times 4 + 0.25 \times 3 = 7.75$
    >
    >  Note que para cada $y_t$ foram necessÃ¡rias 2 multiplicaÃ§Ãµes e 2 adiÃ§Ãµes, e o nÃºmero de operaÃ§Ãµes depende do nÃºmero de termos na expansÃ£o.

**Lema 1:**
    A expansÃ£o do operador $(1 - aL)^{-1}$ atÃ© o termo $n$, ou seja,  $1 + aL + a^2 L^2 + \ldots + a^{n}L^{n}$, requer $n$ operaÃ§Ãµes de multiplicaÃ§Ã£o para o cÃ¡lculo dos coeficientes. AlÃ©m disso, para aplicar o operador truncado em uma sequÃªncia de comprimento $T$, sÃ£o necessÃ¡rias $n \times T$ operaÃ§Ãµes de multiplicaÃ§Ã£o e $(n-1)\times T$ operaÃ§Ãµes de soma.
  *   **Prova:**
       I.  O cÃ¡lculo dos coeficientes da expansÃ£o requer calcular $a^k$ para $k = 1, 2, \ldots, n$, o que leva a $n$ multiplicaÃ§Ãµes.
       II. Para cada elemento da sequÃªncia de tempo com comprimento $T$, a aplicaÃ§Ã£o do operador exige $n$ multiplicaÃ§Ãµes pelos coeficientes e $(n-1)$ somas, para somar os valores defasados multiplicados por estes coeficientes.
       III. Portanto, o custo computacional Ã© $n \times T$ operaÃ§Ãµes de multiplicaÃ§Ã£o e $(n-1)\times T$ operaÃ§Ãµes de soma.  â– 

**Lema 2:**
     A aÃ§Ã£o de um operador polinomial de grau $n$, $p(L) = \sum_{k=0}^{n} a_k L^k$ em uma sequÃªncia de tempo $x_t$ requer no mÃ¡ximo $n$ atrasos e $n$ multiplicaÃ§Ãµes para cada elemento $x_t$.
  *   **Prova:**
        I. A aÃ§Ã£o do operador $p(L)$ em $x_t$ resulta em $p(L)x_t = a_0x_t + a_1x_{t-1} + \ldots + a_n x_{t-n}$.
        II. Para calcular $p(L)x_t$, precisamos atrasar a sequÃªncia $x_t$ atÃ© um mÃ¡ximo de $n$ perÃ­odos.
        III. Para cada um dos $n+1$ termos, precisamos multiplicar $x_{t-k}$ por $a_k$.
        IV. Portanto, para cada $t$ precisamos de $n$ multiplicaÃ§Ãµes e $n$ atrasos.  â– 

**Teorema 1:** A complexidade computacional para aplicar um operador linear de ordem $n$ a uma sÃ©rie temporal de comprimento $T$ Ã© $O(nT)$ no nÃºmero de operaÃ§Ãµes. Isto significa que o tempo de computaÃ§Ã£o cresce linearmente com o tamanho da sÃ©rie e a ordem do operador.

*Prova:*
I. A aplicaÃ§Ã£o de um operador linear de ordem $n$ envolve operaÃ§Ãµes com os $n+1$ coeficientes do operador e os valores correspondentes da sÃ©rie.
II. Para cada ponto no tempo, temos que multiplicar e somar os valores defasados com os coeficientes, um total de $n$ operaÃ§Ãµes para obter o resultado em cada passo de tempo.
III.  Para uma sÃ©rie de tempo de comprimento $T$, isso implica que sÃ£o necessÃ¡rias aproximadamente $n \times T$ operaÃ§Ãµes de multiplicaÃ§Ã£o/soma.
IV. Portanto, a complexidade computacional Ã© $O(nT)$. $\blacksquare$

**Teorema 1.1** A complexidade computacional da composiÃ§Ã£o de dois operadores polinomiais de ordem $n$ e $m$  Ã© $O(nm)$ para calcular os coeficientes do novo operador e $O((n+m)T)$ para aplicar o operador resultante em uma sequÃªncia de tempo de comprimento $T$.
 *   **Prova:**
     I. Pela proposiÃ§Ã£o 1, a composiÃ§Ã£o de dois operadores polinomiais resulta em um novo operador de ordem $n+m$ cujos coeficientes exigem $O(nm)$ operaÃ§Ãµes para serem calculados.
     II. Pelo teorema 1, a aplicaÃ§Ã£o de um operador de ordem $n+m$ em uma sequÃªncia de tempo de comprimento $T$ tem complexidade $O((n+m)T)$.
     III. Portanto, a complexidade computacional total da composiÃ§Ã£o e aplicaÃ§Ã£o em uma sÃ©rie temporal Ã© $O(nm)+O((n+m)T)$. $\blacksquare$

**Teorema 1.2:** A aplicaÃ§Ã£o sucessiva de dois operadores polinomiais de ordem $n$ e $m$ em uma sequÃªncia de tempo de comprimento $T$ tem complexidade computacional $O(nT + mT)$.
*   **Prova:**
    I.  Pelo Teorema 1, a aplicaÃ§Ã£o de um operador de ordem $n$ em uma sequÃªncia de comprimento $T$ tem complexidade $O(nT)$.
    II.  Similarmente, a aplicaÃ§Ã£o de um operador de ordem $m$ em uma sequÃªncia de comprimento $T$ tem complexidade $O(mT)$.
    III. A aplicaÃ§Ã£o sucessiva dos dois operadores implica aplicar o primeiro operador na sequÃªncia original e, em seguida, aplicar o segundo operador na sequÃªncia resultante.
    IV. Portanto, a complexidade computacional total Ã© $O(nT + mT)$. $\blacksquare$

**Teorema 1.3:** A complexidade computacional da aplicaÃ§Ã£o de um operador polinomial de ordem n a uma sequÃªncia de tempo de comprimento $T$, utilizando uma abordagem recursiva, Ã© $O(nT)$, onde $n$ Ã© a ordem do operador e $T$ Ã© o comprimento da sequÃªncia.
 *   **Prova:**
     I. Em uma abordagem recursiva para aplicar um operador polinomial $p(L) = \sum_{k=0}^n a_k L^k$ em uma sequÃªncia $x_t$, cada elemento da sequÃªncia resultante $y_t$ Ã© calculado como $y_t = \sum_{k=0}^n a_k x_{t-k}$.
     II. Para cada $t$, o cÃ¡lculo de $y_t$ envolve $n$ multiplicaÃ§Ãµes e $n-1$ somas.
     III. Assim, o nÃºmero total de operaÃ§Ãµes Ã© proporcional a $n$ para cada ponto no tempo, e como existem $T$ pontos de tempo, a complexidade total Ã© $O(nT)$. $\blacksquare$

### TÃ©cnicas de SimplificaÃ§Ã£o e OtimizaÃ§Ã£o de CÃ³digo
Para lidar com a complexidade computacional inerente Ã  expansÃ£o de operadores compostos, vÃ¡rias tÃ©cnicas de simplificaÃ§Ã£o e otimizaÃ§Ã£o de cÃ³digo podem ser utilizadas:

1.  **Truncamento da SÃ©rie:** Uma das abordagens mais comuns para lidar com operadores inversos Ã© truncar a sÃ©rie infinita em um nÃºmero finito de termos. O nÃºmero de termos a serem incluÃ­dos depende da precisÃ£o desejada e dos recursos computacionais disponÃ­veis. A escolha do nÃºmero de termos Ã© um trade-off entre a exatidÃ£o e o custo computacional.
2.  **ImplementaÃ§Ã£o Eficiente do Operador de Atraso:** Em vez de usar loops para implementar o operador de atraso, o uso de funÃ§Ãµes vetorizadas (como aquelas disponÃ­veis em bibliotecas como o `numpy` do Python) pode acelerar consideravelmente o cÃ¡lculo, aproveitando a paralelizaÃ§Ã£o das operaÃ§Ãµes na CPU.
3.  **Algoritmos Recursivos:** Em vez de expandir completamente o operador, podemos usar algoritmos recursivos que calculam os valores da sequÃªncia $y_t$ termo a termo, sem precisar armazenar todos os termos da expansÃ£o.
4. **Transformada Z e FFT:** A transformada Z, juntamente com a Transformada RÃ¡pida de Fourier (FFT), podem ser usadas para implementar operaÃ§Ãµes com operadores de forma eficiente. A transformada Z transforma a equaÃ§Ã£o de diferenÃ§as em uma equaÃ§Ã£o algÃ©brica e apÃ³s a resoluÃ§Ã£o no domÃ­nio de frequÃªncias, a transformada inversa (FFT) permite voltar para o domÃ­nio do tempo. Essa abordagem pode ser mais eficiente do que uma expansÃ£o direta do operador de atraso em muitas situaÃ§Ãµes.
5.  **Filtros Digitais:** Em muitos casos, os operadores de atraso correspondem a filtros digitais. O uso de bibliotecas que implementam esses filtros de forma otimizada (por exemplo, a funÃ§Ã£o `scipy.signal.lfilter` em Python) pode melhorar significativamente a eficiÃªncia da implementaÃ§Ã£o.

    > ðŸ’¡ **Exemplo NumÃ©rico (Algoritmo Recursivo):**
    > Considere a equaÃ§Ã£o $(1 - 0.7L)y_t = w_t$. Em vez de expandir o operador inverso, podemos usar um algoritmo recursivo:
    > $y_t = 0.7y_{t-1} + w_t$.
    > Este algoritmo calcula os valores de $y_t$ a partir do valor anterior e do ruÃ­do atual, evitando armazenar a sÃ©rie infinita do operador inverso. Em Python, a implementaÃ§Ã£o seria:
    >
    > ```python
    > import numpy as np
    >
    > def recursive_solution(w, phi, y0=0):
    >     y = np.zeros_like(w)
    >     y[0] = y0 + w[0]
    >     for i in range(1,len(w)):
    >         y[i] = phi*y[i-1] + w[i]
    >     return y
    >
    > w = np.random.randn(100)
    > y = recursive_solution(w, 0.7)
    > ```
    > Este algoritmo recursivo evita a necessidade de computar a sÃ©rie do operador inverso e torna a implementaÃ§Ã£o da soluÃ§Ã£o mais eficiente.
    >
    > ðŸ’¡ **Exemplo NumÃ©rico (FFT):**
    >  Considere o operador inverso $(1-0.5L)^{-1}$. Em vez de calcular todos os coeficientes da sÃ©rie, podemos usar a FFT para calcular a aÃ§Ã£o do operador no domÃ­nio da frequÃªncia, para em seguida voltar ao domÃ­nio do tempo utilizando a transformada inversa. Para uma sequÃªncia $w$ de tamanho $n$, a aplicaÃ§Ã£o da FFT a $w$ tem complexidade computacional $O(n \log n)$, ao passo que a expansÃ£o direta do operador tem complexidade computacional $O(n^2)$.
    >
    >  ```python
    >   import numpy as np
    >   from scipy.fft import fft, ifft
    >
    >   n = 1024
    >   w = np.random.randn(n)
    >
    >   # Representa o operador no domÃ­nio da frequÃªncia
    >   h_omega = 1.0 / (1.0 - 0.5*np.exp(-1j * np.arange(n) * 2 * np.pi / n))
    >
    >  # Calculo a FFT de w
    >   w_omega = fft(w)
    >
    >   # Aplica o operador ao domÃ­nio da frequÃªncia
    >   y_omega = h_omega * w_omega
    >
    >  # Retorna para o domÃ­nio do tempo
    >   y_fft = ifft(y_omega).real
    >  ```
    > Para ilustrar o ganho em eficiÃªncia, vamos simular o tempo de execuÃ§Ã£o usando `timeit`:
    > ```python
    > import numpy as np
    > from scipy.fft import fft, ifft
    > import timeit
    >
    > n = 2**12  # 4096
    > w = np.random.randn(n)
    >
    > def apply_operator_direct(w, phi=0.5, n_terms=100):
    >  y = np.zeros_like(w)
    >  for i in range(len(w)):
    >     for k in range(min(i + 1, n_terms)):
    >        y[i] += (phi**k) * w[i-k]
    >  return y
    >
    > def apply_operator_fft(w, phi=0.5):
    >    h_omega = 1.0 / (1.0 - phi*np.exp(-1j * np.arange(len(w)) * 2 * np.pi / len(w)))
    >    w_omega = fft(w)
    >    y_omega = h_omega * w_omega
    >    return ifft(y_omega).real
    >
    > time_direct = timeit.timeit(lambda: apply_operator_direct(w), number=10)
    > time_fft = timeit.timeit(lambda: apply_operator_fft(w), number=10)
    >
    > print(f"Tempo com expansÃ£o direta: {time_direct:.4f} segundos")
    > print(f"Tempo com FFT: {time_fft:.4f} segundos")
    > ```
    > Note que ao executar este cÃ³digo, para um tamanho de sequÃªncia $n=4096$, o tempo de execuÃ§Ã£o da implementaÃ§Ã£o via FFT serÃ¡ significativamente inferior ao da implementaÃ§Ã£o direta.

**Teorema 2:**
     A complexidade computacional da aplicaÃ§Ã£o de um operador linear a uma sequÃªncia de comprimento $T$ usando a transformada de Fourier rÃ¡pida (FFT) tem complexidade $O(T \log T)$.
  *   **Prova:**
       I. A FFT Ã© um algoritmo que computa a transformada discreta de Fourier (DFT) de uma sequÃªncia com complexidade $O(n \log n)$, onde $n$ Ã© o tamanho da sequÃªncia.
       II. Aplicar um operador linear a uma sequÃªncia usando a FFT envolve: calcular a FFT da sequÃªncia de entrada, calcular a FFT do operador, multiplicar as duas sequÃªncias no domÃ­nio da frequÃªncia e aplicar a transformada inversa.
       III. Cada uma dessas etapas possui complexidade $O(T \log T)$.
        IV.  Portanto, a complexidade total Ã© $O(T \log T)$. $\blacksquare$

**CorolÃ¡rio 1.**
    O uso da FFT para aplicar um operador linear a uma sÃ©rie temporal Ã© mais eficiente que o uso da expansÃ£o direta quando o tamanho da sÃ©rie temporal Ã© grande.
   *  **Prova:**
      I. Pelo Teorema 1, a aplicaÃ§Ã£o direta de um operador linear de ordem $n$ a uma sÃ©rie de tamanho $T$ tem complexidade $O(nT)$.
      II. Pelo Teorema 2, a aplicaÃ§Ã£o usando a FFT tem complexidade $O(T \log T)$.
      III. Para $T$ grande, a complexidade $O(T \log T)$ cresce mais lentamente do que $O(nT)$,  tornando o uso da FFT mais eficiente para tamanhos de sequÃªncia de tempo maiores.  $\blacksquare$

**CorolÃ¡rio 1.1:** Quando o operador a ser aplicado via FFT corresponde a uma funÃ§Ã£o racional no domÃ­nio da frequÃªncia, como Ã© o caso dos operadores polinomiais, Ã© possÃ­vel usar a propriedade de que o operador no domÃ­nio da frequÃªncia (i.e. a sua transformada) Ã© o resultado da transformada dos coeficientes do operador de atraso.
* **Prova**
   I. A transformada Z de um operador polinomial $p(L) = \sum_{k=0}^n a_k L^k$ Ã© dada por $P(z) = \sum_{k=0}^n a_k z^{-k}$.
   II. A transformada discreta de Fourier (DFT) de $p(L)$ quando avaliada nos pontos $z=e^{j\omega}$ resulta em $P(e^{j\omega}) =  \sum_{k=0}^n a_k e^{-jk\omega}$.
   III. Ao aplicar a transformada de Fourier nos coeficientes do operador, obtemos uma representaÃ§Ã£o do operador no domÃ­nio da frequÃªncia, $P(e^{j\omega})$, que pode ser utilizada na implementaÃ§Ã£o da convoluÃ§Ã£o com a sequÃªncia de tempo utilizando FFT. $\blacksquare$

**Lema 3:** A transformada Z de um operador de atraso $L$ Ã© dada por $z^{-1}$.
* **Prova:**
    I. A transformada Z de uma sequÃªncia $x_t$ Ã© definida como $X(z) = \sum_{t=-\infty}^{\infty} x_t z^{-t}$.
    II. A aÃ§Ã£o do operador de atraso $L$ em $x_t$ resulta em $x_{t-1}$.
    III. Portanto, a transformada Z de $L x_t$ Ã© dada por $\sum_{t=-\infty}^{\infty} x_{t-1} z^{-t}$.
    IV. Fazendo a mudanÃ§a de variÃ¡vel $k=t-1$, temos que a transformada Z de $L x_t$ Ã© igual a $\sum_{k=-\infty}^{\infty} x_k z^{-(k+1)} = z^{-1} \sum_{k=-\infty}^{\infty} x_k z^{-k} = z^{-1}X(z)$.
    V. Logo, a transformada Z de $L$ Ã© $z^{-1}$. $\blacksquare$

**Lema 4:** A transformada Z de um operador polinomial $p(L) = \sum_{k=0}^n a_k L^k$ Ã© dada por $P(z) = \sum_{k=0}^n a_k z^{-k}$.
* **Prova:**
  I. Pelo Lema 3, a transformada Z do operador de atraso $L$ Ã© $z^{-1}$.
  II. A transformada Z de uma constante multiplicada por uma sequÃªncia Ã© a constante multiplicada pela transformada Z da sequÃªncia.
  III. A transformada Z de uma soma de sequÃªncias Ã© a soma das transformadas Z das sequÃªncias.
  IV. Portanto, a transformada Z de $p(L) = \sum_{k=0}^n a_k L^k$ Ã© a soma das transformadas Z de cada termo, ou seja, $P(z) = \sum_{k=0}^n a_k (z^{-1})^k = \sum_{k=0}^n a_k z^{-k}$. $\blacksquare$

### ConclusÃ£o
A expansÃ£o de operadores compostos na manipulaÃ§Ã£o de equaÃ§Ãµes de diferenÃ§a pode levar a um aumento da complexidade computacional. No entanto, atravÃ©s do uso de tÃ©cnicas de simplificaÃ§Ã£o e otimizaÃ§Ã£o de cÃ³digo, como o truncamento de sÃ©ries, algoritmos recursivos, transformada de Fourier e implementaÃ§Ã£o eficiente de operadores de atraso, Ã© possÃ­vel lidar com essa complexidade e manter um bom desempenho computacional. A escolha da tÃ©cnica apropriada depende da natureza do problema, da precisÃ£o desejada e dos recursos computacionais disponÃ­veis. A compreensÃ£o das propriedades do operador de atraso e da sua relaÃ§Ã£o com as representaÃ§Ãµes computacionais Ã© essencial para desenvolver modelos eficientes de sÃ©ries temporais.

### ReferÃªncias
[^2.2.2]:  "This equation, in turn, can be rearranged using standard algebra, yt â€“ Ï†Lyt = wt or (1 â€“ Ï†L)yt = wt."
[^2.2.9]: "y, = w, + Ï†w,-1 + Ï†Â²w,-2 + Ï†Â³w,-3 +...."
[^2.2.8]:  "(1 â€“ Ï†L)-1 = lim (1 + Ï†L + Ï†2L2 + Ï†3L3 + ... + Ï†/L/)."
<!-- END -->
