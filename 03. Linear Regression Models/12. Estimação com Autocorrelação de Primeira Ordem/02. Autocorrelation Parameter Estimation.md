## EstimaÃ§Ã£o da AutocorrelaÃ§Ã£o de Primeira Ordem via ResÃ­duos
### IntroduÃ§Ã£o
Em continuidade Ã  discussÃ£o sobre estimaÃ§Ã£o de modelos de regressÃ£o linear com erros correlacionados, focamos agora na estimaÃ§Ã£o do parÃ¢metro de autocorrelaÃ§Ã£o, especificamente, em um modelo de primeira ordem AR(1). Conforme visto anteriormente, ao lidarmos com modelos onde os resÃ­duos apresentam autocorrelaÃ§Ã£o, os estimadores de MÃ­nimos Quadrados OrdinÃ¡rios (OLS) podem perder a eficiÃªncia. Uma abordagem para lidar com esta questÃ£o envolve o uso de estimadores de MÃ­nimos Quadrados Generalizados (GLS), que levam em conta a estrutura de covariÃ¢ncia dos erros. Exploraremos mÃ©todos alternativos para estimar o parÃ¢metro de autocorrelaÃ§Ã£o, com foco em abordagens que utilizam os resÃ­duos da regressÃ£o OLS. Em particular, discutiremos como a estimativa direta da autocorrelaÃ§Ã£o dos resÃ­duos pode fornecer resultados assintoticamente equivalentes ao mÃ©todo iterativo de Cochrane-Orcutt, apresentado em [^8.3.15].

### Conceitos Fundamentais
Como abordado em [^8.3.16], o parÃ¢metro de autocorrelaÃ§Ã£o $\rho$ pode ser estimado por:
$$
\hat{\rho} = \frac{\sum_{t=1}^{T} \hat{u}_t \hat{u}_{t-1}}{\sum_{t=1}^{T} \hat{u}_{t-1}^2},
$$
onde $\hat{u}_t = y_t - x_t'b$ sÃ£o os resÃ­duos da regressÃ£o OLS, e $b$ Ã© o estimador OLS de $\beta$. O texto menciona uma forma de simplificar as expressÃµes utilizando uma amostra com T+1 observaÃ§Ãµes renomeadas como $y_0, y_1, ..., y_T$, com o objetivo de usar $T$ observaÃ§Ãµes na estimativa condicional da mÃ¡xima verossimilhanÃ§a. Note que, ao aplicar essa reformulaÃ§Ã£o, temos:
$$\hat{u}_t = (y_t - \beta'x_t) + (\beta'x_t - b'x_t) = u_t + (\beta - b)'x_t$$
Assim, ao derivarmos o numerador da equaÃ§Ã£o da autocorrelaÃ§Ã£o temos que:
$$ \sum_{t=1}^{T} \hat{u}_t \hat{u}_{t-1} = \sum_{t=1}^{T} [u_t + (\beta - b)'x_t][u_{t-1} + (\beta - b)'x_{t-1}] $$
Expandindo esta expressÃ£o, obtemos:
$$ \sum_{t=1}^{T} \hat{u}_t \hat{u}_{t-1} =  \sum_{t=1}^{T} u_t u_{t-1} + \sum_{t=1}^{T}(\beta-b)'x_t u_{t-1} + \sum_{t=1}^{T} u_t (\beta-b)'x_{t-1} + \sum_{t=1}^{T} (\beta-b)'x_t x_{t-1}'(\beta-b) $$
Ao analisarmos essa expansÃ£o, e considerando que as premissas do modelo garantem que as covariÃ¢ncias entre $u_t$ e $x_t$ sejam zero, e sob as condiÃ§Ãµes de que $b$ seja um estimador consistente para $\beta$ e que os limites de $\frac{1}{T}\sum_{t=1}^{T} x_t u_{t-1}$, $\frac{1}{T}\sum_{t=1}^{T} u_t x_{t-1}$ e $\frac{1}{T}\sum_{t=1}^{T} x_t x_{t-1}$ existam, chegamos a:
$$ \frac{1}{T} \sum_{t=1}^{T} \hat{u}_t \hat{u}_{t-1} \approx \frac{1}{T} \sum_{t=1}^{T} u_t u_{t-1} $$
> ðŸ’¡ **Exemplo NumÃ©rico:**
> Vamos considerar um cenÃ¡rio simplificado com $T=5$ para ilustrar a aproximaÃ§Ã£o. Suponha que temos os seguintes resÃ­duos verdadeiros ($u_t$) e os regressores ($x_t$):
>
> | t | $u_t$ | $x_t$ |
> |---|-------|-------|
> | 0 | 0.5   | 1     |
> | 1 | -0.3  | 2     |
> | 2 | 0.2   | 1.5   |
> | 3 | 0.1   | 3     |
> | 4 | -0.4  | 2.5   |
> | 5 | 0.25  | 1.8   |
>
> E suponha que o estimador OLS $b$ seja prÃ³ximo do valor verdadeiro $\beta$, de tal forma que $(\beta-b)$ Ã© pequeno (por exemplo, 0.05). Para simplificar, considere que $x_t$ Ã© um escalar.  Vamos calcular $\frac{1}{T} \sum_{t=1}^{T} u_t u_{t-1}$ e $\frac{1}{T}\sum_{t=1}^{T} \hat{u}_t \hat{u}_{t-1}$ e comparar.
>
> Primeiro, calculamos $\frac{1}{T}\sum_{t=1}^{T} u_t u_{t-1}$:
>
>  $\frac{1}{5} [(-0.3)(0.5) + (0.2)(-0.3) + (0.1)(0.2) + (-0.4)(0.1) + (0.25)(-0.4)] = \frac{1}{5} [-0.15 -0.06 + 0.02 -0.04 -0.1] = -0.066$
>
>Agora, vamos calcular os resÃ­duos estimados $\hat{u}_t$. Usando a fÃ³rmula $\hat{u}_t = u_t + (\beta - b)x_t$:
>
>| t | $u_t$ | $x_t$ | $(\beta-b)x_t$ |  $\hat{u}_t$ |
>|---|-------|-------|----------------|-------------|
>| 0 | 0.5   | 1     | 0.05           |   0.55        |
>| 1 | -0.3  | 2     | 0.10           |   -0.20       |
>| 2 | 0.2   | 1.5   | 0.075           |   0.275       |
>| 3 | 0.1   | 3     | 0.15           |   0.25        |
>| 4 | -0.4  | 2.5   | 0.125           |   -0.275       |
>| 5 | 0.25  | 1.8   | 0.09           |   0.34        |
>
> Calculando $\frac{1}{T}\sum_{t=1}^{T} \hat{u}_t \hat{u}_{t-1}$:
>
>  $\frac{1}{5} [(-0.20)(0.55) + (0.275)(-0.20) + (0.25)(0.275) + (-0.275)(0.25) + (0.34)(-0.275)] = \frac{1}{5} [-0.11 - 0.055 + 0.06875 -0.06875 -0.0935] = -0.05165$
>
>Como podemos ver, -0.066 Ã© relativamente prÃ³ximo de -0.05165, o que ilustra a aproximaÃ§Ã£o teÃ³rica. Em amostras maiores, a aproximaÃ§Ã£o se torna ainda mais precisa.
>
>Este exemplo demonstra numericamente como a aproximaÃ§Ã£o $\frac{1}{T} \sum_{t=1}^{T} \hat{u}_t \hat{u}_{t-1} \approx \frac{1}{T} \sum_{t=1}^{T} u_t u_{t-1}$ funciona na prÃ¡tica.

**Prova da aproximaÃ§Ã£o do numerador:**
Vamos provar que $\frac{1}{T} \sum_{t=1}^{T} \hat{u}_t \hat{u}_{t-1} \approx \frac{1}{T} \sum_{t=1}^{T} u_t u_{t-1}$

I.  ComeÃ§amos com a expressÃ£o expandida:
    $$ \frac{1}{T}\sum_{t=1}^{T} \hat{u}_t \hat{u}_{t-1} = \frac{1}{T}\sum_{t=1}^{T} u_t u_{t-1} + \frac{1}{T}\sum_{t=1}^{T}(\beta-b)'x_t u_{t-1} + \frac{1}{T}\sum_{t=1}^{T} u_t (\beta-b)'x_{t-1} + \frac{1}{T}\sum_{t=1}^{T} (\beta-b)'x_t x_{t-1}'(\beta-b) $$

II. Usando o fato de que $b$ Ã© um estimador consistente para $\beta$, temos que $(\beta - b)$ converge em probabilidade para zero, ou seja, $(\beta - b) \stackrel{p}{\longrightarrow} 0$.

III.  Assumindo que os limites $\frac{1}{T}\sum_{t=1}^{T} x_t u_{t-1}$, $\frac{1}{T}\sum_{t=1}^{T} u_t x_{t-1}$ e $\frac{1}{T}\sum_{t=1}^{T} x_t x_{t-1}$ existem e sÃ£o finitos, entÃ£o:
     $$ \frac{1}{T}\sum_{t=1}^{T}(\beta-b)'x_t u_{t-1} \stackrel{p}{\longrightarrow} 0 $$
      $$ \frac{1}{T}\sum_{t=1}^{T} u_t (\beta-b)'x_{t-1} \stackrel{p}{\longrightarrow} 0 $$
      $$ \frac{1}{T}\sum_{t=1}^{T} (\beta-b)'x_t x_{t-1}'(\beta-b) \stackrel{p}{\longrightarrow} 0 $$
     
IV. Portanto, Ã  medida que $T$ cresce, os termos adicionais na expansÃ£o convergem em probabilidade para zero, e a aproximaÃ§Ã£o torna-se cada vez mais precisa:
$$ \frac{1}{T} \sum_{t=1}^{T} \hat{u}_t \hat{u}_{t-1} \approx \frac{1}{T} \sum_{t=1}^{T} u_t u_{t-1} $$
â– 

**Lema 1**
A premissa de que as covariÃ¢ncias entre $u_t$ e $x_t$ sejam zero, isto Ã©, $Cov(u_t, x_t) = 0$ para todo $t$, Ã© uma condiÃ§Ã£o fundamental para a consistÃªncia do estimador OLS. Essa premissa assegura que os regressores nÃ£o sejam correlacionados com os erros, uma das hipÃ³teses bÃ¡sicas do modelo linear clÃ¡ssico. Essa condiÃ§Ã£o garante que o estimador OLS $b$ converge em probabilidade para $\beta$.

Da mesma forma, o denominador pode ser expresso como:
$$
\sum_{t=1}^{T} \hat{u}_{t-1}^2 = \sum_{t=1}^{T} [u_{t-1} + (\beta - b)'x_{t-1}]^2
$$
Expandindo essa expressÃ£o, obtemos:
$$ \sum_{t=1}^{T} \hat{u}_{t-1}^2 = \sum_{t=1}^{T} u_{t-1}^2 + 2 \sum_{t=1}^{T} u_{t-1}(\beta - b)'x_{t-1} + \sum_{t=1}^{T} [(\beta - b)'x_{t-1}]^2 $$
Assumindo as mesmas premissas para o caso anterior, chegamos a:
$$ \frac{1}{T} \sum_{t=1}^{T} \hat{u}_{t-1}^2 \approx \frac{1}{T} \sum_{t=1}^{T} u_{t-1}^2$$

> ðŸ’¡ **Exemplo NumÃ©rico:**
> Utilizando os mesmos dados do exemplo anterior, vamos calcular $\frac{1}{T} \sum_{t=1}^{T} u_{t-1}^2$ e $\frac{1}{T} \sum_{t=1}^{T} \hat{u}_{t-1}^2$ para ilustrar a aproximaÃ§Ã£o do denominador:
>
>  $\frac{1}{T} \sum_{t=1}^{T} u_{t-1}^2 = \frac{1}{5} [(0.5)^2 + (-0.3)^2 + (0.2)^2 + (0.1)^2 + (-0.4)^2 ] = \frac{1}{5} [0.25 + 0.09 + 0.04 + 0.01 + 0.16] = 0.11$
>
> Usando os valores de $\hat{u}_t$ calculados no exemplo anterior:
>
>  $\frac{1}{T} \sum_{t=1}^{T} \hat{u}_{t-1}^2 = \frac{1}{5} [(0.55)^2 + (-0.2)^2 + (0.275)^2 + (0.25)^2 + (-0.275)^2] = \frac{1}{5} [0.3025 + 0.04 + 0.075625 + 0.0625 + 0.075625] = 0.11125$
>
> Novamente, vemos que $0.11$ e $0.11125$ sÃ£o muito prÃ³ximos, o que ilustra a aproximaÃ§Ã£o teÃ³rica do denominador.

**Prova da aproximaÃ§Ã£o do denominador:**
Vamos provar que $\frac{1}{T} \sum_{t=1}^{T} \hat{u}_{t-1}^2 \approx \frac{1}{T} \sum_{t=1}^{T} u_{t-1}^2$

I. ComeÃ§amos com a expressÃ£o expandida:
    $$ \frac{1}{T}\sum_{t=1}^{T} \hat{u}_{t-1}^2 = \frac{1}{T}\sum_{t=1}^{T} u_{t-1}^2 + \frac{2}{T}\sum_{t=1}^{T} u_{t-1}(\beta - b)'x_{t-1} + \frac{1}{T}\sum_{t=1}^{T} [(\beta - b)'x_{t-1}]^2 $$

II. Usando o fato de que $b$ Ã© um estimador consistente para $\beta$, temos que $(\beta - b)$ converge em probabilidade para zero, ou seja, $(\beta - b) \stackrel{p}{\longrightarrow} 0$.

III. Assumindo que os limites $\frac{1}{T}\sum_{t=1}^{T} u_{t-1}x_{t-1}$ e $\frac{1}{T}\sum_{t=1}^{T} x_{t-1}x_{t-1}'$ existem e sÃ£o finitos, entÃ£o:
    $$ \frac{2}{T}\sum_{t=1}^{T} u_{t-1}(\beta - b)'x_{t-1} \stackrel{p}{\longrightarrow} 0 $$
     $$ \frac{1}{T}\sum_{t=1}^{T} [(\beta - b)'x_{t-1}]^2 \stackrel{p}{\longrightarrow} 0 $$

IV. Portanto, Ã  medida que $T$ cresce, os termos adicionais na expansÃ£o convergem em probabilidade para zero, e a aproximaÃ§Ã£o torna-se cada vez mais precisa:
$$ \frac{1}{T} \sum_{t=1}^{T} \hat{u}_{t-1}^2 \approx \frac{1}{T} \sum_{t=1}^{T} u_{t-1}^2 $$
â– 

**Lema 1.1**
A convergÃªncia em probabilidade de $\frac{1}{T}\sum_{t=1}^{T} \hat{u}_{t-1}^2$ para $\frac{1}{T}\sum_{t=1}^{T} u_{t-1}^2$ Ã© crucial para estabelecer a consistÃªncia do estimador $\hat{\rho}$. Essa convergÃªncia depende da consistÃªncia do estimador OLS $b$ e das condiÃ§Ãµes de momento finito sobre os regressores e os erros.

A partir dessas aproximaÃ§Ãµes, podemos observar que:
$$ \frac{\frac{1}{T}\sum_{t=1}^{T} \hat{u}_t \hat{u}_{t-1}}{\frac{1}{T}\sum_{t=1}^{T} \hat{u}_{t-1}^2} \approx \frac{\frac{1}{T}\sum_{t=1}^{T} u_t u_{t-1}}{\frac{1}{T}\sum_{t=1}^{T} u_{t-1}^2} $$

Essa expressÃ£o demonstra que a estimativa de $\rho$ via resÃ­duos OLS converge em probabilidade para a estimativa utilizando a populaÃ§Ã£o de erros, ou seja:
$$ \hat{\rho} \stackrel{p}{\longrightarrow} \rho $$

> ðŸ’¡ **Exemplo NumÃ©rico:**
> Continuando com o mesmo exemplo, vamos calcular $\hat{\rho}$ usando os resÃ­duos estimados e os resÃ­duos verdadeiros:
>
> Usando os resultados anteriores:
>
> $\hat{\rho}_{res} = \frac{\frac{1}{T}\sum_{t=1}^{T} \hat{u}_t \hat{u}_{t-1}}{\frac{1}{T}\sum_{t=1}^{T} \hat{u}_{t-1}^2} = \frac{-0.05165}{0.11125} \approx -0.464$
>
> $\hat{\rho}_{true} = \frac{\frac{1}{T}\sum_{t=1}^{T} u_t u_{t-1}}{\frac{1}{T}\sum_{t=1}^{T} u_{t-1}^2} = \frac{-0.066}{0.11} = -0.6$
>
>Como podemos observar, os valores sÃ£o prÃ³ximos.  Em amostras maiores a convergÃªncia serÃ¡ ainda maior. Este exemplo numÃ©rico mostra que a estimativa de $\rho$ usando os resÃ­duos da regressÃ£o OLS se aproxima da estimativa usando os erros verdadeiros.

**Prova da convergÃªncia em probabilidade de $\hat{\rho}$ para $\rho$:**

I. Sabemos que:
    $$\hat{\rho} = \frac{\sum_{t=1}^{T} \hat{u}_t \hat{u}_{t-1}}{\sum_{t=1}^{T} \hat{u}_{t-1}^2} = \frac{\frac{1}{T}\sum_{t=1}^{T} \hat{u}_t \hat{u}_{t-1}}{\frac{1}{T}\sum_{t=1}^{T} \hat{u}_{t-1}^2}$$

II. Das provas anteriores, temos as seguintes aproximaÃ§Ãµes:
     $$\frac{1}{T}\sum_{t=1}^{T} \hat{u}_t \hat{u}_{t-1} \approx \frac{1}{T}\sum_{t=1}^{T} u_t u_{t-1}$$
     $$\frac{1}{T}\sum_{t=1}^{T} \hat{u}_{t-1}^2 \approx \frac{1}{T}\sum_{t=1}^{T} u_{t-1}^2$$

III. Portanto,
    $$ \hat{\rho} \approx \frac{\frac{1}{T}\sum_{t=1}^{T} u_t u_{t-1}}{\frac{1}{T}\sum_{t=1}^{T} u_{t-1}^2} $$
IV. Dado que $\frac{1}{T}\sum_{t=1}^{T} u_t u_{t-1}$ converge em probabilidade para $Cov(u_t, u_{t-1})$ e $\frac{1}{T}\sum_{t=1}^{T} u_{t-1}^2$ converge em probabilidade para $Var(u_t)$, podemos concluir:
    $$ \hat{\rho} \stackrel{p}{\longrightarrow} \frac{Cov(u_t, u_{t-1})}{Var(u_t)} = \rho$$
    Onde $\rho$ Ã© o verdadeiro parÃ¢metro de autocorrelaÃ§Ã£o.
â– 

AlÃ©m disso, o texto afirma em [^8.3.19], que a convergÃªncia em probabilidade de  $\frac{1}{T} \sum_{t=1}^{T} \hat{u}_t\hat{u}_{t-1}$  para  $\rho Var(u)$ pode ser demonstrada, assumindo que $b$ Ã© um estimador consistente para $\beta$, e que os limites  $\frac{1}{T} \sum_{t=1}^{T} u_t u_{t-1}$, $\frac{1}{T} \sum_{t=1}^{T} u_t x_{t-1}$, $\frac{1}{T} \sum_{t=1}^{T} x_t u_{t-1}$, e $\frac{1}{T} \sum_{t=1}^{T} x_t x_{t-1}$ existem. Em [^8.3.20], o texto apresenta a distribuiÃ§Ã£o assintÃ³tica da estimativa de $\rho$ quando calculada com a populaÃ§Ã£o de erros, e em [^8.3.21] demonstra que a estimativa de $\rho$ calculada com resÃ­duos da regressÃ£o OLS tem a mesma distribuiÃ§Ã£o assintÃ³tica:
$$ \sqrt{T}(\hat{\rho} - \rho) \xrightarrow{d} N(0, 1-\rho^2) $$
> ðŸ’¡ **Exemplo NumÃ©rico:**
> Suponha que temos uma amostra grande (T=200) e que a estimativa de $\rho$ pelos resÃ­duos seja $\hat{\rho} = 0.6$.  O verdadeiro valor de $\rho$ Ã© desconhecido. Podemos usar a distribuiÃ§Ã£o assintÃ³tica para construir um intervalo de confianÃ§a para o verdadeiro valor de $\rho$. A variÃ¢ncia assintÃ³tica de $\hat{\rho}$ Ã© estimada por $(1-\hat{\rho}^2)/T = (1-0.6^2)/200 = 0.0032$. O desvio padrÃ£o assintÃ³tico Ã© a raiz quadrada da variÃ¢ncia, ou seja, $\sqrt{0.0032} \approx 0.0566$. Usando um nÃ­vel de confianÃ§a de 95%,  o valor crÃ­tico de $Z$ Ã© de aproximadamente $1.96$. Portanto o intervalo de confianÃ§a para $\rho$ Ã©:
> $$ 0.6 \pm 1.96 \times 0.0566$$
> $$ 0.6 \pm 0.111$$
> Portanto o intervalo de confianÃ§a serÃ¡ aproximadamente [0.489, 0.711]
> Isso significa que, sob as premissas do modelo, temos 95% de confianÃ§a que o verdadeiro valor de $\rho$ estÃ¡ dentro desse intervalo.
> AlÃ©m disso, podemos realizar testes de hipÃ³teses sobre $\rho$. Por exemplo, testar $H_0 : \rho = 0$ contra $H_1 : \rho \neq 0$. A estatÃ­stica de teste seria:
> $$ Z = \frac{\hat{\rho} - 0}{\sqrt{(1-\hat{\rho}^2)/T}} = \frac{0.6}{\sqrt{0.0032}} \approx 10.6 $$
>
> Como o valor de Z Ã© muito maior que 1.96, rejeitamos a hipÃ³tese nula com um nÃ­vel de significÃ¢ncia de 5%. Isso nos da evidÃªncia que hÃ¡ autocorrelaÃ§Ã£o nos resÃ­duos.

**Teorema 1**
A distribuiÃ§Ã£o assintÃ³tica de $\hat{\rho}$  nos mostra que para amostras grandes, $\hat{\rho}$  Ã© aproximadamente normalmente distribuÃ­do com mÃ©dia $\rho$ e variÃ¢ncia $(1-\rho^2)/T$. Esta distribuiÃ§Ã£o Ã© fundamental para a inferÃªncia estatÃ­stica, permitindo construir intervalos de confianÃ§a e testar hipÃ³teses sobre o parÃ¢metro de autocorrelaÃ§Ã£o $\rho$.

**CorolÃ¡rio 1**
A convergÃªncia em distribuiÃ§Ã£o de $\sqrt{T}(\hat{\rho} - \rho)$ para $N(0, 1-\rho^2)$ implica que, para amostras grandes, a diferenÃ§a entre a estimativa $\hat{\rho}$ e o verdadeiro valor $\rho$, multiplicada por $\sqrt{T}$, Ã© aproximadamente normalmente distribuÃ­da. Este resultado Ã© crucial para testes de hipÃ³teses e construÃ§Ã£o de intervalos de confianÃ§a para $\rho$.
### ConclusÃ£o
Em resumo, a estimativa do parÃ¢metro de autocorrelaÃ§Ã£o $\rho$ utilizando diretamente os resÃ­duos da regressÃ£o OLS Ã© consistente e assintoticamente equivalente Ã  estimativa obtida pelo mÃ©todo iterativo de Cochrane-Orcutt. Embora este mÃ©todo iterativo possa convergir para um mÃ¡ximo local da funÃ§Ã£o de verossimilhanÃ§a, a estimativa direta baseada nos resÃ­duos do OLS Ã© computacionalmente mais simples e ainda fornece resultados assintoticamente vÃ¡lidos. Portanto, a abordagem de estimar a autocorrelaÃ§Ã£o diretamente a partir dos resÃ­duos OLS oferece uma alternativa eficiente e prÃ¡tica para lidar com modelos de regressÃ£o com erros autocorrelacionados, simplificando a implementaÃ§Ã£o em cenÃ¡rios onde estimativas rÃ¡pidas e precisas sÃ£o desejadas.
**ProposiÃ§Ã£o 1**
A simplicidade computacional da estimativa direta de $\rho$ baseada nos resÃ­duos OLS, em comparaÃ§Ã£o com o mÃ©todo iterativo de Cochrane-Orcutt, torna-a preferÃ­vel em cenÃ¡rios que exigem rapidez e eficiÃªncia no cÃ¡lculo. No entanto, a escolha do mÃ©todo mais adequado deve considerar o compromisso entre simplicidade e a necessidade de resultados com melhor precisÃ£o em casos especÃ­ficos.
### ReferÃªncias
[^8.3.15]:  DiscussÃ£o sobre o mÃ©todo iterativo de Cochrane-Orcutt
[^8.3.16]: ApresentaÃ§Ã£o da fÃ³rmula para estimativa da autocorrelaÃ§Ã£o dos resÃ­duos.
[^8.3.19]: DemonstraÃ§Ã£o da convergÃªncia em probabilidade do numerador da autocorrelaÃ§Ã£o.
[^8.3.20]: DistribuiÃ§Ã£o assintÃ³tica da estimativa do parÃ¢metro de autocorrelaÃ§Ã£o usando a populaÃ§Ã£o de erros.
[^8.3.21]:  DistribuiÃ§Ã£o assintÃ³tica da estimativa do parÃ¢metro de autocorrelaÃ§Ã£o usando os resÃ­duos OLS.
<!-- END -->
