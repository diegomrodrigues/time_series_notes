## A Estat√≠stica F e Testes Conjuntos de Restri√ß√µes Lineares

### Introdu√ß√£o
Este cap√≠tulo explora em detalhes a estat√≠stica F, um instrumento fundamental para realizar testes de hip√≥teses conjuntas sobre os par√¢metros em modelos de regress√£o linear. Construindo sobre o conceito de testes de hip√≥teses para um √∫nico coeficiente, que foi abordado anteriormente, agora nos aprofundaremos na an√°lise de m√∫ltiplos par√¢metros, apresentando a estat√≠stica F e a sua deriva√ß√£o, al√©m de suas propriedades sob diferentes condi√ß√µes.

### Conceitos Fundamentais

A estat√≠stica F √© uma ferramenta essencial quando se deseja testar v√°rias restri√ß√µes lineares simultaneamente sobre os coeficientes de um modelo de regress√£o. Diferente do teste *t*, que se aplica a hip√≥teses sobre um √∫nico par√¢metro, a estat√≠stica *F* avalia se um conjunto de restri√ß√µes lineares impostas aos coeficientes do modelo s√£o suportadas pelos dados.

Formalmente, a hip√≥tese nula que desejamos testar √© da forma $H_0: R\beta = r$ [^8.1.27], onde $R$ √© uma matriz conhecida $(m \times k)$ que especifica as combina√ß√µes lineares dos coeficientes $\beta$ que queremos testar, e $r$ √© um vetor conhecido $(m \times 1)$ que representa os valores que acreditamos que essas combina√ß√µes lineares assumem sob a hip√≥tese nula. Aqui, $m$ representa o n√∫mero de restri√ß√µes lineares que est√£o sendo testadas simultaneamente.

> üí° **Exemplo Num√©rico:** Suponha que temos um modelo de regress√£o com tr√™s preditores: $y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 + \epsilon$. Queremos testar a hip√≥tese nula de que $\beta_1 + \beta_2 = 1$ e $\beta_3 = 0$. Neste caso, $R = \begin{bmatrix} 0 & 1 & 1 & 0 \\ 0 & 0 & 0 & 1 \end{bmatrix}$, $\beta = \begin{bmatrix} \beta_0 \\ \beta_1 \\ \beta_2 \\ \beta_3 \end{bmatrix}$, e $r = \begin{bmatrix} 1 \\ 0 \end{bmatrix}$. Aqui, $m=2$ pois temos duas restri√ß√µes.

#### Deriva√ß√£o da Estat√≠stica F
A estat√≠stica *F* √© constru√≠da utilizando uma raz√£o entre duas estat√≠sticas qui-quadrado [^8.1.32]. O numerador est√° associado com as restri√ß√µes impostas pela hip√≥tese nula, enquanto o denominador est√° associado com o erro do modelo. O numerador mede a varia√ß√£o na soma dos quadrados dos res√≠duos (RSS) resultante da imposi√ß√£o das restri√ß√µes, enquanto o denominador estima a vari√¢ncia do erro do modelo.

O teste de Wald para testar a hip√≥tese $H_0$ √© dado por [^8.1.32]:

$$F = \frac{(Rb - r)'[s^2R(X'X)^{-1}R']^{-1}(Rb - r)}{m}$$

onde:

*   $b$ √© o estimador OLS dos coeficientes $\beta$.
*   $s^2$ √© o estimador n√£o viesado da vari√¢ncia do erro.
*   $R$ √© a matriz de restri√ß√µes lineares.
*   $r$ √© o vetor de valores sob a hip√≥tese nula.
*   $m$ √© o n√∫mero de restri√ß√µes (graus de liberdade do numerador).

Este teste se baseia na seguinte propriedade [^8.1.31]:

$$(Rb - r)'[\sigma^2 R(X'X)^{-1}R']^{-1}(Rb - r) \sim \chi^2(m)$$

que afirma que sob a hip√≥tese nula, a estat√≠stica acima segue uma distribui√ß√£o qui-quadrado com $m$ graus de liberdade.

Ao substituir $\sigma^2$ pelo seu estimador $s^2$ e dividir pelo n√∫mero de restri√ß√µes, $m$, chegamos √† estat√≠stica *F*. Formalmente, essa estat√≠stica √© obtida pela raz√£o entre a estat√≠stica qui-quadrado associada √† hip√≥tese nula, dividida por seus graus de liberdade ($m$), e a estat√≠stica qui-quadrado associada ao erro do modelo, dividida por seus graus de liberdade ($T-k$) [^8.1.32]:

$$F = \frac{(Rb - r)'[\sigma^2R(X'X)^{-1}R']^{-1}(Rb - r)/m}{RSS/(T-k)/\sigma^2}$$

Essa estat√≠stica F tem uma distribui√ß√£o *F* com *m* graus de liberdade no numerador e *T-k* graus de liberdade no denominador, sob a hip√≥tese nula e as condi√ß√µes cl√°ssicas de regress√£o linear [^8.1.32].

#### Express√£o Alternativa para a Estat√≠stica F
Uma forma alternativa e √∫til para calcular a estat√≠stica F envolve comparar a soma dos quadrados dos res√≠duos (RSS) de um modelo sem restri√ß√µes com a soma dos quadrados dos res√≠duos de um modelo com as restri√ß√µes impostas [^8.1.37].

Seja $RSS_1$ a soma dos quadrados dos res√≠duos do modelo irrestrito e $RSS_0$ a soma dos quadrados dos res√≠duos do modelo restrito [^8.1.35, 8.1.36]. A estat√≠stica F pode ser expressa como:

$$F = \frac{(RSS_0 - RSS_1)/m}{RSS_1/(T-k)}$$

Esta express√£o √© numericamente id√™ntica √† anterior [^8.1.37] e √∫til na pr√°tica porque permite calcular o valor da estat√≠stica *F* comparando o desempenho dos modelos com e sem as restri√ß√µes impostas.

> üí° **Exemplo Num√©rico:** Vamos supor que ajustamos um modelo de regress√£o com 100 observa√ß√µes (T=100) e 4 par√¢metros (k=4), incluindo o intercepto. O modelo irrestrito (sem restri√ß√µes) tem uma soma dos quadrados dos res√≠duos de $RSS_1 = 150$. Aplicamos duas restri√ß√µes lineares (m=2) e o modelo restrito tem uma soma dos quadrados dos res√≠duos de $RSS_0 = 200$. Podemos calcular a estat√≠stica F da seguinte forma:
>
> $\text{Step 1: } RSS_0 - RSS_1 = 200 - 150 = 50$
>
> $\text{Step 2: } (RSS_0 - RSS_1) / m = 50 / 2 = 25$
>
> $\text{Step 3: } RSS_1 / (T - k) = 150 / (100 - 4) = 150 / 96 \approx 1.5625$
>
> $\text{Step 4: } F = 25 / 1.5625 \approx 16$
>
> Portanto, a estat√≠stica F √© aproximadamente 16. Para avaliar a signific√¢ncia estat√≠stica, comparamos este valor com a distribui√ß√£o F com 2 e 96 graus de liberdade.

**Proposi√ß√£o 1** A estat√≠stica F pode ser expressa em termos dos $R^2$ dos modelos irrestrito e restrito.
*Demonstra√ß√£o:*
Sejam $R_1^2$ e $R_0^2$ os $R^2$ dos modelos irrestrito e restrito, respectivamente. Sabemos que $R^2 = 1 - \frac{RSS}{TSS}$, onde TSS √© a soma total dos quadrados. Ent√£o, $RSS = (1-R^2)TSS$.
Substituindo na express√£o da estat√≠stica F, temos:
$$F = \frac{((1-R_0^2)TSS - (1-R_1^2)TSS)/m}{(1-R_1^2)TSS/(T-k)} = \frac{TSS(R_1^2 - R_0^2)/m}{TSS(1-R_1^2)/(T-k)} = \frac{(R_1^2 - R_0^2)/m}{(1-R_1^2)/(T-k)}$$

Assim, a estat√≠stica F pode ser expressa em termos de $R^2$ como:
$$F = \frac{(R_1^2 - R_0^2)/m}{(1-R_1^2)/(T-k)}$$

Essa representa√ß√£o √© particularmente √∫til quando o foco est√° em comparar o poder explicativo dos modelos restrito e irrestrito.

> üí° **Exemplo Num√©rico:** Continuando o exemplo anterior, suponha que o $R^2$ do modelo irrestrito ($R_1^2$) seja 0.7 e o $R^2$ do modelo restrito ($R_0^2$) seja 0.6. Com $m = 2$, $T=100$ e $k=4$, podemos calcular a estat√≠stica F usando a f√≥rmula com $R^2$:
>
> $\text{Step 1: } R_1^2 - R_0^2 = 0.7 - 0.6 = 0.1$
>
> $\text{Step 2: } (R_1^2 - R_0^2) / m = 0.1 / 2 = 0.05$
>
> $\text{Step 3: } 1 - R_1^2 = 1 - 0.7 = 0.3$
>
> $\text{Step 4: } (1 - R_1^2) / (T - k) = 0.3 / (100 - 4) = 0.3 / 96 \approx 0.003125$
>
> $\text{Step 5: } F = 0.05 / 0.003125 \approx 16$
>
> Observe que a estat√≠stica F calculada usando R¬≤ √© a mesma que a calculada usando RSS, como esperado. A interpreta√ß√£o seria que as restri√ß√µes impostas diminuem o poder explicativo do modelo (redu√ß√£o no R¬≤) e essa diminui√ß√£o √© estatisticamente significativa dado o valor da estat√≠stica F e os seus graus de liberdade.

#### Teste F como Generaliza√ß√£o do Teste T
√â importante notar que o teste *t* para um √∫nico coeficiente √© um caso especial do teste *F*. Ao testar uma √∫nica restri√ß√£o linear sobre um coeficiente ($\beta_i = \beta_i^0$), o teste *F* torna-se equivalente ao quadrado do teste *t* [^8.1.33]:

$$F = \frac{(b_i - \beta_i^0)^2}{s^2 \xi^{ii}} = t^2$$

Onde $\xi^{ii}$ √© o i-√©simo elemento da diagonal da matriz $(X'X)^{-1}$. Isso ocorre porque uma distribui√ß√£o F com 1 grau de liberdade no numerador √© equivalente ao quadrado de uma distribui√ß√£o *t*.

> üí° **Exemplo Num√©rico:**  Suponha que estamos testando a hip√≥tese nula de que um coeficiente espec√≠fico $\beta_1$ √© igual a 0 ($H_0: \beta_1 = 0$). O estimador OLS para $\beta_1$ √© $b_1 = 2.5$, o erro padr√£o de $b_1$ √© $se(b_1) = 0.8$ e o estimador da vari√¢ncia do erro √© $s^2$.  Ent√£o o teste t seria:
>
> $t = \frac{2.5 - 0}{0.8} = 3.125$
>
> O teste F correspondente (com apenas uma restri√ß√£o) seria:
>
> $F = \frac{(2.5 - 0)^2}{s^2 \xi^{11}} = \frac{(2.5)^2}{(0.8)^2} = 9.7656 \approx (3.125)^2$
>
>
> Note que o valor da estat√≠stica F √© aproximadamente o quadrado do valor da estat√≠stica t. O valor cr√≠tico para um teste F com 1 e T-k graus de liberdade √© o quadrado do valor cr√≠tico do teste t com T-k graus de liberdade.

**Lema 1.1** A equival√™ncia entre o teste F e o quadrado do teste t tamb√©m se verifica em termos da express√£o alternativa da estat√≠stica F baseada nas somas dos quadrados dos res√≠duos.
*Demonstra√ß√£o:*
Considerando a restri√ß√£o $R\beta = r$, onde $R$ √© um vetor linha de zeros com um 1 na i-√©sima posi√ß√£o e $r = \beta_i^0$, a soma dos quadrados dos res√≠duos do modelo restrito, $RSS_0$, difere da soma dos quadrados do modelo irrestrito, $RSS_1$ pela diferen√ßa:

$$RSS_0 - RSS_1 = \frac{(b_i - \beta_i^0)^2}{\xi^{ii}}$$

Substituindo na express√£o alternativa da estat√≠stica F, com $m = 1$, temos:

$$F = \frac{(RSS_0 - RSS_1)/1}{RSS_1/(T-k)} = \frac{(b_i - \beta_i^0)^2/\xi^{ii}}{s^2} = \frac{(b_i - \beta_i^0)^2}{s^2 \xi^{ii}} = t^2$$

Isto demonstra que o teste F √© um caso geral do teste t, incluso quando usamos a express√£o em termos de somas de quadrados de res√≠duos.

#### Distribui√ß√£o da Estat√≠stica F
Sob as premissas cl√°ssicas de regress√£o linear (erros independentes, identicamente distribu√≠dos e normalmente distribu√≠dos), a estat√≠stica *F* tem uma distribui√ß√£o *F* exata [^8.1.32]. No entanto, em condi√ß√µes mais gerais, especialmente quando os erros n√£o s√£o normais, a distribui√ß√£o da estat√≠stica *F* √© aproximada assintoticamente. √â importante notar que mesmo se os res√≠duos n√£o forem normais, a estat√≠stica F continua sendo uma ferramenta √∫til para avaliar a signific√¢ncia das restri√ß√µes impostas sob a perspectiva assint√≥tica.

**Teorema 2** (Teorema do Limite Central para a Estat√≠stica F) Sob condi√ß√µes de regularidade, mesmo que os erros n√£o sejam normalmente distribu√≠dos, a distribui√ß√£o da estat√≠stica F converge para uma distribui√ß√£o F sob a hip√≥tese nula, √† medida que o tamanho da amostra aumenta.
*Prova (Esbo√ßo):*
I. O teorema se baseia na converg√™ncia assint√≥tica dos estimadores OLS (Ordinary Least Squares) para seus verdadeiros valores populacionais. Sob condi√ß√µes de regularidade, os estimadores OLS, representados por $b$, convergem em probabilidade para $\beta$, o vetor de par√¢metros verdadeiro. Formalmente, $\text{plim}(b) = \beta$.

II.  A estat√≠stica F √© constru√≠da com base nesses estimadores. A estat√≠stica do numerador,  $(Rb - r)'[s^2R(X'X)^{-1}R']^{-1}(Rb - r)$, pode ser reescrita como $(R(b-\beta))' [s^2 R(X'X)^{-1} R']^{-1} (R(b-\beta))$, sob a hip√≥tese nula $R\beta=r$.

III. O termo $R(b-\beta)$ converge para uma distribui√ß√£o normal multivariada com m√©dia zero. Isso √© uma consequ√™ncia do Teorema do Limite Central aplicado aos estimadores OLS.

IV.  A estat√≠stica do numerador √© ent√£o uma fun√ß√£o quadr√°tica de uma vari√°vel aleat√≥ria aproximadamente normal, que converge em distribui√ß√£o para uma vari√°vel Qui-quadrado com *m* graus de liberdade, $m$ sendo o n√∫mero de restri√ß√µes em $R$.

V. O termo no denominador, $RSS/(T-k)$, converge em probabilidade para $\sigma^2$. Isso implica que $s^2$ converge para $\sigma^2$.

VI.   A raz√£o entre as duas estat√≠sticas, ap√≥s dividir pelos seus respectivos graus de liberdade, resulta na estat√≠stica F. Como o numerador e denominador convergem para distribui√ß√µes qui-quadrado e para uma constante, respectivamente, a distribui√ß√£o da estat√≠stica F converge para uma distribui√ß√£o F com $m$ e $T-k$ graus de liberdade.

A converg√™ncia da estat√≠stica F para a distribui√ß√£o F com m e T-k graus de liberdade, no limite, implica que para amostras suficientemente grandes, podemos usar os resultados te√≥ricos sobre a distribui√ß√£o F como uma aproxima√ß√£o razo√°vel. ‚ñ†

### Conclus√£o

A estat√≠stica F √© uma ferramenta fundamental na an√°lise de modelos de regress√£o, permitindo testar hip√≥teses conjuntas sobre os par√¢metros. Sua constru√ß√£o atrav√©s da raz√£o de estat√≠sticas qui-quadrado, junto com sua rela√ß√£o com o teste *t* e sua aplica√ß√£o em diferentes condi√ß√µes, a torna indispens√°vel na modelagem e an√°lise de dados. A compreens√£o das propriedades e do uso da estat√≠stica F √© crucial para a tomada de decis√µes baseadas em infer√™ncias estat√≠sticas sobre modelos de regress√£o linear.

### Refer√™ncias
[^8.1.27]:  Apresenta a forma geral da hip√≥tese nula para testes conjuntos.
[^8.1.32]:  Deriva a estat√≠stica F a partir de distribui√ß√µes qui-quadrado e especifica sua distribui√ß√£o sob a hip√≥tese nula.
[^8.1.31]:  Apresenta a distribui√ß√£o da estat√≠stica associada √† hip√≥tese nula.
[^8.1.35]:  Define a soma dos quadrados dos res√≠duos do modelo irrestrito.
[^8.1.36]:  Define a soma dos quadrados dos res√≠duos do modelo restrito.
[^8.1.37]:  Apresenta a forma alternativa para calcular a estat√≠stica F usando as somas de quadrados dos res√≠duos.
[^8.1.33]:  Mostra a rela√ß√£o entre a estat√≠stica F e a estat√≠stica t para um √∫nico coeficiente.
<!-- END -->
