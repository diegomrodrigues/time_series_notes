## Teste de Wald para Restri√ß√µes N√£o Lineares em Modelos de Regress√£o Linear

### Introdu√ß√£o
Expandindo o conceito de testes assint√≥ticos explorados anteriormente, este cap√≠tulo aborda o teste de Wald para restri√ß√µes n√£o lineares em modelos de regress√£o linear. Em continuidade ao teste t assint√≥tico, que avalia hip√≥teses sobre par√¢metros individuais, o teste de Wald oferece uma abordagem mais geral para avaliar hip√≥teses complexas envolvendo m√∫ltiplas restri√ß√µes, e em particular, restri√ß√µes n√£o lineares. Este cap√≠tulo detalha como a estat√≠stica de Wald √© derivada, sua distribui√ß√£o assint√≥tica e sua aplica√ß√£o em diversos contextos de regress√£o linear, com especial aten√ß√£o √† situa√ß√µes onde as premissas cl√°ssicas n√£o s√£o satisfeitas [^8.2].

### Conceitos Fundamentais
O teste de Wald, diferentemente do teste t, n√£o se limita a testar restri√ß√µes lineares sobre os par√¢metros de um modelo de regress√£o linear. Ele permite avaliar hip√≥teses envolvendo restri√ß√µes n√£o lineares sobre esses par√¢metros, o que √© crucial em diversas aplica√ß√µes pr√°ticas onde as rela√ß√µes te√≥ricas entre par√¢metros s√£o complexas. O teste √© baseado na ideia de que, se a restri√ß√£o n√£o linear √© verdadeira, ent√£o a aproxima√ß√£o linear da restri√ß√£o em torno do valor verdadeiro dos par√¢metros deve ser pr√≥xima de zero.

Em termos formais, considere que se deseja testar a hip√≥tese nula $H_0: g(\beta) = 0$, onde $g: \mathbb{R}^k \to \mathbb{R}^m$ √© uma fun√ß√£o n√£o linear dos par√¢metros $\beta$, com $m$ representando o n√∫mero de restri√ß√µes impostas sobre os par√¢metros, e onde $k$ √© o n√∫mero de par√¢metros.

A ideia central do teste de Wald √© aproximar a fun√ß√£o n√£o linear $g(\beta)$ em torno do estimador OLS $\hat{\beta}$ usando uma expans√£o de Taylor de primeira ordem. A aproxima√ß√£o linear √© dada por:

$$ g(\beta) \approx g(\hat{\beta}) + \frac{\partial g(\hat{\beta})}{\partial \beta'} (\beta - \hat{\beta})$$

Sob a hip√≥tese nula $g(\beta) = 0$, e assumindo que o estimador $\hat{\beta}$ √© consistente para $\beta$, ent√£o $g(\hat{\beta})$ deve estar "pr√≥ximo" de zero em grandes amostras. A estat√≠stica de Wald mede qu√£o longe $g(\hat{\beta})$ est√° de zero, utilizando a vari√¢ncia assint√≥tica do estimador $b$, com uma corre√ß√£o para levar em conta a aproxima√ß√£o linear.

A estat√≠stica de teste de Wald √© definida como:

$$ W = [g(\hat{\beta})]' \left[ \frac{\partial g(\hat{\beta})}{\partial \beta'} \hat{V}(\hat{\beta}) \frac{\partial g(\hat{\beta})}{\partial \beta} \right]^{-1} [g(\hat{\beta})]$$

onde:
- $g(\hat{\beta})$ √© a fun√ß√£o n√£o linear avaliada no estimador OLS.
- $\frac{\partial g(\hat{\beta})}{\partial \beta'}$ √© a matriz Jacobiana das derivadas parciais de $g$ em rela√ß√£o a $\beta$, avaliada em $\hat{\beta}$.
- $\hat{V}(\hat{\beta})$ √© a matriz de covari√¢ncia assint√≥tica do estimador OLS $\hat{\beta}$, que pode ser estimada usando m√©todos robustos √† heterocedasticidade [^8.3].

> üí° **Exemplo Num√©rico:**
> Considere um modelo de regress√£o linear com dois par√¢metros, $\beta_1$ e $\beta_2$. Vamos testar a hip√≥tese nula de que esses par√¢metros s√£o iguais, $H_0: \beta_1 = \beta_2$, e seja o estimador OLS $\hat{\beta}$.
>
>  A restri√ß√£o n√£o linear √© ent√£o: $g(\beta) = \beta_1 - \beta_2 = 0$
>  O gradiente de g em rela√ß√£o a $\beta = [\beta_1, \beta_2]'$ √©:
> $$\frac{\partial g}{\partial \beta'} = [1, -1]$$
>  Suponha que os estimadores OLS sejam $\hat{\beta}_1=2$ e $\hat{\beta}_2=3$ e que a matriz de covari√¢ncia do estimador seja:
> $$V(\hat{\beta}) = \begin{bmatrix} 0.1 & 0.05 \\ 0.05 & 0.2 \end{bmatrix}$$
>  Aplicando a estat√≠stica de Wald:
> $$ W = [2-3] \begin{bmatrix} 1 & -1 \end{bmatrix} \begin{bmatrix} 0.1 & 0.05 \\ 0.05 & 0.2 \end{bmatrix} \begin{bmatrix} 1 \\ -1 \end{bmatrix}^{-1}  [2-3]$$
>  $$ W = [-1] [1,-1] \begin{bmatrix} 0.1 & 0.05 \\ 0.05 & 0.2 \end{bmatrix} \begin{bmatrix} 1 \\ -1 \end{bmatrix}^{-1} [-1]$$
> $$ W = [-1] [0.1 - 0.05, 0.05 - 0.2] \begin{bmatrix} 1 \\ -1 \end{bmatrix}^{-1} [-1]$$
> $$ W = [-1] [0.05, -0.15] \begin{bmatrix} 1 \\ -1 \end{bmatrix}^{-1} [-1]$$
>  $$ W = [-1] (0.05+0.15) ^{-1} [-1]$$
>  $$ W = [-1] (0.2)^{-1} [-1] $$
>  $$ W = [-1] 5 [-1] = 5 $$
> O valor 5 da estat√≠stica de Wald ser√° comparado com a distribui√ß√£o qui-quadrado com 1 grau de liberdade para inferir se a hip√≥tese nula deve ser rejeitada ou n√£o.
>
> üí° **Exemplo Num√©rico (Restri√ß√£o N√£o Linear):**
> Suponha agora que a hip√≥tese nula seja n√£o linear: $H_0: \beta_1^2 + \beta_2^2 = 5$. Nesse caso, $g(\beta) = \beta_1^2 + \beta_2^2 - 5$. Usando os mesmos estimadores OLS $\hat{\beta}_1 = 2$ e $\hat{\beta}_2 = 3$, temos $g(\hat{\beta}) = 2^2 + 3^2 - 5 = 4 + 9 - 5 = 8$.
>
> A matriz Jacobiana √©:
> $$\frac{\partial g}{\partial \beta'} = [2\beta_1, 2\beta_2] = [2*2, 2*3] = [4, 6]$$
>
> Usando a mesma matriz de covari√¢ncia $V(\hat{\beta})$ do exemplo anterior, a estat√≠stica de Wald √©:
>
>  $$ W = [8] \begin{bmatrix} 4 & 6 \end{bmatrix} \begin{bmatrix} 0.1 & 0.05 \\ 0.05 & 0.2 \end{bmatrix} \begin{bmatrix} 4 \\ 6 \end{bmatrix}^{-1} [8]$$
>
>  $$ W = [8] [0.4 + 0.3, 0.2 + 1.2] \begin{bmatrix} 4 \\ 6 \end{bmatrix}^{-1} [8]$$
>  $$ W = [8] [0.7, 1.4] \begin{bmatrix} 4 \\ 6 \end{bmatrix}^{-1} [8]$$
>  $$ W = [8] (0.7*4 + 1.4*6)^{-1} [8]$$
>  $$ W = [8] (2.8 + 8.4)^{-1} [8]$$
>  $$ W = [8] (11.2)^{-1} [8]$$
>  $$ W = [8] 0.089 [8] $$
>  $$ W = 64 * 0.089 \approx 5.7$$
>
> Novamente, comparamos 5.7 com a distribui√ß√£o qui-quadrado com 1 grau de liberdade para decidir se rejeitamos a hip√≥tese nula.

Sob certas condi√ß√µes de regularidade e sob a hip√≥tese nula, a estat√≠stica de Wald converge assintoticamente para uma distribui√ß√£o qui-quadrado com $m$ graus de liberdade [^8.2.23], onde $m$ √© o n√∫mero de restri√ß√µes impostas (ou seja, o n√∫mero de linhas da fun√ß√£o $g(\beta)$).

### Distribui√ß√£o Assint√≥tica da Estat√≠stica de Wald
A distribui√ß√£o assint√≥tica da estat√≠stica de Wald √© fundamental para a realiza√ß√£o de testes de hip√≥teses sobre restri√ß√µes n√£o lineares. A converg√™ncia da estat√≠stica de Wald para uma distribui√ß√£o qui-quadrado √© uma consequ√™ncia do teorema do limite central aplicado ao estimador OLS e a sua matriz de covari√¢ncia. Formalmente, sob as premissas apresentadas em [^8.2], e com as devidas adapta√ß√µes para o contexto de restri√ß√µes n√£o lineares, temos:

$$ W \xrightarrow{d} \chi^2(m) $$

onde "$\xrightarrow{d}$" denota converg√™ncia em distribui√ß√£o, e $\chi^2(m)$ representa a distribui√ß√£o qui-quadrado com $m$ graus de liberdade. Essa converg√™ncia √© v√°lida sob a hip√≥tese nula $H_0 : g(\beta)=0$. A converg√™ncia garante que podemos usar a distribui√ß√£o qui-quadrado para realizar infer√™ncias em grandes amostras.

**Lema 2**
A consist√™ncia da matriz de covari√¢ncia do estimador OLS, $\hat{V}(\hat{\beta})$, garante que o teste de Wald seja assintoticamente v√°lido sob heterocedasticidade e/ou autocorrela√ß√£o, desde que $\hat{V}(\hat{\beta})$ seja calculada usando erros padr√£o robustos, conforme discutido em [^8.2].

*Proof:*
Para provar o lema 2, precisamos demonstrar que a converg√™ncia em distribui√ß√£o da estat√≠stica de Wald para uma qui-quadrado ainda se mant√©m mesmo quando a matriz de covari√¢ncia √© estimada de forma consistente, mesmo sob heterocedasticidade e autocorrela√ß√£o.

I. A estat√≠stica de Wald √© definida como:
$W = [g(\hat{\beta})]' \left[ \frac{\partial g(\hat{\beta})}{\partial \beta'} \hat{V}(\hat{\beta}) \frac{\partial g(\hat{\beta})}{\partial \beta} \right]^{-1} [g(\hat{\beta})]$

II. Sabemos que, sob condi√ß√µes de regularidade e sob a hip√≥tese nula,
$\sqrt{T}(\hat{\beta} - \beta) \xrightarrow{d} N(0, \Sigma)$, onde $\Sigma$ √© a matriz de covari√¢ncia assint√≥tica de $\hat{\beta}$, e que o estimador OLS √© consistente,  $\hat{\beta} \xrightarrow{p} \beta$.

III. A fun√ß√£o $g$ √© diferenci√°vel, e usando a expans√£o de Taylor,
$\sqrt{T}[g(\hat{\beta}) - g(\beta)] \approx  \frac{\partial g(\beta)}{\partial \beta'} \sqrt{T}(\hat{\beta} - \beta)$

IV. Sob a hip√≥tese nula $g(\beta) = 0$:
$\sqrt{T}g(\hat{\beta})  \xrightarrow{d} N(0,  \frac{\partial g(\beta)}{\partial \beta'} \Sigma \frac{\partial g(\beta)}{\partial \beta}  ) $

V. Se $\hat{V}(\hat{\beta})$ √© um estimador consistente para  $ \frac{\Sigma}{T} $, ent√£o
 $T\hat{V}(\hat{\beta}) \xrightarrow{p} \Sigma$

VI. Substituindo em $W$, e sob a hip√≥tese nula:
$ W = [g(\hat{\beta})]' \left[ \frac{\partial g(\hat{\beta})}{\partial \beta'} \hat{V}(\hat{\beta}) \frac{\partial g(\hat{\beta})}{\partial \beta} \right]^{-1} [g(\hat{\beta})]$
 $ W \xrightarrow{d}  \chi^2(m) $

VII. Logo, mesmo que a matriz de covari√¢ncia seja estimada de forma consistente, e levando em considera√ß√£o heterocedasticidade e/ou autocorrela√ß√£o, a distribui√ß√£o assint√≥tica da estat√≠stica de Wald ainda √© qui-quadrado. ‚ñ†

Assim, a estat√≠stica de Wald √© uma ferramenta flex√≠vel e √∫til em modelos de regress√£o, permitindo que as hip√≥teses sejam testadas mesmo em situa√ß√µes onde os pressupostos cl√°ssicos de homocedasticidade e independ√™ncia n√£o s√£o v√°lidos, desde que as estimativas de vari√¢ncia-covari√¢ncia sejam calculadas corretamente.

**Proposi√ß√£o 3**
Sob as mesmas condi√ß√µes de regularidade do Lema 2, o teste de Wald tamb√©m √© v√°lido assintoticamente quando aplicado a modelos de regress√£o com vari√°veis instrumentais (IV), desde que a matriz de covari√¢ncia assint√≥tica do estimador IV seja utilizada no c√°lculo da estat√≠stica W.
*Proof:* A validade assint√≥tica do teste de Wald em modelos IV segue um racioc√≠nio an√°logo ao do Lema 2. A principal diferen√ßa reside no uso do estimador IV, $\hat{\beta}_{IV}$, e sua respectiva matriz de covari√¢ncia assint√≥tica, $\hat{V}(\hat{\beta}_{IV})$. O estimador IV tamb√©m possui uma distribui√ß√£o assint√≥tica normal, e, se consistente, converge em probabilidade para o verdadeiro valor de $\beta$. A estat√≠stica de Wald para o modelo IV √© definida como:

$$ W_{IV} = [g(\hat{\beta}_{IV})]' \left[ \frac{\partial g(\hat{\beta}_{IV})}{\partial \beta'} \hat{V}(\hat{\beta}_{IV}) \frac{\partial g(\hat{\beta}_{IV})}{\partial \beta} \right]^{-1} [g(\hat{\beta}_{IV})]$$

I. Sob a hip√≥tese nula $H_0: g(\beta) = 0$ e condi√ß√µes de regularidade, temos que
$$\sqrt{T}(\hat{\beta}_{IV} - \beta) \xrightarrow{d} N(0, \Sigma_{IV})$$
e que a matriz de covari√¢ncia do estimador $\hat{V}(\hat{\beta}_{IV})$ √© consistente para $\Sigma_{IV}/T$.

II. A expans√£o de Taylor da fun√ß√£o $g(\beta)$ em torno de $\hat{\beta}_{IV}$ √©:
$\sqrt{T}[g(\hat{\beta}_{IV}) - g(\beta)] \approx  \frac{\partial g(\beta)}{\partial \beta'} \sqrt{T}(\hat{\beta}_{IV} - \beta)$.

III. Substituindo na estat√≠stica de Wald, sob a hip√≥tese nula:
$$W_{IV} = [g(\hat{\beta}_{IV})]' \left[ \frac{\partial g(\hat{\beta}_{IV})}{\partial \beta'} \hat{V}(\hat{\beta}_{IV}) \frac{\partial g(\hat{\beta}_{IV})}{\partial \beta} \right]^{-1} [g(\hat{\beta}_{IV})]$$
$$W_{IV} \xrightarrow{d} \chi^2(m).$$

IV. Portanto, o teste de Wald, quando baseado no estimador IV e sua respectiva matriz de covari√¢ncia, mant√©m sua validade assint√≥tica em modelos de regress√£o com vari√°veis instrumentais. ‚ñ†

### Aplica√ß√£o em Testes de Hip√≥teses
Na pr√°tica, o teste de Wald √© usado para verificar se as restri√ß√µes n√£o lineares sobre os par√¢metros de um modelo de regress√£o s√£o suportadas pelos dados. Para realizar o teste, o pesquisador define a hip√≥tese nula $H_0: g(\beta) = 0$ e a hip√≥tese alternativa $H_1: g(\beta) \neq 0$. O teste consiste nos seguintes passos:
1.  Estimar os par√¢metros do modelo de regress√£o linear usando o m√©todo de OLS, obtendo $\hat{\beta}$ e a matriz de covari√¢ncia $\hat{V}(\hat{\beta})$.
2.  Calcular a fun√ß√£o de restri√ß√£o $g(\hat{\beta})$, a matriz Jacobiana $\frac{\partial g(\hat{\beta})}{\partial \beta'}$ e a estat√≠stica de Wald $W$.
3.  Comparar o valor da estat√≠stica de Wald com o valor cr√≠tico da distribui√ß√£o qui-quadrado com $m$ graus de liberdade, no n√≠vel de signific√¢ncia desejado $\alpha$.
4.  Rejeitar a hip√≥tese nula se o valor de $W$ for maior que o valor cr√≠tico, ou seja, se $W > \chi^2_{m, 1-\alpha}$.

> üí° **Exemplo Num√©rico:**
> Utilizando os dados do exemplo num√©rico anterior, vamos supor que o valor cr√≠tico para um teste com $\alpha = 0.05$ para a qui-quadrado com 1 grau de liberdade √© 3.84. Como o valor da estat√≠stica de Wald √© 5 (no primeiro exemplo) e 5.7 (no segundo exemplo), que s√£o maiores que o valor cr√≠tico 3.84, rejeitamos a hip√≥tese nula em ambos os casos a um n√≠vel de signific√¢ncia de 5%.

O teste de Wald permite verificar se o conjunto de restri√ß√µes n√£o lineares impostas sobre os par√¢metros do modelo s√£o estatisticamente suportadas pelos dados. Se a estat√≠stica de Wald for significativamente grande, significa que a hip√≥tese nula de que as restri√ß√µes s√£o v√°lidas deve ser rejeitada.

### Observa√ß√µes sobre o Teste de Wald
√â importante observar algumas peculiaridades do teste de Wald:
1. **Invari√¢ncia √† reparametriza√ß√£o:** O teste de Wald n√£o √© invariante √† reparametriza√ß√£o das restri√ß√µes n√£o lineares. Diferentes formas de expressar a mesma restri√ß√£o podem levar a resultados diferentes em amostras finitas.
2. **Sensibilidade √† amostra:** Em amostras pequenas, o teste de Wald pode n√£o ter um bom desempenho, e a aproxima√ß√£o pela distribui√ß√£o qui-quadrado pode ser inadequada.
3. **Erros padr√£o robustos:** A utiliza√ß√£o de erros padr√£o robustos, como os erros padr√£o de White, permite que o teste de Wald seja v√°lido mesmo quando a premissa de homocedasticidade n√£o √© satisfeita.
4. **Estimadores GLS:** Para modelos com heterocedasticidade ou autocorrela√ß√£o, o uso de estimadores GLS pode melhorar a efici√™ncia das estimativas, al√©m de permitir a utiliza√ß√£o da matriz de covari√¢ncia correta.

> üí° **Exemplo Num√©rico (Erros Padr√£o Robustos):**
> Suponha que, no primeiro exemplo, a matriz de covari√¢ncia seja estimada usando erros padr√£o robustos de White, e obtenhamos:
>
> $$V(\hat{\beta})_{robust} = \begin{bmatrix} 0.15 & 0.07 \\ 0.07 & 0.25 \end{bmatrix}$$
>
> A estat√≠stica de Wald recalculada seria:
> $$ W = [-1] \begin{bmatrix} 1 & -1 \end{bmatrix} \begin{bmatrix} 0.15 & 0.07 \\ 0.07 & 0.25 \end{bmatrix} \begin{bmatrix} 1 \\ -1 \end{bmatrix}^{-1} [-1]$$
> $$ W = [-1] [0.15-0.07, 0.07-0.25]  \begin{bmatrix} 1 \\ -1 \end{bmatrix}^{-1} [-1]$$
> $$ W = [-1] [0.08, -0.18]  \begin{bmatrix} 1 \\ -1 \end{bmatrix}^{-1} [-1]$$
> $$ W = [-1] (0.08+0.18)^{-1} [-1] =  [-1] (0.26)^{-1} [-1]$$
> $$ W =  0.0384 * [-1][-1] = 3.846  $$
>
>
> O valor da estat√≠stica de Wald √© agora 3.846. Se o valor cr√≠tico da distribui√ß√£o qui-quadrado com 1 grau de liberdade para $\alpha=0.05$ for 3.84, como neste exemplo, quase n√£o rejeitar√≠amos a hip√≥tese nula (p-valor=0.05).
> Isso demonstra como o uso de erros padr√£o robustos pode levar a infer√™ncias diferentes, especialmente quando h√° suspeita de heterocedasticidade.

Apesar das suas limita√ß√µes, o teste de Wald √© uma ferramenta fundamental para a an√°lise de restri√ß√µes n√£o lineares em modelos de regress√£o. Sua flexibilidade e capacidade de tratar diversos tipos de modelos fazem dele um instrumento indispens√°vel para a an√°lise econom√©trica moderna.

**Lema 4**
Em situa√ß√µes onde a fun√ß√£o $g(\beta)$ √© linear, o teste de Wald se reduz ao teste F tradicional para restri√ß√µes lineares, sob as condi√ß√µes cl√°ssicas do modelo de regress√£o linear.

*Proof:*
Se a fun√ß√£o $g(\beta)$ √© linear, podemos express√°-la como $g(\beta) = R\beta - r$, onde $R$ √© uma matriz de restri√ß√µes de dimens√£o $m \times k$ e $r$ √© um vetor de dimens√£o $m \times 1$. Assim, a hip√≥tese nula √© $H_0: R\beta = r$.
A matriz Jacobiana, neste caso, √© constante e igual a $R$. A estat√≠stica de Wald torna-se:
$$W = [R\hat{\beta} - r]' [R \hat{V}(\hat{\beta}) R']^{-1} [R\hat{\beta} - r]$$

I. Sob as premissas cl√°ssicas do modelo de regress√£o, a estat√≠stica $W$ multiplicada por $m$ e dividida por um fator que envolve a soma dos quadrados dos res√≠duos (SSR) e os graus de liberdade, torna-se exatamente a estat√≠stica F utilizada no teste de restri√ß√µes lineares.

II. √â um resultado conhecido que, sob as premissas cl√°ssicas,
$$ F = \frac{(SSR_r - SSR_{ur})/m}{SSR_{ur}/(T-k)} \sim F_{m,T-k}$$
Onde $SSR_r$ √© a soma de quadrados dos res√≠duos do modelo restrito e $SSR_{ur}$ √© a soma de quadrados dos res√≠duos do modelo irrestrito.

III. A estat√≠stica $W$ converge para uma $\chi^2(m)$, e se multiplicarmos $W$ por $m$ e dividirmos pelo seu valor esperado, obtemos a estat√≠stica F. Este resultado decorre do fato de que, sob as premissas cl√°ssicas do modelo de regress√£o linear, a distribui√ß√£o assint√≥tica da estat√≠stica de Wald e a estat√≠stica F para restri√ß√µes lineares s√£o, assintoticamente, equivalentes.

IV. Portanto, em casos de restri√ß√µes lineares, o teste de Wald √© um teste F generalizado, conforme demonstrado.‚ñ†

### Conclus√£o
O teste de Wald para restri√ß√µes n√£o lineares √© uma ferramenta poderosa para a an√°lise de modelos de regress√£o linear. Ao permitir a avalia√ß√£o de hip√≥teses complexas sobre os par√¢metros do modelo, ele oferece uma abordagem flex√≠vel e adapt√°vel a diversas situa√ß√µes pr√°ticas. A distribui√ß√£o assint√≥tica do teste de Wald, sob certas condi√ß√µes, garante a validade do teste mesmo em amostras grandes e em modelos que n√£o se encaixam nas premissas cl√°ssicas de regress√£o. A utiliza√ß√£o de erros padr√£o robustos, conforme discutido anteriormente, amplia ainda mais a aplicabilidade do teste de Wald. Ao combinar os testes assint√≥ticos discutidos neste e em cap√≠tulos anteriores, √© poss√≠vel realizar uma an√°lise econom√©trica completa e precisa, com a seguran√ßa de que os resultados s√£o robustos e confi√°veis mesmo na presen√ßa de modelos complexos e dados heterog√™neos.

### Refer√™ncias
[^8.1.26]:  Se√ß√£o 8.1, p√°gina 204: Apresenta√ß√£o da estat√≠stica t cl√°ssica para testes de hip√≥teses sobre os coeficientes de um modelo de regress√£o linear.
[^8.2]: Se√ß√£o 8.2: Explora√ß√£o de modelos de regress√£o linear sob condi√ß√µes mais gerais, incluindo erros n√£o Gaussianos e vari√°veis estoc√°sticas.
[^8.2.20]: Se√ß√£o 8.2, p√°gina 212: Defini√ß√£o da estat√≠stica do teste t em sua forma assint√≥tica.
[^8.2.23]: Se√ß√£o 8.2, p√°gina 213: Apresenta√ß√£o da distribui√ß√£o assint√≥tica do teste de Wald como uma qui-quadrado.
[^8.3]: Se√ß√£o 8.3: An√°lise de estimadores de m√≠nimos quadrados generalizados (GLS) quando a matriz de vari√¢ncia-covari√¢ncia dos erros n√£o √© escalar.
[^8.3.5]: Se√ß√£o 8.3, p√°gina 220: Apresenta√ß√£o do estimador de m√≠nimos quadrados generalizados (GLS).
[^8.3.20]: Se√ß√£o 8.3, p√°gina 225: Distribui√ß√£o assint√≥tica para a estima√ß√£o da autocorrela√ß√£o em res√≠duos de modelos de regress√£o.
[^8.3.19]: Se√ß√£o 8.3, p√°gina 225: Express√£o da estat√≠stica usada para a estima√ß√£o de autocorrela√ß√£o.
[^8.3.25]: Se√ß√£o 8.3, p√°gina 227:  Apresenta√ß√£o da fun√ß√£o de verossimilhan√ßa para erros com autocorrela√ß√£o.
<!-- END -->
