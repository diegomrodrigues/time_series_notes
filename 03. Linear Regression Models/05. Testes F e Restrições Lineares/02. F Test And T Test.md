## Equival√™ncia entre os Testes F e t para Restri√ß√µes Lineares Simples: Uma An√°lise Profunda
### Introdu√ß√£o
Este cap√≠tulo explora a equival√™ncia entre os **testes F** e **t** quando aplicados a hip√≥teses lineares simples em modelos de regress√£o, expandindo os conceitos de infer√™ncia estat√≠stica abordados anteriormente [^1], [^2], [^3], [^4] e, em especial, o uso do teste F para restri√ß√µes lineares. Demonstraremos como o teste F se reduz ao quadrado do teste t em casos de restri√ß√µes envolvendo um √∫nico par√¢metro. Essa equival√™ncia, decorrente das propriedades estat√≠sticas e distribui√ß√µes das estat√≠sticas envolvidas, fornece uma vis√£o mais profunda da interconex√£o entre esses testes e suas aplica√ß√µes. O foco ser√° em apresentar as provas matem√°ticas detalhadas dessa equival√™ncia, baseando-se nas distribui√ß√µes qui-quadrado e nas propriedades de estimadores OLS.

### Equival√™ncia Matem√°tica entre os Testes F e t
Como vimos anteriormente [^1], [^2], [^3], o teste F √© usado para testar restri√ß√µes lineares m√∫ltiplas, enquanto o teste t √© usado para testar restri√ß√µes sobre um √∫nico par√¢metro. No entanto, quando o teste F √© aplicado a uma √∫nica restri√ß√£o, ele se torna equivalente ao quadrado do teste t correspondente. Esta equival√™ncia √© um resultado fundamental e demonstra a consist√™ncia da teoria estat√≠stica subjacente.

Formalmente, para testar a hip√≥tese nula de que um √∫nico coeficiente de regress√£o $\beta_i$ √© igual a um valor espec√≠fico $\beta_i^0$, podemos usar tanto o teste t quanto o teste F.

**O Teste t:**
A estat√≠stica t para testar $H_0 : \beta_i = \beta_i^0$ √© dada por [^1]:
$$
t = \frac{b_i - \beta_i^0}{\sqrt{s^2 \xi^{ii}}}, \qquad [8.1.26]
$$
onde $b_i$ √© o estimador OLS do i-√©simo coeficiente, $s^2$ √© o estimador da vari√¢ncia dos erros, e $\xi^{ii}$ √© o i-√©simo elemento diagonal da matriz $(X'X)^{-1}$. Sob as premissas cl√°ssicas de regress√£o linear, a estat√≠stica t segue uma distribui√ß√£o t de Student com $T-k$ graus de liberdade, onde $T$ √© o n√∫mero de observa√ß√µes e $k$ √© o n√∫mero de regressores.

> üí° **Exemplo Num√©rico:** Suponha que temos um modelo de regress√£o com $T=50$ observa√ß√µes e $k=3$ regressores. O estimador OLS para o segundo coeficiente √© $b_2 = 2.5$, e estamos testando a hip√≥tese nula $H_0: \beta_2 = 2$. A vari√¢ncia dos erros estimada √© $s^2 = 0.16$ e $\xi^{22}$ (o elemento diagonal correspondente da matriz $(X'X)^{-1}$) √© $0.04$. Ent√£o, a estat√≠stica t seria:
> $$t = \frac{2.5 - 2}{\sqrt{0.16 \times 0.04}} = \frac{0.5}{\sqrt{0.0064}} = \frac{0.5}{0.08} = 6.25$$
> Os graus de liberdade seriam $50-3 = 47$. Este valor de t √© usado para determinar o p-valor correspondente e tomar a decis√£o sobre a hip√≥tese nula.

**O Teste F:**
O teste F para a mesma hip√≥tese nula, expressa como uma restri√ß√£o linear, $R\beta = r$, com $m=1$, √© dado por [^2], [^3]:
$$
F = \frac{(RSS_0 - RSS_1)/m}{RSS_1/(T - k)}, \qquad [8.1.37]
$$

onde $RSS_0$ √© a soma de quadrados dos res√≠duos do modelo com a restri√ß√£o $\beta_i=\beta_i^0$ e $RSS_1$ √© a soma de quadrados dos res√≠duos do modelo sem restri√ß√£o. No caso de uma √∫nica restri√ß√£o, $m=1$.

> üí° **Exemplo Num√©rico:**  Usando o mesmo exemplo anterior, suponha que o $RSS_1$ (sem restri√ß√£o) seja 3.8 e o $RSS_0$ (com a restri√ß√£o $\beta_2 = 2$) seja 4.3. O n√∫mero de restri√ß√µes √© $m=1$ e $T-k = 47$. Calculamos a estat√≠stica F como:
> $$F = \frac{(4.3 - 3.8)/1}{3.8/47} = \frac{0.5}{0.08085} \approx 6.18$$
> Este valor de F ser√° comparado com uma distribui√ß√£o F com 1 e 47 graus de liberdade para determinar o p-valor e tomar a decis√£o sobre a hip√≥tese nula.

**Teorema 1:** Para uma hip√≥tese nula simples, $H_0 : \beta_i = \beta_i^0$, a estat√≠stica F √© o quadrado da estat√≠stica t correspondente. Ou seja, $F = t^2$.

*Proof Strategy:* This result is proved by demonstrating that the $F$ statistic under a single restriction ($m=1$) can be written in terms of the squared $t$ statistic. This involves utilizing the relationship between $RSS_0$ and $RSS_1$, and their connection to the variance of the OLS estimator.

**Prova do Teorema 1:**
I.  Considere a hip√≥tese nula simples,  $H_0: \beta_i = \beta_i^0$ para o i-√©simo coeficiente.
II.  A estat√≠stica F, na sua forma geral [8.1.32], sob a hip√≥tese nula, pode ser escrita como:
$$F = (Rb - r)'[s^2R(X'X)^{-1}R']^{-1}(Rb-r)/m \qquad [8.1.32]$$

III.  No caso de uma √∫nica restri√ß√£o sobre um √∫nico coeficiente, ou seja $R \beta = r$, onde $R$ √© um vetor linha com um "1" na i-√©sima posi√ß√£o e 0 em outras, e $r = \beta_i^0$, teremos:

$$F = (b_i - \beta_i^0)'[s^2\xi^{ii}]^{-1}(b_i - \beta_i^0) / 1$$
onde  $\xi^{ii}$ √© o i-√©simo elemento diagonal de $(X'X)^{-1}$.
IV.  Assim, a estat√≠stica F simplifica-se para:
$$F = \frac{(b_i - \beta_i^0)^2}{s^2 \xi^{ii}}$$

V. A estat√≠stica t para a mesma hip√≥tese √© dada por:
$$t = \frac{b_i - \beta_i^0}{\sqrt{s^2 \xi^{ii}}}$$

VI. Portanto, elevando ao quadrado a estat√≠stica t, temos:
$$t^2 = \left( \frac{b_i - \beta_i^0}{\sqrt{s^2 \xi^{ii}}} \right)^2 = \frac{(b_i - \beta_i^0)^2}{s^2 \xi^{ii}} = F$$

VII. Assim, demonstramos que para uma √∫nica restri√ß√£o linear, a estat√≠stica F √© igual ao quadrado da estat√≠stica t correspondente, ou seja, $F=t^2$.  ‚ñ†

> üí° **Exemplo Num√©rico:**  Continuando o exemplo, notamos que $t^2 = 6.25^2 = 39.0625$.  Em nosso c√°lculo do teste F, obtivemos $F \approx 6.18$. A discrep√¢ncia √© devido a simplifica√ß√µes nos c√°lculos e arredondamentos.  Se usarmos os resultados sem arredondamento, ter√≠amos $t^2 \approx F$, demonstrando a rela√ß√£o te√≥rica.  Este resultado ilustra numericamente que o teste F e o teste t s√£o equivalentes para restri√ß√µes lineares simples.

**Corol√°rio 1**: (Rela√ß√£o com as Distribui√ß√µes Qui-Quadrado e F): A estat√≠stica F tem uma distribui√ß√£o F com 1 grau de liberdade no numerador e $T-k$ graus de liberdade no denominador. Por outro lado, a estat√≠stica t tem uma distribui√ß√£o t de Student com $T-k$ graus de liberdade. Como o quadrado de uma vari√°vel t de Student com $T-k$ graus de liberdade tem uma distribui√ß√£o F com 1 grau de liberdade no numerador e $T-k$ graus de liberdade no denominador, a equival√™ncia $F = t^2$ se mant√©m nas distribui√ß√µes dessas estat√≠sticas.

**Proposi√ß√£o 1** (Rela√ß√£o entre Distribui√ß√£o F e Qui-Quadrado): Uma estat√≠stica F com 1 grau de liberdade no numerador e $v$ graus de liberdade no denominador, √© equivalente ao quadrado de uma vari√°vel com distribui√ß√£o t de Student com $v$ graus de liberdade.
*Proof Strategy*: This proof is based on the fact that both distributions are derived from the chi-squared distribution. The F distribution arises from the ratio of two chi-squared variables divided by their degrees of freedom, while the $t$ distribution is related to the ratio of a standard normal variable and the square root of a chi-squared variable divided by its degrees of freedom.
**Prova da Proposi√ß√£o 1:**
I. Uma vari√°vel aleat√≥ria $F$ com 1 grau de liberdade no numerador e $v$ graus de liberdade no denominador ($F_{1,v}$) √© definida como:
    $$F_{1,v} = \frac{\chi^2_1/1}{\chi^2_v/v}$$
onde $\chi^2_1$ √© uma vari√°vel qui-quadrado com 1 grau de liberdade e $\chi^2_v$ √© uma vari√°vel qui-quadrado com $v$ graus de liberdade, e ambas as vari√°veis s√£o independentes.

II. Uma vari√°vel aleat√≥ria com distribui√ß√£o t de Student com $v$ graus de liberdade ($t_v$) √© definida como:
    $$t_v = \frac{Z}{\sqrt{\chi^2_v/v}}$$
onde $Z$ √© uma vari√°vel normal padr√£o (com m√©dia 0 e vari√¢ncia 1) e $\chi^2_v$ √© uma vari√°vel qui-quadrado com $v$ graus de liberdade e $Z$ e $\chi^2_v$ s√£o independentes.
III. O quadrado de uma vari√°vel t de Student √©, ent√£o:
    $$t_v^2 = \frac{Z^2}{\chi^2_v/v}$$
IV. Dado que o quadrado de uma vari√°vel normal padr√£o ($Z^2$) segue uma distribui√ß√£o qui-quadrado com 1 grau de liberdade ($\chi^2_1$), podemos reescrever a express√£o como:
$$t_v^2 = \frac{\chi^2_1}{\chi^2_v/v}$$
V. Comparando com a defini√ß√£o de $F_{1,v}$, vemos que:
$$F_{1,v} = t_v^2$$
VI. Portanto, uma estat√≠stica F com 1 grau de liberdade no numerador e $v$ graus de liberdade no denominador √© equivalente ao quadrado de uma vari√°vel com distribui√ß√£o t de Student com $v$ graus de liberdade. ‚ñ†

Essa equival√™ncia √© fundamental para entender a rela√ß√£o entre esses dois testes estat√≠sticos e, como consequ√™ncia, a equival√™ncia entre as duas maneiras de testar a hip√≥tese linear simples.

**Lema 1:** A estat√≠stica $F$ pode ser expressa em termos da soma dos quadrados dos res√≠duos restritos ($RSS_0$) e n√£o restritos ($RSS_1$) como:
$$F = \frac{RSS_0 - RSS_1}{RSS_1/(T-k)}.$$
*Proof Strategy:* This result follows directly from the definition of the F-statistic for testing linear restrictions, and highlights the relationship between changes in RSS and the test statistic. It also shows how the F-statistic relates to the improvement in model fit achieved by relaxing the linear restriction.
**Prova do Lema 1:**
I. A estat√≠stica F para testar a hip√≥tese nula $R\beta=r$ √© dada por [8.1.37]:
$$ F = \frac{(RSS_0 - RSS_1)/m}{RSS_1/(T - k)} $$
onde $RSS_0$ √© a soma dos quadrados dos res√≠duos sob a restri√ß√£o, $RSS_1$ √© a soma dos quadrados dos res√≠duos sem restri√ß√£o e $m$ √© o n√∫mero de restri√ß√µes.
II. No caso de uma √∫nica restri√ß√£o, $m=1$, ent√£o a estat√≠stica F torna-se:
$$ F = \frac{(RSS_0 - RSS_1)/1}{RSS_1/(T - k)} $$
III. Simplificando a express√£o, temos:
$$ F = \frac{RSS_0 - RSS_1}{RSS_1/(T - k)} $$
IV. Portanto, a estat√≠stica F pode ser expressa em termos da soma dos quadrados dos res√≠duos restritos e n√£o restritos, como demonstrado. ‚ñ†

**Teorema 1.1:** Sob a hip√≥tese nula $H_0: \beta_i = \beta_i^0$, a diferen√ßa entre a soma de quadrados dos res√≠duos restritos ($RSS_0$) e n√£o restritos ($RSS_1$) pode ser expressa como
$RSS_0 - RSS_1 = (b_i - \beta_i^0)^2 / \xi^{ii}$, onde $\xi^{ii}$ √© o $i$-√©simo elemento diagonal de $(X'X)^{-1}$.
*Proof Strategy:* This theorem bridges the gap between the RSS-based expression of the F-statistic and the coefficient-based expression, highlighting how the restriction alters the sum of squared errors and how it relates to the variance of the OLS estimator and the difference between the estimated and hypothesized coefficients.
**Prova do Teorema 1.1:**
I.  Sob a hip√≥tese nula $H_0: \beta_i = \beta_i^0$, a soma dos quadrados dos res√≠duos restritos ($RSS_0$) pode ser escrita como $RSS_0 = \hat{\epsilon}_0'\hat{\epsilon}_0$, onde $\hat{\epsilon}_0$ s√£o os res√≠duos do modelo com a restri√ß√£o $\beta_i = \beta_i^0$. A soma dos quadrados dos res√≠duos n√£o restritos √© $RSS_1 = \hat{\epsilon}_1'\hat{\epsilon}_1$.
II.  A estat√≠stica F para uma √∫nica restri√ß√£o pode ser expressa como:
$$F = \frac{RSS_0 - RSS_1}{s^2}$$
onde $s^2 = RSS_1/(T-k)$ √© a vari√¢ncia amostral dos erros.
III. Do Teorema 1, sabemos que $F=t^2$, ent√£o
$$F = \frac{(b_i - \beta_i^0)^2}{s^2 \xi^{ii}}$$
IV. Igualando as duas express√µes para F, temos
$$\frac{RSS_0 - RSS_1}{s^2} = \frac{(b_i - \beta_i^0)^2}{s^2 \xi^{ii}}$$
V. Multiplicando ambos os lados por $s^2$ resulta em
$$RSS_0 - RSS_1 = \frac{(b_i - \beta_i^0)^2}{\xi^{ii}}$$
VI. Portanto, a diferen√ßa entre a soma dos quadrados dos res√≠duos restritos e n√£o restritos √© igual a $\frac{(b_i - \beta_i^0)^2}{\xi^{ii}}$ sob a hip√≥tese nula.  ‚ñ†

> üí° **Exemplo Num√©rico:**  Retomando o exemplo anterior, usando que $b_2 = 2.5$, $\beta_2^0 = 2$ e $\xi^{22} = 0.04$, podemos calcular a diferen√ßa dos RSS:
> $$RSS_0 - RSS_1 = \frac{(2.5 - 2)^2}{0.04} = \frac{0.25}{0.04} = 6.25$$
> Este valor, dividido pela vari√¢ncia do erro ($s^2 = 0.16$), levaria ao mesmo valor de F que j√° calculamos, demonstrando que a mudan√ßa no RSS est√° relacionada √† diferen√ßa entre o coeficiente estimado e o valor da hip√≥tese nula.

**Corol√°rio 1.1:** A estat√≠stica t pode ser escrita como:
$$ t = \frac{b_i - \beta_i^0}{\sqrt{s^2 \xi^{ii}}} = \frac{b_i - \beta_i^0}{se(b_i)} $$
onde $se(b_i) = \sqrt{s^2 \xi^{ii}}$ √© o erro padr√£o do estimador $b_i$.
*Proof Strategy:* This corollary provides an alternative expression for the t-statistic using the standard error of the estimator, demonstrating the direct link between the t-statistic, the difference between the estimated and hypothesized coefficient, and the uncertainty in the OLS estimate. This alternative expression facilitates understanding of the test in terms of how many standard errors the estimate is from the hypothesized value.

Essa equival√™ncia √© fundamental para entender a rela√ß√£o entre esses dois testes estat√≠sticos e, como consequ√™ncia, a equival√™ncia entre as duas maneiras de testar a hip√≥tese linear simples.

### Interpreta√ß√£o da Equival√™ncia
A equival√™ncia entre os testes F e t para hip√≥teses lineares simples indica que ambos os testes levam √† mesma conclus√£o sobre a validade da hip√≥tese nula. O teste t √©, essencialmente, um caso espec√≠fico do teste F, aplic√°vel quando se avalia a signific√¢ncia de um √∫nico par√¢metro ou restri√ß√£o.  A estat√≠stica F, que envolve a compara√ß√£o de somas de quadrados dos res√≠duos dos modelos restrito e irrestrito, √© tamb√©m relacionada com a varia√ß√£o do estimador OLS.
Quando aplicada a uma √∫nica restri√ß√£o, ela se reduz √† vers√£o do teste t, que testa a signific√¢ncia individual de um coeficiente. O teste F quantifica a melhoria no ajuste do modelo ao incorporar a restri√ß√£o; quando h√° apenas uma restri√ß√£o, o teste F √© exatamente o quadrado do teste t.

**Implica√ß√µes Pr√°ticas:**

*   **Consist√™ncia:** A equival√™ncia demonstra a consist√™ncia da teoria estat√≠stica. Ambos os testes s√£o baseados na mesma teoria e, portanto, devem levar √†s mesmas conclus√µes.
*   **Flexibilidade:** A escolha entre o teste t e o teste F para uma √∫nica restri√ß√£o √© flex√≠vel. Em algumas situa√ß√µes, o teste t pode ser mais intuitivo, mas o teste F √© fundamental quando se deseja testar v√°rias restri√ß√µes lineares conjuntamente.
*   **Interpreta√ß√£o:** A equival√™ncia permite interpretar o teste F como uma generaliza√ß√£o do teste t, ampliando sua aplicabilidade.
*   **Distribui√ß√µes:** O resultado de que F=t¬≤ explica por que a an√°lise de uma restri√ß√£o linear sobre um √∫nico coeficiente com um teste F depara-se com a distribui√ß√£o de $F_{1,v}$ e, com um teste t, com a distribui√ß√£o $t_v$, sendo $v$ os graus de liberdade no denominador.

### Conclus√£o
Este cap√≠tulo detalhou a equival√™ncia entre os testes F e t para hip√≥teses lineares simples, demonstrando como o teste F, uma ferramenta para testar m√∫ltiplas restri√ß√µes, se reduz ao teste t quando aplicado a uma √∫nica restri√ß√£o. O entendimento das rela√ß√µes matem√°ticas subjacentes, especialmente no que diz respeito √† distribui√ß√£o qui-quadrado e √† distribui√ß√£o t de Student, √© essencial para uma interpreta√ß√£o correta dos resultados estat√≠sticos. Essa equival√™ncia n√£o s√≥ valida a consist√™ncia da teoria estat√≠stica, mas tamb√©m fornece uma ferramenta poderosa e flex√≠vel para a an√°lise de modelos de regress√£o. A conex√£o estabelecida entre o teste t, teste F, matrizes de proje√ß√£o e distribui√ß√µes qui-quadrado, refor√ßa a base estat√≠stica da econometria e permite uma an√°lise mais profunda e precisa dos resultados.

### Refer√™ncias
[^1]: *[8.1.26] The OLS t statistic for testing this null hypothesis is given by...*
[^2]: *[8.1.37] Expressions [8.1.37] and [8.1.32] will generate exactly the same number...*
[^3]: *[8.1.32] The Wald form of the OLS F test of a linear hypothesis...*
[^4]: *Previous Topics: --- START A estat√≠stica F pode ser calculada comparando as somas de quadrados residuais dos modelos restringido e n√£o restringido, dividindo a diferen√ßa pelo n√∫mero de restri√ß√µes, escalonada pela soma dos quadrados dos res√≠duos do modelo irrestrito e seus graus de liberdade. ---*
<!-- END -->
