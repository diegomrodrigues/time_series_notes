## Infer√™ncia Assint√≥tica para um Processo Autorregressivo em Torno de uma Tend√™ncia de Tempo Determin√≠stica: Uma An√°lise Detalhada

### Introdu√ß√£o
Este cap√≠tulo aprofunda a infer√™ncia assint√≥tica em modelos autorregressivos (AR) com tend√™ncia temporal determin√≠stica, explorando a transforma√ß√£o de regressores proposta por Sims, Stock e Watson [^1]. Como vimos anteriormente [^2], essa transforma√ß√£o separa componentes com diferentes taxas de converg√™ncia, o que √© crucial para a an√°lise da distribui√ß√£o assint√≥tica dos estimadores de M√≠nimos Quadrados Ordin√°rios (OLS). O foco aqui √© detalhar a aplica√ß√£o desses conceitos e fornecer uma base s√≥lida para testes de hip√≥teses e infer√™ncias estat√≠sticas em modelos de s√©ries temporais com tend√™ncias e componentes autorregressivos.

### Conceitos Fundamentais
Retomando o modelo autorregressivo geral com tend√™ncia temporal determin√≠stica [16.3.1], temos:
$$ y_t = \alpha + \delta t + \phi_1 y_{t-1} + \phi_2 y_{t-2} + \ldots + \phi_p y_{t-p} + \epsilon_t $$
onde $\epsilon_t$ √© um ru√≠do branco i.i.d. com m√©dia zero, vari√¢ncia $\sigma^2$ e quarto momento finito. As ra√≠zes da equa√ß√£o caracter√≠stica $1 - \phi_1 z - \phi_2 z^2 - \ldots - \phi_p z^p = 0$ est√£o fora do c√≠rculo unit√°rio [^1].

A transforma√ß√£o chave √© a reescrita do modelo [16.3.2]:
$$ y_t = \alpha(1 + \phi_1 + \phi_2 + \ldots + \phi_p) + \delta(1 + \phi_1 + 2\phi_2 + \ldots + p\phi_p) + \delta(\phi_1 + 2\phi_2 + \ldots + p\phi_p) + \phi_1[y_{t-1} - \alpha - \delta(t-1)] + \phi_2[y_{t-2} - \alpha - \delta(t-2)] + \ldots + \phi_p[y_{t-p} - \alpha - \delta(t-p)] + \epsilon_t $$
que leva ao modelo transformado [16.3.3]:
$$ y_t = \alpha^* + \delta^* t + \phi_1^* y_{t-1}^* + \phi_2^* y_{t-2}^* + \ldots + \phi_p^* y_{t-p}^* + \epsilon_t $$
onde $\alpha^*$, $\delta^*$ e $y_{t-j}^*$ s√£o definidos como:
$$ \alpha^* = \alpha(1 + \phi_1 + \phi_2 + \ldots + \phi_p) - \delta(\phi_1 + 2\phi_2 + \ldots + p\phi_p) $$
$$ \delta^* = \delta(1 + \phi_1 + \phi_2 + \ldots + \phi_p) $$
e
$$ y_{t-j}^* = y_{t-j} - \alpha - \delta(t-j), \quad j = 1, 2, \ldots, p $$
Essa transforma√ß√£o isola os componentes com diferentes taxas de converg√™ncia: os termos $y_{t-j}^*$ s√£o vari√°veis estacion√°rias de m√©dia zero, enquanto os termos constante e de tend√™ncia temporal convergem em taxas distintas. Esta separa√ß√£o √© essencial para facilitar a an√°lise assint√≥tica, como observado anteriormente [^2].

> üí° **Exemplo Num√©rico:** Considere um modelo AR(1) com tend√™ncia linear: $y_t = \alpha + \delta t + \phi y_{t-1} + \epsilon_t$. Suponha que os par√¢metros verdadeiros sejam $\alpha = 2$, $\delta = 0.5$ e $\phi = 0.8$. Ent√£o, a transforma√ß√£o resulta em:
> $$ y_t = \alpha(1+\phi) + \delta(1+\phi)t - \delta\phi + \phi[y_{t-1} - \alpha - \delta(t-1)] + \epsilon_t$$
> $$ y_t = \alpha^* + \delta^* t + \phi y_{t-1}^* + \epsilon_t$$
> Onde:
> $$\alpha^* = 2(1+0.8) - 0.5(0.8) = 3.6 - 0.4 = 3.2$$
> $$\delta^* = 0.5(1+0.8) = 0.9$$
> $$ y_{t-1}^* = y_{t-1} - 2 - 0.5(t-1)$$
> Assim, o modelo transformado ser√°:
> $$ y_t = 3.2 + 0.9t + 0.8y_{t-1}^* + \epsilon_t $$
> Este exemplo ilustra como a transforma√ß√£o separa a parte estacion√°ria ($y_{t-1}^*$) da tend√™ncia determin√≠stica.
O modelo original [16.3.5]:
$$ y_t = x_t'\beta + \epsilon_t $$
√© transformado em [16.3.7]:
$$ y_t = x_t G' (G')^{-1} \beta + \epsilon_t = [x_t^*]' \beta^* + \epsilon_t $$
onde $x_t^* = G x_t$ e $\beta^* = (G')^{-1} \beta$. A matriz $G'$ √© definida como [16.3.8]:
$$ G' = \begin{bmatrix}
1 & 0 & 0 & \ldots & 0 & 0 & 0 \\
0 & 1 & 0 & \ldots & 0 & 0 & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots & \vdots & \vdots \\
0 & 0 & 0 & \ldots & 1 & 0 & 0 \\
-\alpha + \delta & -\alpha + 2\delta & \ldots & -\alpha + p\delta & 1 & 0 \\
-\delta & -\delta & \ldots & -\delta & 0 & 1
\end{bmatrix} $$
A matriz $G'$ √© crucial para expressar os regressores originais em termos de vari√°veis estacion√°rias, uma constante e uma tend√™ncia temporal [^2].

O estimador OLS para $\beta^*$ √© dado por [16.3.11]:
$$ b^* = [ \sum_{t=1}^T x_t^* x_t^{*'} ]^{-1} \sum_{t=1}^T x_t^* y_t = (G')^{-1} b $$
onde $b$ √© o estimador OLS para o modelo original.

### Distribui√ß√£o Assint√≥tica dos Estimadores OLS Transformados
A distribui√ß√£o assint√≥tica de $b^*$ √© dada pelo teorema [16.3.13]:
$$ Y_T(b^* - \beta^*) \xrightarrow{d} N(0, \sigma^2 [Q^*]^{-1}) $$
onde $Y_T$ √© a matriz de escalonamento [16.3.14]:
$$
Y_T = \begin{bmatrix}
\sqrt{T} & 0 & 0 & \cdots & 0 & 0 \\
0 & \sqrt{T} & 0 & \cdots & 0 & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
0 & 0 & 0 & \cdots & \sqrt{T} & 0 \\
0 & 0 & 0 & \cdots & 0 & \sqrt{T} \\
0 & 0 & 0 & \cdots & 0 & T^{3/2}
\end{bmatrix}
$$
e $Q^*$ √© a matriz de vari√¢ncia assint√≥tica dos regressores transformados [16.3.15]:
$$
Q^* = \begin{bmatrix}
\gamma_{0}^* & \gamma_{1}^* & \gamma_{2}^* & \cdots & \gamma_{p-1}^* & 0 & 0 \\
\gamma_{1}^* & \gamma_{0}^* & \gamma_{1}^* & \cdots & \gamma_{p-2}^* & 0 & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots & \vdots & \vdots \\
\gamma_{p-1}^* & \gamma_{p-2}^* & \gamma_{p-3}^* & \cdots & \gamma_{0}^* & 0 & 0 \\
0 & 0 & 0 & \cdots & 0 & 1 & 0 \\
0 & 0 & 0 & \cdots & 0 & 0 & 1/3
\end{bmatrix}
$$
Aqui, $\gamma_{j}^* = E(y_t^* y_{t-j}^*)$ s√£o as autocovari√¢ncias da vari√°vel estacion√°ria $y_t^*$. A matriz $Y_T$ reflete as diferentes taxas de converg√™ncia: $\sqrt{T}$ para os coeficientes das vari√°veis estacion√°rias e $T^{3/2}$ para o coeficiente da tend√™ncia temporal [^1].

> üí° **Exemplo Num√©rico:** Considere novamente o modelo AR(1) com tend√™ncia. Suponha que as autocovari√¢ncias de $y_t^*$ sejam $\gamma_0^* = 1.5$ e que a vari√¢ncia do erro seja $\sigma^2=0.8$. A matriz $Q^*$ e sua inversa s√£o:
>
>$$ Q^* = \begin{bmatrix} 1.5 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1/3 \end{bmatrix} \quad \text{e} \quad [Q^*]^{-1} = \begin{bmatrix} 2/3 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 3 \end{bmatrix} $$
>
>A matriz de escalonamento $Y_T$ √©:
>
>$$Y_T = \begin{bmatrix} \sqrt{T} & 0 & 0 \\ 0 & \sqrt{T} & 0 \\ 0 & 0 & T^{3/2} \end{bmatrix} $$
>
>A distribui√ß√£o assint√≥tica dos estimadores transformados, ap√≥s o devido escalonamento, √©:
>$$Y_T(b^* - \beta^*) \xrightarrow{d} N(0, 0.8 [Q^*]^{-1}) = N(0, \begin{bmatrix} 16/30 & 0 & 0 \\ 0 & 0.8 & 0 \\ 0 & 0 & 2.4 \end{bmatrix}) $$
>
>Isso significa que a vari√¢ncia do estimador de $\phi$ √© $\frac{16}{30T}$, do intercepto $\frac{0.8}{T}$, e da tend√™ncia $\frac{2.4}{T^3}$. Observe que a vari√¢ncia do estimador da tend√™ncia decresce mais rapidamente do que as demais.

A prova deste resultado √© baseada na an√°lise do comportamento assint√≥tico dos regressores transformados e no Teorema do Limite Central. O Ap√™ndice 16.A fornece uma demonstra√ß√£o detalhada, mostrando que a matriz $Q^*$ √© o limite da esperan√ßa da matriz de regressores, e que os estimadores dos par√¢metros do modelo transformado convergem para uma distribui√ß√£o normal com m√©dia centrada no valor verdadeiro e vari√¢ncia dada por $\sigma^2 [Q^*]^{-1}$ ap√≥s a devida escalonagem.

**Lema 2.1 (Positividade da matriz Q\*)**
A matriz $Q^*$ definida em [16.3.15] √© positiva definida sob as condi√ß√µes estabelecidas, garantindo que a matriz de covari√¢ncia assint√≥tica dos estimadores seja bem definida e positiva definida.
*Proof:*
I. A matriz $Q^*$ √© composta pelas autocovari√¢ncias do processo estacion√°rio $y_t^*$ e elementos diagonais correspondentes ao intercepto e √† tend√™ncia.
II. A submatriz contendo as autocovari√¢ncias de $y_t^*$ √© positiva definida porque √© a matriz de covari√¢ncia de um processo estacion√°rio, desde que o processo n√£o seja determin√≠stico.
III. Os elementos diagonais correspondentes ao intercepto e √† tend√™ncia tamb√©m s√£o estritamente positivos (1 e 1/3, respectivamente).
IV. Uma vez que $Q^*$ √© uma matriz bloco-diagonal com blocos positivos definidos, ela pr√≥pria √© positiva definida.
‚ñ†

**Lema 2.2 (Inversibilidade de Q\*)**
Sob as mesmas condi√ß√µes do Lema 2.1, a matriz $Q^*$ √© tamb√©m invert√≠vel, o que permite o c√°lculo da matriz de covari√¢ncia assint√≥tica dos estimadores.
*Proof:*
I. Pelo Lema 2.1, a matriz $Q^*$ √© positiva definida.
II. Uma matriz positiva definida √© sempre invert√≠vel.
III. Portanto, a matriz $Q^*$ √© invert√≠vel.
‚ñ†
Este resultado garante que a vari√¢ncia assint√≥tica dos estimadores, dada por $\sigma^2 [Q^*]^{-1}$, est√° bem definida.

### Distribui√ß√£o Assint√≥tica dos Estimadores OLS do Modelo Original
Para obter a distribui√ß√£o assint√≥tica dos estimadores do modelo original, $b$, aplicamos a rela√ß√£o $b = G' b^*$ [16.3.12], resultando em:
$$ Y_T(b-\beta) = Y_T G' (b^* - \beta^*) \xrightarrow{d} N(0, \sigma^2 G' [Q^*]^{-1} G'^{'}) $$
onde $\beta$ √© o vetor de coeficientes do modelo original.

As distribui√ß√µes assint√≥ticas dos estimadores de $\alpha$ e $\delta$ s√£o dadas por [16.3.17]:
$$ \sqrt{T}(\hat{\alpha} - \alpha) \xrightarrow{d} N(0, \sigma^2 g_{\alpha} [Q^*]^{-1} g_{\alpha}^{'}) $$
$$ T^{3/2}(\hat{\delta} - \delta) \xrightarrow{d} N(0, \sigma^2 g_{\delta} [Q^*]^{-1} g_{\delta}^{'}) $$
onde $g_{\alpha}$ e $g_{\delta}$ s√£o vetores de pesos que isolam os componentes $\alpha$ e $\delta$ no vetor $b$, respectivamente.

> üí° **Exemplo Num√©rico (continua√ß√£o):**
> Retomando o exemplo anterior do modelo AR(1) com tend√™ncia, temos $g_{\alpha} = [-\alpha + \delta, 1, 0] = [-2 + 0.5, 1, 0] = [-1.5, 1, 0]$ e $g_{\delta} = [-\delta, 0, 1] = [-0.5, 0, 1]$.  Utilizando $\sigma^2=0.8$ e $[Q^*]^{-1}$ como calculado anteriormente, temos:
>
>$\text{Var}(\sqrt{T}(\hat{\alpha}-\alpha)) = 0.8 \times g_{\alpha} [Q^*]^{-1} g_{\alpha}' =  0.8 \times ([-1.5, 1, 0] \begin{bmatrix} 2/3 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 3 \end{bmatrix} [-1.5, 1, 0]^T) = 0.8 \times (\frac{2}{3} \times 2.25 + 1) = 0.8 \times (1.5 + 1) = 2$
>
>$\text{Var}(T^{3/2}(\hat{\delta}-\delta)) = 0.8 \times g_{\delta} [Q^*]^{-1} g_{\delta}' = 0.8 \times ([-0.5, 0, 1] \begin{bmatrix} 2/3 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 3 \end{bmatrix} [-0.5, 0, 1]^T) = 0.8 \times (\frac{2}{3} \times 0.25 + 3) = 0.8 \times (\frac{1}{6} + 3) = 2.466...$
>
>Assim, $\sqrt{T}(\hat{\alpha}-\alpha)$ converge para uma normal com m√©dia 0 e vari√¢ncia 2, e $T^{3/2}(\hat{\delta}-\delta)$ converge para uma normal com m√©dia 0 e vari√¢ncia 2.466.... Note que as vari√¢ncias dos estimadores escalonados indicam a velocidade com que a incerteza diminui com o tamanho da amostra.

**Teorema 3 (Independ√™ncia Assint√≥tica)**
Os estimadores dos par√¢metros estacion√°rios, que convergem a uma taxa $\sqrt{T}$, s√£o assintoticamente independentes do estimador do par√¢metro da tend√™ncia, que converge a uma taxa $T^{3/2}$ [^1].
*Proof:*
I. De [16.3.16] e [16.3.17], o estimador da tend√™ncia temporal $\delta_T$ √© dado por
$$ \delta_T = g_{\delta} b^* = g_{\delta} (Y_T^{-1} Y_T  b^*)  \approx g_{\delta} Y_T^{-1} N( \beta^*,  \sigma^2 Q^{*-1})  $$
II. Da mesma forma, o estimador do intercepto $\alpha_T$ √© dado por
$$ \alpha_T = g_{\alpha} b^* = g_{\alpha} (Y_T^{-1} Y_T  b^*)  \approx g_{\alpha} Y_T^{-1} N( \beta^*,  \sigma^2 Q^{*-1})  $$
III. A matriz $Q^*$ de [16.3.15] tem uma estrutura bloco diagonal. O bloco superior cont√©m as covari√¢ncias dos componentes AR estacion√°rios, e o bloco inferior cont√©m as vari√¢ncias da constante e da tend√™ncia. Esta estrutura implica que a covari√¢ncia entre os erros que multiplicam os componentes AR estacion√°rios e os erros que multiplicam a constante e a tend√™ncia √© zero.
IV. Assim, as distribui√ß√µes limite dos estimadores s√£o assintoticamente independentes, o que implica que os pr√≥prios estimadores tamb√©m s√£o assintoticamente independentes.
‚ñ†

**Corol√°rio 3.1 (Independ√™ncia Assint√≥tica dos Par√¢metros AR)**
Sob as mesmas condi√ß√µes do Teorema 3, os estimadores dos par√¢metros autorregressivos ($\phi_1, \phi_2, \dots, \phi_p$) s√£o assintoticamente independentes entre si e assintoticamente independentes dos estimadores do intercepto e da tend√™ncia [^1].
*Proof:*
I. A estrutura bloco diagonal de $Q^*$ implica que a covari√¢ncia assint√≥tica entre os estimadores de coeficientes AR distintos √© zero.
II. A estrutura da matriz $Y_T$ introduz fatores de escala que garantem uma distribui√ß√£o assint√≥tica bem definida.
III. Esta diagonalidade de bloco, conforme mostrado na prova do Teorema 3, resulta em independ√™ncia assint√≥tica.
IV. Portanto, os estimadores dos par√¢metros AR, intercepto e tend√™ncia s√£o todos assintoticamente independentes.
‚ñ†
Este corol√°rio √© uma consequ√™ncia direta da estrutura bloco diagonal da matriz $Q^*$. Fornece simplifica√ß√µes cruciais para a infer√™ncia estat√≠stica, permitindo a an√°lise separada dos par√¢metros autorregressivos individuais.

**Proposi√ß√£o 3.2 (Converg√™ncia em Probabilidade)**
Al√©m da converg√™ncia em distribui√ß√£o, os estimadores OLS transformados $b^*$ convergem em probabilidade para seus valores verdadeiros $\beta^*$. Ou seja, $b^* \xrightarrow{p} \beta^*$.
*Proof:*
I. Pelo teorema [16.3.13], temos que $Y_T(b^* - \beta^*) \xrightarrow{d} N(0, \sigma^2 [Q^*]^{-1})$.
II. A converg√™ncia em distribui√ß√£o para uma constante (neste caso, 0) implica converg√™ncia em probabilidade para essa constante. Ou seja, $Y_T(b^* - \beta^*) \xrightarrow{p} 0$.
III. Multiplicando ambos os lados por $Y_T^{-1}$, temos que $b^* - \beta^* \xrightarrow{p} 0$, o que implica que $b^* \xrightarrow{p} \beta^*$.
‚ñ†
Esta proposi√ß√£o √© um resultado importante, pois garante que os estimadores convergem para seus verdadeiros valores √† medida que o tamanho da amostra aumenta.

### Implica√ß√µes para Testes de Hip√≥teses
A independ√™ncia assint√≥tica e as taxas de converg√™ncia diferentes implicam que testes de hip√≥teses podem ser conduzidos de forma mais eficiente. Por exemplo, a hip√≥tese de que um dado par√¢metro autorregressivo √© igual a um valor espec√≠fico pode ser testada sem considerar a presen√ßa da tend√™ncia temporal, dada a independ√™ncia assint√≥tica.

> üí° **Exemplo Num√©rico:** Vamos supor que desejamos testar a hip√≥tese nula $H_0: \phi = 0.8$ contra a alternativa $H_1: \phi \neq 0.8$ em um modelo AR(1) com tend√™ncia.  Usando a distribui√ß√£o assint√≥tica de $\hat{\phi}$ e a independ√™ncia assint√≥tica, podemos construir um teste estat√≠stico utilizando:
> $$ \frac{\hat{\phi} - 0.8}{\sqrt{\frac{\sigma^2 \gamma_0^*}{T}}} \xrightarrow{d} N(0,1) $$
>
>Suponha que, para uma amostra de tamanho $T=100$, tenhamos $\hat{\phi} = 0.85$, $\sigma^2=0.8$ e $\gamma_0^*=1.5$. O valor da estat√≠stica de teste seria:
>
>$$z = \frac{0.85 - 0.8}{\sqrt{\frac{0.8 \times 1.5}{100}}} = \frac{0.05}{0.1095} \approx 0.456$$
>
>Para um n√≠vel de signific√¢ncia de 5%, o valor cr√≠tico de um teste bicaudal seria cerca de 1.96. Como $|0.456| < 1.96$, n√£o rejeitamos a hip√≥tese nula de que $\phi=0.8$. Este exemplo mostra como a independ√™ncia assint√≥tica nos permite realizar testes sobre par√¢metros AR sem se preocupar com a tend√™ncia.

A transforma√ß√£o dos regressores proposta por Sims, Stock e Watson [^1] √© um instrumento poderoso para a an√°lise assint√≥tica de modelos AR com tend√™ncia temporal determin√≠stica, permitindo a separa√ß√£o de componentes com diferentes taxas de converg√™ncia e a obten√ß√£o de resultados precisos para a distribui√ß√£o dos estimadores. A independ√™ncia assint√≥tica dos estimadores, demonstrada pelos resultados do Teorema 3 e Corol√°rio 3.1, simplifica a an√°lise estat√≠stica e permite a realiza√ß√£o de testes de hip√≥teses de forma mais eficaz e direta, como ser√° discutido nas se√ß√µes seguintes deste texto.

### Conclus√£o

Este cap√≠tulo aprofundou a an√°lise da infer√™ncia assint√≥tica para processos autorregressivos com tend√™ncia temporal determin√≠stica. A transforma√ß√£o de regressores, o uso da matriz de escalonamento $Y_T$ e a estrutura bloco diagonal da matriz $Q^*$ foram fundamentais para a obten√ß√£o das distribui√ß√µes assint√≥ticas dos estimadores OLS. A independ√™ncia assint√≥tica dos estimadores de par√¢metros estacion√°rios e de par√¢metros de tend√™ncia permite testes de hip√≥teses mais diretos e eficientes. O uso da transforma√ß√£o, portanto, fornece um framework robusto para an√°lise de modelos de s√©ries temporais com tend√™ncia e componentes autorregressivos, o qual ser√° √∫til no estudo de modelos com ra√≠zes unit√°rias.

### Refer√™ncias
[^1]: Sims, Christopher A., James H. Stock, and Mark W. Watson. 1990. "Inference in Linear Time Series Models with Some Unit Roots." *Econometrica* 58:113‚Äì44.
[^2]: Se√ß√£o 16.3 do texto original.
<!-- END -->
