## Asymptotic Inference for an Autoregressive Process Around a Deterministic Time Trend: Hypothesis Testing

### Introdu√ß√£o

Dando continuidade √† an√°lise de modelos autorregressivos em torno de tend√™ncias de tempo determin√≠sticas, e tendo explorado em detalhe as propriedades assint√≥ticas dos estimadores OLS ap√≥s a aplica√ß√£o da transforma√ß√£o de Sims, Stock e Watson (1990), este cap√≠tulo se concentra na constru√ß√£o e an√°lise de testes de hip√≥teses. Como vimos nas se√ß√µes anteriores, a transforma√ß√£o dos regressores simplifica a an√°lise das distribui√ß√µes limites e das taxas de converg√™ncia, mas a infer√™ncia estat√≠stica requer a capacidade de testar hip√≥teses sobre os par√¢metros de interesse, tanto nos modelos transformados quanto nos originais. Para atingir este objetivo, esta se√ß√£o detalha como usar as propriedades assint√≥ticas j√° estabelecidas para desenvolver testes de hip√≥teses v√°lidos. Abordaremos especificamente como as transforma√ß√µes lineares da matriz dos regressores afetam a constru√ß√£o dos testes e como as distribui√ß√µes assint√≥ticas derivadas para os par√¢metros transformados podem ser usadas para inferir as propriedades assint√≥ticas dos par√¢metros originais.

### Conceitos Fundamentais

Como vimos nos cap√≠tulos anteriores, o modelo autorregressivo com tend√™ncia de tempo determin√≠stica pode ser escrito como:
$$
y_t = \alpha + \delta t + \phi_1 y_{t-1} + \phi_2 y_{t-2} + \dots + \phi_p y_{t-p} + \epsilon_t
$$
[^1]. Ap√≥s a transforma√ß√£o dos regressores, o modelo √© reescrito como:
$$
y_t = \alpha^* + \delta^* t + \phi_1^* y_{t-1}^* + \phi_2^* y_{t-2}^* + \dots + \phi_p^* y_{t-p}^* + \epsilon_t
$$
onde $\alpha^*$, $\delta^*$, $\phi_j^*$ e $y_{t-j}^*$ s√£o os par√¢metros e vari√°veis transformados [^1]. As distribui√ß√µes assint√≥ticas dos estimadores $\hat{\alpha}^*$, $\hat{\delta}^*$ e $\hat{\phi_j^*}$ s√£o mais simples de analisar, com $\hat{\phi_j^*}$ convergindo √† taxa $\sqrt{T}$ e $\hat{\delta}^*$ convergindo √† taxa $T^{3/2}$, e seus estimadores s√£o assintoticamente independentes [^2]. No entanto, em muitas situa√ß√µes, o interesse reside em testar hip√≥teses sobre os par√¢metros originais $\alpha$, $\delta$ e $\phi_j$. Para tal, necessitamos de uma ponte entre as distribui√ß√µes dos estimadores transformados e dos estimadores originais.

> üí° **Revis√£o R√°pida:**
>
> Relembrando as transforma√ß√µes de vari√°veis, a matriz $G'$ conecta os par√¢metros transformados com os par√¢metros originais, tal que $\beta = G' \beta^*$, onde $\beta$ √© o vetor com os par√¢metros originais e $\beta^*$ √© o vetor com os par√¢metros transformados. O estimador OLS dos par√¢metros originais, $b$, est√° relacionado com o estimador transformado, $b^*$, pela rela√ß√£o $b = G' b^*$. A matriz $G'$ e a sua inversa s√£o dadas por:
>
> $$
> G' =
> \begin{bmatrix}
> 1 & 0 & \dots & 0 & 0 & 0 \\
> 0 & 1 & \dots & 0 & 0 & 0 \\
> \vdots & \vdots & \ddots & \vdots & \vdots & \vdots \\
> 0 & 0 & \dots & 1 & 0 & 0 \\
> - \alpha + \delta & - \alpha + 2\delta & \dots & - \alpha + p\delta & 1 & 0 \\
> - \delta & - \delta & \dots & - \delta & 0 & 1
> \end{bmatrix}
> $$
>
> $$
> [G']^{-1} =
> \begin{bmatrix}
> 1 & 0 & \dots & 0 & 0 & 0 \\
> 0 & 1 & \dots & 0 & 0 & 0 \\
> \vdots & \vdots & \ddots & \vdots & \vdots & \vdots \\
> 0 & 0 & \dots & 1 & 0 & 0 \\
> \alpha - \delta & \alpha - 2\delta & \dots & \alpha - p\delta & 1 & 0 \\
> \delta & \delta & \dots & \delta & 0 & 1
> \end{bmatrix}
> $$

A principal ideia √© que, embora a transforma√ß√£o torne a distribui√ß√£o assint√≥tica dos estimadores mais simples, a matriz de transforma√ß√£o $G'$ nos permite realizar infer√™ncia sobre os par√¢metros originais. As propriedades assint√≥ticas derivadas para o estimador transformado $b^*$, combinadas com a matriz de transforma√ß√£o $G'$, nos permitem recuperar as propriedades assint√≥ticas do estimador original $b$ e realizar testes de hip√≥teses v√°lidos.

> üí° **Exemplo Num√©rico:**
>
>  Considerando um modelo AR(1) com tend√™ncia, os par√¢metros originais s√£o $\beta = [\phi_1, \alpha, \delta]'$, e os par√¢metros transformados s√£o $\beta^* = [\phi_1^*, \alpha^*, \delta^*]'$. Os estimadores OLS associados s√£o $b = [\hat{\phi_1}, \hat{\alpha}, \hat{\delta}]'$ e $b^* = [\hat{\phi_1^*}, \hat{\alpha^*}, \hat{\delta^*}]'$, respectivamente.
>  A rela√ß√£o entre esses estimadores √© dada por $b = G' b^*$, ou seja:
>  $$
> \begin{bmatrix}
> \hat{\phi_1} \\
> \hat{\alpha} \\
> \hat{\delta}
> \end{bmatrix} =
> \begin{bmatrix}
> 1 & 0 & 0 \\
> - \alpha + \delta & 1 & 0 \\
> - \delta & 0 & 1
> \end{bmatrix}
> \begin{bmatrix}
> \hat{\phi_1^*} \\
> \hat{\alpha^*} \\
> \hat{\delta^*}
> \end{bmatrix}
> $$
>  Essa rela√ß√£o expressa como os estimadores originais podem ser recuperados a partir dos estimadores transformados. Observe que os elementos da matriz $G'$ dependem dos valores dos par√¢metros originais.  Em uma situa√ß√£o pr√°tica, esses par√¢metros s√£o substitu√≠dos por estimativas. Em nosso contexto, como a matriz $G'$ n√£o depende do tamanho amostral $T$, a substitui√ß√£o por estimativas consistentes n√£o afeta as propriedades assint√≥ticas.
>
> Suponha que tenhamos as seguintes estimativas obtidas ap√≥s aplicar a transforma√ß√£o: $\hat{\phi_1^*} = 0.75$, $\hat{\alpha^*} = 1.8$, e $\hat{\delta^*} = 0.4$ e estimativas consistentes para $\hat{\alpha} = 2$ e $\hat{\delta} = 0.5$. Ent√£o a matriz $G'$ √© estimada como:
> $$
> \hat{G}' =
> \begin{bmatrix}
> 1 & 0 & 0 \\
> -2 + 0.5 & 1 & 0 \\
> -0.5 & 0 & 1
> \end{bmatrix}
> =
> \begin{bmatrix}
> 1 & 0 & 0 \\
> -1.5 & 1 & 0 \\
> -0.5 & 0 & 1
> \end{bmatrix}
> $$
> Com isso, os estimadores originais s√£o recuperados da seguinte forma:
> $$
> b = \hat{G}' b^* =
> \begin{bmatrix}
> 1 & 0 & 0 \\
> -1.5 & 1 & 0 \\
> -0.5 & 0 & 1
> \end{bmatrix}
> \begin{bmatrix}
> 0.75 \\
> 1.8 \\
> 0.4
> \end{bmatrix}
> =
> \begin{bmatrix}
> 0.75 \\
> -1.5 * 0.75 + 1.8 \\
> -0.5 * 0.75 + 0.4
> \end{bmatrix}
> =
> \begin{bmatrix}
> 0.75 \\
> 0.675 \\
> 0.025
> \end{bmatrix}
> $$
>  Logo,  $\hat{\phi_1} = 0.75$,  $\hat{\alpha} = 0.675$ e $\hat{\delta} = 0.025$. Observe que os estimadores transformados podem ser utilizados para obter os estimadores originais.

Para construir testes de hip√≥teses, recorremos √† forma geral da hip√≥tese nula:
$$
H_0: R\beta = r
$$
onde $R$ √© uma matriz de restri√ß√µes (de dimens√£o $m \times (p+2)$), $r$ √© um vetor de constantes (de dimens√£o $m \times 1$), e $m$ √© o n√∫mero de restri√ß√µes.  O teste Wald para essa hip√≥tese pode ser expresso como:
$$
\chi^2 = (Rb - r)' [s^2 R(X'X)^{-1} R']^{-1} (Rb - r)
$$
onde $s^2$ √© o estimador da vari√¢ncia do erro. O objetivo agora √© mostrar como a transforma√ß√£o dos regressores nos permite analisar a distribui√ß√£o assint√≥tica desta estat√≠stica de teste.

**Teorema 3.1**
A estat√≠stica de teste Wald para a hip√≥tese nula $H_0: R\beta = r$ pode ser reescrita em termos dos par√¢metros e regressores transformados, e a estat√≠stica assim constru√≠da converge assintoticamente para uma distribui√ß√£o Qui-Quadrado com $m$ graus de liberdade, onde $m$ √© o n√∫mero de restri√ß√µes.

*Prova:*
I. O teste Wald para a hip√≥tese nula $H_0: R\beta = r$ √© dado por
$$
\chi^2 = (Rb - r)' [s^2 R(X'X)^{-1} R']^{-1} (Rb - r)
$$
II. Substituindo $b = G'b^*$ e $\beta = G'\beta^*$, temos que $Rb = RG'b^*$ e $R\beta = RG'\beta^*$.
III. Definindo $R^* = RG'$, podemos reescrever a hip√≥tese nula como $R^*\beta^* = r$, e o teste Wald torna-se:
$$
\chi^2 = (R^*b^* - r)' [s^2 R^*(X^{*'}X^*)^{-1} R^{*'}]^{-1} (R^*b^* - r)
$$
IV.  A distribui√ß√£o assint√≥tica da estat√≠stica de teste baseia-se na distribui√ß√£o assint√≥tica de $b^*$, j√° estabelecida no cap√≠tulo anterior, e no lema de Slutsky.  Usando o Teorema 2.1, $Y_T(b^*-\beta^*) \xrightarrow{d} N(0, \sigma^2 [Q^*]^{-1})$ e usando o lema de Slutsky, obtemos que a estat√≠stica acima converge em distribui√ß√£o para uma Qui-Quadrado com $m$ graus de liberdade:
$$
\chi^2 \xrightarrow{d} \chi^2(m)
$$
‚ñ†

> üí° **Exemplo Num√©rico:**
>
>  Considerando um modelo AR(1) com tend√™ncia linear e a hip√≥tese nula $H_0 : \delta = 0$, podemos expressar essa restri√ß√£o matricialmente usando: $R = [0, 0, 1]$ e $r = 0$. O teste de hip√≥tese ser√° realizado atrav√©s da seguinte estat√≠stica:
>  $$
> \chi^2 = (\hat{\delta} - 0)' [s^2 [0, 0, 1](X'X)^{-1} [0, 0, 1]']^{-1} (\hat{\delta} - 0)
> $$
>  Usando as propriedades assint√≥ticas, e a rela√ß√£o $b=G'b^*$, podemos reescrever o teste como:
> $$
> \chi^2 = (\hat{\delta}^* (1+\hat{\phi_1}) - 0)' [s^2[0, 0, 1] (X^{*'}X^*)^{-1} [0, 0, 1]']^{-1} (\hat{\delta}^* (1+\hat{\phi_1}) - 0)
> $$
>  A estat√≠stica de teste, ao ser avaliada numericamente, produzir√° o mesmo resultado tanto utilizando o modelo transformado quanto o original, como podemos verificar a seguir:
>
>   Vamos supor que os dados tenham sido estimados e as seguintes estimativas tenham sido obtidas:  $\hat{\phi_1} = 0.70$, $\hat{\alpha} = 2.1$, $\hat{\delta} = 0.03$, $s^2 = 1.2$  e a matriz $(X'X)^{-1}$ √©:
>
> $$
> (X'X)^{-1} =
> \begin{bmatrix}
>  0.02 & -0.01 & 0.001 \\
>  -0.01 & 0.02 & -0.005\\
>  0.001 & -0.005 & 0.001
> \end{bmatrix}
> $$
>
>  O teste da hip√≥tese nula $H_0 : \delta = 0$ √© dado por:
>  $$
>  \chi^2 = (0.03)' [1.2  [0, 0, 1]  \begin{bmatrix}
>  0.02 & -0.01 & 0.001 \\
>  -0.01 & 0.02 & -0.005\\
>  0.001 & -0.005 & 0.001
> \end{bmatrix}  [0, 0, 1]']^{-1} (0.03) = (0.03)'  [1.2 (0.001)]^{-1} (0.03) \approx 7.5
>  $$
>  Sob a hip√≥tese nula, a estat√≠stica de teste converge para uma distribui√ß√£o Qui-Quadrado com 1 grau de liberdade.
>
>   Usando o modelo transformado, obtemos as estimativas  $\hat{\phi_1^*} = 0.70$, $\hat{\alpha^*} = 2.1 - 0.03 = 2.07$ e $\hat{\delta^*} = 0.03/(1+0.70) = 0.0176$
>
>   Calculando a matriz $(X^{*'}X^*)^{-1}$, obtemos:
>  $$
> (X^{*'}X^*)^{-1} =
> \begin{bmatrix}
>  0.02 & -0.01 & 0 \\
>  -0.01 & 0.02 & 0\\
>  0 & 0 & 0.0005
> \end{bmatrix}
> $$
>
>   A estat√≠stica de teste √© agora calculada usando o estimador transformado:
>  $$
>  \chi^2 =  (0.0176 \times (1+0.7))'[1.2 [0, 0, 1]  \begin{bmatrix}
>  0.02 & -0.01 & 0 \\
>  -0.01 & 0.02 & 0\\
>  0 & 0 & 0.0005
> \end{bmatrix}  [0, 0, 1]']^{-1} (0.0176 \times (1+0.7)) \approx 7.5
>  $$
>  Como esperado, o valor da estat√≠stica de teste obtido com o modelo transformado √© id√™ntico ao valor obtido com o modelo original.  Portanto, o teste de hip√≥teses permanece v√°lido mesmo quando aplicado ap√≥s as transforma√ß√µes. Este exemplo ilustra como a transforma√ß√£o dos regressores preserva as propriedades assint√≥ticas do teste.

**Observa√ß√£o 1**
Este teorema assegura que os testes de hip√≥teses constru√≠dos usando as propriedades assint√≥ticas dos estimadores transformados s√£o assintoticamente v√°lidos. Al√©m disso, a estat√≠stica de teste √© numericamente id√™ntica tanto no modelo original quanto no transformado, mesmo que as distribui√ß√µes assint√≥ticas dos estimadores sejam mais f√°ceis de analisar ap√≥s a transforma√ß√£o.

**Lema 3.1**
Em modelos que envolvem par√¢metros com diferentes taxas de converg√™ncia (como os modelos com tend√™ncia de tempo), os testes de hip√≥teses s√£o dominados assintoticamente pelos par√¢metros com as taxas de converg√™ncia mais lentas. Em outras palavras, quando uma hip√≥tese nula envolve par√¢metros que convergem para seus valores verdadeiros em diferentes taxas, o resultado do teste ser√° mais sens√≠vel ao par√¢metro que converge mais lentamente.

*Prova:*
I.  Considere uma hip√≥tese que envolve par√¢metros que convergem √† taxa $\sqrt{T}$ e outro √† taxa $T^{3/2}$.  A estat√≠stica de teste envolve os desvios desses par√¢metros de seus valores sob a hip√≥tese nula, escalonados por suas vari√¢ncias estimadas.
II. Como o par√¢metro que converge √† taxa $T^{3/2}$ se aproxima do seu valor verdadeiro muito mais rapidamente do que aquele que converge √† taxa $\sqrt{T}$, a sua contribui√ß√£o na estat√≠stica de teste se torna assintoticamente desprez√≠vel, pois o termo que envolve o erro da estimativa de $T^{3/2}$ converge para zero mais rapidamente.
III. Portanto, a estat√≠stica de teste acaba sendo dominada pelo par√¢metro que converge mais lentamente, e o resultado do teste √© essencialmente o mesmo que seria obtido se o par√¢metro que converge mais rapidamente fosse conhecido.
‚ñ†

> üí° **Exemplo Num√©rico:**
>
> Considere um teste de hip√≥tese que envolva tanto o par√¢metro da tend√™ncia $\delta$ quanto o par√¢metro autorregressivo $\phi_1$. Pelo lema 3.1, o teste ser√° dominado pelo par√¢metro que converge mais lentamente, que √©  $\phi_1$. Isto ocorre porque  $\delta$ converge muito mais rapidamente para o seu valor verdadeiro do que $\phi_1$,  a sua varia√ß√£o assint√≥tica √© menor e, portanto, a sua contribui√ß√£o para o teste ser√° muito menor no limite.
>
> Vamos supor que estejamos testando a hip√≥tese nula $H_0: \phi_1 = 0$ e $\delta = 0$, onde o par√¢metro $\phi_1$ √© um par√¢metro autorregressivo do modelo AR(1) com tend√™ncia e o par√¢metro $\delta$ √© o coeficiente associado √† tend√™ncia linear. Como o estimador de  $\delta$ converge mais r√°pido, o teste ser√° essencialmente o mesmo que seria obtido se $\delta$ fosse conhecido. Em outras palavras, o teste ser√° dominado pela incerteza na estimativa de  $\phi_1$, e ser√° quase id√™ntico ao teste que apenas avalia a hip√≥tese nula  $H_0: \phi_1 = 0$. A informa√ß√£o adicional sobre a tend√™ncia $\delta$ praticamente n√£o afeta a infer√™ncia sobre $\phi_1$.
>
> Esse resultado se mostra √∫til em aplica√ß√µes pr√°ticas porque simplifica a constru√ß√£o dos testes, pois em muitos casos n√£o √© necess√°rio levar em conta todas as diferentes taxas de converg√™ncia explicitamente.

**Observa√ß√£o 2**
O lema 3.1 √© fundamental para simplificar a an√°lise de testes de hip√≥teses em modelos com diferentes taxas de converg√™ncia. Ele nos diz que, para fins de infer√™ncia, os testes s√£o essencialmente determinados pelos par√¢metros que convergem mais lentamente, e, portanto, em modelos com componentes estacion√°rios e n√£o-estacion√°rios, as infer√™ncias assint√≥ticas podem ser simplificadas.

**Corol√°rio 3.1**
O teste usual de OLS para uma restri√ß√£o linear sobre os par√¢metros, tanto no modelo original quanto no transformado, ser√° assintoticamente v√°lido mesmo na presen√ßa de diferentes taxas de converg√™ncia. Isto implica que os testes padr√£o, como o teste t e o teste F, podem ser usados mesmo em modelos com tend√™ncia de tempo determin√≠stica, desde que se usem os erros padr√£o apropriados, e que a estat√≠stica de teste seja constru√≠da usando a forma geral da hip√≥tese $H_0: R\beta = r$.

*Prova:*
I.  A validade assint√≥tica do teste OLS segue da aplica√ß√£o do Teorema 3.1, que demonstra que a estat√≠stica de teste converge para uma distribui√ß√£o Qui-Quadrado sob a hip√≥tese nula.
II.  As diferentes taxas de converg√™ncia s√£o automaticamente acomodadas pelas transforma√ß√µes que relacionam os par√¢metros originais aos par√¢metros transformados.
III.  O lema 3.1 refor√ßa a ideia de que os testes de hip√≥teses s√£o dominados assintoticamente pelos par√¢metros que convergem mais lentamente, garantindo assim a validade do teste mesmo em modelos com diferentes taxas de converg√™ncia.
IV.  A escolha da matriz de transforma√ß√£o $G$ n√£o afeta a validade assint√≥tica do teste de hip√≥teses, apenas a precis√£o dos estimadores.
‚ñ†

> üí° **Exemplo Num√©rico:**
>
>  Vamos considerar o mesmo exemplo do teste  $H_0: \delta = 0$ em um modelo AR(1) com tend√™ncia linear. O Corol√°rio 3.1 afirma que podemos usar o teste t padr√£o (ou F) para avaliar esta hip√≥tese nula e que o teste ser√° v√°lido assintoticamente, tanto no modelo original quanto no transformado.
>
>  Suponha que, ap√≥s a estima√ß√£o, obtivemos o estimador OLS para $\delta$ como sendo  $\hat{\delta} = 0.03$, e um erro padr√£o estimado de  $0.01$, usando a estimativa da matriz de vari√¢ncia-covari√¢ncia assint√≥tica, $\hat{V}$. O teste t para a hip√≥tese $H_0: \delta = 0$ √© dado por:
> $$
> t = \frac{\hat{\delta}}{se(\hat{\delta})} = \frac{0.03}{0.01} = 3
> $$
>  Sob a hip√≥tese nula, esta estat√≠stica convergir√° para uma distribui√ß√£o normal padr√£o. Se usarmos um n√≠vel de signific√¢ncia de 5%, podemos rejeitar a hip√≥tese nula se o valor absoluto da estat√≠stica t for maior do que 1.96. No nosso caso, como $3 > 1.96$, rejeitamos a hip√≥tese nula que o coeficiente da tend√™ncia linear √© zero, e conclu√≠mos que h√° evid√™ncia de uma tend√™ncia na s√©rie.
>
>  √â importante notar que este resultado se mant√©m mesmo que as distribui√ß√µes dos estimadores originais e transformados sejam diferentes. A transforma√ß√£o apenas nos permite obter a matriz de covari√¢ncia assint√≥tica dos estimadores. No entanto, o corol√°rio 3.1 nos garante que o teste t usual, constru√≠do usando as estimativas obtidas no modelo original, √© v√°lido assintoticamente.

**Observa√ß√£o 3**
Os resultados obtidos neste cap√≠tulo refor√ßam a ideia de que, embora a transforma√ß√£o dos regressores simplifique a an√°lise das distribui√ß√µes assint√≥ticas e taxas de converg√™ncia, as propriedades assint√≥ticas dos testes de hip√≥teses usuais s√£o preservadas. Em particular, o corol√°rio 3.1 demonstra que os testes padr√£o, como o teste t, s√£o assintoticamente v√°lidos em modelos com tend√™ncias determin√≠sticas, o que justifica o uso de ferramentas inferenciais padr√£o mesmo quando estamos trabalhando com dados n√£o estacion√°rios.

**Teorema 3.2**
Sob condi√ß√µes de regularidade, o teste da raz√£o de verossimilhan√ßa (LR) para a hip√≥tese nula $H_0 : R\beta = r$ converge assintoticamente para uma distribui√ß√£o Qui-Quadrado com $m$ graus de liberdade, onde $m$ √© o n√∫mero de restri√ß√µes, e a estat√≠stica do teste LR √© assintoticamente equivalente √† estat√≠stica do teste Wald.

*Prova:*
I.  O teste LR √© definido como a diferen√ßa entre o valor m√°ximo da fun√ß√£o de log-verossimilhan√ßa sob a hip√≥tese nula e o valor m√°ximo sem restri√ß√µes, multiplicado por -2.
II.  Sob condi√ß√µes de regularidade e usando a expans√£o de Taylor, pode-se mostrar que a estat√≠stica LR √© assintoticamente equivalente √† estat√≠stica de teste de Wald. Isto significa que a diferen√ßa entre as duas estat√≠sticas converge para zero quando o tamanho amostral aumenta.
III. Uma vez que a estat√≠stica do teste de Wald converge para uma distribui√ß√£o Qui-Quadrado com m graus de liberdade, a estat√≠stica do teste LR tamb√©m converge para a mesma distribui√ß√£o.
IV.   Essa equival√™ncia assint√≥tica garante que tanto o teste LR como o teste Wald podem ser usados em testes de hip√≥teses sobre os par√¢metros do modelo.
‚ñ†

**Lema 3.2**
Se a hip√≥tese nula envolver apenas os par√¢metros que convergem √† taxa $\sqrt{T}$, a estat√≠stica de teste, seja ela Wald ou LR, ser√° assintoticamente id√™ntica √† estat√≠stica obtida se o par√¢metro que converge mais rapidamente (√† taxa $T^{3/2}$) fosse conhecido.

*Prova:*
I. Este lema estende o Lema 3.1, mostrando que se a restri√ß√£o de hip√≥tese envolver apenas par√¢metros que convergem √† taxa $\sqrt{T}$, o par√¢metro que converge mais r√°pido, como a tend√™ncia, n√£o afeta assintoticamente a distribui√ß√£o do teste.
II.  A estat√≠stica do teste envolve o desvio dos estimadores em rela√ß√£o aos valores nulos, escalonado pelas suas vari√¢ncias estimadas. Como os estimadores de $\delta$ convergem muito mais r√°pido, a sua vari√¢ncia ser√° desprez√≠vel no limite, relativamente √† vari√¢ncia dos par√¢metros que convergem mais lentamente.
III. Assim, o teste se comporta assintoticamente como se o par√¢metro que converge rapidamente fosse conhecido, simplificando a an√°lise do teste.
‚ñ†

> üí° **Exemplo Num√©rico:**
>
> Suponha que estamos testando a hip√≥tese nula $H_0: \phi_1 = 0$ em um modelo AR(1) com tend√™ncia linear. Pelo Lema 3.2, a estat√≠stica do teste de hip√≥tese ser√° assintoticamente a mesma que seria obtida se o par√¢metro da tend√™ncia linear, $\delta$, fosse conhecido. Isso ocorre porque o estimador de $\delta$ converge muito mais rapidamente do que o estimador de $\phi_1$. Portanto, a incerteza sobre $\delta$ se torna desprez√≠vel no limite e n√£o afeta o resultado do teste sobre $\phi_1$.
>  Assim, a estat√≠stica de teste para $H_0: \phi_1 = 0$ pode ser constru√≠da considerando $\delta$ como conhecido, simplificando a infer√™ncia.  Este resultado √© importante porque demonstra que podemos focar em realizar infer√™ncias sobre os par√¢metros de interesse sem nos preocuparmos com as diferentes taxas de converg√™ncia.

**Corol√°rio 3.2**
Em modelos com componentes n√£o estacion√°rios, mas nos quais se aplica a transforma√ß√£o de Sims, Stock e Watson (1990), as conclus√µes obtidas sobre os par√¢metros que convergem √† taxa $\sqrt{T}$ ser√£o assintoticamente id√™nticas √†s que seriam obtidas em um modelo sem tend√™ncia, desde que se utilize o estimador transformado e a transforma√ß√£o seja feita corretamente.

*Prova:*
I.  A transforma√ß√£o de Sims, Stock e Watson (1990) remove a tend√™ncia determin√≠stica, resultando em par√¢metros transformados que t√™m distribui√ß√µes assint√≥ticas mais simples.
II.  Pelo lema 3.2, os testes sobre os par√¢metros que convergem √† taxa $\sqrt{T}$ (como os par√¢metros autorregressivos) s√£o dominados pela incerteza associada a esses par√¢metros.
III.  Como a transforma√ß√£o remove a n√£o-estacionariedade causada pela tend√™ncia, a distribui√ß√£o assint√≥tica dos estimadores transformados associados aos par√¢metros estacion√°rios ser√° a mesma que se obteria em um modelo sem tend√™ncia.
IV.  Portanto, os testes de hip√≥teses sobre os par√¢metros autorregressivos ser√£o assintoticamente id√™nticos aos que se obteriam se n√£o houvesse tend√™ncia, uma vez que os efeitos da tend√™ncia s√£o eliminados pela transforma√ß√£o.
‚ñ†

> üí° **Exemplo Num√©rico:**
>
>  Considerando um modelo AR(1) com tend√™ncia linear e o teste da hip√≥tese nula $H_0: \phi_1 = 0$. Pelo Corol√°rio 3.2, o teste sobre o par√¢metro $\phi_1$ ser√° assintoticamente id√™ntico ao teste que seria obtido em um modelo AR(1) sem tend√™ncia, ap√≥s a transforma√ß√£o de Sims, Stock e Watson (1990). Isto significa que, para fins de infer√™ncia sobre $\phi_1$, podemos essencialmente ignorar a presen√ßa da tend√™ncia determin√≠stica, pois o estimador transformado j√° incorpora a corre√ß√£o necess√°ria para a presen√ßa da tend√™ncia.
>
> Este resultado simplifica a an√°lise de dados com tend√™ncia, pois podemos usar os m√©todos de infer√™ncia j√° conhecidos para modelos estacion√°rios, desde que seja feita a transforma√ß√£o adequada dos regressores.  Essa simplifica√ß√£o √© crucial para a aplica√ß√£o pr√°tica dos modelos em s√©ries temporais.

**Observa√ß√£o 4**
Os resultados adicionais aqui apresentados (Teorema 3.2, Lema 3.2 e Corol√°rio 3.2) fornecem uma vis√£o mais aprofundada sobre a aplica√ß√£o de testes de hip√≥teses em modelos com tend√™ncia determin√≠stica. Eles mostram que o teste da raz√£o de verossimilhan√ßa √© assintoticamente equivalente ao teste Wald e que, em testes de par√¢metros que convergem mais lentamente, os par√¢metros que convergem mais rapidamente n√£o exercem influ√™ncia assint√≥tica. Al√©m disso, mostramos que a transforma√ß√£o de Sims, Stock e Watson (1990) permite a aplica√ß√£o direta de m√©todos inferenciais para modelos estacion√°rios sobre os par√¢metros transformados, simplificando a an√°lise estat√≠stica.

### Conclus√£o

Esta se√ß√£o detalhou a constru√ß√£o e an√°lise de testes de hip√≥teses em modelos autorregressivos com tend√™ncias determin√≠sticas. Demonstramos que a transforma√ß√£o de Sims, Stock e Watson (1990), embora inicialmente utilizada para simplificar a an√°lise das distribui√ß√µes assint√≥ticas, n√£o interfere na validade assint√≥tica dos testes de hip√≥teses sobre os par√¢metros originais. Vimos que a estat√≠stica de teste Wald pode ser reescrita tanto nos par√¢metros transformados quanto nos originais, mantendo a mesma distribui√ß√£o limite. Al√©m disso, demonstramos que os testes de hip√≥teses s√£o dominados assintoticamente pelos par√¢metros que convergem mais lentamente. Finalmente, mostramos que os testes t e F usuais podem ser aplicados em modelos com tend√™ncias determin√≠sticas, desde que se utilizem os erros padr√£o apropriados. Em resumo, esta se√ß√£o estabeleceu uma base s√≥lida para a infer√™ncia estat√≠stica em modelos autorregressivos com tend√™ncias determin√≠sticas, utilizando as propriedades assint√≥ticas obtidas pela transforma√ß√£o dos regressores. Os resultados aqui apresentados complementam as se√ß√µes anteriores e mostram como usar os conceitos discutidos para realizar infer√™ncias estat√≠sticas v√°lidas e construir testes de hip√≥teses em modelos mais complexos [^1].

### Refer√™ncias
[^1]: Sims, Christopher A., James H. Stock, and Mark W. Watson. 1990. "Inference in Linear Time Series Models with Some Unit Roots." *Econometrica* 58:113-44.
[^2]:  Fuller, Wayne A. 1976. *Introduction to Statistical Time Series*. New York: Wiley.
<!-- END -->
