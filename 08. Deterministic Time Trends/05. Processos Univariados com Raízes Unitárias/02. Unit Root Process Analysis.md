## Processos Univariados com Ra√≠zes Unit√°rias e Movimento Browniano

### Introdu√ß√£o
Como vimos anteriormente, no cap√≠tulo 16, a an√°lise de processos com tend√™ncias de tempo determin√≠sticas revela que as taxas de converg√™ncia dos estimadores podem variar, exigindo abordagens espec√≠ficas para a obten√ß√£o de distribui√ß√µes assint√≥ticas. Agora, nos aprofundaremos nos **processos univariados com ra√≠zes unit√°rias**, um tema fundamental em s√©ries temporais n√£o estacion√°rias.  Este cap√≠tulo estabelece as bases para compreender as distribui√ß√µes assint√≥ticas desses processos, particularmente quando as taxas de converg√™ncia dos coeficientes estimados diferem dos casos estacion√°rios [^1].  Um conceito chave para esta an√°lise √© o **movimento Browniano**, que ser√° explorado como a base para entender o comportamento limitante de certas estat√≠sticas. O estudo de processos com ra√≠zes unit√°rias exige uma nova abordagem para estabelecer suas distribui√ß√µes assint√≥ticas devido √† n√£o estacionariedade, e uma das ferramentas fundamentais para essa an√°lise √© o movimento Browniano, um processo estoc√°stico cont√≠nuo que serve como base para as distribui√ß√µes limitantes das estat√≠sticas de interesse.
**Proposi√ß√£o 1** Uma caracter√≠stica fundamental de processos com ra√≠zes unit√°rias √© a n√£o estacionariedade em sua forma original, tornando invi√°vel a aplica√ß√£o direta dos resultados assint√≥ticos cl√°ssicos para processos estacion√°rios. Este comportamento n√£o estacion√°rio manifesta-se, por exemplo, em um passeio aleat√≥rio, onde a vari√¢ncia do processo aumenta linearmente com o tempo.

> üí° **Exemplo Num√©rico:** Imagine um passeio aleat√≥rio simulado com 100 passos, onde cada passo $e_t$ √© um sorteio aleat√≥rio de uma distribui√ß√£o normal com m√©dia 0 e desvio padr√£o 1 (i.e. $e_t \sim N(0,1)$).  O processo √© definido como $y_t = y_{t-1} + e_t$, com $y_0 = 0$.  A vari√¢ncia de $y_t$ cresce com $t$. Se observarmos $y_{20}$, sua vari√¢ncia ser√° aproximadamente 20, enquanto a vari√¢ncia de $y_{100}$ ser√° aproximadamente 100.  Este comportamento de vari√¢ncia crescente √© t√≠pico de processos com raiz unit√°ria e exemplifica a n√£o estacionariedade.
```python
import numpy as np
import matplotlib.pyplot as plt

np.random.seed(42)  # For reproducibility
n_steps = 100
errors = np.random.normal(0, 1, n_steps)
random_walk = np.cumsum(errors)
time = np.arange(n_steps)

plt.figure(figsize=(8, 4))
plt.plot(time, random_walk, label='Random Walk')
plt.xlabel('Time (t)')
plt.ylabel('Value (y_t)')
plt.title('Simulated Random Walk')
plt.grid(True)
plt.legend()
plt.show()

print(f"Variance of y_20 (approx): {np.var(random_walk[:20]):.2f}")
print(f"Variance of y_100 (approx): {np.var(random_walk):.2f}")
```

### Conceitos Fundamentais

A an√°lise de **processos com ra√≠zes unit√°rias** introduz desafios significativos em compara√ß√£o com processos estacion√°rios. As taxas de converg√™ncia dos coeficientes estimados e as distribui√ß√µes assint√≥ticas das estat√≠sticas de teste n√£o s√£o as mesmas para os dois tipos de processos. No caso de processos com ra√≠zes unit√°rias, a an√°lise da distribui√ß√£o assint√≥tica envolve o conceito de **movimento Browniano**, que servir√° de base para entender o comportamento limitante de certas estat√≠sticas [^1].

O **movimento Browniano** √© um processo estoc√°stico cont√≠nuo que descreve o movimento aleat√≥rio de uma part√≠cula em um fluido. Em s√©ries temporais, ele serve como base para as distribui√ß√µes limitantes de certas estat√≠sticas envolvendo processos com raiz unit√°ria. A ideia fundamental √© que as flutua√ß√µes de longo prazo de processos com raiz unit√°ria podem ser aproximadas por um movimento Browniano escalonado [^1]. A formaliza√ß√£o dessas ideias utiliza o conceito de **funcionais do movimento Browniano**, que s√£o fun√ß√µes do caminho do movimento Browniano, e estas fun√ß√µes desempenham um papel crucial na descri√ß√£o das distribui√ß√µes assint√≥ticas.
**Lema 1** O movimento Browniano, denotado por $W(t)$, possui as seguintes propriedades:
    1. $W(0) = 0$ (Come√ßa na origem).
    2. $W(t)$ tem incrementos independentes.
    3. $W(t) - W(s) \sim \mathcal{N}(0, t-s)$ para $t > s$.
    4. As trajet√≥rias de $W(t)$ s√£o cont√≠nuas.
Estas propriedades s√£o cruciais para derivar as distribui√ß√µes assint√≥ticas dos estimadores em modelos de s√©ries temporais com ra√≠zes unit√°rias.

> üí° **Exemplo Num√©rico:** Para ilustrar o Lema 1, considere que simulamos um movimento browniano discreto com 1000 pontos em um intervalo de tempo [0,1]. Um exemplo de incremento independente seria a diferen√ßa entre $W(0.2)$ e $W(0.1)$, que √© independente da diferen√ßa entre $W(0.9)$ e $W(0.8)$. A distribui√ß√£o da diferen√ßa $W(0.2) - W(0.1)$ √© aproximadamente $\mathcal{N}(0, 0.1)$, e a diferen√ßa $W(0.9) - W(0.8)$ √© aproximadamente $\mathcal{N}(0, 0.1)$.
```python
import numpy as np
import matplotlib.pyplot as plt

np.random.seed(42)
n_points = 1000
time = np.linspace(0, 1, n_points)
increments = np.random.normal(0, np.sqrt(1/n_points), n_points)
brownian_motion = np.cumsum(increments)

plt.figure(figsize=(8, 4))
plt.plot(time, brownian_motion, label='Simulated Brownian Motion')
plt.xlabel('Time (t)')
plt.ylabel('W(t)')
plt.title('Simulated Brownian Motion')
plt.grid(True)
plt.legend()
plt.show()

print(f"Mean of W(0.2) - W(0.1) (approx): {np.mean(brownian_motion[200:200+100] - brownian_motion[100:100+100]):.3f}")
print(f"Variance of W(0.2) - W(0.1) (approx): {np.var(brownian_motion[200:200+100] - brownian_motion[100:100+100]):.3f}")
print(f"Mean of W(0.9) - W(0.8) (approx): {np.mean(brownian_motion[900:900+100] - brownian_motion[800:800+100]):.3f}")
print(f"Variance of W(0.9) - W(0.8) (approx): {np.var(brownian_motion[900:900+100] - brownian_motion[800:800+100]):.3f}")
```

As ferramentas t√©cnicas usadas para estabelecer as distribui√ß√µes assint√≥ticas de estat√≠sticas envolvendo processos com raiz unit√°ria s√£o desenvolvidas na se√ß√£o 17.3 do contexto, utilizando funcionais de movimento Browniano [^1]. Embora a compreens√£o detalhada dessas ferramentas n√£o seja estritamente necess√°ria para seguir as se√ß√µes 17.4-17.9, ela √© fundamental para entender a teoria subjacente.
**Teorema 1** (Teorema Central do Limite Funcional ou Princ√≠pio de Invari√¢ncia de Donsker) Este teorema formaliza a converg√™ncia do processo de soma parcial de ru√≠dos brancos escalonados para o movimento Browniano. Mais precisamente, se $\{e_t\}$ √© uma sequ√™ncia de vari√°veis aleat√≥rias independentes e identicamente distribu√≠das com m√©dia zero e vari√¢ncia $\sigma^2$, e definirmos $S_n(t) = \frac{1}{\sigma\sqrt{n}} \sum_{i=1}^{\lfloor nt \rfloor} e_i $, ent√£o $S_n(t)$ converge em distribui√ß√£o para um movimento Browniano padr√£o $W(t)$, √† medida que $n \to \infty$. Este resultado justifica a utiliza√ß√£o do movimento Browniano para modelar o comportamento limitante de processos com ra√≠zes unit√°rias.
**Prova do Teorema 1:**
Vamos provar o Teorema Central do Limite Funcional (Princ√≠pio de Invari√¢ncia de Donsker), que estabelece a converg√™ncia do processo de soma parcial de ru√≠dos brancos escalonados para o movimento Browniano padr√£o.
I.  Definimos uma sequ√™ncia de vari√°veis aleat√≥rias independentes e identicamente distribu√≠das (i.i.d.) $\{e_t\}$ com m√©dia zero, $\mathbb{E}[e_t] = 0$, e vari√¢ncia $\sigma^2$, $\mathbb{E}[e_t^2] = \sigma^2$.

II.  Considere o processo de soma parcial escalonado $S_n(t)$ definido como:
    $$ S_n(t) = \frac{1}{\sigma\sqrt{n}} \sum_{i=1}^{\lfloor nt \rfloor} e_i, $$
     onde $\lfloor nt \rfloor$ denota a parte inteira de $nt$.

III.  O Teorema Central do Limite (TCL) cl√°ssico para somas parciais estabelece que para um $t$ fixo:
    $$ \frac{1}{\sqrt{n}} \sum_{i=1}^{n} e_i \xrightarrow{d} \mathcal{N}(0,\sigma^2). $$
     Este √© o caso quando $t=1$.

IV.  O Princ√≠pio de Invari√¢ncia de Donsker estende o TCL para o espa√ßo de fun√ß√µes cont√≠nuas. Ele afirma que o processo estoc√°stico $S_n(t)$ converge em distribui√ß√£o no espa√ßo de fun√ß√µes cont√≠nuas $C[0,1]$ para o movimento Browniano padr√£o $W(t)$. Em outras palavras, para qualquer funcional cont√≠nuo $F$ definido em $C[0,1]$:
    $$ F(S_n) \xrightarrow{d} F(W) $$
     quando $n \to \infty$, em que $\xrightarrow{d}$ denota converg√™ncia em distribui√ß√£o.

V.  Uma forma de interpretar essa converg√™ncia √© observar que a distribui√ß√£o das somas parciais escalonadas de vari√°veis aleat√≥rias i.i.d., quando normalizadas corretamente e analisadas como fun√ß√µes do tempo, aproxima-se da distribui√ß√£o do movimento Browniano padr√£o.
     O processo $S_n(t)$ torna-se cada vez mais semelhante ao caminho aleat√≥rio do movimento Browniano padr√£o $W(t)$ quando $n$ √© suficientemente grande, o que √© o significado da converg√™ncia no espa√ßo de fun√ß√µes cont√≠nuas.
     O rigor matem√°tico dessa prova envolve considera√ß√µes t√©cnicas mais avan√ßadas, incluindo o espa√ßo de fun√ß√µes cont√≠nuas e a topologia correspondente, o que vai al√©m do escopo deste contexto.

VI.  Portanto, o resultado justifica o uso do movimento Browniano para modelar o comportamento limite de processos com ra√≠zes unit√°rias, especialmente porque estas somas parciais aparecem nas estat√≠sticas envolvendo estes processos.

Portanto, demonstramos que $S_n(t)$ converge em distribui√ß√£o para o movimento Browniano padr√£o $W(t)$ quando $n \to \infty$. ‚ñ†

> üí° **Exemplo Num√©rico:** Consideremos uma sequ√™ncia de 1000 vari√°veis aleat√≥rias i.i.d. $e_t \sim \mathcal{N}(0,1)$.  Calculamos $S_n(t)$ para $n=1000$ e diferentes valores de $t$.  Por exemplo, para $t=0.5$, temos $S_{1000}(0.5) = \frac{1}{\sqrt{1000}}\sum_{i=1}^{500} e_i$.  Segundo o Teorema 1, para $n$ grande, $S_n(t)$ se aproxima de um movimento Browniano. Podemos visualizar isso com um gr√°fico que mostra o processo $S_n(t)$ ao longo do tempo. Para $t=1$ o resultado seria a distribui√ß√£o de uma soma de 1000 vari√°veis aleat√≥rias normalizadas que se aproxima de $N(0,1)$.

```python
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import norm

np.random.seed(42)
n = 1000
e = np.random.normal(0, 1, n)
t_values = np.linspace(0, 1, n)
S_n_t = np.cumsum(e) / np.sqrt(n)

plt.figure(figsize=(8,4))
plt.plot(t_values, S_n_t, label='$S_n(t)$')
plt.xlabel('t')
plt.ylabel('$S_n(t)$')
plt.title('Processo $S_n(t)$')
plt.grid(True)
plt.legend()
plt.show()

s_n_1 = np.sum(e)/np.sqrt(n)
print(f"Sample mean of S_n(1) (approx): {np.mean(s_n_1):.3f}")
print(f"Sample variance of S_n(1) (approx): {np.var(s_n_1):.3f}")

num_simulations = 1000
s_n_1_simulations = []
for _ in range(num_simulations):
    e_sim = np.random.normal(0, 1, n)
    s_n_1_simulations.append(np.sum(e_sim)/np.sqrt(n))
plt.figure(figsize=(8,4))
plt.hist(s_n_1_simulations, bins = 30, density=True, alpha=0.6, label='Histogram of S_n(1) simulations')

x = np.linspace(-4, 4, 100)
plt.plot(x, norm.pdf(x), 'r', label='N(0,1) pdf')
plt.xlabel('S_n(1)')
plt.ylabel('Density')
plt.title('Distribution of S_n(1) ')
plt.grid(True)
plt.legend()
plt.show()
```
Como vimos no contexto, a se√ß√£o 17.4 foca na deriva√ß√£o da distribui√ß√£o assint√≥tica do coeficiente estimado de uma **autorregress√£o de primeira ordem**, em que o verdadeiro processo √© um passeio aleat√≥rio, ou seja, um processo com raiz unit√°ria. A forma da distribui√ß√£o resultante depende da presen√ßa ou n√£o de um termo constante ou de uma tend√™ncia de tempo na regress√£o estimada e da presen√ßa ou n√£o de um desvio n√£o-nulo no passeio aleat√≥rio verdadeiro [^1]. As estat√≠sticas dos testes de hip√≥teses sobre o coeficiente da raiz unit√°ria podem ser descritas em termos de funcionais do movimento Browniano, o que permite entender suas propriedades assint√≥ticas [^1].
**Corol√°rio 1** A distribui√ß√£o assint√≥tica do estimador do coeficiente de primeira ordem ($\hat{\rho}$) em um modelo AR(1) com raiz unit√°ria n√£o converge para uma normal, como acontece em modelos estacion√°rios. Em vez disso, sua distribui√ß√£o assint√≥tica √© um funcional do movimento Browniano. Este resultado √© uma consequ√™ncia direta do Teorema 1 e sublinha a necessidade de utilizar abordagens n√£o convencionais para a infer√™ncia estat√≠stica em modelos com raiz unit√°ria.
**Prova do Corol√°rio 1:**
Para demonstrar que a distribui√ß√£o assint√≥tica do estimador $\hat{\rho}$ em um modelo AR(1) com raiz unit√°ria n√£o converge para uma normal e, em vez disso, √© um funcional do movimento Browniano, seguimos os seguintes passos l√≥gicos:

I.  Considere um processo AR(1) com raiz unit√°ria, que pode ser descrito como um passeio aleat√≥rio:
    $$ y_t = y_{t-1} + e_t $$
     onde $e_t$ √© um ru√≠do branco com m√©dia zero e vari√¢ncia $\sigma^2$.

II.  O estimador de m√≠nimos quadrados do coeficiente $\rho$ (denotado por $\hat{\rho}$) em um modelo AR(1) √© dado por:
    $$ \hat{\rho} = \frac{\sum_{t=2}^T y_t y_{t-1}}{\sum_{t=2}^T y_{t-1}^2} $$
     onde $T$ √© o tamanho da amostra.

III.  Quando h√° uma raiz unit√°ria ($y_t = y_{t-1} + e_t$), podemos reescrever $y_t$ como a soma parcial dos ru√≠dos:
     $$ y_t = \sum_{i=1}^t e_i $$
     (assumindo $y_0=0$).

IV. Substitu√≠mos esta express√£o de $y_t$ na express√£o de $\hat{\rho}$:
    $$ \hat{\rho} = \frac{\sum_{t=2}^T \left(\sum_{i=1}^t e_i\right) \left(\sum_{j=1}^{t-1} e_j\right)}{\sum_{t=2}^T \left(\sum_{j=1}^{t-1} e_j\right)^2} $$

V.  Ao analisar o comportamento assint√≥tico desta express√£o, observamos que as somas s√£o aproximadamente escalonamentos de uma amostra de ru√≠do branco, e pela defini√ß√£o do Teorema 1, convergindo para um movimento Browniano. Podemos escrever a express√£o assintoticamente como:
    $$ \hat{\rho} \approx \frac{\frac{1}{T^2} \sum_{t=2}^T \left(\sum_{i=1}^t e_i\right) \left(\sum_{j=1}^{t-1} e_j\right)}{\frac{1}{T^2} \sum_{t=2}^T \left(\sum_{j=1}^{t-1} e_j\right)^2} \approx \frac{\int_0^1 W(t)dW(t)}{\int_0^1 W(t)^2 dt} $$
     onde $W(t)$ √© um movimento Browniano padr√£o. Esta aproxima√ß√£o √© baseada no Teorema Central do Limite Funcional.

VI.  A distribui√ß√£o assint√≥tica de $\hat{\rho}$ n√£o √© uma normal, mas sim uma fun√ß√£o do movimento Browniano, especificamente o quociente de duas funcionais do movimento Browniano. A integral de Ito $\int_0^1 W(t)dW(t)$ e a integral $\int_0^1 W(t)^2 dt$ s√£o funcionais de movimento Browniano, e as estat√≠sticas resultantes n√£o s√£o normalmente distribu√≠das.
    Este resultado difere do caso de processos estacion√°rios, onde a distribui√ß√£o do estimador converge para uma normal.

VII. Portanto, demonstr√°mos que a distribui√ß√£o assint√≥tica do estimador $\hat{\rho}$ em um modelo AR(1) com raiz unit√°ria n√£o converge para uma normal, mas sim para uma fun√ß√£o de um movimento Browniano. ‚ñ†

> üí° **Exemplo Num√©rico:** Suponha que simulamos 100 amostras de um passeio aleat√≥rio com 500 observa√ß√µes cada ($y_t = y_{t-1} + e_t$, $e_t \sim \mathcal{N}(0,1)$, $y_0=0$). Em seguida, estimamos o modelo AR(1) $y_t = \rho y_{t-1} + \epsilon_t$ para cada amostra e obtemos os estimadores $\hat{\rho}$. Se construirmos um histograma dos estimadores $\hat{\rho}$, veremos que essa distribui√ß√£o n√£o se parece com uma distribui√ß√£o normal. A distribui√ß√£o de $\hat{\rho}$ se aproxima de uma distribui√ß√£o funcional de um movimento browniano, o que refor√ßa que a abordagem de processos com raiz unit√°ria √© diferente de processos estacion√°rios.
```python
import numpy as np
import matplotlib.pyplot as plt
from statsmodels.regression.linear_model import OLS

np.random.seed(42)
num_simulations = 100
T = 500
rho_hats = []

for _ in range(num_simulations):
    e = np.random.normal(0, 1, T)
    y = np.cumsum(e)
    y_lagged = y[:-1]
    y_current = y[1:]
    model = OLS(y_current, y_lagged)
    results = model.fit()
    rho_hats.append(results.params[0])

plt.figure(figsize=(8,4))
plt.hist(rho_hats, bins = 30, alpha=0.6, label='Histogram of estimated rho')
plt.xlabel('Estimated rho')
plt.ylabel('Frequency')
plt.title('Distribution of estimated AR(1) coefficient')
plt.grid(True)
plt.legend()
plt.show()
```
A se√ß√£o 17.5 expande os resultados da se√ß√£o anterior, ao analisar processos com raiz unit√°ria em que as diferen√ßas exibem correla√ß√£o serial geral. Estes resultados s√£o usados no desenvolvimento de testes para ra√≠zes unit√°rias,  incluindo as abordagens de Phillips e Perron (1988) e Dickey e Fuller (1979). A abordagem de Phillips e Perron ajusta as estat√≠sticas calculadas a partir de uma autorregress√£o de primeira ordem, para considerar a correla√ß√£o serial dos dados diferenciados. A abordagem de Dickey e Fuller adiciona lags √† autorregress√£o para acomodar o efeito da correla√ß√£o serial [^1].
**Teorema 1.1** (Extens√£o do Teorema 1 para Inova√ß√£o com Depend√™ncia Serial) Se $\{e_t\}$ for uma sequ√™ncia de vari√°veis aleat√≥rias que podem ter depend√™ncia serial, mas que satisfazem certas condi√ß√µes de regularidade, e definirmos um processo $S_n(t)$ similarmente ao Teorema 1, ent√£o $S_n(t)$ convergir√° em distribui√ß√£o para um movimento Browniano escalonado, ou seja, $\sigma W(t)$ com uma vari√¢ncia de longo prazo $\sigma$. Este resultado, embora mais t√©cnico, permite lidar com processos com ra√≠zes unit√°rias com maior generalidade e justifica o uso de testes de raiz unit√°ria que incorporam a correla√ß√£o serial.
**Prova do Teorema 1.1:**
Vamos demonstrar a extens√£o do Teorema 1 para o caso em que as inova√ß√µes $\{e_t\}$ exibem depend√™ncia serial, mas mant√™m condi√ß√µes de regularidade.
I. Considere uma sequ√™ncia de vari√°veis aleat√≥rias $\{e_t\}$ que podem apresentar depend√™ncia serial, mas que satisfazem certas condi√ß√µes de regularidade. Em particular, assumimos que $\{e_t\}$ √© um processo linear estacion√°rio e causal que pode ser representado como:
    $$ e_t = \sum_{j=0}^{\infty} \psi_j \epsilon_{t-j} $$
    onde $\{\epsilon_t\}$ √© uma sequ√™ncia de ru√≠dos brancos com m√©dia zero e vari√¢ncia $\sigma_\epsilon^2$, e os coeficientes $\psi_j$ satisfazem $\sum_{j=0}^{\infty} |\psi_j| < \infty$.

II.  Definimos o processo de soma parcial escalonada $S_n(t)$ como no Teorema 1:
    $$ S_n(t) = \frac{1}{\sqrt{n}} \sum_{i=1}^{\lfloor nt \rfloor} e_i $$

III.  A presen√ßa da depend√™ncia serial em $\{e_t\}$ n√£o invalida o princ√≠pio de invari√¢ncia, mas afeta a distribui√ß√£o limitante. A vari√¢ncia de longo prazo de $e_t$ √© dada por:
    $$ \sigma^2 = \lim_{n \to \infty} \frac{1}{n} \mathbb{E}\left[\left(\sum_{t=1}^n e_t\right)^2\right] $$
   que √© a vari√¢ncia de longo prazo do processo. Esta pode ser diferente da vari√¢ncia de $\sigma_\epsilon^2$ de $\epsilon_t$.

IV.  A express√£o da vari√¢ncia de longo prazo $\sigma^2$ pode tamb√©m ser escrita como:
    $$ \sigma^2 = \sigma_\epsilon^2 \left(\sum_{j=0}^{\infty} \psi_j\right)^2 $$
     Se a depend√™ncia serial for nula, ent√£o $\sigma^2 = \sigma_\epsilon^2$.

V.  Sob condi√ß√µes de regularidade adequadas, incluindo o decaimento das autocovari√¢ncias de $e_t$ e certas condi√ß√µes de momento, o Teorema Central do Limite Funcional generalizado implica que o processo $S_n(t)$ converge em distribui√ß√£o para um movimento Browniano escalonado:
     $$ S_n(t) \xrightarrow{d} \sigma W(t) $$
    onde $W(t)$ √© o movimento Browniano padr√£o e $\sigma$ √© a raiz quadrada da vari√¢ncia de longo prazo do processo $\{e_t\}$. A demonstra√ß√£o completa desse resultado requer ferramentas mais t√©cnicas e avan√ßadas, como a utiliza√ß√£o de martingais e desigualdades para somas de vari√°veis aleat√≥rias dependentes, que est√£o fora do escopo desta discuss√£o.

VI. A diferen√ßa principal em rela√ß√£o ao Teorema 1 √© que, devido √† depend√™ncia serial das inova√ß√µes, a vari√¢ncia do movimento Browniano √© agora ajustada para $\sigma^2$, a vari√¢ncia de longo prazo das inova√ß√µes, em vez de a vari√¢ncia original do processo de inova√ß√£o.

VII.  Portanto, o Teorema 1.1 demonstra que, mesmo sob depend√™ncia serial nas inova√ß√µes, o comportamento assint√≥tico de somas parciais de vari√°veis aleat√≥rias escalonadas converge para o movimento Browniano, mas a vari√¢ncia deve ser ajustada para a vari√¢ncia de longo prazo, o que implica que os funcionais limites s√£o tamb√©m funcional de $\sigma W(t)$ em vez de $W(t)$. ‚ñ†

> üí° **Exemplo Num√©rico:** Imagine que $\{e_t\}$ segue um processo MA(1) $e_t = \epsilon_t + 0.7\epsilon_{t-1}$, onde $\epsilon_t \sim \mathcal{N}(0,1)$.  Neste caso, $\sigma_\epsilon^2 = 1$ e $\psi_0 = 1$, $\psi_1 = 0.7$, e $\psi_j = 0$ para $j > 1$. Ent√£o a vari√¢ncia de longo prazo de $\{e_t\}$ √©:
>
> $\sigma^2 = 1(1 + 0.7)^2 = 1(1.7)^2 = 2.89$
>
> Se simulamos esse processo e calculamos $S_n(t)$, este convergir√° para um movimento browniano escalonado $\sqrt{2.89}W(t)$.

```python
import numpy as np
import matplotlib.pyplot as plt

np.random.seed(42)
n = 1000
epsilon = np.random.normal(0, 1, n + 1)  # Add one extra for MA(1) lag
ma1 = epsilon[1:] + 0.7 * epsilon[:-1] # MA(1) process
S_n_t_ma1 = np.cumsum(ma1) / np.sqrt(n)

time = np.linspace(0, 1, n)

plt.figure(figsize=(8,4))
plt.plot(time, S_n_t_ma1, label = r'$S_n(t)$ with MA(1)')
plt.xlabel('t')
plt.ylabel('$S_n(t)$')
plt.title('Processo $S_n(t)$ with serial correlation')
plt.grid(True)
plt.legend()
plt.show()
long_run_variance = (1 + 0.7)**2
print(f"Long run variance is approx.: {long_run_variance:.3f}")
```

Em resumo, a an√°lise de **processos com ra√≠zes unit√°rias** demanda o uso de novas ferramentas e t√©cnicas em compara√ß√£o com processos estacion√°rios. O **movimento Browniano** e os **funcionais do movimento Browniano** s√£o essenciais para descrever as distribui√ß√µes assint√≥ticas e as taxas de converg√™ncia dos estimadores, revelando a complexidade do comportamento de s√©ries temporais n√£o estacion√°rias [^1].
**Lema 1.1** (Propriedades de Integrais de Funcionais do Movimento Browniano) Integral de funcionais do movimento Browniano, como $\int_0^1 W(t) dt$ ou $\int_0^1 W(t)^2 dt$, s√£o vari√°veis aleat√≥rias bem definidas. Elas aparecem nas distribui√ß√µes assint√≥ticas de estimadores de processos com ra√≠zes unit√°rias. As propriedades dessas integrais s√£o fundamentais para construir e analisar os testes de hip√≥teses nesses contextos.

### Conclus√£o
Este cap√≠tulo introduz conceitos fundamentais para an√°lise de processos univariados com ra√≠zes unit√°rias, mostrando como a teoria do movimento Browniano √© usada para estudar a distribui√ß√£o assint√≥tica dos estimadores.  Os resultados obtidos aqui servem como base para entender a complexidade da an√°lise de s√©ries temporais n√£o estacion√°rias e para o desenvolvimento de testes de hip√≥teses apropriados, complementando a an√°lise j√° feita no cap√≠tulo anterior sobre tend√™ncias de tempo determin√≠sticas. As t√©cnicas apresentadas neste cap√≠tulo fornecem um arcabou√ßo para estudar a infer√™ncia estat√≠stica em processos com ra√≠zes unit√°rias. A utiliza√ß√£o do movimento Browniano como uma base para descrever a distribui√ß√£o assint√≥tica dos estimadores, destaca a necessidade de se adaptar as metodologias estat√≠sticas para lidar com as propriedades espec√≠ficas de s√©ries temporais n√£o estacion√°rias, como as que exibem ra√≠zes unit√°rias.

### Refer√™ncias
[^1]: Cap√≠tulo 17 do texto base.
<!-- END -->
