## Teste de Hip√≥teses para o Modelo de Tend√™ncia Temporal Simples

### Introdu√ß√£o
Como vimos anteriormente, os coeficientes de modelos de regress√£o envolvendo tend√™ncias de tempo determin√≠sticas s√£o tipicamente estimados por M√≠nimos Quadrados Ordin√°rios (MQO) [^1]. No entanto, as distribui√ß√µes assint√≥ticas das estimativas dos coeficientes n√£o podem ser calculadas da mesma forma que aquelas para modelos de regress√£o envolvendo vari√°veis estacion√°rias [^1]. Em particular, as estimativas de diferentes par√¢metros geralmente ter√£o diferentes taxas assint√≥ticas de converg√™ncia [^1]. Este cap√≠tulo visa introduzir a ideia de diferentes taxas de converg√™ncia e desenvolve uma abordagem geral para obter distribui√ß√µes assint√≥ticas, seguindo Sims, Stock e Watson (1990) [^1]. Especificamente, focamos em processos envolvendo tend√™ncias de tempo determin√≠sticas, mas sem ra√≠zes unit√°rias [^1]. Uma das conclus√µes ser√° que as estat√≠sticas *t* e *F* usuais do MQO, calculadas da maneira usual, t√™m as mesmas distribui√ß√µes assint√≥ticas que aquelas para regress√µes estacion√°rias [^1]. Embora as distribui√ß√µes limitantes sejam padr√£o, as t√©cnicas usadas para verificar essas distribui√ß√µes limitantes diferem daquelas utilizadas no Cap√≠tulo 8 [^1].

Este t√≥pico se concentrar√° em como os testes de hip√≥teses s√£o realizados no contexto de modelos de tend√™ncias de tempo determin√≠sticas.

### Conceitos Fundamentais
Para o modelo de tend√™ncia de tempo simples apresentado anteriormente $y_t = \alpha + \delta t + \epsilon_t$ [^2], onde $\epsilon_t$ √© um processo de ru√≠do branco com $\epsilon_t \sim N(0, \sigma^2)$, as estimativas de MQO $\hat{\alpha}_T$ e $\hat{\delta}_T$ s√£o Gaussianas. Al√©m disso, as estat√≠sticas *t* e *F* padr√£o do MQO t√™m distribui√ß√µes exatas de amostra pequena *t* e *F* para todos os tamanhos de amostra *T* [^3]. No entanto, apesar de $\hat{\alpha}_T$ e $\hat{\delta}_T$ terem diferentes taxas assint√≥ticas de converg√™ncia, os erros padr√£o $\hat{\sigma}_{\hat{\alpha}_T}$ e $\hat{\sigma}_{\hat{\delta}_T}$ exibem um comportamento assint√≥tico de compensa√ß√£o, de forma que estat√≠sticas como $(\hat{\delta}_T - \delta) / \hat{\sigma}_{\hat{\delta}_T}$ s√£o assintoticamente $N(0,1)$ quando as inova√ß√µes s√£o Gaussianas [^3]. Isso leva √† conjectura de que os testes *t* e *F* usuais s√£o assintoticamente v√°lidos mesmo para inova√ß√µes n√£o Gaussianas [^3].

> üí° **Exemplo Num√©rico:** Suponha que temos um modelo de tend√™ncia temporal $y_t = \alpha + \delta t + \epsilon_t$. Vamos gerar dados para um exemplo pr√°tico, onde $\alpha = 5$, $\delta = 2$, $\sigma^2 = 4$, e $T = 100$.

```python
import numpy as np
import pandas as pd
import statsmodels.api as sm
from scipy import stats
import matplotlib.pyplot as plt
import seaborn as sns

# Define os par√¢metros
alpha_true = 5
delta_true = 2
sigma_true = 2
T = 100

# Gera o tempo
t = np.arange(1, T + 1)

# Gera os erros aleat√≥rios
np.random.seed(42) # Fixa a semente para reproducibilidade
epsilon = np.random.normal(0, sigma_true, T)

# Gera os dados y_t
y = alpha_true + delta_true * t + epsilon

# Cria um DataFrame com os dados
data = pd.DataFrame({'t': t, 'y': y})
sns.lineplot(data=data, x='t', y='y')
plt.title('S√©rie Temporal Gerada')
plt.xlabel('Tempo (t)')
plt.ylabel('Valor (y)')
plt.show()
# Adiciona a coluna de constante
X = sm.add_constant(data['t'])
# Estima o modelo por MQO
model = sm.OLS(data['y'], X)
results = model.fit()

# Imprime os resultados
print(results.summary())

# Extrai os coeficientes e erros padr√µes
alpha_hat = results.params[0]
delta_hat = results.params[1]
sigma_hat = np.sqrt(results.mse_resid)
se_alpha = results.bse[0]
se_delta = results.bse[1]

print(f'\nEstimativas:\nalpha_hat: {alpha_hat:.4f}\ndelta_hat: {delta_hat:.4f}\nsigma_hat: {sigma_hat:.4f}')
print(f'Erros Padr√£o:\nse_alpha: {se_alpha:.4f}\nse_delta: {se_delta:.4f}')

t_stat_delta = (delta_hat - delta_true)/se_delta
print(f'\nEstat√≠stica t para delta: {t_stat_delta:.4f}')

```
Este c√≥digo gera dados com uma tend√™ncia temporal, estima os par√¢metros por MQO, e exibe os resultados, incluindo os erros padr√£o das estimativas e a estat√≠stica t para o par√¢metro $\delta$. A estat√≠stica t calculada deve, teoricamente, se aproximar de uma distribui√ß√£o normal padr√£o quando o tamanho da amostra tende ao infinito.

Para verificar esta conjectura, vamos considerar o teste *t* do MQO para a hip√≥tese nula $\alpha = \alpha_0$ [^3]. Este teste √© definido como:

$$t_T = \frac{\hat{\alpha}_T - \alpha_0}{s_T \sqrt{[1 \, 0](X_T'X_T)^{-1}[1 \, 0]'}}$$ [^3]

Onde $s_T^2$ √© a estimativa de MQO de $\sigma^2$ [^3]:

$$s_T^2 = \frac{1}{T-2} \sum_{t=1}^T (y_t - \hat{\alpha}_T - \hat{\delta}_T t)^2$$ [^3]

E $(X_T'X_T)^{-1}$ √© a matriz em [16.1.16] [^3]. O numerador e o denominador de $t_T$ podem ser multiplicados por $\sqrt{T}$ resultando em [^3]:

$$t_T = \frac{\sqrt{T}(\hat{\alpha}_T - \alpha_0)}{s_T \sqrt{[\sqrt{T} \, 0](X_T'X_T)^{-1} [\sqrt{T} \, 0]'}}$$ [^3]

Usando [16.1.17], obtemos:

$$[\sqrt{T} \, 0] = [1 \, 0]Y_T$$ [^3]

Substituindo isto em $t_T$, obtemos [^3]:

$$t_T = \frac{\sqrt{T}(\hat{\alpha}_T - \alpha_0)}{s_T \sqrt{[1 \, 0]Y_T(X_T'X_T)^{-1}Y_T'[1 \, 0]'}}$$ [^3]

Como $Y_T(X_T'X_T)^{-1}Y_T' \rightarrow Q^{-1}$ [^3], onde $Q$ √© definido em [16.1.20], e $\sqrt{T}(\hat{\alpha}_T - \alpha_0) \rightarrow N(0, \sigma^2q^{11})$ [^3], onde $q^{11}$ √© o elemento (1,1) de $Q^{-1}$, temos [^3]:

$$t_T = \frac{\sqrt{T}(\hat{\alpha}_T - \alpha_0)}{\sqrt{\hat{\sigma}^2[1 \, 0]Q^{-1}[1 \, 0]'}} \rightarrow N(0, 1)$$ [^3]

Este resultado demonstra que o teste *t* padr√£o do MQO para $\alpha = \alpha_0$ √© assintoticamente v√°lido [^3].

*Prova:*
I. Come√ßamos com a estat√≠stica *t* para testar a hip√≥tese nula $\alpha = \alpha_0$:
   $$t_T = \frac{\hat{\alpha}_T - \alpha_0}{s_T \sqrt{[1 \, 0](X_T'X_T)^{-1}[1 \, 0]'}}$$

II. Multiplicamos o numerador e o denominador por $\sqrt{T}$:
    $$t_T = \frac{\sqrt{T}(\hat{\alpha}_T - \alpha_0)}{s_T \sqrt{[\sqrt{T} \, 0](X_T'X_T)^{-1} [\sqrt{T} \, 0]'}}$$

III. Aplicamos o resultado de que $[\sqrt{T} \, 0] = [1 \, 0]Y_T$:
    $$t_T = \frac{\sqrt{T}(\hat{\alpha}_T - \alpha_0)}{s_T \sqrt{[1 \, 0]Y_T(X_T'X_T)^{-1}Y_T'[1 \, 0]'}}$$

IV.  Usamos o fato de que $Y_T(X_T'X_T)^{-1}Y_T' \rightarrow Q^{-1}$ e $\sqrt{T}(\hat{\alpha}_T - \alpha_0) \rightarrow N(0, \sigma^2q^{11})$:
    $$t_T = \frac{\sqrt{T}(\hat{\alpha}_T - \alpha_0)}{\sqrt{\hat{\sigma}^2[1 \, 0]Q^{-1}[1 \, 0]'}}$$

V.  Portanto, a estat√≠stica *t* converge em distribui√ß√£o para uma normal padr√£o:
    $$t_T \rightarrow N(0, 1)$$‚ñ†

> üí° **Exemplo Num√©rico:** Utilizando o c√≥digo Python do exemplo anterior, vamos realizar o teste *t* para $\alpha$.  Assumindo a hip√≥tese nula $H_0: \alpha = 4$.
```python
alpha_null = 4
t_stat_alpha = (alpha_hat - alpha_null) / se_alpha
print(f'Estat√≠stica t para alpha (H0: alpha=4): {t_stat_alpha:.4f}')
p_value_alpha = 2 * (1 - stats.t.cdf(np.abs(t_stat_alpha), df=T-2))
print(f'p-valor do teste t: {p_value_alpha:.4f}')

```
Este c√≥digo calcula a estat√≠stica *t* para o teste da hip√≥tese de que $\alpha = 4$ e calcula o valor *p*. O valor *p* indica a probabilidade de observar um valor t√£o extremo ou mais extremo da estat√≠stica *t*, se a hip√≥tese nula for verdadeira.

Similarmente, para o teste *t* do MQO da hip√≥tese nula $\delta = \delta_0$, temos [^3]:

$$t_T = \frac{\hat{\delta}_T - \delta_0}{s_T \sqrt{[0 \, 1](X_T'X_T)^{-1}[0 \, 1]'}}$$ [^3]

Multiplicando o numerador e o denominador por $T^{3/2}$, obtemos [^3]:

$$t_T = \frac{T^{3/2}(\hat{\delta}_T - \delta_0)}{s_T \sqrt{[0 \, T^{3/2}](X_T'X_T)^{-1}[0 \, T^{3/2}]'}}$$ [^3]

Usando o resultado de que $Y_T(X_T'X_T)^{-1}Y_T' \rightarrow Q^{-1}$, temos [^3]:
$$t_T = \frac{T^{3/2}(\hat{\delta}_T - \delta_0)}{\sqrt{\hat{\sigma}^2[0 \, 1]Q^{-1}[0 \, 1]'}} \rightarrow N(0, 1)$$ [^3]
Isso mostra que o teste *t* do MQO para $\delta = \delta_0$ tamb√©m √© assintoticamente v√°lido [^3].

*Prova:*
I. Come√ßamos com a estat√≠stica *t* para testar a hip√≥tese nula $\delta = \delta_0$:
   $$t_T = \frac{\hat{\delta}_T - \delta_0}{s_T \sqrt{[0 \, 1](X_T'X_T)^{-1}[0 \, 1]'}}$$

II. Multiplicamos o numerador e o denominador por $T^{3/2}$:
    $$t_T = \frac{T^{3/2}(\hat{\delta}_T - \delta_0)}{s_T \sqrt{[0 \, T^{3/2}](X_T'X_T)^{-1}[0 \, T^{3/2}]'}}$$

III. Usando o resultado de que $Y_T(X_T'X_T)^{-1}Y_T' \rightarrow Q^{-1}$ e $\sqrt{T^3}(\hat{\delta}_T-\delta_0) \rightarrow N(0,\sigma^2 q^{22})$ temos:
    $$t_T = \frac{T^{3/2}(\hat{\delta}_T - \delta_0)}{\sqrt{\hat{\sigma}^2[0 \, 1]Q^{-1}[0 \, 1]'}}$$

IV.  Portanto, a estat√≠stica *t* converge em distribui√ß√£o para uma normal padr√£o:
    $$t_T \rightarrow N(0, 1)$$‚ñ†

> üí° **Exemplo Num√©rico:** Vamos agora calcular a estat√≠stica t para o par√¢metro $\delta$ considerando a hip√≥tese nula $H_0: \delta = 1.8$, utilizando o c√≥digo do exemplo anterior.
```python
delta_null = 1.8
t_stat_delta = (delta_hat - delta_null) / se_delta
print(f'Estat√≠stica t para delta (H0: delta=1.8): {t_stat_delta:.4f}')
p_value_delta = 2 * (1 - stats.t.cdf(np.abs(t_stat_delta), df=T-2))
print(f'p-valor do teste t: {p_value_delta:.4f}')

```
Este c√≥digo realiza o teste t para a hip√≥tese nula de que $\delta = 1.8$. Os resultados mostram a estat√≠stica *t* e seu correspondente valor *p*.

**Lema 1**
A converg√™ncia em distribui√ß√£o dos testes *t* para $\alpha$ e $\delta$ demonstra um importante principio assint√≥tico: as diferentes taxas de converg√™ncia dos estimadores s√£o compensadas pelos respectivos erros padr√£o, levando a estat√≠sticas *t* com distribui√ß√£o assint√≥tica padr√£o $N(0,1)$. Este lema √© fundamental para a validade dos testes de hip√≥teses em modelos com tend√™ncias temporais.

Podemos agora considerar um teste de hip√≥tese conjunto envolvendo $\alpha$ e $\delta$ da forma $H_0: r_1 \alpha + r_2 \delta = r$ [^3], onde $r_1, r_2$ e $r$ s√£o par√¢metros que descrevem a hip√≥tese. O teste de $H_0$ pode ser obtido pela raiz quadrada do teste *F* do MQO [^3]:

$$t_T = \frac{r_1 \hat{\alpha}_T + r_2 \hat{\delta}_T - r}{\sqrt{s_T^2[r_1 \, r_2](X_T'X_T)^{-1}[r_1 \, r_2]'}}$$ [^3]

Nesse caso, multiplicamos o numerador e denominador por $\sqrt{T}$ [^3]:

$$t_T = \frac{\sqrt{T}(r_1 \hat{\alpha}_T + r_2 \hat{\delta}_T - r)}{\sqrt{s_T^2[r_1 \, r_2](X_T'X_T)^{-1}[r_1 \, r_2]'}}$$ [^3]

Utilizando $Y_T$ temos [^3]:
$$t_T = \frac{\sqrt{T}(r_1 \hat{\alpha}_T + r_2 \hat{\delta}_T - r)}{\sqrt{s_T^2 [r_1 \, r_2]Y_T(X_T'X_T)^{-1}Y_T' [r_1 \, r_2]'}}$$ [^3]

e usando as propriedades da converg√™ncia de $Y_T(X_T'X_T)^{-1}Y_T' \to Q^{-1}$ e a superconsist√™ncia de $\hat{\delta_T}$, temos [^3]:
$$t_T \to N(0,1)$$ [^3]

*Prova*:
I. Come√ßamos com a estat√≠stica *t* para testar a hip√≥tese conjunta $H_0: r_1 \alpha + r_2 \delta = r$:
   $$t_T = \frac{r_1 \hat{\alpha}_T + r_2 \hat{\delta}_T - r}{\sqrt{s_T^2[r_1 \, r_2](X_T'X_T)^{-1}[r_1 \, r_2]'}}$$

II. Multiplicamos o numerador e o denominador por $\sqrt{T}$:
    $$t_T = \frac{\sqrt{T}(r_1 \hat{\alpha}_T + r_2 \hat{\delta}_T - r)}{\sqrt{s_T^2[r_1 \, r_2](X_T'X_T)^{-1}[r_1 \, r_2]'}}$$

III. Usando o resultado de que $[r_1 \, r_2] = [r_1 \, r_2]Y_T$, obtemos:
    $$t_T = \frac{\sqrt{T}(r_1 \hat{\alpha}_T + r_2 \hat{\delta}_T - r)}{\sqrt{s_T^2 [r_1 \, r_2]Y_T(X_T'X_T)^{-1}Y_T' [r_1 \, r_2]'}}$$

IV. Usando o fato de que $Y_T(X_T'X_T)^{-1}Y_T' \rightarrow Q^{-1}$ e a superconsist√™ncia de $\hat{\delta}_T$, temos:
    $$t_T = \frac{\sqrt{T}(r_1 \hat{\alpha}_T + r_2 \hat{\delta}_T - r)}{\sqrt{\hat{\sigma}^2[r_1 \, r_2]Q^{-1}[r_1 \, r_2]'}}$$

V. Portanto, a estat√≠stica *t* converge em distribui√ß√£o para uma normal padr√£o:
    $$t_T \rightarrow N(0, 1)$$‚ñ†

> üí° **Exemplo Num√©rico:** Consideremos a hip√≥tese conjunta $H_0: 2\alpha + \delta = 12$. Vamos calcular a estat√≠stica *t* usando os valores estimados no exemplo anterior.
```python
r1, r2, r = 2, 1, 12
t_stat_joint = (r1 * alpha_hat + r2 * delta_hat - r) / np.sqrt(results.mse_resid * np.dot(np.dot(np.array([r1, r2]), results.cov_params()), np.array([r1, r2]).T))
print(f'Estat√≠stica t para H0: 2alpha + delta = 12: {t_stat_joint:.4f}')
p_value_joint = 2 * (1 - stats.t.cdf(np.abs(t_stat_joint), df=T-2))
print(f'p-valor do teste t: {p_value_joint:.4f}')

```
Este c√≥digo calcula a estat√≠stica *t* para o teste da hip√≥tese conjunta. O valor *p* associado indica a probabilidade de observar um valor t√£o extremo ou mais extremo para a estat√≠stica *t*, dado que a hip√≥tese nula seja verdadeira.

Este exemplo demonstra um princ√≠pio geral: um teste envolvendo uma √∫nica restri√ß√£o entre par√¢metros com taxas de converg√™ncia diferentes √© dominado assintoticamente pelos par√¢metros com as taxas de converg√™ncia mais lentas [^3].

**Teorema 1**
O resultado assint√≥tico do teste *t* para a hip√≥tese conjunta $H_0: r_1 \alpha + r_2 \delta = r$ demonstra um comportamento similar aos testes para $\alpha$ e $\delta$ individualmente. A estat√≠stica converge para uma distribui√ß√£o normal padr√£o, destacando a generalidade da abordagem de compensa√ß√£o das taxas de converg√™ncia.
*Prova*: Segue diretamente da aplica√ß√£o da converg√™ncia de $Y_T(X_T'X_T)^{-1}Y_T'$ para $Q^{-1}$ e das propriedades de superconsist√™ncia de $\hat{\delta}_T$. O fator de converg√™ncia $\sqrt{T}$ no numerador e denominador garante que a estat√≠stica *t* convirja para uma normal padr√£o, de forma an√°loga aos testes anteriores.

Finalmente, vamos considerar um teste conjunto para hip√≥teses separadas sobre $\alpha$ e $\delta$ [^3]:

$$H_0: \begin{bmatrix} \alpha \\ \delta \end{bmatrix} = \begin{bmatrix} \alpha_0 \\ \delta_0 \end{bmatrix}$$ [^3]

Ou, em forma vetorial [^3]:

$$\beta = \beta_0$$ [^3]

A forma de Wald do teste $X^2$ do MQO para $H_0$ √© obtida de [8.2.23] [^3]:

$$\chi^2_T = (b_T - \beta_0)'[s_T^2(X_T'X_T)^{-1}]^{-1}(b_T - \beta_0)$$
$$ = (b_T - \beta_0)'Y_T [Y_Ts_T^2(X_T'X_T)^{-1}Y_T']^{-1}Y_T' (b_T - \beta_0)$$
$$ \rightarrow (b_T - \beta_0)'[Q^{-1}]^{-1} (b_T - \beta_0)$$ [^3]

Como vimos anteriormente, $\sqrt{T}(b_T - \beta_0)$ converge para uma distribui√ß√£o normal multivariada, o que implica que $\chi^2_T$ tem uma distribui√ß√£o assint√≥tica $X^2(2)$ [^3].

*Prova:*
I. Come√ßamos com a forma de Wald do teste $\chi^2$ para a hip√≥tese conjunta $H_0: \beta = \beta_0$:
    $$\chi^2_T = (b_T - \beta_0)'[s_T^2(X_T'X_T)^{-1}]^{-1}(b_T - \beta_0)$$

II. Usando o resultado de que $[s_T^2(X_T'X_T)^{-1}]^{-1} = Y_T[Y_Ts_T^2(X_T'X_T)^{-1}Y_T']^{-1}Y_T'$, temos:
    $$\chi^2_T = (b_T - \beta_0)'Y_T [Y_Ts_T^2(X_T'X_T)^{-1}Y_T']^{-1}Y_T' (b_T - \beta_0)$$

III. Usando o fato de que $Y_T(X_T'X_T)^{-1}Y_T' \rightarrow Q^{-1}$, temos:
    $$\chi^2_T \rightarrow (b_T - \beta_0)'[Q^{-1}]^{-1} (b_T - \beta_0)$$

IV. Dado que $\sqrt{T}(b_T - \beta_0)$ converge para uma distribui√ß√£o normal multivariada, a estat√≠stica $\chi^2_T$ converge para uma distribui√ß√£o $\chi^2$ com graus de liberdade igual ao n√∫mero de restri√ß√µes, que neste caso √© 2:
    $$\chi^2_T \rightarrow \chi^2(2)$$‚ñ†

> üí° **Exemplo Num√©rico:** Vamos realizar um teste $\chi^2$ conjunto utilizando os resultados do exemplo, com a hip√≥tese nula $H_0: \alpha=4 \text{ e } \delta=1.8$.

```python
beta_null = np.array([4, 1.8])
beta_hat = np.array([alpha_hat, delta_hat])
cov_params = results.cov_params()
chi2_stat = (beta_hat - beta_null) @ np.linalg.inv(cov_params) @ (beta_hat - beta_null).T
p_value_chi2 = 1 - stats.chi2.cdf(chi2_stat, df=2)
print(f'Estat√≠stica chi2 para H0: alpha=4 e delta=1.8: {chi2_stat:.4f}')
print(f'p-valor do teste chi2: {p_value_chi2:.4f}')
```
Este c√≥digo calcula a estat√≠stica chi2 para a hip√≥tese conjunta e o p-valor. O p-valor indica a probabilidade de observar uma estat√≠stica chi2 t√£o extrema ou mais extrema, dada a hip√≥tese nula ser verdadeira.

**Teorema 2**
A forma de Wald do teste $\chi^2$ para a hip√≥tese conjunta $H_0: \begin{bmatrix} \alpha \\ \delta \end{bmatrix} = \begin{bmatrix} \alpha_0 \\ \delta_0 \end{bmatrix}$ converge para uma distribui√ß√£o $\chi^2(2)$. Este resultado mostra que, mesmo com diferentes taxas de converg√™ncia para $\alpha$ e $\delta$, a estat√≠stica de teste resultante possui uma distribui√ß√£o assint√≥tica bem definida, permitindo a realiza√ß√£o de infer√™ncias conjuntas.
*Prova:* A prova se baseia na converg√™ncia de $\sqrt{T}(b_T - \beta_0)$ para uma distribui√ß√£o normal multivariada. A forma da estat√≠stica $\chi^2_T$ e a converg√™ncia de $Y_T(X_T'X_T)^{-1}Y_T'$ para $Q^{-1}$ garantem que a estat√≠stica converge para uma distribui√ß√£o $\chi^2$ com graus de liberdade iguais ao n√∫mero de restri√ß√µes, que neste caso √© 2.

### Conclus√£o

Este cap√≠tulo estabeleceu que, para modelos de tend√™ncias de tempo determin√≠sticas, os testes *t* e *F* usuais do MQO s√£o assintoticamente v√°lidos, mesmo quando as inova√ß√µes n√£o s√£o Gaussianas [^3]. Isso ocorre devido ao comportamento assint√≥tico de compensa√ß√£o dos erros padr√£o, que incorpora diferentes ordens de *T* correspondentes √†s diferentes taxas de converg√™ncia dos estimadores [^3]. As an√°lises apresentadas destacam a import√¢ncia de considerar as taxas de converg√™ncia ao realizar testes de hip√≥teses em modelos que envolvem tend√™ncias de tempo determin√≠sticas e lan√ßam as bases para uma an√°lise de modelos mais complexos nos cap√≠tulos seguintes. Como tal, este conhecimento complementa os conceitos discutidos nos cap√≠tulos anteriores sobre o comportamento assint√≥tico dos estimadores.

**Corol√°rio 1**
A validade assint√≥tica dos testes *t* e *F*, tanto para hip√≥teses individuais quanto conjuntas em modelos com tend√™ncia de tempo determin√≠stica, √© um resultado robusto. Isso implica que, para tamanhos de amostra suficientemente grandes, podemos usar os procedimentos de teste de hip√≥teses usuais do MQO, mesmo quando as inova√ß√µes n√£o s√£o Gaussianas, o que simplifica a an√°lise e torna os resultados mais aplic√°veis.
*Justificativa:* Este corol√°rio resume os principais resultados do cap√≠tulo, enfatizando a robustez dos testes estat√≠sticos. A converg√™ncia para distribui√ß√µes assint√≥ticas bem definidas permite que os pesquisadores apliquem os testes *t* e *F* padr√£o em uma variedade de cen√°rios pr√°ticos.

### Refer√™ncias
[^1]:  The coefficients of regression models involving unit roots or deterministic time trends are typically estimated by ordinary least squares. However, the asymptotic distributions of the coefficient estimates cannot be calculated in the same way as are those for regression models involving stationary variables. Among other difficulties, the estimates of different parameters will in general have different asymptotic rates of convergence. This chapter introduces the idea of different rates of convergence and develops a general approach to obtaining asymptotic distributions suggested by Sims, Stock, and Watson (1990). This chapter deals exclusively with processes involving deterministic time trends but no unit roots. One of the results for such processes will be that the usual OLS t and F statistics, calculated in the usual way, have the same asymptotic distributions as they do for stationary regressions. Although the limiting distributions are standard, the techniques used to verify these limiting distributions are different from those used in Chapter 8. These techniques will also be used to develop the asymptotic distributions for processes including unit roots in Chapters 17 and 18.
[^2]: This section considers OLS estimation of the parameters of a simple time trend, $y_t = \alpha + \delta t + \epsilon_t$, for $\epsilon_t$ a white noise process.
[^3]: If the innovations $\epsilon_t$ for the simple time trend [16.1.1] are Gaussian, then the OLS estimates $\hat{\alpha}_T$ and $\hat{\delta}_T$ are Gaussian and the usual OLS *t* and *F* tests have exact small-sample *t* and *F* distributions for all sample sizes T. Thus, despite the fact that $\hat{\alpha}_T$ and $\hat{\delta}_T$ have different asymptotic rates of convergence, the standard errors $\hat{\sigma}_{\hat{\alpha}_T}$ and $\hat{\sigma}_{\hat{\delta}_T}$, evidently have offsetting asymptotic behavior so that the statistics such as $(\hat{\delta}_T - \delta)/ \hat{\sigma}_{\hat{\delta}_T}$ are asymptotically N(0, 1) when the innovations are Gaussian. We might thus conjecture that the usual *t* and *F* tests are asymptotically valid for non-Gaussian innovations as well. This conjecture is indeed correct, as we now verify.
<!-- END -->
