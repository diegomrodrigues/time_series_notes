## Teste de Hip√≥teses para o Modelo de Tend√™ncia Temporal Simples

### Introdu√ß√£o
Como discutido em cap√≠tulos anteriores, a estima√ß√£o de coeficientes em modelos de regress√£o com tend√™ncias temporais determin√≠sticas utilizando M√≠nimos Quadrados Ordin√°rios (MQO) apresenta particularidades nas distribui√ß√µes assint√≥ticas dos estimadores [^1]. As taxas de converg√™ncia distintas entre diferentes par√¢metros exigem uma an√°lise cuidadosa para garantir a validade dos testes de hip√≥teses [^1]. Este cap√≠tulo aborda como os testes de hip√≥teses s√£o realizados para modelos com tend√™ncias de tempo, focando na abordagem geral para a obten√ß√£o de distribui√ß√µes assint√≥ticas, conforme proposto por Sims, Stock e Watson (1990) [^1]. O foco recai sobre processos que incluem tend√™ncias temporais determin√≠sticas sem ra√≠zes unit√°rias [^1]. O resultado chave √© que as estat√≠sticas *t* e *F* do MQO, calculadas da forma usual, apresentam as mesmas distribui√ß√µes assint√≥ticas que para regress√µes com vari√°veis estacion√°rias [^1], embora as t√©cnicas de verifica√ß√£o sejam distintas do Cap√≠tulo 8 [^1].

### Conceitos Fundamentais
No contexto do modelo de tend√™ncia temporal simples $y_t = \alpha + \delta t + \epsilon_t$ [^2], onde $\epsilon_t$ segue um processo de ru√≠do branco com distribui√ß√£o normal $\epsilon_t \sim N(0, \sigma^2)$, as estimativas de MQO $\hat{\alpha}_T$ e $\hat{\delta}_T$ s√£o Gaussianas [^3]. As estat√≠sticas *t* e *F* padr√£o do MQO possuem distribui√ß√µes exatas *t* e *F* para tamanhos de amostra finitos *T* [^3]. Contudo, $\hat{\alpha}_T$ e $\hat{\delta}_T$ apresentam taxas de converg√™ncia assint√≥tica distintas. Os erros padr√£o $\hat{\sigma}_{\hat{\alpha}_T}$ e $\hat{\sigma}_{\hat{\delta}_T}$ exibem um comportamento assint√≥tico compensat√≥rio, garantindo que estat√≠sticas como $(\hat{\delta}_T - \delta) / \hat{\sigma}_{\hat{\delta}_T}$ sejam assintoticamente $N(0,1)$ quando as inova√ß√µes s√£o Gaussianas [^3]. Isso sugere que os testes *t* e *F* usuais podem ser assintoticamente v√°lidos tamb√©m para inova√ß√µes n√£o Gaussianas [^3].

> üí° **Exemplo Num√©rico:** Suponha que temos os seguintes dados para $y_t$ e $t$:
> ```python
> import numpy as np
> import pandas as pd
> import statsmodels.api as sm
>
> # Dados de exemplo
> t = np.arange(1, 101) # Tempo de 1 a 100
> np.random.seed(42)
> eps = np.random.normal(0, 2, 100) # Erros aleat√≥rios
> alpha_true = 5
> delta_true = 0.5
> y = alpha_true + delta_true * t + eps # Gerando y_t
>
> # Criando um DataFrame para facilitar a an√°lise
> data = pd.DataFrame({'t': t, 'y': y})
>
> # Adicionando uma constante para o modelo
> X = sm.add_constant(data['t'])
>
> # Ajustando o modelo de regress√£o linear
> model = sm.OLS(data['y'], X)
> results = model.fit()
>
> # Imprimindo os resultados
> print(results.summary())
>
> # Extraindo os coeficientes estimados
> alpha_hat = results.params[0]
> delta_hat = results.params[1]
> print(f"Coeficiente alpha estimado: {alpha_hat}")
> print(f"Coeficiente delta estimado: {delta_hat}")
> ```
>
> Este c√≥digo gera dados simulados com uma tend√™ncia temporal linear e adiciona ru√≠do branco gaussiano. Em seguida, ele realiza a regress√£o e imprime os resultados, que incluem os coeficientes estimados, seus erros padr√£o e as estat√≠sticas t. Os valores estimados $\hat{\alpha}_T$ e $\hat{\delta}_T$ s√£o pr√≥ximos dos valores verdadeiros, e os testes *t* para os coeficientes podem ser analisados. Por exemplo, com uma hip√≥tese nula de $\alpha_0=0$, o teste *t* √© calculado como $(\hat{\alpha}_T - 0) / \hat{\sigma}_{\hat{\alpha}_T}$.

Para o teste *t* do MQO para a hip√≥tese nula $\alpha = \alpha_0$, a estat√≠stica √© dada por [^3]:

$$t_T = \frac{\hat{\alpha}_T - \alpha_0}{s_T \sqrt{[1 \, 0](X_T'X_T)^{-1}[1 \, 0]'}}$$

onde $s_T^2$ √© a estimativa de MQO da vari√¢ncia $\sigma^2$ [^3].  Para garantir a validade assint√≥tica, a estat√≠stica √© transformada utilizando $\sqrt{T}$ como fator multiplicativo, o que equivale ao uso da vari√¢ncia amostral e a inversa da matriz $X'X$ [^3]:

$$t_T = \frac{\sqrt{T}(\hat{\alpha}_T - \alpha_0)}{s_T \sqrt{[\sqrt{T} \, 0](X_T'X_T)^{-1} [\sqrt{T} \, 0]'}}$$

Essa transforma√ß√£o √© fundamental para assegurar a validade assint√≥tica dos testes sob condi√ß√µes n√£o Gaussianas. Usando o resultado de [16.1.17], $[\sqrt{T} \, 0] = [1 \, 0]Y_T$, e a converg√™ncia de $Y_T(X_T'X_T)^{-1}Y_T' \rightarrow Q^{-1}$ [^3], a estat√≠stica *t* pode ser escrita como:

$$t_T = \frac{\sqrt{T}(\hat{\alpha}_T - \alpha_0)}{\sqrt{\hat{\sigma}^2[1 \, 0]Q^{-1}[1 \, 0]'}}$$

Essa forma da estat√≠stica *t* converge assintoticamente para uma distribui√ß√£o normal padr√£o $N(0,1)$, como demonstrado anteriormente.

*Prova:*
I. Partimos da estat√≠stica *t* para testar a hip√≥tese nula $\alpha = \alpha_0$:
   $$t_T = \frac{\hat{\alpha}_T - \alpha_0}{s_T \sqrt{[1 \, 0](X_T'X_T)^{-1}[1 \, 0]'}}$$
II. Multiplicamos o numerador e denominador por $\sqrt{T}$:
    $$t_T = \frac{\sqrt{T}(\hat{\alpha}_T - \alpha_0)}{s_T \sqrt{[\sqrt{T} \, 0](X_T'X_T)^{-1} [\sqrt{T} \, 0]'}}$$
III. Usamos a rela√ß√£o $[\sqrt{T} \, 0] = [1 \, 0]Y_T$:
    $$t_T = \frac{\sqrt{T}(\hat{\alpha}_T - \alpha_0)}{s_T \sqrt{[1 \, 0]Y_T(X_T'X_T)^{-1}Y_T'[1 \, 0]'}}$$
IV. Aplicando $Y_T(X_T'X_T)^{-1}Y_T' \rightarrow Q^{-1}$ e $\sqrt{T}(\hat{\alpha}_T - \alpha_0) \rightarrow N(0, \sigma^2q^{11})$:
    $$t_T = \frac{\sqrt{T}(\hat{\alpha}_T - \alpha_0)}{\sqrt{\hat{\sigma}^2[1 \, 0]Q^{-1}[1 \, 0]'}}$$
V. Resultando na converg√™ncia para uma distribui√ß√£o normal padr√£o:
    $$t_T \rightarrow N(0, 1)$$‚ñ†

**Lema 1**
A matriz $Q$ mencionada acima, que aparece como o limite de $Y_T(X_T'X_T)^{-1}Y_T'$, √© uma matriz de informa√ß√£o Fisher, que desempenha um papel crucial na an√°lise assint√≥tica dos estimadores de MQO em modelos com tend√™ncias temporais. Para o modelo simples $y_t = \alpha + \delta t + \epsilon_t$, a matriz $Q$ pode ser expressa analiticamente como:

$$
Q = \begin{bmatrix}
    q_{11} & q_{12} \\
    q_{21} & q_{22}
\end{bmatrix} =
\begin{bmatrix}
    1 & 1/2 \\
    1/2 & 1/3
\end{bmatrix}
$$
*Prova:*
I. A matriz $X_T$ no modelo de tend√™ncia temporal simples √© dada por:
$X_T = \begin{bmatrix} 1 & 1 \\ 1 & 2 \\ \vdots & \vdots \\ 1 & T \end{bmatrix}$.

II. Ent√£o, $X_T'X_T = \begin{bmatrix} T & \sum_{t=1}^{T} t \\ \sum_{t=1}^{T} t & \sum_{t=1}^{T} t^2 \end{bmatrix}$.

III. Usando as f√≥rmulas para as somas de pot√™ncias de inteiros:
$\sum_{t=1}^{T} t = \frac{T(T+1)}{2}$ e
$\sum_{t=1}^{T} t^2 = \frac{T(T+1)(2T+1)}{6}$.

IV. Assim,
$X_T'X_T = \begin{bmatrix} T & T(T+1)/2 \\ T(T+1)/2 & T(T+1)(2T+1)/6 \end{bmatrix}$.

V. A matriz $Y_T$ √© dada por $Y_T = \begin{bmatrix} \sqrt{T} & 0 \\ 0 & T^{3/2} \end{bmatrix}$.

VI. Ent√£o,  $Y_T^{-1}(X_T'X_T)Y_T^{-1} = \begin{bmatrix} T/\sqrt{T} & T(T+1)/2T^{3/2} \\ T(T+1)/2T^{3/2} & T(T+1)(2T+1)/6T^{3} \end{bmatrix} = \begin{bmatrix} \sqrt{T} & (T+1)/(2\sqrt{T}) \\ (T+1)/(2\sqrt{T}) & (2T^2+3T+1)/(6T^{3/2}) \end{bmatrix}$

VII. A matriz $Y_T(X_T'X_T)^{-1}Y_T'$ converge para $Q^{-1}$ conforme demonstrado no texto, onde $Q^{-1}$ √© a inversa da matriz $Q$. Logo, $Q =  \begin{bmatrix}
    1 & 1/2 \\
    1/2 & 1/3
\end{bmatrix}$
‚ñ†

> üí° **Exemplo Num√©rico:** Continuando com o exemplo anterior, e utilizando os resultados obtidos:
> ```python
> import numpy as np
> import pandas as pd
> import statsmodels.api as sm
>
> # Dados de exemplo (reutilizando os dados do exemplo anterior)
> t = np.arange(1, 101)  # Tempo de 1 a 100
> np.random.seed(42)
> eps = np.random.normal(0, 2, 100)  # Erros aleat√≥rios
> alpha_true = 5
> delta_true = 0.5
> y = alpha_true + delta_true * t + eps  # Gerando y_t
>
> # Criando um DataFrame para facilitar a an√°lise
> data = pd.DataFrame({'t': t, 'y': y})
>
> # Adicionando uma constante para o modelo
> X = sm.add_constant(data['t'])
>
> # Ajustando o modelo de regress√£o linear
> model = sm.OLS(data['y'], X)
> results = model.fit()
>
> # Extraindo os resultados necess√°rios
> alpha_hat = results.params[0]
> delta_hat = results.params[1]
> sigma_hat_squared = results.mse_resid
> X_matrix = X.values
>
> # Hip√≥tese nula para alpha
> alpha_0 = 0
>
> # Matriz X'X
> XTX = X_matrix.T @ X_matrix
> # Inversa de X'X
> XTX_inv = np.linalg.inv(XTX)
>
> # Calculando a estat√≠stica t para alpha
> t_alpha = (alpha_hat - alpha_0) / np.sqrt(sigma_hat_squared * XTX_inv[0, 0])
>
> # Imprimindo os resultados
> print(f"Estat√≠stica t para alpha (sem ajuste assint√≥tico): {t_alpha}")
>
> # Calculando a estat√≠stica t ajustada assintoticamente
> T = len(y)
> t_alpha_asymptotic = np.sqrt(T) * (alpha_hat - alpha_0) / np.sqrt(sigma_hat_squared * (np.array([1, 0]) @ np.array([[1, 1/2], [1/2, 1/3]]) @ np.array([1, 0]).T))
> print(f"Estat√≠stica t para alpha (ajustada assintoticamente): {t_alpha_asymptotic}")
> ```
>
> Neste c√≥digo, calculamos a estat√≠stica *t* para testar a hip√≥tese nula $\alpha = 0$ com e sem o ajuste assint√≥tico.  A estat√≠stica *t* original usa o erro padr√£o diretamente da regress√£o, enquanto a estat√≠stica *t* ajustada utiliza a matriz Q e $\sqrt{T}$, conforme derivado na teoria. O ajuste assint√≥tico garante que a estat√≠stica *t* convirja para uma distribui√ß√£o normal padr√£o, mesmo com tamanho amostral finito e poss√≠veis viola√ß√µes de gaussianidade.

De forma semelhante, para o teste *t* para a hip√≥tese nula $\delta = \delta_0$, a estat√≠stica √© definida como [^3]:

$$t_T = \frac{\hat{\delta}_T - \delta_0}{s_T \sqrt{[0 \, 1](X_T'X_T)^{-1}[0 \, 1]'}}$$

Neste caso, a transforma√ß√£o necess√°ria para assegurar a validade assint√≥tica envolve a multiplica√ß√£o por $T^{3/2}$ [^3]:

$$t_T = \frac{T^{3/2}(\hat{\delta}_T - \delta_0)}{s_T \sqrt{[0 \, T^{3/2}](X_T'X_T)^{-1}[0 \, T^{3/2}]'}}$$

Este processo de escalonamento garante que as diferentes taxas de converg√™ncia de $\hat{\alpha}_T$ e $\hat{\delta}_T$ sejam devidamente levadas em conta, resultando em uma estat√≠stica *t* com uma distribui√ß√£o assint√≥tica normal padr√£o.  Usando a propriedade de que $Y_T(X_T'X_T)^{-1}Y_T' \rightarrow Q^{-1}$ [^3], a estat√≠stica *t* pode ser escrita como:

$$t_T = \frac{T^{3/2}(\hat{\delta}_T - \delta_0)}{\sqrt{\hat{\sigma}^2[0 \, 1]Q^{-1}[0 \, 1]'}}$$
que tamb√©m converge para uma distribui√ß√£o normal padr√£o $N(0,1)$ [^3].

*Prova:*
I. A estat√≠stica *t* para testar $\delta = \delta_0$ √©:
    $$t_T = \frac{\hat{\delta}_T - \delta_0}{s_T \sqrt{[0 \, 1](X_T'X_T)^{-1}[0 \, 1]'}}$$
II. Multiplicamos numerador e denominador por $T^{3/2}$:
     $$t_T = \frac{T^{3/2}(\hat{\delta}_T - \delta_0)}{s_T \sqrt{[0 \, T^{3/2}](X_T'X_T)^{-1}[0 \, T^{3/2}]'}}$$
III. Usamos $Y_T(X_T'X_T)^{-1}Y_T' \rightarrow Q^{-1}$:
    $$t_T = \frac{T^{3/2}(\hat{\delta}_T - \delta_0)}{\sqrt{\hat{\sigma}^2[0 \, 1]Q^{-1}[0 \, 1]'}}$$
IV. E, assim,  $t_T \rightarrow N(0, 1)$
    $$t_T \rightarrow N(0, 1)$$‚ñ†

> üí° **Exemplo Num√©rico:** Continuando com o mesmo conjunto de dados, agora calculamos a estat√≠stica *t* para testar a hip√≥tese nula $\delta = 0.5$:
> ```python
> import numpy as np
> import pandas as pd
> import statsmodels.api as sm
>
> # Dados de exemplo (reutilizando os dados anteriores)
> t = np.arange(1, 101)  # Tempo de 1 a 100
> np.random.seed(42)
> eps = np.random.normal(0, 2, 100)  # Erros aleat√≥rios
> alpha_true = 5
> delta_true = 0.5
> y = alpha_true + delta_true * t + eps  # Gerando y_t
>
> # Criando um DataFrame para facilitar a an√°lise
> data = pd.DataFrame({'t': t, 'y': y})
>
> # Adicionando uma constante para o modelo
> X = sm.add_constant(data['t'])
>
> # Ajustando o modelo de regress√£o linear
> model = sm.OLS(data['y'], X)
> results = model.fit()
>
> # Extraindo os resultados necess√°rios
> alpha_hat = results.params[0]
> delta_hat = results.params[1]
> sigma_hat_squared = results.mse_resid
> X_matrix = X.values
>
> # Hip√≥tese nula para delta
> delta_0 = 0.5
>
> # Matriz X'X
> XTX = X_matrix.T @ X_matrix
> # Inversa de X'X
> XTX_inv = np.linalg.inv(XTX)
>
> # Calculando a estat√≠stica t para delta
> t_delta = (delta_hat - delta_0) / np.sqrt(sigma_hat_squared * XTX_inv[1, 1])
>
> # Imprimindo os resultados
> print(f"Estat√≠stica t para delta (sem ajuste assint√≥tico): {t_delta}")
>
> # Calculando a estat√≠stica t ajustada assintoticamente
> T = len(y)
> t_delta_asymptotic = (T**(3/2)) * (delta_hat - delta_0) / np.sqrt(sigma_hat_squared * (np.array([0, 1]) @ np.array([[1, 1/2], [1/2, 1/3]]) @ np.array([0, 1]).T))
> print(f"Estat√≠stica t para delta (ajustada assintoticamente): {t_delta_asymptotic}")
> ```
>
> Similar ao exemplo anterior, aqui calculamos a estat√≠stica *t* para testar $\delta = 0.5$, com e sem o ajuste assint√≥tico. O fator de escala $T^{3/2}$ √© usado na estat√≠stica ajustada, refletindo a taxa de converg√™ncia de $\hat{\delta}_T$. Comparando ambas estat√≠sticas, podemos observar como o ajuste assint√≥tico influencia a estat√≠stica do teste.

**Teorema 1**
Al√©m dos testes *t* individuais para os par√¢metros $\alpha$ e $\delta$, podemos tamb√©m realizar um teste *F* para verificar a signific√¢ncia conjunta dos par√¢metros em um modelo de tend√™ncia temporal simples. A hip√≥tese nula conjunta √© dada por $H_0: \alpha = \alpha_0 \text{ e } \delta = \delta_0$. A estat√≠stica *F* √© calculada da seguinte forma:
$$F_T = \frac{(\mathbf{y} - X\mathbf{\beta_0})'(X(X'X)^{-1}X')(\mathbf{y} - X\mathbf{\beta_0})/k}{(\mathbf{y} - X\mathbf{\hat{\beta}})'(\mathbf{y} - X\mathbf{\hat{\beta}})/(T-k)},$$
onde $\mathbf{\beta_0} = [\alpha_0, \delta_0]'$, $\mathbf{\hat{\beta}} = [\hat{\alpha}_T, \hat{\delta}_T]'$, $X$ √© a matriz de regressores (coluna de uns e a tend√™ncia temporal), e $k=2$ √© o n√∫mero de restri√ß√µes. Essa estat√≠stica *F* converge para uma distribui√ß√£o $\chi^2$ com $k$ graus de liberdade, dividida por $k$, ou seja, uma distribui√ß√£o $F$ com $k$ e $T-k$ graus de liberdade.  Notavelmente, sob a hip√≥tese nula, $F_T$ possui uma distribui√ß√£o assint√≥tica $F(k, \infty)$.

*Prova:*
I. A estat√≠stica *F* para o teste de hip√≥tese conjunta √© definida como a raz√£o entre a varia√ß√£o explicada pela restri√ß√£o e a varia√ß√£o n√£o explicada no modelo.
II. Sob a hip√≥tese nula, a estat√≠stica *F* converge em distribui√ß√£o para uma distribui√ß√£o *F* com $k$ e $T-k$ graus de liberdade.
III. Quando $T \to \infty$, a distribui√ß√£o $F(k,T-k)$ se aproxima da distribui√ß√£o $\chi^2(k)/k$.
IV. Em nosso contexto, com $k=2$, o teste *F* compara a qualidade do modelo restrito (sob $H_0$) com a qualidade do modelo irrestrito.
V. A converg√™ncia para uma distribui√ß√£o $\chi^2$ dividida por seus graus de liberdade, na situa√ß√£o assint√≥tica, √© uma consequ√™ncia do teorema do limite central aplicado aos estimadores de MQO em modelos com tend√™ncias temporais.
‚ñ†
> üí° **Exemplo Num√©rico:** Utilizando o mesmo conjunto de dados, agora calculamos a estat√≠stica *F* para testar a hip√≥tese conjunta $H_0: \alpha = 0 \text{ e } \delta = 0.5$:
> ```python
> import numpy as np
> import pandas as pd
> import statsmodels.api as sm
>
> # Dados de exemplo (reutilizando os dados anteriores)
> t = np.arange(1, 101)  # Tempo de 1 a 100
> np.random.seed(42)
> eps = np.random.normal(0, 2, 100)  # Erros aleat√≥rios
> alpha_true = 5
> delta_true = 0.5
> y = alpha_true + delta_true * t + eps  # Gerando y_t
>
> # Criando um DataFrame para facilitar a an√°lise
> data = pd.DataFrame({'t': t, 'y': y})
>
> # Adicionando uma constante para o modelo
> X = sm.add_constant(data['t'])
>
> # Ajustando o modelo de regress√£o linear
> model = sm.OLS(data['y'], X)
> results = model.fit()
>
> # Extraindo os resultados necess√°rios
> alpha_hat = results.params[0]
> delta_hat = results.params[1]
> beta_hat = np.array([alpha_hat, delta_hat])
> sigma_hat_squared = results.mse_resid
> y_values = data['y'].values
> X_matrix = X.values
> T = len(y)
> k = 2
>
> # Hip√≥tese nula
> beta_0 = np.array([0, 0.5])
>
> # Calculando a estat√≠stica F
> y_hat = X_matrix @ beta_hat
> y_hat_restricted = X_matrix @ beta_0
>
> SST = np.sum((y_values - np.mean(y_values))**2)
> SSR = np.sum((y_hat - np.mean(y_values))**2)
> SSR_restricted = np.sum((y_hat_restricted - np.mean(y_values))**2)
> SSE = np.sum((y_values - y_hat)**2)
>
> F_stat = ((SSR - SSR_restricted) / k) / (SSE / (T - k))
>
> print(f"Estat√≠stica F: {F_stat}")
>
> # Estat√≠stica F do modelo
> F_stat_model = results.fvalue
> print(f"Estat√≠stica F do modelo (statsmodels): {F_stat_model}")
> ```
>
> Este exemplo mostra como calcular a estat√≠stica *F* para testar a hip√≥tese conjunta. A estat√≠stica *F* compara a qualidade do modelo irrestrito com o modelo restrito, onde $\alpha$ e $\delta$ s√£o fixados em valores espec√≠ficos. A fun√ß√£o `statsmodels` tamb√©m √© usada para comparar com o resultado obtido manualmente. Sob a hip√≥tese nula, essa estat√≠stica segue uma distribui√ß√£o *F* com 2 e T-2 graus de liberdade, que pode ser utilizada para verificar se a hip√≥tese nula √© rejeitada ou n√£o.

### Conclus√£o
Nesta se√ß√£o, exploramos os testes de hip√≥teses para modelos de tend√™ncia temporal simples, com foco espec√≠fico nos testes *t* para as hip√≥teses nulas $\alpha = \alpha_0$ e $\delta = \delta_0$ [^3]. A chave para a validade assint√≥tica desses testes reside na transforma√ß√£o das estat√≠sticas usando fatores de escala apropriados, como $\sqrt{T}$ e $T^{3/2}$, que s√£o equivalentes ao uso da vari√¢ncia amostral e a inversa da matriz $X'X$. Essas transforma√ß√µes garantem que os testes sejam assintoticamente v√°lidos mesmo em condi√ß√µes n√£o Gaussianas [^3].

A estat√≠stica para testar a hip√≥tese nula $\alpha = \alpha_0$ √© definida usando a vari√¢ncia amostral e a inversa da matriz $(X'X)^{-1}$, que, na pr√°tica, resulta na utiliza√ß√£o de $\sqrt{T}$ como fator de escala. Essa transforma√ß√£o √© essencial para garantir que a distribui√ß√£o assint√≥tica da estat√≠stica *t* se aproxime de uma distribui√ß√£o normal padr√£o, permitindo testes de hip√≥teses v√°lidos mesmo sob condi√ß√µes n√£o gaussianas. A estat√≠stica para o teste $\delta = \delta_0$ utiliza um procedimento de escala similar, empregando $T^{3/2}$ como fator de multiplica√ß√£o para assegurar que a distribui√ß√£o assint√≥tica tamb√©m se aproxime de uma distribui√ß√£o normal padr√£o [^3].

Em resumo, as estat√≠sticas de teste para os par√¢metros $\alpha$ e $\delta$ s√£o adequadamente escalonadas, utilizando $\sqrt{T}$ para $\alpha$ e $T^{3/2}$ para $\delta$. Este procedimento garante a validade assint√≥tica dos testes, superando as dificuldades associadas √†s diferentes taxas de converg√™ncia dos estimadores [^3].

### Refer√™ncias
[^1]:  The coefficients of regression models involving unit roots or deterministic time trends are typically estimated by ordinary least squares. However, the asymptotic distributions of the coefficient estimates cannot be calculated in the same way as are those for regression models involving stationary variables. Among other difficulties, the estimates of different parameters will in general have different asymptotic rates of convergence. This chapter introduces the idea of different rates of convergence and develops a general approach to obtaining asymptotic distributions suggested by Sims, Stock, and Watson (1990). This chapter deals exclusively with processes involving deterministic time trends but no unit roots. One of the results for such processes will be that the usual OLS t and F statistics, calculated in the usual way, have the same asymptotic distributions as they do for stationary regressions. Although the limiting distributions are standard, the techniques used to verify these limiting distributions are different from those used in Chapter 8. These techniques will also be used to develop the asymptotic distributions for processes including unit roots in Chapters 17 and 18.
[^2]: This section considers OLS estimation of the parameters of a simple time trend, $y_t = \alpha + \delta t + \epsilon_t$, for $\epsilon_t$ a white noise process.
[^3]: If the innovations $\epsilon_t$ for the simple time trend [16.1.1] are Gaussian, then the OLS estimates $\hat{\alpha}_T$ and $\hat{\delta}_T$ are Gaussian and the usual OLS *t* and *F* tests have exact small-sample *t* and *F* distributions for all sample sizes T. Thus, despite the fact that $\hat{\alpha}_T$ and $\hat{\delta}_T$ have different asymptotic rates of convergence, the standard errors $\hat{\sigma}_{\hat{\alpha}_T}$ and $\hat{\sigma}_{\hat{\delta}_T}$, evidently have offsetting asymptotic behavior so that the statistics such as $(\hat{\delta}_T - \delta)/ \hat{\sigma}_{\hat{\delta}_T}$ are asymptotically N(0, 1) when the innovations are Gaussian. We might thus conjecture that the usual *t* and *F* tests are asymptotically valid for non-Gaussian innovations as well. This conjecture is indeed correct, as we now verify.
<!-- END -->
