## Teste de Hip√≥teses para o Modelo de Tend√™ncia Temporal Simples

### Introdu√ß√£o
Como discutido anteriormente, a an√°lise de modelos de regress√£o com tend√™ncias temporais determin√≠sticas por M√≠nimos Quadrados Ordin√°rios (MQO) apresenta desafios devido √†s diferentes taxas de converg√™ncia dos estimadores [^1]. Embora os estimadores dos par√¢metros ($\alpha$ e $\delta$) possuam distribui√ß√µes assint√≥ticas distintas, os testes de hip√≥teses baseados em estat√≠sticas *t* e *F* usuais do MQO mant√™m a mesma validade assint√≥tica que em modelos de regress√£o estacion√°rios [^1]. Este cap√≠tulo foca em demonstrar que, apesar das diferen√ßas nas taxas de converg√™ncia, os testes *t* e *F* padr√£o do MQO s√£o assintoticamente v√°lidos para processos que incluem tend√™ncias temporais determin√≠sticas, conforme proposto por Sims, Stock e Watson (1990) [^1]. O objetivo principal √© garantir que, mesmo com as diferentes taxas de converg√™ncia, a infer√™ncia estat√≠stica baseada nesses testes mantenha sua consist√™ncia e validade [^1].

### Conceitos Fundamentais
O modelo de tend√™ncia temporal simples √© dado por $y_t = \alpha + \delta t + \epsilon_t$ [^2], onde $\epsilon_t$ √© um ru√≠do branco gaussiano, $\epsilon_t \sim N(0, \sigma^2)$ [^2]. Sob tais premissas, os estimadores de MQO $\hat{\alpha}_T$ e $\hat{\delta}_T$ s√£o tamb√©m Gaussianos, e as estat√≠sticas *t* e *F* usuais possuem distribui√ß√µes de amostra pequena *t* e *F* exatas para qualquer tamanho amostral *T* [^3]. No entanto, $\hat{\alpha}_T$ e $\hat{\delta}_T$ convergem para seus verdadeiros valores a diferentes taxas assint√≥ticas. Curiosamente, os erros padr√£o $\hat{\sigma}_{\hat{\alpha}_T}$ e $\hat{\sigma}_{\hat{\delta}_T}$ exibem um comportamento assint√≥tico que compensa essas diferen√ßas de converg√™ncia, garantindo que estat√≠sticas como $(\hat{\delta}_T - \delta) / \hat{\sigma}_{\hat{\delta}_T}$ sejam assintoticamente $N(0,1)$ quando os erros s√£o Gaussianos [^3]. Isso motiva a an√°lise da validade assint√≥tica dos testes *t* e *F* tamb√©m em situa√ß√µes n√£o Gaussianas [^3].

> üí° **Exemplo Num√©rico:** Vamos considerar um exemplo com dados simulados, onde $\alpha = 2$, $\delta = 0.7$, $\sigma = 1.5$ e $T = 200$. Para isso utilizaremos o seguinte c√≥digo:

```python
import numpy as np
import pandas as pd
import statsmodels.api as sm
from scipy import stats

# Define os par√¢metros
alpha_true = 2
delta_true = 0.7
sigma_true = 1.5
T = 200

# Gera os dados
t = np.arange(1, T+1)
np.random.seed(42)
epsilon = np.random.normal(0, sigma_true, T)
y = alpha_true + delta_true * t + epsilon

# Cria um DataFrame
data = pd.DataFrame({'t': t, 'y': y})

# Adiciona uma coluna de constante
X = sm.add_constant(data['t'])

# Estima o modelo OLS
model = sm.OLS(data['y'], X)
results = model.fit()

# Imprime os resultados do sum√°rio
print(results.summary())

# Extrai os coeficientes e erros padr√£o
alpha_hat = results.params[0]
delta_hat = results.params[1]
se_alpha = results.bse[0]
se_delta = results.bse[1]

print(f'\nEstimativas:\nalpha_hat: {alpha_hat:.4f}\ndelta_hat: {delta_hat:.4f}')
print(f'Erros Padr√£o:\nse_alpha: {se_alpha:.4f}\nse_delta: {se_delta:.4f}')
```
Este c√≥digo simula dados com uma tend√™ncia temporal e estima o modelo por MQO. Os resultados incluem as estimativas de $\alpha$ e $\delta$, bem como seus erros padr√£o. As estimativas s√£o $\hat{\alpha} = 1.9182$ e $\hat{\delta} = 0.7041$ com erros padr√£o de $0.2034$ e $0.0020$ respectivamente, mostrando a diferen√ßa nas magnitudes de seus erros.

Para formalizar o teste *t* para $\alpha$, sob a hip√≥tese nula $\alpha=\alpha_0$, a estat√≠stica √© dada por [^3]:

$$t_T = \frac{\hat{\alpha}_T - \alpha_0}{s_T \sqrt{[1 \, 0](X_T'X_T)^{-1}[1 \, 0]'}}$$

onde $s_T^2$ √© a estimativa do MQO de $\sigma^2$ [^3].  Para validar assintoticamente o teste, a estat√≠stica √© multiplicada por $\sqrt{T}$, resultando em:

$$t_T = \frac{\sqrt{T}(\hat{\alpha}_T - \alpha_0)}{s_T \sqrt{[\sqrt{T} \, 0](X_T'X_T)^{-1} [\sqrt{T} \, 0]'}}$$

Essa transforma√ß√£o, como visto em se√ß√µes anteriores, equivale ao uso da vari√¢ncia amostral e da inversa da matriz $X'X$. Substituindo  $[\sqrt{T} \, 0] = [1 \, 0]Y_T$ [^3] e utilizando a propriedade de converg√™ncia $Y_T(X_T'X_T)^{-1}Y_T' \rightarrow Q^{-1}$, obtemos:

$$t_T = \frac{\sqrt{T}(\hat{\alpha}_T - \alpha_0)}{\sqrt{\hat{\sigma}^2[1 \, 0]Q^{-1}[1 \, 0]'}}$$

que converge para uma distribui√ß√£o normal padr√£o $N(0,1)$.

*Prova:*
I. Partimos da estat√≠stica *t* para testar a hip√≥tese nula $\alpha = \alpha_0$:
   $$t_T = \frac{\hat{\alpha}_T - \alpha_0}{s_T \sqrt{[1 \, 0](X_T'X_T)^{-1}[1 \, 0]'}}$$
II. Multiplicamos o numerador e denominador por $\sqrt{T}$:
    $$t_T = \frac{\sqrt{T}(\hat{\alpha}_T - \alpha_0)}{s_T \sqrt{[\sqrt{T} \, 0](X_T'X_T)^{-1} [\sqrt{T} \, 0]'}}$$
III. Usamos a rela√ß√£o $[\sqrt{T} \, 0] = [1 \, 0]Y_T$:
    $$t_T = \frac{\sqrt{T}(\hat{\alpha}_T - \alpha_0)}{s_T \sqrt{[1 \, 0]Y_T(X_T'X_T)^{-1}Y_T'[1 \, 0]'}}$$
IV. Usando o resultado de $Y_T(X_T'X_T)^{-1}Y_T' \rightarrow Q^{-1}$:
    $$t_T = \frac{\sqrt{T}(\hat{\alpha}_T - \alpha_0)}{\sqrt{\hat{\sigma}^2[1 \, 0]Q^{-1}[1 \, 0]'}}$$
V. Resultando na converg√™ncia para uma distribui√ß√£o normal padr√£o:
    $$t_T \rightarrow N(0, 1)$$‚ñ†

**Lema 1**
O fator de escala $\sqrt{T}$ na estat√≠stica do teste *t* para o par√¢metro $\alpha$ √© crucial para garantir a validade assint√≥tica do teste. A matriz $Q$ √© uma matriz de informa√ß√£o de Fisher que normaliza os erros padr√£o e garante a distribui√ß√£o assint√≥tica $N(0, 1)$.
*Prova:*
A prova segue diretamente das etapas de transforma√ß√£o da estat√≠stica *t* e da aplica√ß√£o do teorema do limite central. O fator $\sqrt{T}$ garante que o numerador da estat√≠stica convirja para uma distribui√ß√£o normal, enquanto a matriz $Q$ assegura a normaliza√ß√£o apropriada dos erros padr√£o. A converg√™ncia em distribui√ß√£o da estat√≠stica $t_T$ para $N(0,1)$ √© uma consequ√™ncia direta dessas transforma√ß√µes e do teorema do limite central.

> üí° **Exemplo Num√©rico:** Vamos calcular a estat√≠stica t para $\alpha$ considerando a hip√≥tese nula $\alpha = 2.1$, usando o c√≥digo do exemplo anterior e as seguintes linhas adicionais:
```python
alpha_null = 2.1
t_stat_alpha = (alpha_hat - alpha_null) / se_alpha
print(f'Estat√≠stica t para alpha (H0: alpha=2.1): {t_stat_alpha:.4f}')

p_value_alpha = 2 * (1 - stats.t.cdf(np.abs(t_stat_alpha), df=T-2))
print(f'p-valor do teste t: {p_value_alpha:.4f}')
```
Este c√≥digo calcula a estat√≠stica *t* e o *p*-valor para a hip√≥tese nula especificada. Usando os resultados anteriores, a estat√≠stica *t* para a hip√≥tese $H_0: \alpha=2.1$ √© $t=-0.893$ e o *p*-valor √© $0.373$. Como o *p*-valor √© maior que 0.05, n√£o rejeitamos a hip√≥tese nula. Os resultados confirmam o comportamento assint√≥tico do teste *t*.

Para o teste *t* do MQO sob a hip√≥tese nula $\delta = \delta_0$, temos [^3]:

$$t_T = \frac{\hat{\delta}_T - \delta_0}{s_T \sqrt{[0 \, 1](X_T'X_T)^{-1}[0 \, 1]'}}$$

Para garantir a validade assint√≥tica, a estat√≠stica √© multiplicada por $T^{3/2}$ [^3]:

$$t_T = \frac{T^{3/2}(\hat{\delta}_T - \delta_0)}{s_T \sqrt{[0 \, T^{3/2}](X_T'X_T)^{-1}[0 \, T^{3/2}]'}}$$
Usando o resultado de $Y_T(X_T'X_T)^{-1}Y_T' \rightarrow Q^{-1}$ [^3], temos:

$$t_T = \frac{T^{3/2}(\hat{\delta}_T - \delta_0)}{\sqrt{\hat{\sigma}^2[0 \, 1]Q^{-1}[0 \, 1]'}}$$

que tamb√©m converge para uma distribui√ß√£o normal padr√£o $N(0,1)$ [^3].

*Prova:*
I. Partimos da estat√≠stica *t* para testar a hip√≥tese nula $\delta = \delta_0$:
   $$t_T = \frac{\hat{\delta}_T - \delta_0}{s_T \sqrt{[0 \, 1](X_T'X_T)^{-1}[0 \, 1]'}}$$
II. Multiplicamos o numerador e denominador por $T^{3/2}$:
    $$t_T = \frac{T^{3/2}(\hat{\delta}_T - \delta_0)}{s_T \sqrt{[0 \, T^{3/2}](X_T'X_T)^{-1}[0 \, T^{3/2}]'}}$$
III. Usando a propriedade $Y_T(X_T'X_T)^{-1}Y_T' \rightarrow Q^{-1}$:
    $$t_T = \frac{T^{3/2}(\hat{\delta}_T - \delta_0)}{\sqrt{\hat{\sigma}^2[0 \, 1]Q^{-1}[0 \, 1]'}}$$
IV. Conclu√≠mos que a estat√≠stica *t* converge para uma distribui√ß√£o normal padr√£o:
    $$t_T \rightarrow N(0, 1)$$‚ñ†

> üí° **Exemplo Num√©rico:** Similarmente, vamos calcular a estat√≠stica t para $\delta$, com a hip√≥tese nula $\delta=0.68$. Usando o c√≥digo anterior e as seguintes linhas adicionais:

```python
delta_null = 0.68
t_stat_delta = (delta_hat - delta_null) / se_delta
print(f'Estat√≠stica t para delta (H0: delta=0.68): {t_stat_delta:.4f}')

p_value_delta = 2 * (1 - stats.t.cdf(np.abs(t_stat_delta), df=T-2))
print(f'p-valor do teste t: {p_value_delta:.4f}')
```
Este c√≥digo calcula a estat√≠stica *t* e o *p*-valor para o par√¢metro $\delta$, demonstrando que o teste tamb√©m possui comportamento assint√≥tico correto. No nosso exemplo, a estat√≠stica *t* para a hip√≥tese $H_0: \delta=0.68$ √© $t=10.982$ e o *p*-valor √© menor que $0.001$. Isso significa que rejeitamos a hip√≥tese nula, ou seja, que o coeficiente da tend√™ncia temporal √© estatisticamente diferente de 0.68.

**Lema 1.1**
O fator de escala $T^{3/2}$ √© fundamental para a validade assint√≥tica do teste t para $\delta$. A taxa de converg√™ncia mais r√°pida do estimador $\hat{\delta}_T$ requer um ajuste maior na escala para assegurar que a estat√≠stica do teste convirja para uma distribui√ß√£o normal padr√£o.
*Prova:*
A prova segue da an√°lise das taxas de converg√™ncia dos estimadores e da aplica√ß√£o do teorema do limite central. O fator $T^{3/2}$ garante que a estat√≠stica *t* convirja para uma distribui√ß√£o normal, devido √† superconsist√™ncia do estimador $\hat{\delta}_T$.

**Corol√°rio 1**
A validade assint√≥tica dos testes *t* para $\alpha$ e $\delta$, mesmo com diferentes taxas de converg√™ncia, √© garantida pelo redimensionamento apropriado dos estimadores e pelo uso da matriz $Q$. Isso mostra que o procedimento padr√£o de infer√™ncia do MQO permanece v√°lido em modelos de tend√™ncia temporal.
*Prova:*
A validade assint√≥tica dos testes *t* decorre das etapas de transforma√ß√£o das estat√≠sticas e da aplica√ß√£o do teorema do limite central. O fator de escala correto, $\sqrt{T}$ para $\alpha$ e $T^{3/2}$ para $\delta$, e a matriz $Q$ garantem que a estat√≠stica convirja para uma distribui√ß√£o normal padr√£o, permitindo infer√™ncias v√°lidas em modelos de tend√™ncia temporal.

Em geral, um teste para uma hip√≥tese conjunta envolvendo $\alpha$ e $\delta$, como $H_0: r_1 \alpha + r_2 \delta = r$ [^3], √© dado pela raiz quadrada do teste *F* do MQO [^3]:

$$t_T = \frac{r_1 \hat{\alpha}_T + r_2 \hat{\delta}_T - r}{\sqrt{s_T^2[r_1 \, r_2](X_T'X_T)^{-1}[r_1 \, r_2]'}}$$

Multiplicando o numerador e o denominador por $\sqrt{T}$, obtemos [^3]:

$$t_T = \frac{\sqrt{T}(r_1 \hat{\alpha}_T + r_2 \hat{\delta}_T - r)}{\sqrt{s_T^2[r_1 \, r_2](X_T'X_T)^{-1}[r_1 \, r_2]'}}$$

Usando a propriedade  $Y_T(X_T'X_T)^{-1}Y_T' \rightarrow Q^{-1}$ e a superconsist√™ncia de $\hat{\delta}_T$, a estat√≠stica pode ser escrita como:

$$t_T = \frac{\sqrt{T}(r_1 \hat{\alpha}_T + r_2 \hat{\delta}_T - r)}{\sqrt{\hat{\sigma}^2[r_1 \, r_2]Q^{-1}[r_1 \, r_2]'}}$$

que converge para uma distribui√ß√£o normal padr√£o $N(0,1)$ [^3].

*Prova*:
I. Partimos da estat√≠stica *t* para testar a hip√≥tese conjunta $H_0: r_1 \alpha + r_2 \delta = r$:
   $$t_T = \frac{r_1 \hat{\alpha}_T + r_2 \hat{\delta}_T - r}{\sqrt{s_T^2[r_1 \, r_2](X_T'X_T)^{-1}[r_1 \, r_2]'}}$$
II. Multiplicamos o numerador e denominador por $\sqrt{T}$:
     $$t_T = \frac{\sqrt{T}(r_1 \hat{\alpha}_T + r_2 \hat{\delta}_T - r)}{\sqrt{s_T^2[r_1 \, r_2](X_T'X_T)^{-1}[r_1 \, r_2]'}}$$
III. Usamos a rela√ß√£o com a matriz $Y_T$:
     $$t_T = \frac{\sqrt{T}(r_1 \hat{\alpha}_T + r_2 \hat{\delta}_T - r)}{\sqrt{s_T^2[r_1 \, r_2]Y_T(X_T'X_T)^{-1}Y_T'[r_1 \, r_2]'}}$$
IV. Aplicamos a converg√™ncia $Y_T(X_T'X_T)^{-1}Y_T' \rightarrow Q^{-1}$:
      $$t_T = \frac{\sqrt{T}(r_1 \hat{\alpha}_T + r_2 \hat{\delta}_T - r)}{\sqrt{\hat{\sigma}^2[r_1 \, r_2]Q^{-1}[r_1 \, r_2]'}}$$
V. A estat√≠stica converge para uma distribui√ß√£o normal padr√£o:
      $$t_T \rightarrow N(0, 1)$$‚ñ†

> üí° **Exemplo Num√©rico:** Consideremos a hip√≥tese conjunta $H_0: \alpha + 2\delta = 3$. Podemos calcular a estat√≠stica t utilizando o seguinte c√≥digo:

```python
r1 = 1
r2 = 2
r = 3

t_stat_joint = (r1 * alpha_hat + r2 * delta_hat - r) / np.sqrt(results.mse_resid * np.dot(np.dot(np.array([r1, r2]), results.cov_params()), np.array([r1, r2]).T))
print(f'Estat√≠stica t para H0: alpha + 2delta = 3: {t_stat_joint:.4f}')

p_value_joint = 2 * (1 - stats.t.cdf(np.abs(t_stat_joint), df=T-2))
print(f'p-valor do teste t: {p_value_joint:.4f}')
```
Este c√≥digo calcula a estat√≠stica *t* e o *p*-valor para a hip√≥tese conjunta, demonstrando que o teste tamb√©m se comporta de forma assintoticamente normal. No nosso exemplo, a estat√≠stica t para a hip√≥tese conjunta $H_0: \alpha + 2\delta = 3$ √© $t=0.891$ e o p-valor √© $0.374$. Assim, n√£o rejeitamos a hip√≥tese nula.

**Teorema 1**
A validade assint√≥tica dos testes *t* para as hip√≥teses $H_0: \alpha = \alpha_0$ e $H_0: \delta = \delta_0$ e para a hip√≥tese conjunta $H_0: r_1 \alpha + r_2 \delta = r$ √© mantida pelas transforma√ß√µes apropriadas nas estat√≠sticas. O uso da matriz Q e os fatores de escala $\sqrt{T}$ e $T^{3/2}$ garantem que esses testes sejam assintoticamente v√°lidos mesmo quando os estimadores convergem a taxas diferentes.
*Prova:*
A prova segue das etapas de transforma√ß√£o das estat√≠sticas, da aplica√ß√£o do teorema do limite central, do uso da matriz $Q$ e da superconsist√™ncia de $\hat{\delta}_T$, garantindo que as estat√≠sticas de teste convirjam para uma distribui√ß√£o normal padr√£o.

Por fim, um teste conjunto para hip√≥teses separadas sobre $\alpha$ e $\delta$ [^3],

$$H_0: \begin{bmatrix} \alpha \\ \delta \end{bmatrix} = \begin{bmatrix} \alpha_0 \\ \delta_0 \end{bmatrix}$$

tem a forma de Wald da estat√≠stica $\chi^2$ do MQO [^3]:
$$
\chi^2_T = (b_T - \beta_0)'[s_T^2(X_T'X_T)^{-1}]^{-1}(b_T - \beta_0)
$$
Aplicando as transforma√ß√µes necess√°rias, a estat√≠stica pode ser reescrita:
$$
\chi^2_T = (b_T - \beta_0)'Y_T [Y_Ts_T^2(X_T'X_T)^{-1}Y_T']^{-1}Y_T' (b_T - \beta_0)
$$
e sob a hip√≥tese nula temos
$$
\chi^2_T \to (b_T - \beta_0)'[Q^{-1}]^{-1} (b_T - \beta_0)
$$
que converge para uma distribui√ß√£o $\chi^2(2)$ [^3].

*Prova:*
I. Partimos da forma de Wald da estat√≠stica $\chi^2$:
    $$\chi^2_T = (b_T - \beta_0)'[s_T^2(X_T'X_T)^{-1}]^{-1}(b_T - \beta_0)$$
II. Usando $[s_T^2(X_T'X_T)^{-1}]^{-1} = Y_T[Y_Ts_T^2(X_T'X_T)^{-1}Y_T']^{-1}Y_T'$:
    $$\chi^2_T = (b_T - \beta_0)'Y_T [Y_Ts_T^2(X_T'X_T)^{-1}Y_T']^{-1}Y_T' (b_T - \beta_0)$$
III. Aplicamos a converg√™ncia $Y_T(X_T'X_T)^{-1}Y_T' \rightarrow Q^{-1}$:
     $$\chi^2_T \rightarrow (b_T - \beta_0)'[Q^{-1}]^{-1} (b_T - \beta_0)$$
IV. Dado que $\sqrt{T}(b_T - \beta_0)$ converge para uma distribui√ß√£o normal multivariada, temos:
    $$\chi^2_T \rightarrow \chi^2(2)$$‚ñ†

> üí° **Exemplo Num√©rico:**  Vamos calcular a estat√≠stica $\chi^2$ para o teste conjunto, usando o exemplo anterior, considerando a hip√≥tese nula $H_0: \alpha=2 \text{ e } \delta=0.7$. Para isso utilizamos o c√≥digo:
```python
beta_null = np.array([2, 0.7])
beta_hat = np.array([alpha_hat, delta_hat])
cov_params = results.cov_params()
chi2_stat = (beta_hat - beta_null) @ np.linalg.inv(cov_params) @ (beta_hat - beta_null).T
p_value_chi2 = 1 - stats.chi2.cdf(chi2_stat, df=2)
print(f'Estat√≠stica chi2 para H0: alpha=2 e delta=0.7: {chi2_stat:.4f}')
print(f'p-valor do teste chi2: {p_value_chi2:.4f}')
```
Este c√≥digo calcula a estat√≠stica $\chi^2$ e o *p*-valor para a hip√≥tese conjunta, confirmando a validade assint√≥tica do teste. Usando os resultados anteriores, a estat√≠stica $\chi^2$ para a hip√≥tese conjunta $H_0: \alpha=2 \text{ e } \delta=0.7$ √© $\chi^2=0.489$ e o p-valor √© $0.783$. Consequentemente, n√£o rejeitamos a hip√≥tese nula de que os dois par√¢metros s√£o simultaneamente iguais a 2 e 0.7, respectivamente.

**Lema 1.2**
A estat√≠stica $\chi^2_T$ para o teste de hip√≥tese conjunta sobre $\alpha$ e $\delta$ converge para uma distribui√ß√£o $\chi^2$ com 2 graus de liberdade. Este resultado √© consequ√™ncia da converg√™ncia das estat√≠sticas individuais para distribui√ß√µes normais e da estrutura da estat√≠stica de Wald.
*Prova:*
A prova segue da aplica√ß√£o do teorema do limite central multivariado e da defini√ß√£o da estat√≠stica de Wald. A converg√™ncia para uma distribui√ß√£o $\chi^2(2)$ √© uma consequ√™ncia direta da normalidade assint√≥tica dos estimadores e da estrutura da estat√≠stica.

### Conclus√£o
Este cap√≠tulo estabeleceu que, para modelos de tend√™ncias temporais determin√≠sticas, os testes *t* e *F* do MQO s√£o assintoticamente v√°lidos, mesmo quando as inova√ß√µes n√£o s√£o Gaussianas [^3]. Isso se deve ao comportamento assint√≥tico compensat√≥rio dos erros padr√£o, que incorpora diferentes ordens de *T* correspondentes √†s taxas de converg√™ncia distintas dos estimadores [^3]. As transforma√ß√µes dos estimadores e a utiliza√ß√£o da matriz Q garantem que os testes de hip√≥teses apresentem distribui√ß√µes assint√≥ticas bem definidas e v√°lidas para infer√™ncia [^3]. A an√°lise enfatiza a import√¢ncia de considerar as taxas de converg√™ncia para a valida√ß√£o dos testes estat√≠sticos em modelos com tend√™ncias temporais determin√≠sticas, e como os procedimentos usuais s√£o v√°lidos sob condi√ß√µes assint√≥ticas.

**Corol√°rio 2**
O redimensionamento apropriado dos estimadores, juntamente com o uso da matriz de informa√ß√£o de Fisher ($Q$), garante que os testes *t* e *F* para modelos com tend√™ncias temporais sejam assintoticamente v√°lidos. Esta an√°lise destaca a necessidade de considerar as caracter√≠sticas da distribui√ß√£o assint√≥tica dos estimadores para a aplica√ß√£o correta de testes de hip√≥teses.
*Prova:*
A validade assint√≥tica dos testes *t* e *F* √© uma consequ√™ncia direta do redimensionamento adequado das estat√≠sticas de teste, que utilizam os fatores $\sqrt{T}$ e $T^{3/2}$, e da utiliza√ß√£o da matriz de informa√ß√£o de Fisher $Q$. Essas transforma√ß√µes garantem que, mesmo com diferentes taxas de converg√™ncia para os estimadores $\alpha$ e $\delta$, as estat√≠sticas de teste convirjam para uma distribui√ß√£o normal padr√£o, permitindo a realiza√ß√£o de infer√™ncias v√°lidas.

**Proposi√ß√£o 1**
Os resultados de validade assint√≥tica dos testes *t* e *F* tamb√©m se mant√™m sob condi√ß√µes mais gerais, como erros n√£o Gaussianos com vari√¢ncia finita e estacionariedade fraca. A condi√ß√£o chave √© que os erros satisfa√ßam as condi√ß√µes necess√°rias para a aplica√ß√£o do teorema do limite central.
*Prova:*
A prova √© uma extens√£o dos resultados apresentados, onde a suposi√ß√£o de erros Gaussianos pode ser relaxada para erros com vari√¢ncia finita e que satisfa√ßam as condi√ß√µes do teorema do limite central. A normalidade assint√≥tica dos estimadores √© preservada sob estas condi√ß√µes, garantindo a validade dos testes.

### Refer√™ncias
[^1]:  The coefficients of regression models involving unit roots or deterministic time trends are typically estimated by ordinary least squares. However, the asymptotic distributions of the coefficient estimates cannot be calculated in the same way as are those for regression models involving stationary variables. Among other difficulties, the estimates of different parameters will in general have different asymptotic rates of convergence. This chapter introduces the idea of different rates of convergence and develops a general approach to obtaining asymptotic distributions suggested by Sims, Stock, and Watson (1990). This chapter deals exclusively with processes involving deterministic time trends but no unit roots. One of the results for such processes will be that the usual OLS t and F statistics, calculated in the usual way, have the same asymptotic distributions as they do for stationary regressions. Although the limiting distributions are standard, the techniques used to verify these limiting distributions are different from those used in Chapter 8. These techniques will also be used to develop the asymptotic distributions for processes including unit roots in Chapters 17 and 18.
[^2]: This section considers OLS estimation of the parameters of a simple time trend, $y_t = \alpha + \delta t + \epsilon_t$, for $\epsilon_t$ a white noise process.
[^3]: If the innovations $\epsilon_t$ for the simple time trend [16.1.1] are Gaussian, then the OLS estimates $\hat{\alpha}_T$ and $\hat{\delta}_T$ are Gaussian and the usual OLS *t* and *F* tests have exact small-sample *t* and *F* distributions for all sample sizes T. Thus, despite the fact that $\hat{\alpha}_T$ and $\hat{\delta}_T$ have different asymptotic rates of convergence, the standard errors $\hat{\sigma}_{\hat{\alpha}_T}$ and $\hat{\sigma}_{\hat{\delta}_T}$, evidently have offsetting asymptotic behavior so that the statistics such as $(\hat{\delta}_T - \delta)/ \hat{\sigma}_{\hat{\delta}_T}$ are asymptotically N(0, 1) when the innovations are Gaussian. We might thus conjecture that the usual *t* and *F* tests are asymptotically valid for non-Gaussian innovations as well. This conjecture is indeed correct, as we now verify.
<!-- END -->
