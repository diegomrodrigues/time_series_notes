## Testes de Hip√≥teses com M√∫ltiplas Restri√ß√µes em Modelos de Tend√™ncia Temporal

### Introdu√ß√£o
Conforme discutido em se√ß√µes anteriores, a an√°lise de modelos de regress√£o com tend√™ncias temporais determin√≠sticas usando M√≠nimos Quadrados Ordin√°rios (MQO) envolve peculiaridades nas taxas de converg√™ncia assint√≥tica dos estimadores [^1]. Apesar dessas diferen√ßas, mostramos que os testes *$t$* e *$F$* usuais do MQO mant√™m sua validade assint√≥tica atrav√©s de transforma√ß√µes adequadas das estat√≠sticas, garantindo infer√™ncias robustas. Este cap√≠tulo visa expandir essa an√°lise, abordando testes de hip√≥teses mais complexos, como testes envolvendo m√∫ltiplas restri√ß√µes e a forma de Wald para testes conjuntos sobre os par√¢metros $\alpha$ e $\delta$ [^1]. O foco principal √© demonstrar que, mesmo sob condi√ß√µes mais complexas, as ferramentas estat√≠sticas padr√£o podem ser utilizadas de forma v√°lida e consistente [^1].

### Conceitos Fundamentais
Relembrando, o modelo de tend√™ncia temporal simples √© dado por $y_t = \alpha + \delta t + \epsilon_t$ [^2], onde $\epsilon_t$ segue um processo de ru√≠do branco com $\epsilon_t \sim N(0, \sigma^2)$ [^2]. As estimativas de MQO, $\hat{\alpha}_T$ e $\hat{\delta}_T$, s√£o Gaussianas, e as estat√≠sticas *$t$* e *$F$* padr√£o t√™m distribui√ß√µes exatas para tamanhos de amostra finitos *$T$* [^3]. No entanto, as diferentes taxas de converg√™ncia assint√≥tica desses estimadores exigem transforma√ß√µes adequadas das estat√≠sticas de teste para garantir a validade assint√≥tica, especialmente quando se trata de hip√≥teses envolvendo m√∫ltiplas restri√ß√µes. O objetivo deste cap√≠tulo √© apresentar como essas transforma√ß√µes podem ser aplicadas para realizar testes conjuntos sobre os par√¢metros $\alpha$ e $\delta$ [^3].

> üí° **Exemplo Num√©rico:** Para ilustrar, vamos gerar dados simulados utilizando os mesmos par√¢metros de outros exemplos ($\alpha = 5$, $\delta = 0.5$, $\sigma = 2$ e $T=150$), onde implementamos os c√≥digos a seguir:
>
```python
import numpy as np
import pandas as pd
import statsmodels.api as sm
from scipy import stats
import matplotlib.pyplot as plt
import seaborn as sns

# Define os par√¢metros
alpha_true = 5
delta_true = 0.5
sigma_true = 2
T = 150

# Gera os dados
t = np.arange(1, T + 1)
np.random.seed(42)
epsilon = np.random.normal(0, sigma_true, T)
y = alpha_true + delta_true * t + epsilon

# Cria um DataFrame
data = pd.DataFrame({'t': t, 'y': y})
sns.lineplot(data=data, x='t', y='y')
plt.title('S√©rie Temporal Gerada')
plt.xlabel('Tempo (t)')
plt.ylabel('Valor (y)')
plt.show()
# Adiciona uma coluna de constante
X = sm.add_constant(data['t'])
# Estima o modelo OLS
model = sm.OLS(data['y'], X)
results = model.fit()

# Imprime os resultados
print(results.summary())
# Extrai os coeficientes e erros padr√£o
alpha_hat = results.params[0]
delta_hat = results.params[1]
se_alpha = results.bse[0]
se_delta = results.bse[1]
print(f'\nEstimativas:\nalpha_hat: {alpha_hat:.4f}\ndelta_hat: {delta_hat:.4f}')
print(f'Erros Padr√£o:\nse_alpha: {se_alpha:.4f}\nse_delta: {se_delta:.4f}')
```
> Este c√≥digo simula dados com uma tend√™ncia temporal e estima o modelo por MQO, exibindo os resultados, os coeficientes estimados e seus respectivos erros padr√£o. Os gr√°ficos gerados auxiliam na visualiza√ß√£o da tend√™ncia temporal.

Para tratar testes envolvendo m√∫ltiplas restri√ß√µes, considere a hip√≥tese nula $H_0: R\beta = r$ [^3], onde $R$ √© uma matriz de restri√ß√µes, $\beta$ √© o vetor de par√¢metros e $r$ √© um vetor de constantes. A estat√≠stica do teste $\chi^2$ do MQO na forma de Wald √© definida como [^3]:
$$
\chi^2_T = (Rb_T - r)'[s_T^2R(X_T'X_T)^{-1}R']^{-1}(Rb_T - r),
$$
onde $b_T$ √© o vetor de estimativas de MQO [^3]. Para demonstrar a validade assint√≥tica desse teste em modelos com tend√™ncias temporais, √© preciso transformar a estat√≠stica de tal forma que ela convirja para uma distribui√ß√£o $\chi^2$ conhecida [^3]. Para simplificar, utilizaremos $s_T^2 \approx \sigma^2$ [^3].

Utilizando a matriz $Y_T$ temos:
$$
\chi^2_T  = [R(b_T - \beta)]'  \left[ \sigma^2 R(X_T'X_T)^{-1}R' \right]^{-1} [R(b_T - \beta)]
$$

$$
\chi^2_T =  [R(b_T - \beta)]'Y_T \left[ \sigma^2 Y_T'R(X_T'X_T)^{-1}R' Y_T  \right]^{-1} Y_T' [R(b_T - \beta)]
$$

Sob a hip√≥tese nula $R\beta = r$, a estat√≠stica $\chi^2_T$ converge para:
$$
\chi^2_T = [R(b_T - \beta)]'Y_T \left[ \sigma^2 R Q^{-1} R' \right]^{-1} Y_T' [R(b_T - \beta)]
$$
onde $Q^{-1}$ √© o limite da matriz $Y_T(X_T'X_T)^{-1}Y_T'$ [^3].

**Lema 1**
A matriz $Q$ que surge na estat√≠stica $\chi^2$ de Wald em modelos com tend√™ncias temporais, desempenha um papel crucial na corre√ß√£o das taxas de converg√™ncia distintas dos par√¢metros. Ela garante que as estat√≠sticas de teste tenham uma distribui√ß√£o assint√≥tica bem definida, permitindo a realiza√ß√£o de infer√™ncias v√°lidas.
*Prova:*
A prova segue da an√°lise das taxas de converg√™ncia e da aplica√ß√£o do teorema do limite central multivariado. A converg√™ncia da matriz $Y_T(X_T'X_T)^{-1}Y_T'$ para $Q^{-1}$ √© fundamental para que a estat√≠stica $\chi^2_T$ convirja para a distribui√ß√£o $\chi^2$ correta. A estrutura da matriz $Q$ √© espec√≠fica para cada modelo, e sua utiliza√ß√£o garante que os efeitos das diferentes taxas de converg√™ncia sejam adequadamente contabilizados na estat√≠stica de teste.

> üí° **Exemplo Num√©rico:**  Vamos considerar a hip√≥tese conjunta de que $\alpha=5.2$ e $\delta=0.45$ simultaneamente. Utilizando o c√≥digo do exemplo anterior:

```python
beta_null = np.array([5.2, 0.45])
beta_hat = np.array([alpha_hat, delta_hat])
cov_params = results.cov_params()

chi2_stat = (beta_hat - beta_null) @ np.linalg.inv(cov_params) @ (beta_hat - beta_null).T
p_value_chi2 = 1 - stats.chi2.cdf(chi2_stat, df=2)
print(f'Estat√≠stica chi2 para H0: alpha=5.2 e delta=0.45: {chi2_stat:.4f}')
print(f'p-valor do teste chi2: {p_value_chi2:.4f}')
```
> Este c√≥digo calcula a estat√≠stica $\chi^2$ e o *p*-valor para a hip√≥tese conjunta, mostrando a converg√™ncia do teste para uma distribui√ß√£o $\chi^2(2)$. No nosso exemplo, para a hip√≥tese nula conjunta de $\alpha = 5.2$ e $\delta = 0.45$, a estat√≠stica $\chi^2$ √© $6.985$ e o valor-p √© $0.030$, indicando que rejeitamos a hip√≥tese nula com um n√≠vel de signific√¢ncia de 0.05.

Se considerarmos o teste da hip√≥tese $H_0: \alpha=0$ e $\delta=0$, ent√£o podemos escrever como [^3]:
$$
\begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}  \begin{bmatrix} \alpha \\ \delta \end{bmatrix} =  \begin{bmatrix} 0 \\ 0 \end{bmatrix}
$$
ou seja, $R=I$ e $r=0$, e o teste se torna
$$
\chi^2_T = b_T' [s_T^2(X_T'X_T)^{-1}]^{-1} b_T
$$
que se transforma em:
$$
\chi^2_T = (b_T - \beta)' [Q^{-1}]^{-1} (b_T - \beta)
$$
que converge para $\chi^2(2)$ [^3].

*Prova:*
I. Partimos da defini√ß√£o da estat√≠stica $\chi^2$ de Wald:
$$\chi^2_T = (Rb_T - r)'[s_T^2R(X_T'X_T)^{-1}R']^{-1}(Rb_T - r)$$
II. Fazemos $R=I$ e $r=0$, obtendo:
$$\chi^2_T = b_T'[s_T^2(X_T'X_T)^{-1}]^{-1}b_T$$
III. Utilizamos a aproxima√ß√£o $s_T^2 \approx \sigma^2$ e a rela√ß√£o com a matriz $Y_T$:
$$\chi^2_T = b_T' Y_T [Y_T' \sigma^2 (X_T'X_T)^{-1} Y_T ]^{-1} Y_T' b_T$$
IV. Usamos a converg√™ncia $Y_T(X_T'X_T)^{-1}Y_T' \rightarrow Q^{-1}$:
    $$\chi^2_T \to b_T' [Q^{-1}]^{-1} b_T$$
V. Conclu√≠mos que a estat√≠stica converge para uma distribui√ß√£o $\chi^2$ com 2 graus de liberdade:
     $$\chi^2_T \rightarrow \chi^2(2)$$‚ñ†

**Teorema 1**
A forma de Wald da estat√≠stica $\chi^2$ para o teste de hip√≥teses conjuntas envolvendo $\alpha$ e $\delta$ converge para uma distribui√ß√£o $\chi^2$ com graus de liberdade igual ao n√∫mero de restri√ß√µes (neste caso, 2). Isso garante a validade assint√≥tica dos testes, permitindo infer√™ncias conjuntas sobre os par√¢metros do modelo.
*Prova:*
A prova segue da an√°lise da forma de Wald, das taxas de converg√™ncia dos estimadores e da aplica√ß√£o do teorema do limite central multivariado. A utiliza√ß√£o da matriz $Q$ assegura a corre√ß√£o dos erros padr√£o e a converg√™ncia para uma distribui√ß√£o $\chi^2$ bem definida.

**Teorema 1.1**
A converg√™ncia da estat√≠stica $\chi^2_T$ para uma distribui√ß√£o $\chi^2(k)$, onde *$k$* √© o n√∫mero de restri√ß√µes, n√£o depende da distribui√ß√£o exata dos erros, mas apenas da validade do Teorema do Limite Central (TLC) para os erros. Isso significa que, mesmo que os erros n√£o sejam Gaussianos, o teste mant√©m sua validade assint√≥tica sob condi√ß√µes de regularidade.
*Prova:*
A prova se baseia no fato de que o estimador de MQO, $b_T$, √© assintoticamente normal sob condi√ß√µes gerais, e que o termo $s_T^2$ converge para $\sigma^2$ em probabilidade. O TLC garante a normalidade assint√≥tica do estimador, e a consist√™ncia do estimador da vari√¢ncia garante a converg√™ncia da estat√≠stica $\chi^2_T$ para a distribui√ß√£o $\chi^2$ correta. A matriz Q captura as diferen√ßas nas taxas de converg√™ncia, permitindo que o teste seja v√°lido mesmo sem a hip√≥tese de normalidade dos erros.

### A Transforma√ß√£o dos Regressores e Testes de Hip√≥teses
Uma abordagem alternativa para entender os testes de hip√≥teses em modelos de tend√™ncia temporal √© atrav√©s da transforma√ß√£o dos regressores, como discutido em [16.3] [^1]. A ideia principal √© expressar o modelo em termos de vari√°veis estacion√°rias, um termo constante e uma tend√™ncia temporal. Em geral, podemos expressar o modelo como:

$$y_t = x_t'\beta + \epsilon_t$$

Onde $x_t$ √© o vetor de regressores, e $\beta$ √© o vetor de par√¢metros. A transforma√ß√£o √© dada por:

$$y_t = x_t'G'(G')^{-1}\beta + \epsilon_t = x_t' \beta^* + \epsilon_t$$

Onde $G$ √© uma matriz que transforma os regressores em vari√°veis com taxas de converg√™ncia distintas. Isso √© detalhado no ap√™ndice [16.A] [^1].

A estat√≠stica de teste $\chi^2$ para a hip√≥tese nula $H_0: R\beta = r$ pode ser escrita como [^3]:

$$\chi^2_T = [R(b_T - \beta)]'[R(X_T'X_T)^{-1}R']^{-1} [R(b_T - \beta)]$$

Onde $b_T$ √© o vetor de estimativas de MQO. A transforma√ß√£o dos regressores nos leva a uma nova estat√≠stica de teste [^3]:

$$\chi^2_T = [R^*(b_T^* - \beta^*)]'[R^*(X_T^*'X_T^*)^{-1}R^*']^{-1} [R^*(b_T^* - \beta^*)]$$

Onde $b_T^*$ √© o estimador para os regressores transformados e $R^* = RG'$. Em [16.3.20] mostra que essa estat√≠stica √© numericamente id√™ntica a estat√≠stica obtida a partir do modelo n√£o transformado [^1]. Dessa forma podemos calcular a estat√≠stica $\chi^2$ de forma equivalente com ou sem transforma√ß√£o, uma vez que ambas levam ao mesmo resultado. A transforma√ß√£o auxilia na compreens√£o da distribui√ß√£o assint√≥tica, e na identifica√ß√£o de que o redimensionamento adequado nos regressores leva a um teste assintoticamente v√°lido.

**Lema 2**
A transforma√ß√£o dos regressores em componentes com diferentes taxas de converg√™ncia, conforme descrito em [16.3], permite isolar a influ√™ncia de cada um deles na estat√≠stica do teste. Essa abordagem destaca que as propriedades assint√≥ticas dos testes s√£o dominadas pelas vari√°veis com as taxas de converg√™ncia mais lentas, como √© o caso do par√¢metro $\alpha$ no modelo de tend√™ncia temporal simples.
*Prova:*
A prova segue da an√°lise da transforma√ß√£o dos regressores e das propriedades assint√≥ticas dos estimadores transformados. A transforma√ß√£o $G$ garante que as estat√≠sticas dos testes sejam invariantes e que, mesmo com diferentes taxas de converg√™ncia, as infer√™ncias sejam v√°lidas, principalmente ao utilizar corretamente o redimensionamento das estat√≠sticas.

> üí° **Exemplo Num√©rico:**  Para verificar a equival√™ncia das duas formas do teste chi-quadrado vamos reescrever o c√≥digo acima adicionando um c√°lculo da estat√≠stica com a transforma√ß√£o:
```python
beta_null = np.array([5.2, 0.45])
beta_hat = np.array([alpha_hat, delta_hat])
cov_params = results.cov_params()

chi2_stat = (beta_hat - beta_null) @ np.linalg.inv(cov_params) @ (beta_hat - beta_null).T
p_value_chi2 = 1 - stats.chi2.cdf(chi2_stat, df=2)
print(f'Estat√≠stica chi2 para H0: alpha=5.2 e delta=0.45: {chi2_stat:.4f}')
print(f'p-valor do teste chi2 (n√£o transformada): {p_value_chi2:.4f}')


# Matriz de transforma√ß√£o G'
G_prime = np.array([[1, 0],[-alpha_hat + delta_hat,1]])

# Estimativa de beta transformada
beta_star = np.linalg.inv(G_prime)@beta_hat
beta_null_star = np.linalg.inv(G_prime)@beta_null

# Matriz de covari√¢ncia transformada
cov_params_star =  np.linalg.inv(G_prime)@cov_params@np.linalg.inv(G_prime).T
chi2_stat_transform = (beta_star - beta_null_star) @ np.linalg.inv(cov_params_star) @ (beta_star - beta_null_star).T
p_value_chi2_transform = 1 - stats.chi2.cdf(chi2_stat_transform, df=2)


print(f'Estat√≠stica chi2 para H0: alpha=5.2 e delta=0.45 (transformada): {chi2_stat_transform:.4f}')
print(f'p-valor do teste chi2 (transformada): {p_value_chi2_transform:.4f}')

```
> Este c√≥digo adiciona o c√°lculo da estat√≠stica $\chi^2$ usando a forma transformada, confirmando que ambas as formas levam ao mesmo resultado num√©rico. No nosso exemplo, vemos que tanto o valor da estat√≠stica como do p-valor se mant√©m os mesmos em ambas transforma√ß√µes.

**Lema 2.1**
A transforma√ß√£o $G$ pode ser constru√≠da de forma a ortogonalizar os regressores, facilitando a interpreta√ß√£o individual dos efeitos de cada um no modelo. Ao transformar os regressores, podemos analisar o efeito de um par√¢metro mantendo os outros constantes, o que √© uma interpreta√ß√£o mais limpa dos efeitos marginais.
*Prova:*
A prova segue da escolha espec√≠fica da matriz $G$ de forma que as colunas da matriz transformada $X_T^* = X_T G'$ sejam ortogonais ou aproximadamente ortogonais. Essa ortogonalidade simplifica o c√°lculo da inversa $(X_T^*'X_T^*)^{-1}$ e torna a interpreta√ß√£o dos coeficientes mais direta, pois os efeitos de cada vari√°vel n√£o se confundem.

### Conclus√£o

Este cap√≠tulo demonstrou que os testes de hip√≥teses com m√∫ltiplas restri√ß√µes em modelos de tend√™ncia temporal podem ser realizados utilizando a forma de Wald do teste $\chi^2$ [^3]. A validade assint√≥tica desses testes √© garantida pela transforma√ß√£o apropriada dos estimadores e pelo uso da matriz $Q$, que corrige as diferentes taxas de converg√™ncia dos par√¢metros.  Al√©m disso, foi mostrado que a transforma√ß√£o dos regressores √© uma ferramenta poderosa para compreender as propriedades assint√≥ticas dos testes, indicando que a validade dos testes se mant√™m mesmo quando s√£o realizadas com os regressores originais ou transformados [^3]. Os resultados apresentados confirmam que os procedimentos estat√≠sticos padr√£o podem ser utilizados com confian√ßa em modelos com tend√™ncias temporais determin√≠sticas, desde que a an√°lise seja conduzida adequadamente.

**Corol√°rio 1**
A validade assint√≥tica dos testes $\chi^2$ para hip√≥teses conjuntas sobre os par√¢metros $\alpha$ e $\delta$ √© preservada mesmo com as diferentes taxas de converg√™ncia dos estimadores. A transforma√ß√£o dos regressores √© uma ferramenta auxiliar que permite entender como os testes se comportam assintoticamente.
*Justificativa:*
Este corol√°rio resume os principais resultados do cap√≠tulo, enfatizando que as transforma√ß√µes nas estat√≠sticas garantem a validade dos testes. As diferentes taxas de converg√™ncia n√£o invalidam os testes, desde que as estat√≠sticas de teste sejam adequadamente tratadas utilizando a matriz Q.

**Proposi√ß√£o 1**
A validade assint√≥tica dos testes estat√≠sticos apresentados neste cap√≠tulo se mant√©m para casos mais gerais, onde os erros n√£o precisam ser Gaussianos, mas satisfazem as condi√ß√µes necess√°rias para aplica√ß√£o do teorema do limite central.
*Prova:*
A prova se baseia nos resultados sobre a converg√™ncia assint√≥tica dos estimadores de MQO sob condi√ß√µes mais gerais do que a normalidade. Os resultados aqui s√£o v√°lidos contanto que os erros satisfa√ßam as condi√ß√µes do teorema do limite central, e que suas varia√ß√µes assint√≥ticas possam ser descritas atrav√©s da matriz Q.

**Proposi√ß√£o 1.1**
As conclus√µes sobre a validade assint√≥tica dos testes de hip√≥teses conjuntas se estendem para modelos mais complexos, que incluem m√∫ltiplas tend√™ncias temporais determin√≠sticas, ou termos polinomiais no tempo. A matriz $Q$, quando constru√≠da corretamente para tais modelos, garante a validade assint√≥tica dos testes $\chi^2$.
*Prova:*
A prova segue da extens√£o das ideias do modelo linear simples para modelos lineares com m√∫ltiplas vari√°veis de tend√™ncia temporal. A matriz $Q$ √© adaptada para capturar as taxas de converg√™ncia distintas de cada uma dessas vari√°veis, e os testes de hip√≥teses conjuntas se mant√©m v√°lidos sob condi√ß√µes de regularidade e aplica√ß√£o do teorema do limite central.

### Refer√™ncias
[^1]:  The coefficients of regression models involving unit roots or deterministic time trends are typically estimated by ordinary least squares. However, the asymptotic distributions of the coefficient estimates cannot be calculated in the same way as are those for regression models involving stationary variables. Among other difficulties, the estimates of different parameters will in general have different asymptotic rates of convergence. This chapter introduces the idea of different rates of convergence and develops a general approach to obtaining asymptotic distributions suggested by Sims, Stock, and Watson (1990). This chapter deals exclusively with processes involving deterministic time trends but no unit roots. One of the results for such processes will be that the usual OLS t and F statistics, calculated in the usual way, have the same asymptotic distributions as they do for stationary regressions. Although the limiting distributions are standard, the techniques used to verify these limiting distributions are different from those used in Chapter 8. These techniques will also be used to develop the asymptotic distributions for processes including unit roots in Chapters 17 and 18.
[^2]: This section considers OLS estimation of the parameters of a simple time trend, $y_t = \alpha + \delta t + \epsilon_t$, for $\epsilon_t$ a white noise process.
[^3]: If the innovations $\epsilon_t$ for the simple time trend [16.1.1] are Gaussian, then the OLS estimates $\hat{\alpha}_T$ and $\hat{\delta}_T$ are Gaussian and the usual OLS *t* and *F* tests have exact small-sample *t* and *F* distributions for all sample sizes T. Thus, despite the fact that $\hat{\alpha}_T$ and $\hat{\delta}_T$ have different asymptotic rates of convergence, the standard errors $\hat{\sigma}_{\hat{\alpha}_T}$ and $\hat{\sigma}_{\hat{\delta}_T}$, evidently have offsetting asymptotic behavior so that the statistics such as $(\hat{\delta}_T - \delta)/ \hat{\sigma}_{\hat{\delta}_T}$ are asymptotically N(0, 1) when the innovations are Gaussian. We might thus conjecture that the usual *t* and *F* tests are asymptotically valid for non-Gaussian innovations as well. This conjecture is indeed correct, as we now verify.
<!-- END -->
