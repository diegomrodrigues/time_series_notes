## Testes de Hip√≥teses para o Modelo de Tend√™ncia de Tempo Simples: An√°lise Detalhada da Estat√≠stica t
### Introdu√ß√£o
Como explorado anteriormente, o cap√≠tulo 16 introduz o conceito de diferentes taxas de converg√™ncia para estimadores de modelos com tend√™ncia de tempo determin√≠stica [^1]. Especificamente, o estimador do intercepto ($\hat{\alpha}_T$) converge a uma taxa de $T^{1/2}$, enquanto o estimador do coeficiente da tend√™ncia ($\hat{\delta}_T$) converge a uma taxa de $T^{3/2}$ [^1].  Este cap√≠tulo busca aprofundar a an√°lise da validade dos testes de hip√≥teses usuais, particularmente o teste $t$, nesse contexto, focando na constru√ß√£o e nas propriedades assint√≥ticas da estat√≠stica de teste. Expandindo a discuss√£o anterior sobre a converg√™ncia assint√≥tica dos estimadores OLS, vamos nos concentrar na constru√ß√£o da estat√≠stica *$t$* e sua distribui√ß√£o limite.

**Lema 1**  A converg√™ncia em probabilidade de $\hat{\sigma}^2_T$ para $\sigma^2$ √© crucial para a validade assint√≥tica dos testes *$t$*. Este resultado, que decorre das propriedades assint√≥ticas dos estimadores OLS e da Lei dos Grandes N√∫meros, permite que as estat√≠sticas *$t$* convirjam para uma distribui√ß√£o normal padr√£o, mesmo quando as distribui√ß√µes dos erros n√£o s√£o normais.

### Conceitos Fundamentais
O teste *$t$* para hip√≥teses sobre os coeficientes em modelos de tend√™ncia de tempo √© constru√≠do pela raz√£o entre o desvio do estimador do valor hipot√©tico e o seu erro padr√£o, com o numerador e o denominador multiplicados por fatores de escala apropriados para obter distribui√ß√µes limites n√£o degeneradas. Este processo √© essencial para lidar com as diferentes taxas de converg√™ncia dos estimadores [^1].

A estat√≠stica $t$ para testar a hip√≥tese nula $H_0: \alpha = \alpha_0$ √© dada por:

$$
t_T = \frac{\hat{\alpha}_T - \alpha_0}{\sqrt{s^2_T [1 \, 0](X'X)^{-1} \begin{bmatrix} 1 \\ 0 \end{bmatrix} }}
$$
onde $s^2_T$ √© o estimador OLS da vari√¢ncia do erro e $(X'X)^{-1}$ √© a matriz inversa da matriz de momentos dos regressores, como definido em [16.1.16] [^1].  Para analisar o comportamento assint√≥tico desta estat√≠stica, multiplicamos tanto o numerador quanto o denominador por $\sqrt{T}$:
$$
t_T = \frac{\sqrt{T}(\hat{\alpha}_T - \alpha_0)}{\sqrt{s^2_T [\sqrt{T} \, 0](X'X)^{-1} \begin{bmatrix} \sqrt{T} \\ 0 \end{bmatrix} }}
$$
Essa multiplica√ß√£o pelo fator $\sqrt{T}$ √© crucial, pois ela adequa a escala da estat√≠stica para que tenhamos um limite n√£o degenerado. Utilizando os resultados de [16.1.17] e [16.1.19], podemos reescrever a express√£o acima:

$$
t_T = \frac{\sqrt{T}(\hat{\alpha}_T - \alpha_0)}{\sqrt{s^2_T [1 \, 0] Q^{-1} \begin{bmatrix} 1 \\ 0 \end{bmatrix} }}
$$
onde $Q$ √© a matriz limite definida em [16.1.20] [^1]. O numerador, $\sqrt{T}(\hat{\alpha}_T - \alpha_0)$, converge para uma distribui√ß√£o normal $N(0, \sigma^2 q^{11})$, onde $q^{11}$ √© o elemento (1,1) de $Q^{-1}$ [^1]. Simultaneamente, o denominador, $\sqrt{s^2_T [1 \, 0] Q^{-1} \begin{bmatrix} 1 \\ 0 \end{bmatrix} }$, converge em probabilidade para $\sqrt{\sigma^2 q^{11}}$. Pelo Teorema de Slutsky, a estat√≠stica $t_T$ converge em distribui√ß√£o para $N(0,1)$, validando assintoticamente o teste para $\alpha$ mesmo sem a hip√≥tese de normalidade dos erros, como discutido no Teorema 1 [^1].

> üí° **Detalhes da Constr√ß√£o da Estat√≠stica t:** A multiplica√ß√£o por $\sqrt{T}$ no numerador e no denominador √© uma forma de normalizar a estat√≠stica $t$, que, em sua forma original, tenderia para zero ou infinito √† medida que o tamanho da amostra aumenta. A raz√£o pela qual escolhemos  $\sqrt{T}$ √© porque $\hat{\alpha}_T$ converge a essa taxa, de modo que $\sqrt{T}(\hat{\alpha}_T - \alpha_0)$ tem uma distribui√ß√£o limite n√£o degenerada. De forma an√°loga, ao lidar com o coeficiente da tend√™ncia, $\hat{\delta}_T$,  multiplicamos o numerador e o denominador por $T^{3/2}$, j√° que essa √© a taxa de converg√™ncia de $\hat{\delta}_T$.

> üí° **Exemplo Num√©rico:** Vamos simular dados para um modelo de tend√™ncia de tempo simples e calcular a estat√≠stica t para $\alpha$.
>
> ```python
> import numpy as np
> import pandas as pd
> import statsmodels.api as sm
>
> # Par√¢metros verdadeiros
> alpha_true = 5
> delta_true = 0.2
> sigma_true = 1.5
> T = 200
>
> # Gera√ß√£o dos dados
> t = np.arange(1, T + 1)
> X = np.column_stack((np.ones(T), t))
> errors = np.random.normal(0, sigma_true, T)
> y = alpha_true + delta_true * t + errors
>
> # Estima√ß√£o por OLS
> model = sm.OLS(y, X)
> results = model.fit()
>
> # Extraindo os resultados
> alpha_hat = results.params[0]
> delta_hat = results.params[1]
> s_squared = results.mse_resid
>
> # Matriz de covari√¢ncia dos coeficientes
> cov_matrix = results.cov_params()
>
> # C√°lculo da estat√≠stica t para alpha
> alpha_0 = 5  # Hip√≥tese nula para alpha
> t_stat_alpha = (alpha_hat - alpha_0) / np.sqrt(s_squared * cov_matrix[0, 0])
>
> # C√°lculo da estat√≠stica t escalada por sqrt(T) (vers√£o para an√°lise assint√≥tica)
> t_stat_alpha_scaled = (np.sqrt(T) * (alpha_hat - alpha_0)) / np.sqrt(s_squared * cov_matrix[0, 0] * T)
>
> # Imprimindo os resultados
> print(f"Estimativa de alpha: {alpha_hat:.4f}")
> print(f"Estimativa de delta: {delta_hat:.4f}")
> print(f"Estimativa da vari√¢ncia do erro: {s_squared:.4f}")
> print(f"Estat√≠stica t para alpha: {t_stat_alpha:.4f}")
> print(f"Estat√≠stica t para alpha (escalada): {t_stat_alpha_scaled:.4f}")
>
> # Comparando com o valor cr√≠tico de uma normal padr√£o
> from scipy.stats import norm
> critical_value = norm.ppf(0.975)  # Para um teste bicaudal de 5%
> print(f"Valor cr√≠tico (bicaudal, 5%): {critical_value:.4f}")
> if abs(t_stat_alpha) > critical_value:
>    print("Rejeita-se a hip√≥tese nula para alpha")
> else:
>    print("N√£o se rejeita a hip√≥tese nula para alpha")
>
> # DataFrame para an√°lise
> results_df = pd.DataFrame({
>    'Parametro':['alpha', 'delta'],
>    'Estimativa':[alpha_hat, delta_hat],
>    'Erro Padr√£o':[np.sqrt(cov_matrix[0,0]), np.sqrt(cov_matrix[1,1])],
>    'Estat√≠stica T':[results.tvalues[0], results.tvalues[1]],
>    'P-valor':[results.pvalues[0], results.pvalues[1]]
> })
> print("\nResultados da regress√£o:\n", results_df)
> ```
>
> Este c√≥digo simula dados, estima os par√¢metros do modelo usando OLS (m√≠nimos quadrados ordin√°rios) e calcula a estat√≠stica t para o intercepto. A vers√£o escalada pela raiz de T ilustra como a normaliza√ß√£o afeta a estat√≠stica t, permitindo que ela convirja para uma distribui√ß√£o normal padr√£o quando o tamanho da amostra aumenta. Comparando a estat√≠stica t com o valor cr√≠tico, podemos avaliar a signific√¢ncia estat√≠stica do estimador.  Al√©m disso, √© mostrado como a fun√ß√£o `summary()` do modelo OLS j√° retorna os resultados de interesse.

A estat√≠stica $t$ para testar a hip√≥tese nula $H_0: \delta = \delta_0$ √© similarmente constru√≠da:

$$
t_T = \frac{\hat{\delta}_T - \delta_0}{\sqrt{s^2_T [0 \, 1](X'X)^{-1} \begin{bmatrix} 0 \\ 1 \end{bmatrix} }}
$$
Multiplicando o numerador e denominador por $T^{3/2}$, temos:
$$
t_T = \frac{T^{3/2}(\hat{\delta}_T - \delta_0)}{\sqrt{s^2_T [0 \, T^{3/2}](X'X)^{-1} \begin{bmatrix} 0 \\ T^{3/2} \end{bmatrix} }}
$$
Usando [16.1.17], a express√£o acima √© reescrita como:
$$
t_T = \frac{T^{3/2}(\hat{\delta}_T - \delta_0)}{\sqrt{s^2_T [0 \, 1] Q^{-1} \begin{bmatrix} 0 \\ 1 \end{bmatrix} }}
$$
Nesse caso, o numerador $T^{3/2}(\hat{\delta}_T - \delta_0)$ converge para uma distribui√ß√£o normal $N(0, \sigma^2 q^{22})$ e o denominador converge em probabilidade para $\sqrt{\sigma^2 q^{22}}$. Assim, pelo Teorema de Slutsky, a estat√≠stica $t_T$ converge em distribui√ß√£o para $N(0,1)$, validando o teste para $\delta$ [^1].

**Prova para a Converg√™ncia da Estat√≠stica t para $\delta$**

Aqui, apresentamos uma prova detalhada passo a passo da converg√™ncia da estat√≠stica $t$ para $\delta$ para uma distribui√ß√£o normal padr√£o.

I.  A estat√≠stica $t$ para testar $H_0: \delta = \delta_0$ √© dada por:
$$ t_T = \frac{\hat{\delta}_T - \delta_0}{\sqrt{s^2_T [0 \, 1](X'X)^{-1} \begin{bmatrix} 0 \\ 1 \end{bmatrix} }} $$

II. Multiplicamos o numerador e o denominador por $T^{3/2}$:
$$ t_T = \frac{T^{3/2}(\hat{\delta}_T - \delta_0)}{\sqrt{s^2_T [0 \, T^{3/2}](X'X)^{-1} \begin{bmatrix} 0 \\ T^{3/2} \end{bmatrix} }} $$

III. Substituindo $(X'X)^{-1}$ por $Q^{-1}$ escalado por $T^{-2}$ (de [16.1.17]), obtemos:
$$ t_T = \frac{T^{3/2}(\hat{\delta}_T - \delta_0)}{\sqrt{s^2_T T^{-2}[0 \, T^{3/2}] Q^{-1} \begin{bmatrix} 0 \\ T^{3/2} \end{bmatrix} }} $$

IV. Simplificando a express√£o, obtemos:
$$ t_T = \frac{T^{3/2}(\hat{\delta}_T - \delta_0)}{\sqrt{s^2_T [0 \, 1] Q^{-1} \begin{bmatrix} 0 \\ 1 \end{bmatrix} }} $$

V. Sabemos que $T^{3/2}(\hat{\delta}_T - \delta_0) \xrightarrow{d} N(0, \sigma^2 q^{22})$, onde $q^{22}$ √© o elemento (2,2) de $Q^{-1}$ [^1].

VI. Tamb√©m sabemos que $s^2_T \xrightarrow{p} \sigma^2$, e  $[0 \, 1] Q^{-1} \begin{bmatrix} 0 \\ 1 \end{bmatrix}$ √© igual a $q^{22}$.

VII. Portanto, o denominador converge em probabilidade para $\sqrt{\sigma^2 q^{22}}$.

VIII. Pelo Teorema de Slutsky, a estat√≠stica $t_T$ converge em distribui√ß√£o para:
$$ \frac{N(0, \sigma^2 q^{22})}{\sqrt{\sigma^2 q^{22}}} = N(0,1) $$

IX. Assim, provamos que a estat√≠stica $t_T$ para testar a hip√≥tese $H_0: \delta = \delta_0$ converge em distribui√ß√£o para $N(0,1)$. ‚ñ†

> üí° **Exemplo Num√©rico:** Continuando o exemplo anterior, vamos calcular a estat√≠stica t para $\delta$.
>
> ```python
> import numpy as np
> import pandas as pd
> import statsmodels.api as sm
>
> # Par√¢metros verdadeiros (os mesmos do exemplo anterior)
> alpha_true = 5
> delta_true = 0.2
> sigma_true = 1.5
> T = 200
>
> # Gera√ß√£o dos dados (os mesmos do exemplo anterior)
> t = np.arange(1, T + 1)
> X = np.column_stack((np.ones(T), t))
> errors = np.random.normal(0, sigma_true, T)
> y = alpha_true + delta_true * t + errors
>
> # Estima√ß√£o por OLS (os mesmos do exemplo anterior)
> model = sm.OLS(y, X)
> results = model.fit()
>
> # Extraindo os resultados (os mesmos do exemplo anterior)
> alpha_hat = results.params[0]
> delta_hat = results.params[1]
> s_squared = results.mse_resid
>
> # Matriz de covari√¢ncia dos coeficientes (os mesmos do exemplo anterior)
> cov_matrix = results.cov_params()
>
> # C√°lculo da estat√≠stica t para delta
> delta_0 = 0.2  # Hip√≥tese nula para delta
> t_stat_delta = (delta_hat - delta_0) / np.sqrt(s_squared * cov_matrix[1, 1])
>
> # C√°lculo da estat√≠stica t escalada por T^(3/2) (vers√£o para an√°lise assint√≥tica)
> t_stat_delta_scaled = (T**(3/2) * (delta_hat - delta_0)) / np.sqrt(s_squared * cov_matrix[1, 1] * T**3)
>
> # Imprimindo os resultados
> print(f"Estimativa de alpha: {alpha_hat:.4f}")
> print(f"Estimativa de delta: {delta_hat:.4f}")
> print(f"Estimativa da vari√¢ncia do erro: {s_squared:.4f}")
> print(f"Estat√≠stica t para delta: {t_stat_delta:.4f}")
> print(f"Estat√≠stica t para delta (escalada): {t_stat_delta_scaled:.4f}")
>
> # Comparando com o valor cr√≠tico de uma normal padr√£o
> from scipy.stats import norm
> critical_value = norm.ppf(0.975)  # Para um teste bicaudal de 5%
> print(f"Valor cr√≠tico (bicaudal, 5%): {critical_value:.4f}")
> if abs(t_stat_delta) > critical_value:
>    print("Rejeita-se a hip√≥tese nula para delta")
> else:
>    print("N√£o se rejeita a hip√≥tese nula para delta")
>
> # DataFrame para an√°lise
> results_df = pd.DataFrame({
>    'Parametro':['alpha', 'delta'],
>    'Estimativa':[alpha_hat, delta_hat],
>    'Erro Padr√£o':[np.sqrt(cov_matrix[0,0]), np.sqrt(cov_matrix[1,1])],
>    'Estat√≠stica T':[results.tvalues[0], results.tvalues[1]],
>    'P-valor':[results.pvalues[0], results.pvalues[1]]
> })
> print("\nResultados da regress√£o:\n", results_df)
> ```
>
> Este c√≥digo calcula a estat√≠stica t para o coeficiente de tend√™ncia ($\delta$) usando os mesmos dados simulados do exemplo anterior. Observe a escala por $T^{3/2}$, que √© a taxa de converg√™ncia de $\hat{\delta}_T$. Isso demonstra como a estat√≠stica t √© ajustada para lidar com as diferentes taxas de converg√™ncia.  Novamente, comparamos com um valor cr√≠tico para avaliar a signific√¢ncia estat√≠stica, e constru√≠mos um dataframe para apresentar os principais resultados da an√°lise.

**Lema 2** A converg√™ncia da matriz de momentos dos regressores, $\frac{X'X}{T^2} \xrightarrow{p} Q$, onde Q √© uma matriz definida positiva, √© um resultado fundamental que justifica a substitui√ß√£o de $(X'X)^{-1}$ por $Q^{-1}$ no denominador das estat√≠sticas *$t$* ao analisar suas propriedades assint√≥ticas. Esta converg√™ncia √© uma consequ√™ncia da estrutura espec√≠fica do modelo de tend√™ncia de tempo e da aplica√ß√£o da Lei dos Grandes N√∫meros.

> üí° **Justificativa da Multiplica√ß√£o por $T^{3/2}$:** A escolha de $T^{3/2}$ para a estat√≠stica t de $\delta$ √© devido √† taxa de converg√™ncia de $\hat{\delta}_T$. Ao multiplicar por $T^{3/2}$, estamos normalizando a estat√≠stica para que ela possua uma distribui√ß√£o limite n√£o degenerada, o que permite a infer√™ncia estat√≠stica. Essa manipula√ß√£o √© an√°loga √† multiplica√ß√£o por $\sqrt{T}$ no caso de $\hat{\alpha}_T$, refletindo as diferentes taxas de converg√™ncia dos estimadores.

Para testar a hip√≥tese conjunta $H_0: r_1\alpha + r_2\delta = r$, a estat√≠stica *$t$* √© dada por:

$$
t_T = \frac{r_1\hat{\alpha}_T + r_2\hat{\delta}_T - r}{\sqrt{s_T^2 \begin{bmatrix} r_1 & r_2 \end{bmatrix} (X'X)^{-1} \begin{bmatrix} r_1 \\ r_2 \end{bmatrix} }}
$$
Multiplicando o numerador e o denominador por $\sqrt{T}$, obtemos:

$$
t_T = \frac{\sqrt{T}(r_1\hat{\alpha}_T + r_2\hat{\delta}_T - r)}{\sqrt{s_T^2 \begin{bmatrix} r_1 & r_2/T^{3/2} \end{bmatrix} Q^{-1} \begin{bmatrix} r_1 \\ r_2/T^{3/2} \end{bmatrix} }}
$$
O comportamento assint√≥tico desta estat√≠stica √© dominado por $\sqrt{T}\hat{\alpha}_T$, j√° que $\hat{\delta}_T$ converge mais rapidamente para o seu valor verdadeiro. Assim, a estat√≠stica $t$ converge em distribui√ß√£o para $N(0,1)$. Este resultado, tamb√©m discutido no Teorema 1.1, enfatiza como o teste √© dominado pela taxa de converg√™ncia mais lenta dos estimadores.

> üí° **Implica√ß√µes da Taxa de Converg√™ncia para Testes Conjuntos:** A taxa de converg√™ncia desempenha um papel crucial nos testes conjuntos, pois determina qual componente dominar√° o comportamento assint√≥tico da estat√≠stica de teste. Em nosso caso, como $\hat{\delta}_T$ converge mais r√°pido do que $\hat{\alpha}_T$, √© a taxa de converg√™ncia de  $\hat{\alpha}_T$ que determinar√° a distribui√ß√£o limite da estat√≠stica *$t$*.

**Corol√°rio 1** A converg√™ncia da estat√≠stica t para a hip√≥tese conjunta $H_0: r_1\alpha + r_2\delta = r$ para uma distribui√ß√£o $N(0,1)$ √© uma consequ√™ncia direta da aplica√ß√£o do Teorema de Slutsky e do fato de que o numerador da estat√≠stica, quando apropriadamente escalado, converge para uma distribui√ß√£o normal, enquanto o denominador converge em probabilidade para uma constante. A domin√¢ncia da taxa de converg√™ncia de $\hat{\alpha}_T$ na distribui√ß√£o limite da estat√≠stica t ressalta a import√¢ncia da escala correta ao lidar com estimadores que convergem a diferentes taxas.

> üí° **Exemplo Num√©rico:**  Vamos realizar um teste de hip√≥tese conjunta, usando os mesmos dados simulados. Vamos testar $H_0: \alpha + 2\delta = 5.4$ (sabendo que os valores verdadeiros s√£o $\alpha=5$ e $\delta=0.2$, ent√£o o valor correto √© 5.4).
>
> ```python
> import numpy as np
> import statsmodels.api as sm
> from scipy.stats import norm
>
> # Par√¢metros verdadeiros (os mesmos do exemplo anterior)
> alpha_true = 5
> delta_true = 0.2
> sigma_true = 1.5
> T = 200
>
> # Gera√ß√£o dos dados (os mesmos do exemplo anterior)
> t = np.arange(1, T + 1)
> X = np.column_stack((np.ones(T), t))
> errors = np.random.normal(0, sigma_true, T)
> y = alpha_true + delta_true * t + errors
>
> # Estima√ß√£o por OLS (os mesmos do exemplo anterior)
> model = sm.OLS(y, X)
> results = model.fit()
>
> # Extraindo os resultados (os mesmos do exemplo anterior)
> alpha_hat = results.params[0]
> delta_hat = results.params[1]
> s_squared = results.mse_resid
> cov_matrix = results.cov_params()
>
> # Teste de hip√≥tese conjunta
> r1 = 1
> r2 = 2
> r = 5.4
>
> # C√°lculo da estat√≠stica t para a hip√≥tese conjunta
> numerator = r1 * alpha_hat + r2 * delta_hat - r
> denominator = np.sqrt(s_squared * np.dot(np.dot(np.array([r1,r2]), cov_matrix), np.array([r1,r2])))
> t_stat_joint = numerator / denominator
>
> # C√°lculo da estat√≠stica t escalada por sqrt(T) (vers√£o para an√°lise assint√≥tica)
> denominator_scaled = np.sqrt(s_squared * np.dot(np.dot(np.array([r1,r2/T**(3/2)]), cov_matrix), np.array([r1,r2/T**(3/2)])) * T)
> t_stat_joint_scaled = (np.sqrt(T) * numerator) / denominator_scaled
>
> # Imprimindo os resultados
> print(f"Estat√≠stica t para a hip√≥tese conjunta: {t_stat_joint:.4f}")
> print(f"Estat√≠stica t para a hip√≥tese conjunta (escalada): {t_stat_joint_scaled:.4f}")
>
> # Comparando com o valor cr√≠tico de uma normal padr√£o
> critical_value = norm.ppf(0.975)  # Para um teste bicaudal de 5%
> print(f"Valor cr√≠tico (bicaudal, 5%): {critical_value:.4f}")
> if abs(t_stat_joint) > critical_value:
>    print("Rejeita-se a hip√≥tese nula conjunta")
> else:
>    print("N√£o se rejeita a hip√≥tese nula conjunta")
> ```
>
> Este exemplo mostra como calcular a estat√≠stica t para um teste de hip√≥tese conjunta envolvendo $\alpha$ e $\delta$. A estat√≠stica t √© calculada usando as estimativas dos par√¢metros, seus erros padr√£o e os valores especificados para a hip√≥tese nula.  Comparando com o valor cr√≠tico, √© poss√≠vel decidir se a hip√≥tese nula conjunta deve ser rejeitada.

Finalmente, para o teste conjunto de hip√≥teses separadas para $\alpha$ e $\delta$, usamos a estat√≠stica $\chi^2$:
$$
\chi^2_T = (\mathbf{b}_T - \mathbf{b}_0)' [s_T^2(X'X)^{-1}]^{-1} (\mathbf{b}_T - \mathbf{b}_0)
$$
onde $\mathbf{b}_T = [\hat{\alpha}_T \, \hat{\delta}_T ]'$ e $\mathbf{b}_0 = [\alpha_0 \, \delta_0]'$.  Utilizando a propriedade de que $Y_T(X'X)^{-1}Y_T \rightarrow Q^{-1}$ [^1], a estat√≠stica $\chi^2$ converge para uma distribui√ß√£o $\chi^2(2)$.

**Proposi√ß√£o 1** (Extens√£o para Testes com Restri√ß√µes Lineares) Para o teste de uma hip√≥tese linear geral sobre os coeficientes do modelo de tend√™ncia de tempo, dada por $H_0: R\mathbf{b} = \mathbf{r}$, onde $R$ √© uma matriz de restri√ß√µes de dimens√£o $q \times 2$, e $\mathbf{b} = [\alpha, \delta]'$, a estat√≠stica *$F$* apropriadamente constru√≠da converge para uma distribui√ß√£o $\chi^2(q)$ assintoticamente, dividida por seus graus de liberdade $q$. Mais precisamente, a estat√≠stica F √© dada por:
$$
F_T = \frac{ (R\mathbf{\hat{b}}_T - \mathbf{r})' [s_T^2 R(X'X)^{-1}R']^{-1} (R\mathbf{\hat{b}}_T - \mathbf{r}) }{q}
$$

**Prova para a Converg√™ncia da Estat√≠stica F**

Aqui, fornecemos uma prova detalhada da converg√™ncia da estat√≠stica $F$ para uma distribui√ß√£o qui-quadrado dividida por seus graus de liberdade.

I. A estat√≠stica $F$ para testar a hip√≥tese linear geral $H_0: R\mathbf{b} = \mathbf{r}$ √© dada por:
$$ F_T = \frac{ (R\mathbf{\hat{b}}_T - \mathbf{r})' [s_T^2 R(X'X)^{-1}R']^{-1} (R\mathbf{\hat{b}}_T - \mathbf{r}) }{q} $$
onde $\mathbf{b} = [\alpha, \delta]'$.

II. Sabemos que $\sqrt{T}(\hat{\mathbf{b}}_T - \mathbf{b})$ converge para uma distribui√ß√£o normal multivariada com m√©dia zero e matriz de covari√¢ncia $\sigma^2 Q^{-1}$, ou seja:
$$\sqrt{T}(\hat{\mathbf{b}}_T - \mathbf{b}) \xrightarrow{d} N(0, \sigma^2 Q^{-1})$$
Assim:
$$ \sqrt{T}(R\hat{\mathbf{b}}_T - R\mathbf{b}) \xrightarrow{d} N(0, \sigma^2 RQ^{-1}R') $$

III. Sob a hip√≥tese nula $H_0$, $R\mathbf{b} = \mathbf{r}$, ent√£o $\sqrt{T}(R\hat{\mathbf{b}}_T - \mathbf{r}) \xrightarrow{d} N(0, \sigma^2 RQ^{-1}R')$.

IV. Usando a propriedade que se $\mathbf{z} \sim N(0, \Sigma)$, ent√£o $\mathbf{z}'\Sigma^{-1}\mathbf{z} \sim \chi^2(k)$, onde k √© a dimens√£o de $\mathbf{z}$,  e o fato de que $s^2_T \xrightarrow{p} \sigma^2$:
$$T(R\hat{\mathbf{b}}_T - \mathbf{r})' [\sigma^2 R(X'X)^{-1}R']^{-1} (R\hat{\mathbf{b}}_T - \mathbf{r})  \xrightarrow{d} \chi^2(q)$$

V. Dividindo pelo n√∫mero de restri√ß√µes q e sabendo que $s^2_T$ converge em probabilidade para $\sigma^2$:
$$ \frac{ (R\mathbf{\hat{b}}_T - \mathbf{r})' [s_T^2 R(X'X)^{-1}R']^{-1} (R\mathbf{\hat{b}}_T - \mathbf{r}) }{q} \xrightarrow{d} \frac{\chi^2(q)}{q} $$

VI. Portanto, provamos que a estat√≠stica $F_T$ converge em distribui√ß√£o para uma distribui√ß√£o qui-quadrado com $q$ graus de liberdade, dividida por $q$. ‚ñ†

> üí° **Exemplo Num√©rico:** Vamos calcular a estat√≠stica F para testar a hip√≥tese conjunta $H_0: \alpha = 5$ e $\delta = 0.2$.
>
> ```python
> import numpy as np
> import statsmodels.api as sm
> from scipy.stats import chi2
>
> # Par√¢metros verdadeiros (os mesmos do exemplo anterior)
> alpha_true = 5
> delta_true = 0.2
> sigma_true = 1.5
> T = 200
>
> # Gera√ß√£o dos dados (os mesmos do exemplo anterior)
> t = np.arange(1, T + 1)
> X = np.column_stack((np.ones(T), t))
> errors = np.random.normal(0, sigma_true, T)
> y = alpha_true + delta_true * t + errors
>
> # Estima√ß√£o por OLS (os mesmos do exemplo anterior)
> model = sm.OLS(y, X)
> results = model.fit()
>
> # Extraindo os resultados (os mesmos do exemplo anterior)
> alpha_hat = results.params[0]
> delta_hat = results.params[1]
> s_squared = results.mse_resid
> cov_matrix = results.cov_params()
>
> # Hip√≥teses nulas
> alpha_0 = 5
> delta_0 = 0.2
>
> # Vetor de estimativas e hip√≥teses nulas
> b_hat = np.array([alpha_hat, delta_hat])
> b_0 = np.array([alpha_0, delta_0])
>
> # Matriz de restri√ß√£o
> R = np.eye(2) # Testamos alfa e delta individualmente
> r = b_0
>
> # Calculando a estat√≠stica F
> numerator = np.dot(np.dot((R @ b_hat - r).T, np.linalg.inv(s_squared * R @ cov_matrix @ R.T)), (R @ b_hat - r))
> F_stat = numerator / 2 # q = 2, n√∫mero de restri√ß√µes
>
> # Imprimindo os resultados
> print(f"Estat√≠stica F: {F_stat:.4f}")
>
> # Comparando com o valor cr√≠tico de uma chi-quadrado
> degrees_freedom = 2
> critical_value = chi2.ppf(0.95, degrees_freedom)
> print(f"Valor cr√≠tico (chi-quadrado, 5%): {critical_value:.4f}")
>
> if F_stat > critical_value:
>    print("Rejeita-se a hip√≥tese nula conjunta")
> else:
>    print("N√£o se rejeita a hip√≥tese nula conjunta")
> ```
> Este exemplo mostra como calcular a estat√≠stica F para um teste conjunto das hip√≥teses $H_0: \alpha = \alpha_0$ e $H_0: \delta = \delta_0$. A estat√≠stica F √© constru√≠da usando as estimativas dos par√¢metros, suas covari√¢ncias e os valores especificados sob a hip√≥tese nula. O valor da estat√≠stica F √© ent√£o comparado com um valor cr√≠tico de uma distribui√ß√£o qui-quadrado para determinar se a hip√≥tese nula conjunta deve ser rejeitada.

A demonstra√ß√£o segue um racioc√≠nio an√°logo √† demonstra√ß√£o de converg√™ncia da estat√≠stica $\chi^2$, onde a matriz de covari√¢ncia assint√≥tica dos estimadores √© utilizada para construir a estat√≠stica de teste.

### Conclus√£o
A an√°lise detalhada da estat√≠stica $t$ para modelos com tend√™ncia de tempo revelou que as diferentes taxas de converg√™ncia dos estimadores requerem manipula√ß√µes espec√≠ficas para obter distribui√ß√µes limites n√£o degeneradas. As multiplica√ß√µes por $\sqrt{T}$ e $T^{3/2}$ s√£o essenciais para garantir que as estat√≠sticas $t$ convirjam para distribui√ß√µes normais padr√£o, permitindo a realiza√ß√£o de infer√™ncias estat√≠sticas v√°lidas.  Os resultados discutidos neste cap√≠tulo, que se baseiam na converg√™ncia dos estimadores e da vari√¢ncia dos erros, confirmam que os testes estat√≠sticos padr√£o s√£o aplic√°veis, n√£o apenas para modelos com vari√°veis estacion√°rias, mas tamb√©m para modelos com tend√™ncia de tempo determin√≠stica, demonstrando a robustez dos m√©todos estat√≠sticos.
### Refer√™ncias
[^1]: Se√ß√£o 16.1 do texto fornecido.
<!-- END -->
