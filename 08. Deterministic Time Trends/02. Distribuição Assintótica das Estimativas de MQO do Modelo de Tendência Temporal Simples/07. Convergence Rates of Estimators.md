## AnÃ¡lise das Taxas de ConvergÃªncia e Reescalonamento em Modelos de TendÃªncia Temporal

### IntroduÃ§Ã£o
Este capÃ­tulo aborda a anÃ¡lise das taxas de convergÃªncia dos estimadores de mÃ­nimos quadrados ordinÃ¡rios (MQO) em modelos de regressÃ£o com tendÃªncias temporais determinÃ­sticas. Especificamente, focamos em como as diferentes taxas de convergÃªncia dos estimadores $\hat{\alpha}_T$ e $\hat{\delta}_T$, e como a divergÃªncia da matriz de momentos $(1/T)\sum_{t=1}^T x_t x_t'$ impactam o cÃ¡lculo da distribuiÃ§Ã£o assintÃ³tica e a necessidade de reescalonamento. Expandindo sobre os conceitos de estimaÃ§Ã£o por MQO e distribuiÃ§Ãµes assintÃ³ticas jÃ¡ introduzidos [^10, ^11, ^21, ^22, ^23, ^24, ^25], este capÃ­tulo aprofunda a compreensÃ£o da necessidade de reescalonar as matrizes de momentos para obter resultados estatÃ­sticos vÃ¡lidos.

### Taxas de ConvergÃªncia Distintas e a Matriz de Momentos
Como vimos, o modelo de tendÃªncia temporal simples Ã© dado por [^3]:
$$y_t = \alpha + \delta t + \epsilon_t$$
onde $\epsilon_t$ Ã© um ruÃ­do branco com $\epsilon_t \sim N(0, \sigma^2)$. A forma padrÃ£o de regressÃ£o Ã© [^4]:
$$y_t = x_t'\beta + \epsilon_t$$
com $x_t = [1 \quad t]'$ [^5] e $\beta = [\alpha \quad \delta]'$ [^6]. O estimador MQO de $\beta$ Ã© dado por [^7]:
$$b_T = \begin{bmatrix} \hat{\alpha}_T \\ \hat{\delta}_T \end{bmatrix} = \left( \sum_{t=1}^T x_t x_t' \right)^{-1} \sum_{t=1}^T x_t y_t$$
e o desvio do estimador Ã© [^8, ^9]:
$$b_T - \beta = \left( \sum_{t=1}^T x_t x_t' \right)^{-1} \sum_{t=1}^T x_t \epsilon_t$$
Em contraste com regressÃµes com variÃ¡veis estacionÃ¡rias, onde multiplicamos por $\sqrt{T}$ para obter uma distribuiÃ§Ã£o limite, em modelos com tendÃªncias temporais, as estimativas $\hat{\alpha}_T$ e $\hat{\delta}_T$ convergem para seus valores verdadeiros em taxas diferentes [^23]. Especificamente, $\hat{\alpha}_T$ converge Ã  taxa de $\sqrt{T}$, enquanto $\hat{\delta}_T$ converge Ã  taxa de $T^{3/2}$ [^23]. Para obter distribuiÃ§Ãµes limitantes nÃ£o degeneradas, Ã© preciso reescalonar as estimativas com essas taxas de convergÃªncia.

A matriz de momentos, dada por [^19, ^20]:
$$\sum_{t=1}^T x_t x_t' = \begin{bmatrix} \sum_{t=1}^T 1 & \sum_{t=1}^T t \\ \sum_{t=1}^T t & \sum_{t=1}^T t^2 \end{bmatrix} = \begin{bmatrix} T & \frac{T(T+1)}{2} \\ \frac{T(T+1)}{2} & \frac{T(T+1)(2T+1)}{6} \end{bmatrix} $$
desempenha um papel crucial na anÃ¡lise das propriedades assintÃ³ticas. Os termos $\sum_{t=1}^T t$ e $\sum_{t=1}^T t^2$ sÃ£o assintoticamente equivalentes a $T^2/2$ e $T^3/3$, respectivamente [^16, ^17]. De forma geral, o termo dominante de $\sum_{t=1}^T t^v$ Ã© $\frac{T^{v+1}}{v+1}$ [^18]. Como resultado, a matriz de momentos, dividida por $T$, diverge [^21]. Em vez disso, para obter uma matriz que convirja, ela deve ser dividida por $T^3$ [^21]. No entanto, mesmo com essa divisÃ£o, a matriz resultante nÃ£o Ã© invertÃ­vel, conforme visto anteriormente no Lema 1. Essa Ã© a principal motivaÃ§Ã£o para o reescalonamento com a matriz $Y_T$.

> ðŸ’¡ **Exemplo NumÃ©rico:** Para ilustrar o comportamento da matriz de momentos, vamos usar um exemplo com T=100 e analisar como a matriz $(1/T)\sum_{t=1}^T x_t x_t'$ diverge e como a matriz $(1/T^3)\sum_{t=1}^T x_t x_t'$ tambÃ©m nÃ£o converge para uma matriz nÃ£o-singular.
```python
import numpy as np

T = 100
t = np.arange(1, T + 1)
X = np.vstack([np.ones(T), t]).T
XTX = X.T @ X

XTX_div_T = XTX / T
print("Matriz X'X dividida por T:\n", XTX_div_T)

XTX_div_T3 = XTX / T**3
print("\nMatriz X'X dividida por T^3:\n", XTX_div_T3)
```
O resultado mostra que a matriz dividida por $T$ diverge, enquanto a matriz dividida por $T^3$ converge para uma matriz singular, reforÃ§ando a necessidade de usar o reescalonamento adequado com a matriz $Y_T$ para obter uma matriz limite nÃ£o-singular.

### Reescalonamento com a Matriz Y_T e sua Necessidade
O reescalonamento das estimativas Ã© formalizado pela matriz $Y_T$ [^24, ^25]:
$$Y_T = \begin{bmatrix} \sqrt{T} & 0 \\ 0 & T^{3/2} \end{bmatrix}$$
Esta matriz Ã© usada para reescalonar o desvio do estimador da seguinte forma [^26, ^27]:
$$\begin{bmatrix} \sqrt{T}(\hat{\alpha}_T - \alpha) \\ T^{3/2}(\hat{\delta}_T - \delta) \end{bmatrix} = Y_T (b_T - \beta) = Y_T \left( \sum_{t=1}^T x_t x_t' \right)^{-1} \sum_{t=1}^T x_t \epsilon_t$$
Ao multiplicar o desvio por $Y_T$, estamos essencialmente aplicando as taxas de convergÃªncia corretas para cada parÃ¢metro. O termo $Y_T \left( \sum_{t=1}^T x_t x_t' \right)^{-1} Y_T^{-1}$ converge para uma matriz $Q$ nÃ£o singular [^28, ^29]:
$$Q = \begin{bmatrix} 1 & \frac{1}{2} \\ \frac{1}{2} & \frac{1}{3} \end{bmatrix}$$
Essa convergÃªncia Ã© crucial para a derivaÃ§Ã£o da distribuiÃ§Ã£o assintÃ³tica.

A importÃ¢ncia da matriz $Y_T$ reside em sua capacidade de transformar as estimativas originais em variÃ¡veis que tÃªm uma distribuiÃ§Ã£o limitante nÃ£o degenerada. Como vimos no capÃ­tulo anterior, isso Ã© obtido multiplicando os estimadores pelas suas taxas de convergÃªncia correspondentes [^23].

> ðŸ’¡ **Exemplo NumÃ©rico:** Para exemplificar a atuaÃ§Ã£o da matriz $Y_T$, vamos considerar um cenÃ¡rio em que $T = 100$ e calcular $Y_T (X'X)^{-1} Y_T^{-1}$ para demonstrar sua convergÃªncia Ã  matriz $Q$.
```python
import numpy as np
from numpy.linalg import inv

T = 100
t = np.arange(1, T + 1)
X = np.vstack([np.ones(T), t]).T
Y_T = np.array([[np.sqrt(T), 0], [0, T**(3/2)]])
XTX = X.T @ X
XTX_inv = inv(XTX)
Q_hat = Y_T @ XTX_inv @ Y_T.T
Q = np.array([[1, 1/2], [1/2, 1/3]])

print("Matriz Y_T (X'X)^-1 Y_T':")
print(Q_hat)
print("\nMatriz Q:")
print(Q)
```
O exemplo mostra que a matriz $Y_T (X'X)^{-1} Y_T^{-1}$ converge para a matriz $Q$ conforme $T$ aumenta, demonstrando o efeito do reescalonamento para obter uma matriz nÃ£o-singular.

### O Desvio do Estimador e a Necessidade de Reescalonamento
O desvio do estimador MQO, $b_T - \beta$, Ã© funÃ§Ã£o da matriz de momentos e dos erros. Especificamente:
$$b_T - \beta = \left( \sum_{t=1}^T x_t x_t' \right)^{-1} \sum_{t=1}^T x_t \epsilon_t$$
Como discutido, a matriz de momentos $\sum_{t=1}^T x_t x_t'$ tem elementos que crescem em taxas diferentes com o aumento de $T$. Isso implica que a matriz inversa $\left( \sum_{t=1}^T x_t x_t' \right)^{-1}$ terÃ¡ elementos que decrescem em taxas diferentes, afetando as taxas de convergÃªncia de $\hat{\alpha}_T$ e $\hat{\delta}_T$.
O termo $\sum_{t=1}^T x_t \epsilon_t$ tambÃ©m possui taxas de convergÃªncia distintas para $\sum_{t=1}^T \epsilon_t$ e $\sum_{t=1}^T t \epsilon_t$, com os termos dominantes na ordem de $\sqrt{T}$ e $T^{3/2}$ respectivamente.
Para compensar essas diferentes taxas de convergÃªncia, Ã© necessÃ¡rio reescalonar tanto a matriz de momentos quanto os erros. O reescalonamento com $Y_T$ assegura que os estimadores reescalonados convirjam para uma distribuiÃ§Ã£o assintÃ³tica bem definida.
O termo $Y_T \sum_{t=1}^T x_t \epsilon_t$ Ã© dado por [^30]:
$$Y_T \sum_{t=1}^T x_t \epsilon_t = \begin{bmatrix} \sqrt{T} \frac{1}{T} \sum_{t=1}^T \epsilon_t \\ T^{3/2} \frac{1}{T^2} \sum_{t=1}^T t \epsilon_t \end{bmatrix} = \begin{bmatrix} \frac{1}{\sqrt{T}} \sum_{t=1}^T \epsilon_t \\ \frac{1}{\sqrt{T}} \sum_{t=1}^T \frac{t}{T} \epsilon_t \end{bmatrix}$$
Este vetor converge para uma distribuiÃ§Ã£o normal bivariada, com o primeiro componente convergindo para $N(0, \sigma^2)$ e o segundo para $N(0, \sigma^2/3)$ [^31, ^32, ^33, ^34, ^35].

> ðŸ’¡ **Exemplo NumÃ©rico:** Para ilustrar a convergÃªncia de  $Y_T \sum_{t=1}^T x_t \epsilon_t$, vamos gerar um conjunto de dados com $T=100$, com $\epsilon_t \sim N(0, 1)$, e calcular as estatÃ­sticas do vetor  $Y_T \sum_{t=1}^T x_t \epsilon_t$.  Vamos repetir o processo 1000 vezes para verificar a distribuiÃ§Ã£o assintÃ³tica.
```python
import numpy as np

T = 100
num_simulations = 1000
results = np.zeros((num_simulations, 2))

for i in range(num_simulations):
    epsilon_t = np.random.normal(0, 1, T)
    t = np.arange(1, T + 1)
    x_t = np.vstack([np.ones(T), t]).T
    
    Y_T_sum_x_eps = np.array([
        (1/np.sqrt(T)) * np.sum(epsilon_t),
        (1/np.sqrt(T)) * np.sum((t/T) * epsilon_t)
    ])
    results[i] = Y_T_sum_x_eps
    
mean_vector = np.mean(results, axis=0)
cov_matrix = np.cov(results, rowvar=False)

print("Vetor de MÃ©dias da amostra:", mean_vector)
print("\nMatriz de CovariÃ¢ncia da amostra:\n", cov_matrix)
print("\nVariÃ¢ncia teÃ³rica para o primeiro elemento:", 1)
print("VariÃ¢ncia teÃ³rica para o segundo elemento:", 1/3)
```
Este exemplo mostra que as mÃ©dias amostrais dos elementos de $Y_T \sum_{t=1}^T x_t \epsilon_t$ sÃ£o prÃ³ximas de zero e que a matriz de covariÃ¢ncia se aproxima de $\begin{bmatrix} 1 & 0 \\ 0 & 1/3 \end{bmatrix}$, confirmando a convergÃªncia para a distribuiÃ§Ã£o normal bivariada com variÃ¢ncias $\sigma^2$ e $\sigma^2/3$, respectivamente.

**Lema 3.1**
*Seja $Z_T =  \frac{1}{\sqrt{T}} \sum_{t=1}^T \epsilon_t$ e $W_T =  \frac{1}{\sqrt{T}} \sum_{t=1}^T \frac{t}{T} \epsilon_t$. Se  $\epsilon_t$ Ã© um ruÃ­do branco com mÃ©dia zero, variÃ¢ncia $\sigma^2$ e quarto momento finito, entÃ£o $Z_T \xrightarrow{d} N(0, \sigma^2)$ e $W_T \xrightarrow{d} N(0, \sigma^2/3)$.*

*Prova:*

I. A prova de $Z_T \xrightarrow{d} N(0, \sigma^2)$ segue diretamente do Teorema do Limite Central, jÃ¡ que $\epsilon_t$ Ã© i.i.d. com mÃ©dia zero e variÃ¢ncia $\sigma^2$.
II. A prova de $W_T \xrightarrow{d} N(0, \sigma^2/3)$ foi demonstrada nas referÃªncias [^33, ^34, ^35], que detalham a convergÃªncia para uma distribuiÃ§Ã£o normal usando argumentos de martingale difference sequence e convergÃªncia quadrÃ¡tica mÃ©dia.
Portanto, o lema estÃ¡ provado. â– 

**Teorema 3.1**
*Seja $\hat{\beta}_T = [\hat{\alpha}_T, \hat{\delta}_T]' $ o estimador de MQO do modelo $y_t = \alpha + \delta t + \epsilon_t$, onde $\epsilon_t$ Ã© um ruÃ­do branco com mÃ©dia zero, variÃ¢ncia $\sigma^2$ e quarto momento finito. A distribuiÃ§Ã£o assintÃ³tica do vetor reescalonado Ã© dada por
$$ \begin{bmatrix} \sqrt{T}(\hat{\alpha}_T - \alpha) \\ T^{3/2}(\hat{\delta}_T - \delta) \end{bmatrix} \xrightarrow{d} N(0, \sigma^2 Q^{-1}) $$
onde $Q = \begin{bmatrix} 1 & \frac{1}{2} \\ \frac{1}{2} & \frac{1}{3} \end{bmatrix}$ e $Q^{-1} = \begin{bmatrix} 4 & -6 \\ -6 & 12 \end{bmatrix}$*

*Prova:*
I. O resultado segue diretamente da discussÃ£o anterior. O desvio do estimador MQO Ã© dado por:
   $$b_T - \beta = \left( \sum_{t=1}^T x_t x_t' \right)^{-1} \sum_{t=1}^T x_t \epsilon_t$$
II. Para obter a distribuiÃ§Ã£o assintÃ³tica, multiplicamos por $Y_T$:
$$Y_T(b_T - \beta) = Y_T \left( \sum_{t=1}^T x_t x_t' \right)^{-1}  \sum_{t=1}^T x_t \epsilon_t = Y_T \left( \sum_{t=1}^T x_t x_t' \right)^{-1} Y_T^{-1} Y_T \sum_{t=1}^T x_t \epsilon_t$$
III. Mostramos anteriormente que:
$$Y_T \left( \sum_{t=1}^T x_t x_t' \right)^{-1} Y_T^{-1} \rightarrow Q = \begin{bmatrix} 1 & \frac{1}{2} \\ \frac{1}{2} & \frac{1}{3} \end{bmatrix}$$
IV. AlÃ©m disso, demonstramos no Lema 3.1 que
   $$ Y_T \sum_{t=1}^T x_t \epsilon_t = \begin{bmatrix} \frac{1}{\sqrt{T}} \sum_{t=1}^T \epsilon_t \\ \frac{1}{\sqrt{T}} \sum_{t=1}^T \frac{t}{T} \epsilon_t \end{bmatrix} \xrightarrow{d} N(0, \sigma^2 Q)$$
V. Pelo teorema de Slutsky:
$$Y_T(b_T - \beta) \xrightarrow{d} N(0, \sigma^2 Q^{-1})$$
Portanto, o resultado Ã© comprovado. â– 

**CorolÃ¡rio 3.1** *Sob as mesmas condiÃ§Ãµes do Teorema 3.1, as distribuiÃ§Ãµes assintÃ³ticas dos estimadores individuais reescalonados sÃ£o dadas por:
   $$\sqrt{T}(\hat{\alpha}_T - \alpha) \xrightarrow{d} N(0, 4\sigma^2)$$
   $$T^{3/2}(\hat{\delta}_T - \delta) \xrightarrow{d} N(0, 12\sigma^2)$$*

*Prova:*
I. O resultado segue diretamente da matriz de covariÃ¢ncia obtida no Teorema 3.1. A matriz $Q^{-1} = \begin{bmatrix} 4 & -6 \\ -6 & 12 \end{bmatrix}$ implica que a variÃ¢ncia assintÃ³tica de $\sqrt{T}(\hat{\alpha}_T - \alpha)$ Ã© $4\sigma^2$, e a variÃ¢ncia assintÃ³tica de $T^{3/2}(\hat{\delta}_T - \delta)$ Ã© $12\sigma^2$.
Portanto, o corolÃ¡rio estÃ¡ provado. â– 
> ðŸ’¡ **Exemplo NumÃ©rico:** Para verificar o CorolÃ¡rio 3.1, vamos simular um modelo de tendÃªncia temporal com $\alpha = 2$, $\delta = 0.5$, $\sigma^2=1$ e $T = 100$. Vamos repetir o processo 1000 vezes, estimar os parÃ¢metros e calcular a distribuiÃ§Ã£o empÃ­rica dos estimadores reescalonados.
```python
import numpy as np
import pandas as pd
from numpy.linalg import inv

T = 100
alpha = 2
delta = 0.5
sigma2 = 1
num_simulations = 1000
results_alpha = np.zeros(num_simulations)
results_delta = np.zeros(num_simulations)

for i in range(num_simulations):
    epsilon_t = np.random.normal(0, np.sqrt(sigma2), T)
    t = np.arange(1, T + 1)
    y_t = alpha + delta * t + epsilon_t
    X = np.vstack([np.ones(T), t]).T
    beta_hat = inv(X.T @ X) @ X.T @ y_t
    results_alpha[i] = np.sqrt(T) * (beta_hat[0] - alpha)
    results_delta[i] = T**(3/2) * (beta_hat[1] - delta)

mean_alpha = np.mean(results_alpha)
var_alpha = np.var(results_alpha)
mean_delta = np.mean(results_delta)
var_delta = np.var(results_delta)

print("MÃ©dia amostral de sqrt(T)(alpha_hat - alpha):", mean_alpha)
print("VariÃ¢ncia amostral de sqrt(T)(alpha_hat - alpha):", var_alpha)
print("MÃ©dia amostral de T^(3/2)(delta_hat - delta):", mean_delta)
print("VariÃ¢ncia amostral de T^(3/2)(delta_hat - delta):", var_delta)
print("VariÃ¢ncia teÃ³rica de sqrt(T)(alpha_hat - alpha):", 4 * sigma2)
print("VariÃ¢ncia teÃ³rica de T^(3/2)(delta_hat - delta):", 12 * sigma2)

```
O exemplo mostra que as variÃ¢ncias amostrais dos estimadores reescalonados se aproximam dos valores teÃ³ricos, confirmando o CorolÃ¡rio 3.1.

Este teorema demonstra formalmente como o reescalonamento garante que as estimativas dos parÃ¢metros possuam uma distribuiÃ§Ã£o assintÃ³tica bem definida, permitindo realizar testes de hipÃ³teses e construir intervalos de confianÃ§a vÃ¡lidos. O CorolÃ¡rio 3.1  especifica as distribuiÃ§Ãµes assintÃ³ticas para os estimadores individuais, que sÃ£o Ãºteis para construir intervalos de confianÃ§a para cada parÃ¢metro separadamente.

### ConclusÃ£o
Este capÃ­tulo detalhou a necessidade do reescalonamento em modelos de regressÃ£o com tendÃªncias temporais determinÃ­sticas. Demonstramos que as diferentes taxas de convergÃªncia de $\hat{\alpha}_T$ e $\hat{\delta}_T$, juntamente com a divergÃªncia da matriz de momentos $(1/T)\sum_{t=1}^T x_t x_t'$, exigem um tratamento especial. O reescalonamento com a matriz $Y_T$ permite obter uma distribuiÃ§Ã£o assintÃ³tica nÃ£o degenerada para os estimadores MQO, corrigindo o problema da divergÃªncia. Analisamos como as matrizes de momentos divergem e como o reescalonamento por $Y_T$ assegura que a matriz resultante convirja para uma matriz nÃ£o singular. AlÃ©m disso, apresentamos o Teorema 3.1, que demonstra formalmente como os estimadores reescalonados convergem para uma distribuiÃ§Ã£o normal multivariada, permitindo realizar inferÃªncia assintÃ³tica.

### ReferÃªncias
[^1]:  *Os coeficientes de modelos de regressÃ£o envolvendo raÃ­zes unitÃ¡rias ou tendÃªncias temporais determinÃ­sticas sÃ£o tipicamente estimados por mÃ­nimos quadrados ordinÃ¡rios.*
[^2]:  *No entanto, as distribuiÃ§Ãµes assintÃ³ticas das estimativas dos coeficientes nÃ£o podem ser calculadas da mesma forma que aquelas para modelos de regressÃ£o envolvendo variÃ¡veis estacionÃ¡rias.*
[^3]: *This section considers OLS estimation of the parameters of a simple time trend, $y_t = \alpha + \delta t + \epsilon_t$, for $\epsilon_t$ a white noise process. If $\epsilon_t \sim N(0, \sigma^2)$, then the model [16.1.1] satisfies the classical regression assumptions...*
[^4]: *Write [16.1.1] in the form of the standard regression model, $y_t = x_t'\beta + \epsilon_t$*
[^5]: *where $x_t = [1  \quad t]'$*
[^6]: *$\beta = [\alpha  \quad \delta]'$*
[^7]: *Let $b_T$ denote the OLS estimate of $\beta$ based on a sample of size $T$: $b_T = [\alpha_T  \quad \delta_T]' = (\sum x_t x_t')^{-1} \sum x_t y_t$*
[^8]: *Recall from equation [8.2.3] that the deviation of the OLS estimate from the true value can be expressed as $(b_T - \beta) = (\sum x_t x_t')^{-1} \sum x_t \epsilon_t$*
[^9]: *$(b_T - \beta) = (\sum x_t x_t')^{-1} \sum x_t \epsilon_t$*
[^10]: *To find the limiting distribution for a regression with stationary explanatory variables, the approach in Chapter 8 was to multiply [16.1.6] by $\sqrt{T}$, resulting in $\sqrt{T}(b_T - \beta) = [(1/T) \sum x_t x_t']^{-1} [(1/\sqrt{T}) \sum x_t \epsilon_t]$*
[^11]: *The usual assumption was that $(1/T) \sum x_t x_t'$ converged in probability to a nonsingular matrix $Q$ while $(1/\sqrt{T}) \sum x_t \epsilon_t$ converged in distribution to a $N(0, \sigma^2Q)$ random variable, implying that $\sqrt{T}(b_T - \beta) -> N(0, \sigma^2Q^{-1})$.*
[^12]: *...expression [16.1.6] would be $[(\alpha_T - \alpha)  \quad (\delta_T - \delta)]' = [\sum 1  \quad \sum t ; \sum t  \quad \sum t^2]^{-1} [\sum \epsilon_t ; \sum t\epsilon_t]$*
[^13]: *$[(\alpha_T - \alpha)  \quad (\delta_T - \delta)]' = [\sum 1  \quad \sum t ; \sum t  \quad \sum t^2]^{-1} [\sum \epsilon_t ; \sum t\epsilon_t]$*
[^14]: *It is straightforward to show by induction that $\sum t = T(T+1)/2$*
[^15]: *$\sum t^2 = T(T+1)(2T+1)/6.$*
[^16]: *Thus, the leading term in $\sum t$ is $T^2/2$; that is, $(1/T^2) \sum t = 1/2 + 1/(2T) \rightarrow 1/2$*
[^17]: *Similarly, the leading term in $\sum t^2$ is $T^3/3$: $(1/T^3) \sum t^2 = 1/3 + 1/(2T) + 1/(6T^2) \rightarrow 1/3.*
[^18]: *For future reference, we note here the general pattern-the leading term in $\sum t^v$ is $T^{v+1}/(v+1)$: $(1/T^{v+1}) \sum t^v \rightarrow 1/(v+1)$*
[^19]: *For $x$, given in [16.1.3], results [16.1.9] and [16.1.10] imply that $\sum x_t x_t' = [\sum 1  \quad \sum t ; \sum t  \quad \sum t^2] = [T  \quad T(T+1)/2 ;  T(T+1)/2  \quad T(T+1)(2T+1)/6]$*
[^20]: *$\sum x_t x_t' = [\sum 1  \quad \sum t ; \sum t  \quad \sum t^2] = [T  \quad T(T+1)/2 ;  T(T+1)/2  \quad T(T+1)(2T+1)/6]$*
[^21]: *In contrast to the usual result for stationary regressions, for the matrix in [16.1.16], $(1/T) \sum x_t x_t'$ diverges. To obtain a convergent matrix, [16.1.16] would have to be divided by $T^3$ rather than $T$.*
[^22]: *Unfortunately, this limiting matrix cannot be inverted, as $(1/T) \sum x_t x_t'$ can be in the usual case. Hence, a different approach from that in the stationary case will be needed to calculate the asymptotic distribution of $b_T$.*
[^23]: *It turns out that the OLS estimates $\alpha_T$ and $\delta_T$ have different asymptotic rates of convergence. To arrive at nondegenerate limiting distributions, $\alpha_T$ is multiplied by $\sqrt{T}$, whereas $\delta_T$ must be multiplied by $T^{3/2}$.*
[^24]: *We can think of this adjustment as premultiplying [16.1.6] or [16.1.8] by the matrix $Y_T = [\sqrt{T}  \quad 0 ; 0  \quad T^{3/2}]$*
[^25]: *$Y_T = [\sqrt{T}  \quad 0 ; 0  \quad T^{3/2}]$*
[^26]: *resulting in $[\sqrt{T}(\alpha_T - \alpha)  \quad ; T^{3/2}(\delta_T - \delta)]' = Y_T (\sum x_t x_t')^{-1}  Y_T^{-1} [ (1/\sqrt{T}) \sum x_t \epsilon_t]$*
[^27]: *$[\sqrt{T}(\alpha_T - \alpha)  \quad ; T^{3/2}(\delta_T - \delta)]' = Y_T (\sum x_t x_t')^{-1}  Y_T^{-1} [ (1/\sqrt{T}) \sum x_t \epsilon_t]$*
[^28]: *Consider the first term in the last expression of [16.1.18]. Substituting from [16.1.17] and [16.1.16], ${Y_T (\sum x_t x_t')^{-1} Y_T^{-1}} = [T^{-1/2}  \quad 0 ; 0  \quad T^{-3/2}]  [ \sum 1  \quad \sum t ; \sum t  \quad \sum t^2 ]^{-1} [T^{-1/2} \quad 0 ; 0 \quad T^{-3/2}] = [T^{-1/2}  \quad 0 ; 0  \quad T^{-3/2}] [T  \quad T(T+1)/2 ; T(T+1)/2  \quad T(T+1)(2T+1)/6 ]^{-1} [T^{-1/2} \quad 0 ; 0 \quad T^{-3/2}]$*
[^29]: *Thus, it follows from [16.1.11] and [16.1.12] that  {Y_T (Î£ x_t x_t')^-1 Y_T^-1}  -> Q = [1  1/2 ; 1/2  1/3]*
[^30]: *Turning next to the second term in [16.1.18], $Y_T \sum x_t \epsilon_t = [ T^{-1/2} 0 ; 0 T^{-3/2} ] [Î£ \epsilon_t  ; Î£ t \epsilon_t] = [ (1/\sqrt{T}) Î£ \epsilon_t ; (1/âˆšT) Î£ (t/T) \epsilon_t]$*
[^31]: *$Y_T \sum x_t \epsilon_t = [ (1/âˆšT) \sum \epsilon_t ; (1/âˆšT) \sum (t/T) \epsilon_t]. Under standard assumptions about \epsilon_t , this vector will be asymptotically Gaussian.*
[^32]: *For example, suppose that $\epsilon_t$ is i.i.d. with mean zero, variance $\sigmaÂ²$, and finite fourth moment. Then the first element of the vector in [16.1.21] satisfies $(1/âˆšT) \sum \epsilon_t -> N(0, \sigmaÂ²)$, by the central limit theorem.*
[^33]: *For the second element of the vector in [16.1.21], observe that $\{(t/T)\epsilon_t\}$ is a martingale difference sequence that satisfies the conditions of Proposition 7.8. Specifically, its variance is $\sigma_T^2 = E[(t/T)\epsilon_t]Â² = \sigmaÂ²(tÂ²/TÂ²)$*
[^34]: *$\sigma_T^2 = E[(t/T)\epsilon_t]Â² = \sigmaÂ²(tÂ²/TÂ²)$*
[^35]: *(1/T) Î£ \sigma_t^2 = \sigmaÂ²(1/T) Î£(tÂ²/TÂ²) -> \sigmaÂ²/3*
Furthermore, (1/T) $\sum_{t=1}^T [(t/T)\epsilon_t]^2 \rightarrow \sigma^2/3$. To verify this last claim, notice that

$E((1/T) \sum_{t=1}^T [(t/T)\epsilon_t]^2 - (1/T) \sum_{t=1}^T \sigma_t^2)^2 = E((1/T) \sum_{t=1}^T (t/T)^2\epsilon_t^2  - (1/T) \sum_{t=1}^T  (t/T)^2\sigma^2)^2 =  E((1/T) \sum_{t=1}^T (t/T)^2(\epsilon_t^2 - \sigma^2))^2 = (1/T)^2 \sum_{t=1}^T (t/T)^2 E(\epsilon_t^2 - \sigma^2)^2 $ [^22]

But from [16.1.13], $T$ times the magnitude in [16.1.22] converges to
$(1/T) \sum_{t=1}^T (t/T)E(\epsilon_t^2 - \sigma^2)^2 \rightarrow (1/5) \cdot E(\epsilon_t^2 - \sigma^2)^2$, meaning that [16.1.22] itself converges to zero: $(1/T) \sum_{t=1}^T [(t/T)\epsilon_t]^2 - (1/T)\sum_{t=1}^T \sigma_t^2 \xrightarrow{m.s.} 0$.

But this implies that $(1/T) \sum_{t=1}^T [(t/T)\epsilon_t]^2 \xrightarrow{p} \sigma^2/3$, as claimed. Hence, from Proposition 7.8, $(1/\sqrt{T}) \sum_{t=1}^T (t/T)\epsilon_t$ satisfies the central limit theorem:

$(1/\sqrt{T}) \sum_{t=1}^T (t/T)\epsilon_t \xrightarrow{d} N(0, \sigma^2/3)$.

Finally, consider the joint distribution of the two elements in the $(2 \times 1)$ vector described by [16.1.21]. Any linear combination of these elements takes the form

$(1/\sqrt{T}) \sum_{t=1}^T [\lambda_1 + \lambda_2(t/T)]\epsilon_t$.

Then $[\lambda_1 + \lambda_2(t/T)]\epsilon_t$ is also a martingale difference sequence with positive variance given by $\sigma^2[\lambda_1^2 + 2\lambda_1\lambda_2(t/T) + \lambda_2^2(t/T)^2]$ satisfying

$(1/T) \sum_{t=1}^T \sigma^2[\lambda_1^2 + 2\lambda_1\lambda_2(t/T) + \lambda__2^2(t/T)^2] = \sigma^2[\lambda_1^2 + \lambda_1\lambda_2 + (1/3)\lambda_2^2]$.

In the context of the AR(1) model, the estimated variance is given by

$\hat{\sigma}^2 = \frac{1}{T-1} \sum_{t=2}^{T} (\epsilon_t - \hat{\rho} \epsilon_{t-1})^2$,

where $\hat{\rho}$ is the sample autocorrelation coefficient.  In the case of heteroskedasticity, the OLS estimator remains unbiased, but it is no longer the Best Linear Unbiased Estimator (BLUE). This means that although the estimatorâ€™s expected value equals the true parameter, there exists another linear unbiased estimator with a lower variance. We can obtain a more efficient estimator in the presence of heteroskedasticity by using Generalized Least Squares (GLS). GLS takes into account the heteroskedasticity structure and weights the data accordingly to provide minimum variance estimates.

The White test is a statistical test that can be used to detect heteroskedasticity in regression models. The test involves regressing the squared residuals from the original model on the original regressors, their squares, and cross-products. If this auxiliary regression is statistically significant, this indicates the presence of heteroskedasticity. The null hypothesis for the White test is that the error terms are homoskedastic. If the p-value associated with the test statistic is below a chosen significance level (e.g. 0.05), the null hypothesis is rejected, and we have evidence of heteroskedasticity.

Another method for detecting heteroskedasticity is the Breusch-Pagan test. This test regresses the squared residuals on the original regressors, and a significant relationship is an indication of heteroskedasticity.

The solutions to handle heteroskedasticity include:

1.  **Using Heteroskedasticity-Robust Standard Errors:** These are standard errors that are adjusted for heteroskedasticity, giving valid inference even when the standard assumption of homoskedasticity is violated.
2.  **Generalized Least Squares (GLS):** As mentioned before, GLS uses knowledge of the heteroskedasticity structure to transform the data, leading to more efficient parameter estimates than OLS.
3.  **Transforming the Data:** This involves taking a transformation (such as logarithms or square roots) on the dependent variable which can stabilize the variance across different values of the independent variables.

These solutions ensure that accurate inference can be made in regression models that present heteroskedastic errors. It is crucial to examine model residuals for the presence of heteroskedasticity and take appropriate corrective actions, in order to obtain reliable statistical inference.

<!-- END -->
