## Testes de Hip√≥teses em Modelos Autorregressivos com Tend√™ncia Determin√≠stica

### Introdu√ß√£o
Este cap√≠tulo aborda testes de hip√≥teses em modelos de s√©ries temporais com tend√™ncias determin√≠sticas. O foco √© a an√°lise de modelos autorregressivos onde a presen√ßa de uma tend√™ncia determin√≠stica afeta a distribui√ß√£o assint√≥tica dos estimadores OLS. Em particular, exploramos como as taxas de converg√™ncia dos estimadores influenciam a forma como as estat√≠sticas de teste s√£o constru√≠das. Conforme vimos anteriormente [^1, 2, 3], as distribui√ß√µes assint√≥ticas para processos com tend√™ncias determin√≠sticas diferem daquelas para processos estacion√°rios, especialmente em rela√ß√£o √† taxa de converg√™ncia dos estimadores.

### Conceitos Fundamentais
Conforme apresentado em [^1, 2], as estimativas OLS dos coeficientes em modelos com tend√™ncias determin√≠sticas t√™m diferentes taxas de converg√™ncia. O coeficiente da tend√™ncia, por exemplo, converge mais rapidamente para seu valor verdadeiro do que o intercepto do modelo. Este comportamento diferencial requer uma an√°lise cuidadosa para a constru√ß√£o de testes de hip√≥teses.

Em continuidade ao exposto nas se√ß√µes anteriores, a Se√ß√£o 16.2 introduz o conceito de que, embora os estimadores OLS para o modelo de tend√™ncia de tempo simples possuam taxas de converg√™ncia distintas, os erros padr√£o dos coeficientes tamb√©m se ajustam de forma que as estat√≠sticas t e F padronizadas tenham a mesma distribui√ß√£o assint√≥tica que em modelos de regress√£o estacion√°rios. Esta se√ß√£o explora o teste de hip√≥teses com este modelo com mais detalhe [^4].

Neste contexto, √© crucial relembrar a transforma√ß√£o dos regressores, conforme apresentado na se√ß√£o 16.3 [^11], para isolar as componentes com diferentes taxas de converg√™ncia. A transforma√ß√£o introduz termos com m√©dia zero e estacion√°rios, al√©m de termos de tend√™ncia e intercepto. Esta transforma√ß√£o facilita a obten√ß√£o da distribui√ß√£o assint√≥tica para os estimadores OLS.

A an√°lise a seguir aborda os testes de hip√≥teses para o modelo autorregressivo com tend√™ncia determin√≠stica, utilizando os resultados derivados anteriormente.
**Hip√≥teses Lineares**
Considere um modelo autorregressivo geral com uma tend√™ncia determin√≠stica [^11]:
$$ y_t = \alpha + \delta t + \phi_1 y_{t-1} + \phi_2 y_{t-2} + \ldots + \phi_p y_{t-p} + \epsilon_t. $$
Na Se√ß√£o 16.3, √© demonstrado que este modelo pode ser transformado para facilitar a an√°lise das propriedades assint√≥ticas dos estimadores OLS, onde uma matriz  **G'** √© introduzida para descrever a transforma√ß√£o dos regressores. Essa transforma√ß√£o permite expressar o modelo em termos de vari√°veis estacion√°rias, um termo constante e uma tend√™ncia linear, isolando as componentes com taxas de converg√™ncia distintas [^11, 12].

A quest√£o chave √© que, apesar da transforma√ß√£o, os testes de hip√≥teses no modelo original podem ser conduzidos sem a necessidade de estimar o modelo transformado diretamente. Ou seja, podemos calcular e interpretar os testes de hip√≥teses sobre o modelo n√£o transformado da forma usual [^15].

**Testes de Wald**
Para o teste de hip√≥teses lineares na forma $H_0: R\beta = r$ onde R √© a matriz de restri√ß√µes e r o vetor de restri√ß√µes, a estat√≠stica de teste de Wald para o modelo n√£o transformado √© dada por [^15]:
$$ \chi^2_T = (R\hat{\beta} - r)'[s^2_T R(X'X)^{-1}R']^{-1}(R\hat{\beta} - r), $$
onde $\hat{\beta}$ √© o estimador OLS dos par√¢metros, $s^2_T$ √© a vari√¢ncia residual estimada, e $X$ √© a matriz de regressores. A estat√≠stica de Wald segue uma distribui√ß√£o $\chi^2$ com *m* graus de liberdade sob a hip√≥tese nula, onde *m* √© o n√∫mero de restri√ß√µes lineares [^15].

> üí° **Exemplo Num√©rico:** Suponha que temos um modelo AR(1) com tend√™ncia, dado por $y_t = \alpha + \delta t + \phi_1 y_{t-1} + \epsilon_t$. Queremos testar a hip√≥tese nula de que $\phi_1 = 0.5$, ou seja, $H_0: \phi_1 = 0.5$. Nossa matriz de restri√ß√µes $R$ √© $[0, 0, 1]$ e $r$ √© $[0.5]$. Suponha que ap√≥s a estima√ß√£o com dados simulados, obtivemos os seguintes estimadores: $\hat{\alpha} = 1.2$, $\hat{\delta} = 0.1$, e $\hat{\phi_1} = 0.6$. A matriz $(X'X)^{-1}$ estimada √©:
> ```python
> import numpy as np
>
> # Exemplo de (X'X)^{-1} (simula√ß√£o para fins ilustrativos)
> inv_XTX = np.array([[0.05, 0.001, 0.002],
>                     [0.001, 0.0001, 0.0002],
>                     [0.002, 0.0002, 0.01]])
>
> R = np.array([[0, 0, 1]])
> r = np.array([0.5])
> beta_hat = np.array([1.2, 0.1, 0.6])
> s2_T = 0.2  # Vari√¢ncia residual estimada
>
> # C√°lculo da estat√≠stica de Wald
> numerador = (R @ beta_hat - r).T @ (R @ beta_hat - r)
> denominador = s2_T * R @ inv_XTX @ R.T
> chi2_T = numerador / denominador
>
> print(f"Estat√≠stica de Wald: {chi2_T[0][0]:.4f}")
> ```
> O resultado seria algo como `Estat√≠stica de Wald: 10.0000`. Se o valor cr√≠tico da distribui√ß√£o qui-quadrado com 1 grau de liberdade a 5% de signific√¢ncia √© 3.84, rejeitamos a hip√≥tese nula de que $\phi_1 = 0.5$. Este exemplo num√©rico ilustra o c√°lculo da estat√≠stica de Wald, permitindo realizar o teste de hip√≥teses sobre um par√¢metro espec√≠fico do modelo.
>
A Se√ß√£o 16.3 demonstra que a estat√≠stica de Wald, calculada da forma usual sobre o modelo n√£o transformado, converge para uma distribui√ß√£o $\chi^2$ assintoticamente, mesmo em presen√ßa de diferentes taxas de converg√™ncia entre os par√¢metros do modelo. Esta demonstra√ß√£o utiliza o resultado derivado para o modelo transformado, que tem distribui√ß√£o assint√≥tica conhecida [^15].

**Observa√ß√£o 1**
√â importante notar que, apesar das diferentes taxas de converg√™ncia dos estimadores, a estat√≠stica de Wald utiliza a matriz de covari√¢ncia estimada dos par√¢metros $(\hat{\beta})$, que √© uma estimativa consistente da verdadeira matriz de covari√¢ncia. Essa consist√™ncia garante que a estat√≠stica de teste tenha a distribui√ß√£o assint√≥tica correta. Em outras palavras, mesmo que os estimadores para os par√¢metros de tend√™ncia convirjam em taxas diferentes, a estat√≠stica de Wald, ao empregar essa estimativa de covari√¢ncia, leva em considera√ß√£o essa informa√ß√£o, o que gera um teste com distribui√ß√£o $\chi^2$ quando a hip√≥tese nula √© verdadeira.

A Se√ß√£o 16.3 fornece uma an√°lise detalhada de como a estat√≠stica de teste de Wald pode ser expressa tanto para o modelo transformado quanto para o original, mostrando a equival√™ncia assint√≥tica entre os dois [^15, 16]. Essa equival√™ncia garante que os testes de hip√≥teses lineares sobre os par√¢metros do modelo autorregressivo com tend√™ncia determin√≠stica podem ser realizados diretamente sobre o modelo original, sem a necessidade da transforma√ß√£o dos regressores.

**Teorema 1** (Equival√™ncia Assint√≥tica dos Testes de Wald)
Seja $\chi^2_{T,orig}$ a estat√≠stica de Wald calculada sobre o modelo original (n√£o transformado) e $\chi^2_{T,transf}$ a estat√≠stica de Wald calculada sobre o modelo transformado. Sob a hip√≥tese nula $H_0: R\beta = r$, temos que:
$$ \chi^2_{T,orig} - \chi^2_{T,transf} \xrightarrow{p} 0, $$
onde $\xrightarrow{p}$ denota converg√™ncia em probabilidade.
*Prova:* A demonstra√ß√£o deste teorema √© baseada na linearidade da transforma√ß√£o dos regressores e na consist√™ncia do estimador de vari√¢ncia residual. A equival√™ncia dos testes de Wald entre o modelo transformado e o original √© um resultado assint√≥tico. Ou seja, a diferen√ßa entre as estat√≠sticas de teste, no limite, se torna desprez√≠vel. O detalhamento desta prova pode ser visto na se√ß√£o 16.3 [^15, 16].

I. Seja $\chi^2_{T,orig}$ a estat√≠stica de Wald para o modelo original e $\chi^2_{T,transf}$ para o modelo transformado.

II. A transforma√ß√£o dos regressores √© linear, ou seja, existe uma matriz G tal que $X_{transf} = XG$ , onde $X$ √© a matriz de regressores do modelo original e $X_{transf}$ √© a matriz de regressores do modelo transformado.

III. Os estimadores OLS do modelo transformado $\hat{\beta}_{transf}$ podem ser expressos em termos dos estimadores do modelo original $\hat{\beta}$ como $\hat{\beta}_{transf} = G^{-1}\hat{\beta}$ e sua matriz de covari√¢ncia √© dada por $Var(\hat{\beta}_{transf}) = (G^{-1})'Var(\hat{\beta})G^{-1}$.

IV. As estat√≠sticas de Wald para ambos os modelos s√£o definidas como:
    $$ \chi^2_{T,orig} = (R\hat{\beta} - r)'[s^2_T R(X'X)^{-1}R']^{-1}(R\hat{\beta} - r) $$
    $$ \chi^2_{T,transf} = (R_{transf}\hat{\beta}_{transf} - r)'[s^2_T R_{transf}(X_{transf}'X_{transf})^{-1}R_{transf}']^{-1}(R_{transf}\hat{\beta}_{transf} - r) $$
onde $R_{transf}$ √© a matriz de restri√ß√µes do modelo transformado e $R_{transf} = RG$.

V.  Como a transforma√ß√£o √© linear e os estimadores de vari√¢ncia s√£o consistentes, as duas estat√≠sticas de Wald convergem para a mesma distribui√ß√£o assint√≥tica, portanto,
   $$ \chi^2_{T,orig} - \chi^2_{T,transf} \xrightarrow{p} 0 $$

VI.  A converg√™ncia em probabilidade para zero significa que as estat√≠sticas de teste s√£o assintoticamente equivalentes. Portanto, o teste pode ser conduzido usando o modelo original sem perda de validade assint√≥tica. ‚ñ†

As taxas de converg√™ncia assint√≥tica, abordadas nas se√ß√µes anteriores [^2, 7], s√£o relevantes porque determinam a distribui√ß√£o das estimativas, e, consequentemente, como as estat√≠sticas de teste se comportam. A converg√™ncia mais r√°pida do coeficiente de tend√™ncia ($T^{3/2}$) quando comparada com a taxa do intercepto (T) e par√¢metros autorregressivos ($\sqrt{T}$) √© um aspecto chave que √© considerado na deriva√ß√£o do teste de Wald.

**Lema 1.1** (Distribui√ß√£o Assint√≥tica dos Estimadores OLS com Tend√™ncia)
Considere o modelo autorregressivo com tend√™ncia determin√≠stica. Definindo $\beta$ como o vetor dos coeficientes, temos que, sob condi√ß√µes de regularidade:
$$ \sqrt{T}(\hat{\beta} - \beta) \xrightarrow{d} N(0, \Sigma_{\beta}) $$
onde $\Sigma_{\beta}$ √© a matriz de covari√¢ncia assint√≥tica dos estimadores, e $\xrightarrow{d}$ denota converg√™ncia em distribui√ß√£o. As taxas de converg√™ncia, apesar de diferentes para cada par√¢metro, s√£o consideradas dentro desta matriz de covari√¢ncia.

*Prova:* A prova deste lema √© obtida a partir da an√°lise da distribui√ß√£o assint√≥tica dos estimadores OLS, tomando em considera√ß√£o as taxas de converg√™ncia de cada par√¢metro. Essa an√°lise √© encontrada nas se√ß√µes anteriores, como mencionado em [^1, 2, 7], onde a transforma√ß√£o dos regressores √© utilizada para determinar a distribui√ß√£o dos par√¢metros transformados.

I.  O modelo autorregressivo com tend√™ncia determin√≠stica pode ser escrito como:
   $$ y_t = \alpha + \delta t + \phi_1 y_{t-1} + \phi_2 y_{t-2} + \ldots + \phi_p y_{t-p} + \epsilon_t $$
   onde $\epsilon_t$ √© um ru√≠do branco com m√©dia zero e vari√¢ncia constante.
   
II. Os estimadores OLS $\hat{\beta}$ convergem para os verdadeiros par√¢metros $\beta$ quando o n√∫mero de amostras tende para o infinito.

III. Ao tomar em considera√ß√£o as diferentes taxas de converg√™ncia dos par√¢metros (T para o intercepto e $T^{3/2}$ para a tend√™ncia) dentro da matriz de covari√¢ncia assint√≥tica $\Sigma_{\beta}$, a distribui√ß√£o conjunta dos par√¢metros √© dada por:
$$ \sqrt{T}(\hat{\beta} - \beta) \xrightarrow{d} N(0, \Sigma_{\beta}) $$
   
IV. $\Sigma_{\beta}$ √© a matriz de covari√¢ncia assint√≥tica, que leva em conta as diferentes taxas de converg√™ncia, e n√£o √© simplesmente a matriz de covari√¢ncia cl√°ssica.
   
V.  A converg√™ncia em distribui√ß√£o para uma normal multivariada √© um resultado padr√£o para estimadores OLS, ajustado para incluir as particularidades de modelos com tend√™ncia determin√≠stica. ‚ñ†

> üí° **Exemplo Num√©rico:** Vamos assumir que estimamos um modelo AR(1) com tend√™ncia e temos $T = 100$ observa√ß√µes. Os estimadores OLS obtidos foram: $\hat{\alpha} = 0.8$, $\hat{\delta} = 0.02$, $\hat{\phi_1} = 0.7$. As verdadeiras covari√¢ncias s√£o desconhecidas, mas usando os dados e assumindo as condi√ß√µes necess√°rias, podemos estimar a matriz de covari√¢ncia assint√≥tica $\Sigma_{\beta}$. Digamos que, ap√≥s os c√°lculos,  a matriz $\Sigma_{\beta}$  estimada, ajustada pelas taxas de converg√™ncia, seja:
> ```python
> import numpy as np
>
> # Exemplo de matriz de covari√¢ncia assint√≥tica (simula√ß√£o para fins ilustrativos)
> Sigma_beta = np.array([[0.01, 0.0001, 0.0002],
>                        [0.0001, 0.00001, 0.00002],
>                        [0.0002, 0.00002, 0.004]])
>
> T = 100
> beta_hat = np.array([0.8, 0.02, 0.7]) #Estimativas
> beta_true = np.array([1, 0.01, 0.75]) #Par√¢metros verdadeiros (desconhecidos na pr√°tica)
>
> # Calculando a diferen√ßa entre as estimativas e os valores verdadeiros
> diff_beta = beta_hat - beta_true
>
> # Calculando o erro padr√£o dos estimadores
> std_errors = np.sqrt(np.diag(Sigma_beta) / T)
>
> # Mostrando o resultado
> print("Matriz de covari√¢ncia assint√≥tica estimada:\n", Sigma_beta)
> print("\nDesvios padr√£o dos estimadores (aprox.):", std_errors)
> ```
> A sa√≠da do c√≥digo seria algo como:
> ```
> Matriz de covari√¢ncia assint√≥tica estimada:
>  [[0.01    0.0001  0.0002 ]
>  [0.0001  0.00001 0.00002]
>  [0.0002  0.00002 0.004  ]]
>
> Desvios padr√£o dos estimadores (aprox.): [0.01     0.001    0.0063]
> ```
> Este exemplo mostra como a matriz de covari√¢ncia estimada √© utilizada para obter o desvio padr√£o de cada estimativa. Com esses desvios padr√£o, podemos construir intervalos de confian√ßa e testar hip√≥teses sobre os par√¢metros do modelo. Note que, apesar de n√£o conhecermos os valores verdadeiros dos par√¢metros, a distribui√ß√£o assint√≥tica nos permite fazer infer√™ncias sobre os coeficientes do modelo com base na matriz de covari√¢ncia estimada.

**Corol√°rio 1.1.1**
Sob a hip√≥tese nula $H_0: R\beta = r$, temos que:
$$ (R\hat{\beta} - r)'[s^2_T R(X'X)^{-1}R']^{-1}(R\hat{\beta} - r) \xrightarrow{d} \chi^2(m), $$
onde $\chi^2(m)$ √© a distribui√ß√£o qui-quadrado com *m* graus de liberdade, e *m* √© o n√∫mero de restri√ß√µes lineares.

*Prova:* O corol√°rio decorre do Lema 1.1 e da propriedade da estat√≠stica de Wald. A estat√≠stica √© uma fun√ß√£o quadr√°tica de um vetor que converge para uma normal multivariada, levando a uma distribui√ß√£o qui-quadrado assintoticamente.

I.  Do Lema 1.1, sabemos que $\sqrt{T}(\hat{\beta} - \beta)$ converge em distribui√ß√£o para uma normal multivariada com m√©dia zero e matriz de covari√¢ncia $\Sigma_\beta$.

II.  Sob a hip√≥tese nula $H_0 : R\beta = r$, o vetor $R\hat{\beta} - r$ tamb√©m converge para uma normal multivariada com m√©dia zero.

III. A estat√≠stica de Wald √© definida como:
$$ \chi^2_T = (R\hat{\beta} - r)'[s^2_T R(X'X)^{-1}R']^{-1}(R\hat{\beta} - r) $$

IV. Pela propriedade da distribui√ß√£o normal multivariada, e considerando que $s^2_T$ √© um estimador consistente da vari√¢ncia residual, temos que a estat√≠stica de Wald converge em distribui√ß√£o para uma qui-quadrado com *m* graus de liberdade, onde *m* √© o n√∫mero de restri√ß√µes em R.
$$ (R\hat{\beta} - r)'[s^2_T R(X'X)^{-1}R']^{-1}(R\hat{\beta} - r) \xrightarrow{d} \chi^2(m) $$
‚ñ†

> üí° **Exemplo Num√©rico:** Utilizando o exemplo anterior onde temos $\hat{\beta} = [0.8, 0.02, 0.7]$ e queremos testar a hip√≥tese de que $\phi_1 = 0.75$, ou seja $H_0: R\beta = r$, onde $R=[0, 0, 1]$ e $r=0.75$. Supondo $s^2_T = 0.05$ e  $X'X^{-1}$ j√° calculado anteriormente.
> ```python
> import numpy as np
>
> # Exemplo (continuando do exemplo anterior)
> R = np.array([[0, 0, 1]])
> r = np.array([0.75])
> beta_hat = np.array([0.8, 0.02, 0.7])
> s2_T = 0.05
>
> # Exemplo de (X'X)^{-1} (simula√ß√£o para fins ilustrativos)
> inv_XTX = np.array([[0.05, 0.001, 0.002],
>                     [0.001, 0.0001, 0.0002],
>                     [0.002, 0.0002, 0.01]])
>
> # C√°lculo da estat√≠stica de Wald
> numerador = (R @ beta_hat - r).T @ (R @ beta_hat - r)
> denominador = s2_T * R @ inv_XTX @ R.T
> chi2_T = numerador / denominador
>
> print(f"Estat√≠stica de Wald: {chi2_T[0][0]:.4f}")
> ```
>
> A estat√≠stica de Wald ser√° algo pr√≥ximo a `Estat√≠stica de Wald: 0.5000`. Comparando este valor com o valor cr√≠tico da distribui√ß√£o qui-quadrado com 1 grau de liberdade, que √© aproximadamente 3.84 (para um n√≠vel de signific√¢ncia de 5%), n√£o rejeitamos a hip√≥tese nula. Isso indica que, com base nos dados, n√£o h√° evid√™ncias suficientes para afirmar que $\phi_1$ √© diferente de 0.75.

**Resumo**
As restri√ß√µes lineares sobre os coeficientes dos modelos autorregressivos com tend√™ncia determin√≠stica podem ser testadas usando a estat√≠stica de Wald, calculada a partir dos estimadores OLS do modelo n√£o transformado. N√£o h√° necessidade de calcular os estimadores do modelo transformado para a constru√ß√£o do teste.

A Se√ß√£o 16.3 detalha que a estat√≠stica do teste de hip√≥teses pode ser expressa de forma equivalente tanto no modelo transformado quanto no original, demonstrando que os testes s√£o assintoticamente v√°lidos, com a distribui√ß√£o $\chi^2$ sob a hip√≥tese nula.

### Conclus√£o
Este cap√≠tulo estabeleceu um arcabou√ßo para a an√°lise de hip√≥teses em modelos autorregressivos com tend√™ncia determin√≠stica, mostrando que a transforma√ß√£o dos regressores, embora √∫til para entender o comportamento assint√≥tico das estimativas, n√£o √© essencial para a realiza√ß√£o dos testes de hip√≥teses. Os testes de hip√≥teses lineares, implementados atrav√©s da estat√≠stica de Wald no modelo original, t√™m validade assint√≥tica, mesmo na presen√ßa de diferentes taxas de converg√™ncia entre os par√¢metros. A equival√™ncia entre o teste no modelo transformado e no modelo original garante a aplicabilidade dos resultados de testes de hip√≥teses em modelos de s√©ries temporais com tend√™ncia determin√≠stica. Este resultado √© de extrema import√¢ncia pr√°tica para a an√°lise de s√©ries temporais.

### Refer√™ncias
[^1]: Trecho do texto que aborda a diferentes taxas de converg√™ncia dos estimadores OLS.
[^2]: Trecho do texto que descreve o comportamento assint√≥tico dos estimadores OLS em modelos com tend√™ncia determin√≠stica.
[^3]: Trecho do texto que introduz a ideia da distribui√ß√£o assint√≥tica para processos com tend√™ncia.
[^4]: Trecho do texto que explora os testes de hip√≥teses para o modelo de tend√™ncia de tempo simples.
[^5]: Trecho do texto que apresenta a forma geral do modelo autorregressivo com tend√™ncia.
[^6]: Trecho do texto que indica como se d√° a transforma√ß√£o do modelo para o modelo can√¥nico
[^7]: Trecho do texto onde √© abordada a converg√™ncia do par√¢metro $\delta$ na forma T.
[^8]: Trecho do texto que mostra a forma das matrizes da transforma√ß√£o G.
[^9]: Trecho do texto que afirma que as estimativas do modelo transformado s√£o transforma√ß√µes lineares do modelo original
[^10]: Trecho do texto que apresenta como realizar o teste de hip√≥tese para restri√ß√µes lineares nos coeficientes
[^11]: Trecho do texto que apresenta a transforma√ß√£o de regressores para an√°lise assint√≥tica.
[^12]: Trecho do texto que apresenta a forma do sistema transformado
[^13]: Trecho do texto que demonstra a forma como os estimadores do modelo transformado s√£o obtidos
[^14]: Trecho do texto que detalha a distribui√ß√£o assint√≥tica dos estimadores transformados
[^15]: Trecho do texto que demonstra como a estat√≠stica de Wald √© constru√≠da e que √© id√™ntica para os modelos transformado e n√£o transformado
[^16]: Trecho do texto que aborda a an√°lise da estat√≠stica de Wald com a matriz R*
<!-- END -->
