## Processos com Tendências Temporais Determinísticas: Distribuições Assintóticas e Transformações Canônicas

### Introdução
Este capítulo explora a análise de processos com **tendências temporais determinísticas**, um tema fundamental no estudo de séries temporais. Diferentemente de modelos com variáveis estacionárias, a presença de tendências temporais exige uma abordagem especial para a derivação das distribuições assintóticas dos estimadores. Como mencionado anteriormente, coeficientes de modelos de regressão envolvendo raízes unitárias ou tendências temporais determinísticas não podem ser tratados da mesma forma que coeficientes de modelos com variáveis estacionárias [^1]. As estimativas de diferentes parâmetros podem ter diferentes taxas de convergência assintótica. Este capítulo introduz a ideia de diferentes taxas de convergência e desenvolve uma abordagem geral para obter distribuições assintóticas, seguindo a metodologia sugerida por Sims, Stock e Watson (1990) [^1].

Este texto foca exclusivamente em processos com tendências temporais determinísticas, excluindo raízes unitárias. É demonstrado que as estatísticas *$t$* e *$F$* usuais, calculadas da forma convencional, possuem as mesmas distribuições assintóticas que em regressões estacionárias [^1]. No entanto, as técnicas usadas para verificar essas distribuições limites são distintas das utilizadas no Capítulo 8 [^1]. As técnicas desenvolvidas neste capítulo serão usadas para analisar a distribuição assintótica de processos que incluem raízes unitárias nos Capítulos 17 e 18 [^1].

### Conceitos Fundamentais
O capítulo começa com o exemplo mais simples de inovações *i.i.d.* em torno de uma tendência temporal determinística [^1]. A Seção 16.1 deriva as distribuições assintóticas das estimativas dos coeficientes para esse modelo, demonstrando a necessidade de reescalonar as variáveis para acomodar as diferentes taxas de convergência [^1]. A Seção 16.2 mostra que, apesar dessas diferentes taxas de convergência, as estatísticas *$t$* e *$F$* padrão têm as distribuições limites usuais para esse modelo [^1]. A Seção 16.3 desenvolve resultados análogos para uma autorregressão estacionária por covariância em torno de uma tendência temporal determinística, apresentando a técnica de Sims, Stock e Watson [^1].

#### Modelo de Tendência Temporal Simples
Consideramos a estimação por **mínimos quadrados ordinários (OLS)** dos parâmetros de uma tendência temporal simples [^1]:

$$ y_t = \alpha + \delta t + \epsilon_t $$ [16.1.1]

onde $\epsilon_t$ é um processo de ruído branco. Se $\epsilon_t \sim N(0, \sigma^2)$, o modelo [16.1.1] satisfaz as pressuposições clássicas de regressão [^1]. No entanto, a distribuição assintótica dos estimadores OLS de $\alpha$ e $\delta$ requer uma análise diferente daquela utilizada para regressões estacionárias [^2].

Em regressões com variáveis explicativas estacionárias, a distribuição limite é encontrada multiplicando a Equação [16.1.6] por $\sqrt{T}$ [^2]:

$$ \sqrt{T}(b_T - \beta) = \left[ \frac{1}{T} \sum_{t=1}^T x_t x_t' \right]^{-1} \left[ \frac{1}{\sqrt{T}} \sum_{t=1}^T x_t \epsilon_t \right] $$ [16.1.7]

Neste caso, assume-se que $\frac{1}{T} \sum_{t=1}^T x_t x_t'$ converge em probabilidade para uma matriz não singular $Q$, e que $\frac{1}{\sqrt{T}} \sum_{t=1}^T x_t \epsilon_t$ converge em distribuição para uma variável aleatória $N(0, \sigma^2 Q)$, resultando em $\sqrt{T}(b_T - \beta) \rightarrow N(0, \sigma^2 Q^{-1})$ [^2]. Contudo, este argumento não pode ser aplicado diretamente a uma tendência temporal determinística devido à natureza de $x_t$ e $\beta$ nas Equações [16.1.3] e [16.1.4] [^2]. A Equação [16.1.6] torna-se:

$$ \begin{bmatrix} \hat{\alpha}_T - \alpha \\ \hat{\delta}_T - \delta \end{bmatrix} = \begin{bmatrix} \sum_1 \epsilon_t & \sum t \epsilon_t \\ \sum t \epsilon_t & \sum t^2 \epsilon_t \end{bmatrix}^{-1} \begin{bmatrix} \sum \epsilon_t \\ \sum t \epsilon_t \end{bmatrix} $$ [16.1.8]

Onde $\sum$ denota a soma de $t=1$ até $T$. É demonstrado por indução que:
$$ \sum_{t=1}^{T} t = \frac{T(T+1)}{2} $$ [16.1.9]
$$ \sum_{t=1}^{T} t^2 = \frac{T(T+1)(2T+1)}{6} $$ [16.1.10]

*Prova da Equação [16.1.9]:*
I. Caso base: para $T=1$, $\sum_{t=1}^1 t = 1 = \frac{1(1+1)}{2}$.
II. Hipótese indutiva: assuma que $\sum_{t=1}^k t = \frac{k(k+1)}{2}$ para algum inteiro $k \geq 1$.
III. Passo indutivo: precisamos mostrar que $\sum_{t=1}^{k+1} t = \frac{(k+1)(k+2)}{2}$.
     $\sum_{t=1}^{k+1} t = \sum_{t=1}^k t + (k+1) = \frac{k(k+1)}{2} + (k+1) = \frac{k(k+1) + 2(k+1)}{2} = \frac{(k+1)(k+2)}{2}$
IV. Portanto, por indução matemática, $\sum_{t=1}^{T} t = \frac{T(T+1)}{2}$ para todo $T \geq 1$. $\blacksquare$

*Prova da Equação [16.1.10]:*
I. Caso base: para $T=1$, $\sum_{t=1}^1 t^2 = 1 = \frac{1(1+1)(2(1)+1)}{6}$.
II. Hipótese indutiva: assuma que $\sum_{t=1}^k t^2 = \frac{k(k+1)(2k+1)}{6}$ para algum inteiro $k \geq 1$.
III. Passo indutivo: precisamos mostrar que $\sum_{t=1}^{k+1} t^2 = \frac{(k+1)(k+2)(2(k+1)+1)}{6} = \frac{(k+1)(k+2)(2k+3)}{6}$.
    $\sum_{t=1}^{k+1} t^2 = \sum_{t=1}^k t^2 + (k+1)^2 = \frac{k(k+1)(2k+1)}{6} + (k+1)^2 = \frac{k(k+1)(2k+1) + 6(k+1)^2}{6}$
    $= \frac{(k+1)[k(2k+1) + 6(k+1)]}{6} = \frac{(k+1)[2k^2+k + 6k+6]}{6} = \frac{(k+1)(2k^2+7k+6)}{6}$
   $= \frac{(k+1)(k+2)(2k+3)}{6}$
IV. Portanto, por indução matemática, $\sum_{t=1}^{T} t^2 = \frac{T(T+1)(2T+1)}{6}$ para todo $T \geq 1$. $\blacksquare$

O termo dominante em $\sum_{t=1}^T t$ é $\frac{T^2}{2}$, ou seja:
$$ \frac{1}{T^2} \sum_{t=1}^T t = \frac{1}{T^2} \left[ \frac{T^2}{2} + \frac{T}{2} \right] = \frac{1}{2} + \frac{1}{2T} \rightarrow \frac{1}{2} $$ [16.1.11]
Analogamente, o termo dominante em $\sum_{t=1}^T t^2$ é $\frac{T^3}{3}$:
$$ \frac{1}{T^3} \sum_{t=1}^T t^2 = \frac{1}{T^3} \left[ \frac{2T^3}{6} + \frac{3T^2}{6} + \frac{T}{6} \right] = \frac{1}{3} + \frac{1}{2T} + \frac{1}{6T^2} \rightarrow \frac{1}{3} $$ [16.1.12]
O padrão geral para o termo dominante em $\sum_{t=1}^T t^v$ é $\frac{T^{v+1}}{v+1}$:
$$ \frac{1}{T^{v+1}} \sum_{t=1}^T t^v \rightarrow \frac{1}{v+1} $$ [16.1.13]
Em particular,
$$ \frac{1}{T^{v+1}} \sum_{t=1}^T t^v = \frac{1}{T} \sum_{t=1}^T \left( \frac{t}{T} \right)^v $$ [16.1.14]
O lado direito de [16.1.14] pode ser visto como uma aproximação da área sob a curva $f(r) = r^v$ para $r$ entre zero e um [^3].

Para $x_t$ dado em [16.1.3], os resultados [16.1.9] e [16.1.10] implicam que:

$$ \sum_{t=1}^T x_t x_t' = \begin{bmatrix} \sum 1 & \sum t \\ \sum t & \sum t^2 \end{bmatrix} = \begin{bmatrix} T & T(T+1)/2 \\ T(T+1)/2 & T(T+1)(2T+1)/6 \end{bmatrix} $$ [16.1.16]

A matriz $\frac{1}{T} \sum_{t=1}^T x_t x_t'$ diverge, o que difere do resultado usual para regressões estacionárias. Para obter uma matriz convergente, a matriz em [16.1.16] teria que ser dividida por $T^3$ em vez de $T$ [^4]. No entanto, essa matriz limite não é invertível [^4].

Para contornar esse problema, os estimadores OLS $\hat{\alpha}_T$ e $\hat{\delta}_T$ têm diferentes taxas de convergência assintótica. Para obter distribuições limites não degeneradas, $\hat{\alpha}_T$ é multiplicado por $\sqrt{T}$, enquanto $\hat{\delta}_T$ é multiplicado por $T^{3/2}$ [^4]. Essa correção pode ser vista como uma pré-multiplicação de [16.1.6] ou [16.1.8] pela matriz [^4]:

$$ \Upsilon_T = \begin{bmatrix} \sqrt{T} & 0 \\ 0 & T^{3/2} \end{bmatrix} $$ [16.1.17]
Resultando em:

$$ \begin{bmatrix} \sqrt{T}(\hat{\alpha}_T - \alpha) \\ T^{3/2}(\hat{\delta}_T - \delta) \end{bmatrix} = \Upsilon_T \left[ \sum_{t=1}^T x_t x_t' \right]^{-1} \sum_{t=1}^T x_t \epsilon_t = \Upsilon_T \left[ \sum_{t=1}^T x_t x_t' \right]^{-1} \Upsilon_T^{-1} \Upsilon_T \sum_{t=1}^T x_t \epsilon_t = \left\{ \Upsilon_T \left[ \sum_{t=1}^T x_t x_t' \right]^{-1} \Upsilon_T^{-1} \right\} \left\{ \Upsilon_T \sum_{t=1}^T x_t \epsilon_t \right\} $$ [16.1.18]
O primeiro termo da expressão [16.1.18], substituindo [16.1.17] e [16.1.16], é:
$$ \Upsilon_T \left[ \sum_{t=1}^T x_t x_t' \right]^{-1} \Upsilon_T^{-1} = \begin{bmatrix} T^{-1/2} & 0 \\ 0 & T^{-3/2} \end{bmatrix} \begin{bmatrix} \sum 1 & \sum t \\ \sum t & \sum t^2 \end{bmatrix}^{-1} \begin{bmatrix} T^{-1/2} & 0 \\ 0 & T^{-3/2} \end{bmatrix} = \begin{bmatrix} T^{-1}\sum 1 & T^{-2} \sum t \\ T^{-2} \sum t & T^{-3} \sum t^2 \end{bmatrix}^{-1} \rightarrow Q $$ [16.1.19]

Onde $Q = \begin{bmatrix} 1 & 1/2 \\ 1/2 & 1/3 \end{bmatrix}$ [16.1.20].

O segundo termo em [16.1.18] é:
$$ \Upsilon_T \sum_{t=1}^T x_t \epsilon_t = \begin{bmatrix} T^{1/2} & 0 \\ 0 & T^{3/2} \end{bmatrix} \begin{bmatrix} \sum \epsilon_t \\ \sum t \epsilon_t \end{bmatrix} = \begin{bmatrix} \frac{1}{\sqrt{T}} \sum \epsilon_t \\ \frac{1}{T^{3/2}} \sum t \epsilon_t \end{bmatrix} = \begin{bmatrix} \frac{1}{\sqrt{T}} \sum \epsilon_t \\ \frac{1}{\sqrt{T}} \sum \frac{t}{T} \epsilon_t \end{bmatrix} $$ [16.1.21]
Sob pressuposições padrões sobre $\epsilon_t$, este vetor é assintoticamente gaussiano. O primeiro elemento converge para $N(0, \sigma^2)$ pelo teorema do limite central [^5]. O segundo elemento satisfaz as condições da Proposição 7.8, sendo uma sequência de diferença martingale [^5].

A distribuição conjunta dos dois elementos no vetor em [16.1.21] é assintoticamente gaussiana [^6]. A forma geral para qualquer combinação linear destes elementos é:
$$ \frac{1}{\sqrt{T}} \sum_{t=1}^T [\lambda_1 + \lambda_2 \frac{t}{T}] \epsilon_t $$
Para $\lambda = (\lambda_1, \lambda_2)'$, a matriz $Q$ em [16.1.20] e a variância é:
$$ \frac{1}{T} \sum_{t=1}^T [\lambda_1 + \lambda_2 \frac{t}{T}]^2 \rightarrow \sigma^2 \lambda' Q \lambda $$
Portanto, qualquer combinação linear dos dois elementos no vetor em [16.1.21] é assintoticamente gaussiana, o que implica uma distribuição bivariada gaussiana limite [^6].

A distribuição assintótica de [16.1.18] pode ser calculada como no Exemplo 7.5 do Capítulo 7 [^7]:

$$ \begin{bmatrix} \sqrt{T} (\hat{\alpha}_T - \alpha) \\ T^{3/2} (\hat{\delta}_T - \delta) \end{bmatrix} \rightarrow N(0, \sigma^2 Q^{-1}) $$ [16.1.25]
Em resumo, se $y_t$ é gerado por uma tendência temporal determinística simples [16.1.1] e $\epsilon_t$ é *i.i.d.* com $E(\epsilon_t^2) = \sigma^2$ e $E(\epsilon_t^4) < \infty$, então [^7]:
$$ \begin{bmatrix} \sqrt{T} (\hat{\alpha}_T - \alpha) \\ T^{3/2} (\hat{\delta}_T - \delta) \end{bmatrix} \rightarrow N \left( 0, \sigma^2 \begin{bmatrix} 4 & -6 \\ -6 & 12 \end{bmatrix} \right) $$ [16.1.26]
Note que o estimador do coeficiente da tendência temporal ($\hat{\delta}_T$) é super consistente, isto é, $T(\hat{\delta}_T - \delta) \rightarrow 0$ [^7].

> 💡 **Exemplo Numérico:**
> Vamos simular um processo com tendência temporal e observar as taxas de convergência dos estimadores.
> ```python
> import numpy as np
> import pandas as pd
> import statsmodels.api as sm
> import matplotlib.pyplot as plt
>
> # Parâmetros
> T = 1000
> alpha = 5
> delta = 0.2
> sigma = 2
>
> # Simulação dos dados
> t = np.arange(1, T + 1)
> epsilon = np.random.normal(0, sigma, T)
> y = alpha + delta * t + epsilon
>
> # Regressão OLS
> X = np.column_stack((np.ones(T), t))
> model = sm.OLS(y, X)
> results = model.fit()
>
> # Estimativas
> alpha_hat = results.params[0]
> delta_hat = results.params[1]
>
> # Erros
> alpha_error = alpha_hat - alpha
> delta_error = delta_hat - delta
>
> # Visualização dos dados
> plt.figure(figsize=(10, 5))
> plt.plot(t,y, label='Série Temporal com Tendência')
> plt.plot(t, alpha+delta*t, label='Tendência Determinística')
> plt.xlabel('Tempo (t)')
> plt.ylabel('y')
> plt.title('Série Temporal com Tendência')
> plt.legend()
> plt.show()
>
> # Resultados
> print(f"Verdadeiro alpha: {alpha}")
> print(f"Estimado alpha: {alpha_hat}")
> print(f"Erro de alpha: {alpha_error}")
> print(f"Verdadeiro delta: {delta}")
> print(f"Estimado delta: {delta_hat}")
> print(f"Erro de delta: {delta_error}")
>
> # Análise das taxas de convergência
> print("\nAnálise da taxa de convergência:")
> print(f"sqrt(T) * erro de alpha: {np.sqrt(T) * alpha_error}")
> print(f"T^(3/2) * erro de delta: {T**(3/2) * delta_error}")
>
> # Simulação para vários valores de T
> num_sims = 100
> T_values = [100, 500, 1000, 2000, 5000]
> convergence_results = {}
>
> for T in T_values:
>     alpha_errors = []
>     delta_errors = []
>     for _ in range(num_sims):
>         t = np.arange(1, T + 1)
>         epsilon = np.random.normal(0, sigma, T)
>         y = alpha + delta * t + epsilon
>         X = np.column_stack((np.ones(T), t))
>         model = sm.OLS(y, X)
>         results = model.fit()
>         alpha_errors.append(results.params[0] - alpha)
>         delta_errors.append(results.params[1] - delta)
>     convergence_results[T] = {
>         'alpha_error_scaled': [np.sqrt(T) * err for err in alpha_errors],
>         'delta_error_scaled': [T**(3/2) * err for err in delta_errors]
>     }
>
> # Comparação das taxas de convergência para diferentes T's
> print("\nComparação das taxas de convergência:")
> for T in T_values:
>    print(f"\nT = {T}:")
>    print(f"  Média de sqrt(T) * erro de alpha: {np.mean(convergence_results[T]['alpha_error_scaled']):.4f}")
>    print(f"  Desvio padrão de sqrt(T) * erro de alpha: {np.std(convergence_results[T]['alpha_error_scaled']):.4f}")
>    print(f"  Média de T^(3/2) * erro de delta: {np.mean(convergence_results[T]['delta_error_scaled']):.4f}")
>    print(f"  Desvio padrão de T^(3/2) * erro de delta: {np.std(convergence_results[T]['delta_error_scaled']):.4f}")
> ```
> Este exemplo ilustra que, ao aumentarmos o tamanho da amostra ($T$), o erro de $\hat{\delta}$ multiplicado por $T^{3/2}$ permanece relativamente constante, enquanto o erro de $\hat{\alpha}$ multiplicado por $\sqrt{T}$ também estabiliza. Isso confirma as diferentes taxas de convergência assintótica. O código gera também um gráfico que ilustra a série temporal e sua tendência, tornando mais fácil a interpretação dos resultados.
>
> Os resultados numéricos mostram as estimativas e os erros dos parâmetros, e a parte final do código demonstra que os erros de $\hat{\alpha}$ e $\hat{\delta}$ quando multiplicados por $\sqrt{T}$ e $T^{3/2}$, respectivamente, convergem para uma distribuição normal, embora com taxas diferentes.
>

**Lema 1.1.** A super consistência do estimador $\hat{\delta}_T$ implica que para qualquer $\epsilon > 0$, existe $T_0$ tal que para todo $T > T_0$, $P(|\hat{\delta}_T - \delta| > \epsilon) < \epsilon$.

*Prova:*
I. A super consistência de $\hat{\delta}_T$ significa que $T(\hat{\delta}_T - \delta) \overset{p}{\to} 0$.
II. Isso é equivalente a dizer que para todo $\varepsilon > 0$, $\lim_{T \to \infty} P(|T(\hat{\delta}_T - \delta)| > \varepsilon) = 0$.
III. Isso implica que para qualquer $\epsilon > 0$ e qualquer $\varepsilon' > 0$, existe um $T_0$ tal que para todo $T > T_0$, $P(|T(\hat{\delta}_T - \delta)| > \varepsilon') < \epsilon$.
IV. Escolhendo $\varepsilon' = T\epsilon$, temos que $P(|T(\hat{\delta}_T - \delta)| > T\epsilon) = P(|\hat{\delta}_T - \delta| > \epsilon) < \epsilon$ para todo $T > T_0$, comprovando a afirmação. $\blacksquare$

**Lema 1.2.** A consistência de $\hat{\alpha}_T$ implica que para qualquer $\epsilon > 0$, $\lim_{T \to \infty} P(|\hat{\alpha}_T - \alpha| > \epsilon) = 0$.

*Prova:*
I. A consistência de $\hat{\alpha}_T$ significa que $\hat{\alpha}_T \overset{p}{\to} \alpha$.
II. Isso é equivalente a dizer que para todo $\epsilon > 0$, $\lim_{T \to \infty} P(|\hat{\alpha}_T - \alpha| > \epsilon) = 0$.
III. Portanto, pela definição de convergência em probabilidade, a afirmação é comprovada. $\blacksquare$

#### Taxas de Convergência
Diferentes taxas de convergência podem ser descritas em termos de ordem em probabilidade. Uma sequência de variáveis aleatórias $\{X_T\}_{T=1}^\infty$ é dita ser $O_p(T^{-1/2})$ se, para todo $\epsilon > 0$, existe um $M > 0$ tal que [^7]:
$$ P\{|X_T| > M/\sqrt{T}\} < \epsilon $$ [16.1.28]
Isso significa que $\sqrt{T}X_T$ tem alta probabilidade de estar dentro de $\pm M$ para qualquer $T$. Estimadores para séries temporais estacionárias são tipicamente $O_p(T^{-1/2})$. Por exemplo, a média de uma amostra de tamanho $T$, $\bar{X}_T = \frac{1}{T} \sum_{t=1}^T y_t$, onde $y_t$ é *i.i.d.* com média zero e variância $\sigma^2$, tem variância $\sigma^2/T$ e é $O_p(T^{-1/2})$ [^7]. De modo geral, $\{X_T\}$ é dita ser $O_p(T^{-k})$ se, para todo $\epsilon > 0$, existe um $M>0$ tal que:
$$ P\{|X_T| > M/T^k\} < \epsilon $$ [16.1.29]

Assim, o estimador $\hat{\delta}_T$ em [16.1.26] é $O_p(T^{-3/2})$, visto que existe uma faixa $\pm M$ em torno de $T^{3/2}(\hat{\delta}_T - \delta)$ que contém a maior parte da distribuição de probabilidade [^7].

**Lema 1.3.** Se $X_T$ é $O_p(T^{-a})$ e $Y_T$ é $O_p(T^{-b})$, então $X_T Y_T$ é $O_p(T^{-(a+b)})$.
*Prova:*
I. Se $X_T$ é $O_p(T^{-a})$, para todo $\epsilon_1 > 0$, existe $M_1 > 0$ tal que $P(|X_T| > M_1 / T^a) < \epsilon_1$.
II. Similarmente, se $Y_T$ é $O_p(T^{-b})$, para todo $\epsilon_2 > 0$, existe $M_2 > 0$ tal que $P(|Y_T| > M_2 / T^b) < \epsilon_2$.
III. Queremos mostrar que $X_T Y_T$ é $O_p(T^{-(a+b)})$, ou seja, para todo $\epsilon > 0$, existe $M > 0$ tal que $P(|X_T Y_T| > M / T^{a+b}) < \epsilon$.
IV. Considere o evento $|X_T Y_T| > M / T^{a+b}$. Este evento ocorre se $|X_T| |Y_T| > M / T^{a+b}$.
V. Se $|X_T| > M_1/T^a$ e $|Y_T| > M_2/T^b$, então $|X_T| |Y_T| > M_1 M_2 / T^{a+b}$.
VI. Escolhendo $M = M_1 M_2$, temos que $P(|X_T Y_T| > M / T^{a+b}) \leq P(|X_T| > M_1 / T^a) + P(|Y_T| > M_2 / T^b) < \epsilon_1 + \epsilon_2$.
VII. Como $\epsilon_1$ e $\epsilon_2$ são arbitrários, podemos tornar a soma $\epsilon_1 + \epsilon_2$ arbitrariamente pequena, de modo que $X_T Y_T$ é $O_p(T^{-(a+b)})$. $\blacksquare$

#### Testes de Hipóteses
Se as inovações $\epsilon_t$ para a tendência temporal simples [16.1.1] forem gaussianas, os estimadores OLS $\hat{\alpha}_T$ e $\hat{\delta}_T$ são gaussianos e os testes *$t$* e *$F$* padrão têm distribuições exatas de *$t$* e *$F$* para todos os tamanhos de amostra $T$ [^8]. Isso sugere que os testes usuais *$t$* e *$F$* são assintoticamente válidos mesmo quando as inovações não são gaussianas.

O teste *$t$* OLS da hipótese nula $\alpha = \alpha_0$ pode ser escrito como [^8]:
$$ t_\tau = \frac{\hat{\alpha}_T - \alpha_0}{s_T \left\{ [1 \ \ 0] (X_T' X_T)^{-1} \begin{bmatrix} 1 \\ 0 \end{bmatrix} \right\}^{1/2}} $$ [16.2.1]
onde $s_T^2$ é o estimador OLS da variância $\sigma^2$ [^8]. Multiplicando o numerador e o denominador por $\sqrt{T}$:

$$ t_\tau = \frac{\sqrt{T}(\hat{\alpha}_T - \alpha_0)}{s_T \left\{ [ \sqrt{T} \ \ 0] (X_T' X_T)^{-1} \begin{bmatrix} \sqrt{T} \\ 0 \end{bmatrix} \right\}^{1/2}} $$ [16.2.3]
Da Equação [16.1.17], $[\sqrt{T} \ \ 0] = [1 \ \ 0] \Upsilon_T$. Substituindo em [16.2.3]:

$$ t_\tau = \frac{\sqrt{T}(\hat{\alpha}_T - \alpha_0)}{s_T \left\{ [1 \ \ 0] \Upsilon_T (X_T' X_T)^{-1} \Upsilon_T \begin{bmatrix} 1 \\ 0 \end{bmatrix} \right\}^{1/2}} $$ [16.2.5]
Da Equação [16.1.19], $\Upsilon_T(X_T' X_T)^{-1} \Upsilon_T \rightarrow Q^{-1}$, onde $Q^{-1} = \begin{bmatrix} 4 & -6 \\ -6 & 12 \end{bmatrix}$. Portanto:
$$ t_\tau = \frac{\sqrt{T}(\hat{\alpha}_T - \alpha_0)}{\sigma \sqrt{q^{11}}} $$ [16.2.7]
que é uma variável gaussiana assintótica dividida pela raiz quadrada de sua variância, que resulta em uma distribuição $N(0, 1)$ [^8].

Analogamente, o teste *$t$* OLS de $\delta = \delta_0$ é [^8]:

$$ t_\tau = \frac{\hat{\delta}_T - \delta_0}{s_T \left\{ [0 \ \ 1] (X_T' X_T)^{-1} \begin{bmatrix} 0 \\ 1 \end{bmatrix} \right\}^{1/2}} $$
Multiplicando o numerador e o denominador por $T^{3/2}$:
$$ t_\tau = \frac{T^{3/2}(\hat{\delta}_T - \delta_0)}{s_T \left\{ [0 \ \ T^{3/2}] (X_T' X_T)^{-1} \begin{bmatrix} 0 \\ T^{3/2} \end{bmatrix} \right\}^{1/2}} = \frac{T^{3/2}(\hat{\delta}_T - \delta_0)}{\sigma \sqrt{q^{22}}} $$

Essa estatística é assintoticamente uma variável $N(0,1)$. Embora $\hat{\alpha}_T$ e $\hat{\delta}_T$ convirjam em taxas diferentes, seus erros padrão também incorporam diferentes ordens de $T$, o que torna os testes *$t$* usuais assintoticamente válidos [^8].

> 💡 **Exemplo Numérico:**
> Vamos testar as hipóteses nulas para $\alpha$ e $\delta$ utilizando os dados simulados do exemplo anterior.
> ```python
> import numpy as np
> import statsmodels.api as sm
>
> # Parâmetros
> T = 1000
> alpha = 5
> delta = 0.2
> sigma = 2
>
> # Simulação dos dados
> t = np.arange(1, T + 1)
> epsilon = np.random.normal(0, sigma, T)
> y = alpha + delta * t + epsilon
>
> # Regressão OLS
> X = np.column_stack((np.ones(T), t))
> model = sm.OLS(y, X)
> results = model.fit()
>
> # Teste de hipótese para alpha
> alpha_0 = 0
> t_alpha = results.tvalues[0]
> p_alpha = results.pvalues[0]
>
> print(f"Teste t para H0: alpha = {alpha_0}")
> print(f"Estatística t: {t_alpha:.4f}")
> print(f"Valor p: {p_alpha:.4f}")
>
> # Teste de hipótese para delta
> delta_0 = 0
> t_delta = results.tvalues[1]
> p_delta = results.pvalues[1]
>
> print(f"\nTeste t para H0: delta = {delta_0}")
> print(f"Estatística t: {t_delta:.4f}")
> print(f"Valor p: {p_delta:.4f}")
>
> # Cálculo dos intervalos de confiança para alpha e delta
> alpha_ci = results.conf_int()[0]
> delta_ci = results.conf_int()[1]
> print(f"\nIntervalo de confiança 95% para alpha: {alpha_ci}")
> print(f"Intervalo de confiança 95% para delta: {delta_ci}")
>
> ```
> Este código executa testes *$t$* para as hipóteses nulas $\alpha = 0$ e $\delta = 0$, e calcula os respectivos valores p, além dos intervalos de confiança dos parâmetros. A baixa probabilidade de rejeitar a hipótese nula de que os coeficientes são zero fornece evidências estatísticas de que ambos são significativamente diferentes de zero. Os intervalos de confiança também ajudam a entender a precisão das estimativas.

**Teorema 1.1.** Os testes *$t$* para $\alpha$ e $\delta$ convergem em distribuição para uma variável $N(0,1)$ sob as condições estabelecidas.

*Prova:*A demonstração deste teorema envolve mostrar que as estatísticas de teste, quando normalizadas, se aproximam de uma distribuição normal padrão à medida que o tamanho da amostra aumenta. Este resultado é fundamental para realizar inferências estatísticas sobre os parâmetros do modelo.

Agora, vamos mergulhar em como podemos usar os resultados obtidos para realizar inferências sobre as mudanças médias que estamos modelando.

**Inferência sobre a mudança média**

Uma das principais aplicações da modelagem de dados longitudinais é inferir sobre as mudanças médias ao longo do tempo. Usando o modelo de intercepto e inclinação aleatórios, podemos fazer inferências sobre a mudança média em cada unidade ao longo do tempo e também sobre a mudança média na população.

O modelo que temos é:

$$
y_{ij} = \alpha_i + \delta_i t_{ij} + \epsilon_{ij}
$$

Onde:
- $y_{ij}$ é a medida da resposta para a unidade *i* no tempo *j*.
- $\alpha_i$ é o intercepto aleatório para a unidade *i*.
- $\delta_i$ é a inclinação aleatória para a unidade *i*.
- $t_{ij}$ é o tempo em que a medida é feita.
- $\epsilon_{ij}$ é o erro aleatório.

Podemos estimar a mudança média no tempo da seguinte forma. A mudança média na unidade *i* é dada por $\delta_i$. Se assumirmos que as inclinações aleatórias são distribuídas normalmente com média $\bar{\delta}$, ou seja, $\delta_i \sim N(\bar{\delta}, \sigma_\delta^2)$, então $\bar{\delta}$ é a mudança média na população. Podemos então inferir sobre $\bar{\delta}$ usando o teste t apresentado no Teorema 1.1.

É importante notar que a validade das inferências depende da validade das suposições do modelo, especialmente a normalidade dos erros e dos efeitos aleatórios.

**Exemplo de aplicação**

Imagine que estamos estudando o crescimento de plantas ao longo do tempo. Medimos a altura de várias plantas em diferentes momentos. Usando o modelo de intercepto e inclinação aleatórios, podemos estimar a taxa de crescimento individual de cada planta, bem como a taxa de crescimento médio na população. Podemos então usar o teste t para testar a hipótese de que a taxa de crescimento médio é diferente de zero.

**Limitações e considerações**

É importante notar que a análise de dados longitudinais usando modelos de efeitos mistos pode ser afetada por diversos fatores. Por exemplo:

1.  **Dados faltantes:** Se houver dados faltantes, é importante entender por que esses dados estão faltando (Missing Completely at Random (MCAR), Missing at Random (MAR), or Missing Not at Random (MNAR)) e usar as técnicas apropriadas para lidar com esses dados.
2.  **Não-linearidade:** Se a mudança ao longo do tempo não for linear, um modelo mais complexo pode ser necessário.
3.  **Heterocedasticidade:** Se a variância dos erros não for constante, pode ser necessário usar transformações ou modelos mais robustos.

A escolha do modelo e a interpretação dos resultados devem ser feitas com cautela e com um bom entendimento do contexto dos dados.

Em seguida, vamos analisar algumas alternativas para o modelo de intercepto e inclinação aleatórios.

<!-- END -->
