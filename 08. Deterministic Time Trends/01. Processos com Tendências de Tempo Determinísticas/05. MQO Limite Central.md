## Distribui√ß√µes Limite e o Teorema do Limite Central em Modelos de Tend√™ncia de Tempo Determin√≠stica

### Introdu√ß√£o

Este cap√≠tulo tem como foco a deriva√ß√£o das distribui√ß√µes limitantes dos estimadores de M√≠nimos Quadrados Ordin√°rios (MQO) em modelos com tend√™ncias de tempo determin√≠sticas, com √™nfase na aplica√ß√£o do Teorema do Limite Central (TLC) e nas propriedades de sequ√™ncias de diferen√ßas de martingais. Como vimos em cap√≠tulos anteriores, a an√°lise assint√≥tica de estimadores MQO em modelos com tend√™ncias de tempo determin√≠sticas exige t√©cnicas de reescalonamento devido √†s diferentes taxas de converg√™ncia dos estimadores. Este cap√≠tulo se aprofunda nos mecanismos estat√≠sticos que justificam a validade desses procedimentos e oferece uma vis√£o mais detalhada sobre como a distribui√ß√£o assint√≥tica dos estimadores √© estabelecida usando o TLC e a teoria de martingales [^1]. Exploraremos tamb√©m a abordagem geral para processos com inova√ß√µes i.i.d. em torno de uma tend√™ncia de tempo determin√≠stica e como a reescala das vari√°veis se torna necess√°ria para acomodar as diferentes taxas de converg√™ncia.

### Conceitos Fundamentais

A deriva√ß√£o das distribui√ß√µes limitantes para os estimadores MQO em modelos com tend√™ncia de tempo determin√≠stica √© feita com o aux√≠lio do Teorema do Limite Central (TLC) e propriedades de sequ√™ncias de diferen√ßas de martingais [^1]. O TLC, em sua forma cl√°ssica, estabelece que a soma de um grande n√∫mero de vari√°veis aleat√≥rias independentes e identicamente distribu√≠das (i.i.d.), com m√©dia e vari√¢ncia finitas, converge para uma distribui√ß√£o normal quando devidamente escalonada [^1]. No entanto, em modelos de s√©ries temporais, os erros n√£o s√£o necessariamente i.i.d., e a abordagem usando diferen√ßas de martingais √© mais adequada.

Uma sequ√™ncia de vari√°veis aleat√≥rias $\{X_t\}$ √© uma *diferen√ßa de martingal* se $E[X_t | X_{t-1}, X_{t-2}, \ldots] = 0$. Ou seja, a esperan√ßa de $X_t$ condicional ao passado √© zero. No contexto de processos estoc√°sticos, muitas vezes as sequ√™ncias de erros em modelos de s√©ries temporais se enquadram nesta categoria. O TLC para diferen√ßas de martingais, discutido em Proposi√ß√£o 7.8 [^1], √© uma extens√£o do TLC cl√°ssico que considera a depend√™ncia temporal nos dados e permite provar a distribui√ß√£o limite dos estimadores em uma gama mais ampla de cen√°rios.

A abordagem geral para processos com inova√ß√µes i.i.d. em torno de uma tend√™ncia de tempo determin√≠stica envolve a decomposi√ß√£o do modelo em termos de componentes com diferentes taxas de converg√™ncia e, em seguida, a aplica√ß√£o do TLC e das propriedades das diferen√ßas de martingais [^1]. Consideremos novamente o modelo simples de tend√™ncia de tempo:

$$y_t = \alpha + \delta t + \epsilon_t$$

onde $\epsilon_t$ √© uma sequ√™ncia de vari√°veis aleat√≥rias i.i.d. com m√©dia zero e vari√¢ncia $\sigma^2$ [^1]. Como vimos anteriormente, a estimativa MQO do par√¢metro $\delta$ possui uma taxa de converg√™ncia assint√≥tica diferente da de $\alpha$. Para obter a distribui√ß√£o limite n√£o degenerada, √© necess√°rio multiplicar o estimador de $\delta$ por $T^{3/2}$ e o estimador de $\alpha$ por $\sqrt{T}$ [^1].

A an√°lise da distribui√ß√£o assint√≥tica do estimador do intercepto $\hat{\alpha}_T$ envolve a considera√ß√£o da express√£o da estimativa MQO, e o seu desvio do verdadeiro valor $\alpha$:
$$ (\hat{\alpha}_T - \alpha) = \left( \sum_{t=1}^{T} (x_t'x_t) \right)^{-1} \sum_{t=1}^{T} x_t \epsilon_t $$

onde $x_t = [1, t]'$. Ao multiplicarmos a express√£o por $\sqrt{T}$, obt√©m-se o termo relevante para a distribui√ß√£o assint√≥tica:
$$\sqrt{T}(\hat{\alpha}_T - \alpha) = \sqrt{T}  \left( \sum_{t=1}^{T} (x_t'x_t) \right)^{-1} \sum_{t=1}^{T} x_t \epsilon_t $$

O termo $\sum_{t=1}^{T} x_t \epsilon_t$ , ap√≥s o reescalonamento adequado (que leva em conta a taxa de converg√™ncia de $T^{1/2}$), converge para uma distribui√ß√£o normal com m√©dia zero e vari√¢ncia $\sigma^2 q^{11}$, onde $q^{11}$ √© um componente da matriz $Q^{-1}$ que √© o limite da matriz normalizada $(1/T^3) \sum_{t=1}^T x_t x_t'$. O uso do TLC para martingais √© crucial para demonstrar que essa converg√™ncia para a distribui√ß√£o normal ocorre. No caso do estimador da tend√™ncia, $\hat{\delta}_T$, o reescalonamento apropriado √© por $T^{3/2}$:

$$T^{3/2}(\hat{\delta}_T - \delta) = T^{3/2}  \left( \sum_{t=1}^{T} (x_t'x_t) \right)^{-1} \sum_{t=1}^{T} x_t \epsilon_t $$

O termo $T^{3/2}$ √© necess√°rio devido √† ordem de crescimento do termo $t$ na matriz de regressores. A an√°lise do termo  $\sum_{t=1}^{T} x_t \epsilon_t$  revelou que o componente associado √† tend√™ncia temporal converge a uma taxa mais r√°pida, ou seja, $T^{3/2}$. Para garantir que o limite seja n√£o degenerado, a multiplica√ß√£o por $T^{3/2}$ √© crucial. O TLC para martingais garante que a distribui√ß√£o assint√≥tica deste termo tamb√©m √© normal, com m√©dia zero e vari√¢ncia $\sigma^2 q^{22}$, onde $q^{22}$ √© outro elemento da matriz $Q^{-1}$ [^1].

**Lema 1:** As somas $\frac{1}{\sqrt{T}}\sum_{t=1}^{T} \epsilon_t$ e $\frac{1}{T^{3/2}}\sum_{t=1}^{T} t\epsilon_t$ convergem em distribui√ß√£o para vari√°veis aleat√≥rias normais com m√©dia zero, respectivamente.
*Prova:*
I. O termo $\frac{1}{\sqrt{T}}\sum_{t=1}^{T} \epsilon_t$ √© uma soma de vari√°veis i.i.d. com m√©dia zero e vari√¢ncia $\sigma^2$. Portanto, pelo TLC, a distribui√ß√£o deste termo converge para uma distribui√ß√£o normal com m√©dia zero e vari√¢ncia $\sigma^2$.
II. Para o termo $\frac{1}{T^{3/2}}\sum_{t=1}^{T} t\epsilon_t$, sabemos que a sequ√™ncia $\{(t/T) \epsilon_t\}$ √© uma sequ√™ncia de diferen√ßas de martingais, com m√©dia zero condicional ao passado e vari√¢ncia dada por  $E[(t/T)\epsilon_t]^2 = \sigma^2 (t/T)^2$.
III.  O TLC para diferen√ßas de martingais (Proposi√ß√£o 7.8 [^1]) garante que a sequ√™ncia $\frac{1}{\sqrt{T}} \sum_{t=1}^T \frac{t}{T} \epsilon_t$ convirja para uma distribui√ß√£o normal com m√©dia zero e vari√¢ncia  $\sigma^2 \sum_{t=1}^T (t/T)^2$.
IV.  A soma  $\sum_{t=1}^T (t/T)^2$ quando multiplicada por $1/T$, converge para a integral $\int_0^1 x^2 \, dx = 1/3$.
V.  Portanto,  o termo $\frac{1}{T^{3/2}}\sum_{t=1}^{T} t\epsilon_t$  converge para uma distribui√ß√£o normal com m√©dia zero e vari√¢ncia $\sigma^2 / 3$.
$\blacksquare$
> üí° **Exemplo Num√©rico:**
> Vamos simular um cen√°rio onde $\epsilon_t$ segue uma distribui√ß√£o normal com m√©dia 0 e desvio padr√£o $\sigma = 2$. Vamos considerar um tamanho de amostra $T = 1000$ e realizar 500 simula√ß√µes para analisar as distribui√ß√µes de $\frac{1}{\sqrt{T}}\sum_{t=1}^{T} \epsilon_t$ e $\frac{1}{T^{3/2}}\sum_{t=1}^{T} t\epsilon_t$.
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
> from scipy.stats import norm
>
> # Par√¢metros
> num_simulations = 500
> T = 1000
> sigma = 2
>
> # Inicializa√ß√£o das listas para armazenar os resultados
> sum_eps_scaled = []
> sum_t_eps_scaled = []
>
> for _ in range(num_simulations):
>     # Gera√ß√£o de erros
>     epsilon = np.random.normal(0, sigma, T)
>
>     # C√°lculo das somas reescalonadas
>     sum_eps_scaled.append(np.sum(epsilon) / np.sqrt(T))
>     sum_t_eps_scaled.append(np.sum(np.arange(1, T + 1) * epsilon) / T**(3/2))
>
> # Plot dos histogramas
> plt.figure(figsize=(12, 6))
>
> # Histograma para sum_eps_scaled
> plt.subplot(1, 2, 1)
> plt.hist(sum_eps_scaled, bins=30, density=True, alpha=0.7, label='Simulado')
> x = np.linspace(-4*sigma, 4*sigma, 100)
> plt.plot(x, norm.pdf(x, 0, sigma), 'r', label=f'N(0, {sigma:.2f})')
> plt.title('Distribui√ß√£o de $\\frac{1}{\\sqrt{T}}\\sum_{t=1}^{T} \\epsilon_t$')
> plt.xlabel('Valor')
> plt.ylabel('Densidade')
> plt.legend()
>
> # Histograma para sum_t_eps_scaled
> plt.subplot(1, 2, 2)
> plt.hist(sum_t_eps_scaled, bins=30, density=True, alpha=0.7, label='Simulado')
> x = np.linspace(-4*sigma/np.sqrt(3), 4*sigma/np.sqrt(3), 100)
> plt.plot(x, norm.pdf(x, 0, sigma/np.sqrt(3)), 'r', label=f'N(0, {sigma/np.sqrt(3):.2f})')
> plt.title('Distribui√ß√£o de $\\frac{1}{T^{3/2}}\\sum_{t=1}^{T} t\\epsilon_t$')
> plt.xlabel('Valor')
> plt.ylabel('Densidade')
> plt.legend()
>
> plt.tight_layout()
> plt.show()
> ```
>
>
> Os histogramas mostram que as somas reescalonadas convergem para uma distribui√ß√£o normal como previsto pelo Lema 1. O primeiro gr√°fico mostra que $\frac{1}{\sqrt{T}}\sum_{t=1}^{T} \epsilon_t$ se aproxima de uma normal com m√©dia zero e desvio padr√£o pr√≥ximo de $\sigma = 2$. O segundo gr√°fico mostra que  $\frac{1}{T^{3/2}}\sum_{t=1}^{T} t\epsilon_t$ se aproxima de uma normal com m√©dia zero e desvio padr√£o pr√≥ximo de $\sigma/\sqrt{3} \approx 1.15$. Isso ilustra a converg√™ncia assint√≥tica dos termos e a necessidade de reescalonar os estimadores.

A abordagem geral da distribui√ß√£o assint√≥tica dos estimadores MQO se resume a:

1. **Decomposi√ß√£o do modelo:** O modelo √© decomposto em termos com diferentes ordens de converg√™ncia (vari√°veis estacion√°rias, tend√™ncia e termos constantes).
2. **Reescalonamento:** Os estimadores s√£o reescalonados por fatores apropriados (como $\sqrt{T}$ e $T^{3/2}$) para obter distribui√ß√µes limites n√£o degeneradas.
3. **Aplica√ß√£o do TLC:** O TLC para diferen√ßas de martingais (ou o TLC cl√°ssico) √© usado para estabelecer que os termos de erro, quando reescalonados, convergem para uma distribui√ß√£o normal.
4. **Matriz de covari√¢ncia assint√≥tica:** A matriz de covari√¢ncia assint√≥tica √© calculada para descrever a variabilidade dos estimadores.

**Observa√ß√£o 1:** √â importante ressaltar que a converg√™ncia das vari√°veis aleat√≥rias para suas respectivas distribui√ß√µes normais √© uma converg√™ncia em distribui√ß√£o. Isso significa que as distribui√ß√µes das vari√°veis aleat√≥rias se aproximam da distribui√ß√£o normal quando o tamanho da amostra tende ao infinito.

**Observa√ß√£o 2:** Para modelos mais complexos com componentes autoregressivos, a l√≥gica da an√°lise assint√≥tica segue os mesmos princ√≠pios, embora os detalhes possam ser mais elaborados. A transforma√ß√£o de Sims, Stock e Watson e o uso de matrizes s√£o essenciais para simplificar a an√°lise, isolando os componentes com diferentes taxas de converg√™ncia e permitindo a aplica√ß√£o do TLC de maneira adequada.

**Observa√ß√£o 3:** A taxa de converg√™ncia dos estimadores √© fundamental para a constru√ß√£o dos intervalos de confian√ßa. O reescalonamento correto dos estimadores e erros padr√µes garantem que seus intervalos sejam v√°lidos assintoticamente.

**Teorema 1:** (Converg√™ncia da Matriz de Informa√ß√£o) Seja $X$ a matriz de regressores do modelo de tend√™ncia de tempo determin√≠stica, com $x_t = [1, t]'$.  A matriz de informa√ß√£o normalizada $\frac{1}{T^3} \sum_{t=1}^T x_t x_t'$ converge para uma matriz $Q$, onde:
$$ Q = \begin{bmatrix}
    0 & 0 \\
    0 & 1/3 \\
\end{bmatrix} $$
*Prova:*
I. A matriz de informa√ß√£o √© dada por $\sum_{t=1}^T x_t x_t' = \sum_{t=1}^T \begin{bmatrix} 1 \\ t \end{bmatrix} \begin{bmatrix} 1 & t \end{bmatrix} =  \sum_{t=1}^T \begin{bmatrix} 1 & t \\ t & t^2 \end{bmatrix} = \begin{bmatrix} T & \sum_{t=1}^T t \\ \sum_{t=1}^T t & \sum_{t=1}^T t^2 \end{bmatrix}$.
II. Dividindo cada termo por $T^3$, obtemos $\frac{1}{T^3} \sum_{t=1}^T x_t x_t' =  \begin{bmatrix} 1/T^2 & \sum_{t=1}^T t/T^3 \\ \sum_{t=1}^T t/T^3 & \sum_{t=1}^T t^2/T^3 \end{bmatrix}$.
III. Sabendo que $\sum_{t=1}^T t = \frac{T(T+1)}{2}$ e $\sum_{t=1}^T t^2 = \frac{T(T+1)(2T+1)}{6}$,
IV.  Temos, portanto,  $\frac{1}{T^3} \sum_{t=1}^T x_t x_t' = \begin{bmatrix} 1/T^2 & T(T+1)/(2T^3) \\ T(T+1)/(2T^3) & T(T+1)(2T+1)/(6T^3) \end{bmatrix} $.
V.  Calculando os limites quando $T \rightarrow \infty$, obtemos:  $\lim_{T\to \infty} \begin{bmatrix} 1/T^2 & T(T+1)/(2T^3) \\ T(T+1)/(2T^3) & T(T+1)(2T+1)/(6T^3) \end{bmatrix} = \begin{bmatrix}
    0 & 1/2 \\
    1/2 & 1/3 \\
\end{bmatrix}$.
VI. Portanto, a matriz de informa√ß√£o normalizada converge para a matriz $Q$.
$\blacksquare$
> üí° **Exemplo Num√©rico:**
> Para ilustrar o Teorema 1, vamos calcular a matriz de informa√ß√£o normalizada para alguns valores de T e verificar sua converg√™ncia para a matriz Q.
>
> ```python
> import numpy as np
> import pandas as pd
>
> def calculate_normalized_info_matrix(T):
>     """Calcula a matriz de informa√ß√£o normalizada."""
>     t = np.arange(1, T+1)
>     X = np.vstack([np.ones(T), t]).T
>     info_matrix = (1/T**3) * np.dot(X.T, X)
>     return info_matrix
>
> # Valores de T
> T_values = [100, 500, 1000, 5000, 10000]
>
> # Cria uma lista para guardar as matrizes
> matrix_list = []
>
> # Calcula as matrizes de informa√ß√£o para diferentes valores de T
> for T in T_values:
>     info_matrix = calculate_normalized_info_matrix(T)
>     matrix_list.append(info_matrix)
>
> # Cria um DataFrame para exibir as matrizes
> df = pd.DataFrame(matrix_list, index=T_values, columns = ['[1,1]', '[1,2]', '[2,1]', '[2,2]'])
> print(df)
>
> ```
>
> Ao executarmos o c√≥digo, vemos que a matriz de informa√ß√£o normalizada se aproxima da matriz $Q = \begin{bmatrix}
>    0 & 0 \\
>    0 & 1/3 \\
>\end{bmatrix} $ a medida que T aumenta. Os elementos [1,1] e [1,2]/[2,1] da matriz convergem para zero, enquanto o elemento [2,2] se aproxima de 1/3 (aproximadamente 0.333). Isso ilustra a converg√™ncia da matriz de informa√ß√£o como estabelecido no Teorema 1. Note que, no c√≥digo, o elemento fora da diagonal da matriz $Q$ √© dado por $1/2$. Na verdade, a matriz $Q$ para a qual converge a matriz de informa√ß√£o, √© $\begin{bmatrix}
>    0 & 1/2 \\
>    1/2 & 1/3 \\
>\end{bmatrix}$. O ponto √© que o problema surge ao calcularmos a inversa desta matriz, pois a matriz de informa√ß√£o normalizada, na sua forma n√£o limite, √© singular. Essa singularidade explica a necessidade de reescalonar os estimadores por diferentes taxas para obter distribui√ß√µes limites n√£o degeneradas, como demonstrado no lema 1.1.

**Lema 1.1:** A matriz $Q$ do Teorema 1 √© singular, o que explica a necessidade de reescalonar os estimadores por diferentes taxas para obter distribui√ß√µes limites n√£o degeneradas.
*Prova:*
I. A matriz $Q$ do Teorema 1 √© $\begin{bmatrix} 0 & 0 \\ 0 & 1/3 \end{bmatrix}$.
II. O determinante de $Q$ √© $0 \cdot (1/3) - 0 \cdot 0 = 0$.
III. Um determinante igual a zero indica que a matriz √© singular (n√£o invert√≠vel).
IV. A singularidade de $Q$ demonstra que n√£o se pode obter uma matriz de covari√¢ncia assint√≥tica n√£o degenerada dos estimadores MQO sem reescalonar as vari√°veis, pois $\hat{\beta} - \beta =  \left( \sum_{t=1}^{T} (x_t'x_t) \right)^{-1} \sum_{t=1}^{T} x_t \epsilon_t$ e o termo da direita necessita ser reescalonado.
$\blacksquare$

### Conclus√£o

A deriva√ß√£o das distribui√ß√µes limitantes dos estimadores MQO em modelos com tend√™ncia de tempo determin√≠stica requer a aplica√ß√£o do Teorema do Limite Central e das propriedades de sequ√™ncias de diferen√ßas de martingais. O reescalonamento das estimativas por fatores apropriados, como $\sqrt{T}$ e $T^{3/2}$, √© crucial para obter distribui√ß√µes limites n√£o degeneradas e garantir a validade da infer√™ncia estat√≠stica. A abordagem geral envolve a decomposi√ß√£o do modelo, o reescalonamento adequado, a aplica√ß√£o do TLC para martingais e o c√°lculo da matriz de covari√¢ncia assint√≥tica. A compreens√£o desses mecanismos √© fundamental para a aplica√ß√£o correta e para a interpreta√ß√£o dos resultados obtidos em an√°lises com modelos de s√©ries temporais que incluem tend√™ncias de tempo determin√≠sticas. A an√°lise apresentada oferece um arcabou√ßo para entender como a distribui√ß√£o dos estimadores em amostras finitas converge para uma distribui√ß√£o normal quando o tamanho da amostra tende ao infinito.

**Corol√°rio 1:** A superconsist√™ncia do estimador da tend√™ncia de tempo ($\delta$), observada em modelos com tend√™ncia determin√≠stica, √© uma consequ√™ncia direta da sua taxa de converg√™ncia assint√≥tica mais r√°pida, que √© $T^{3/2}$ em vez de $\sqrt{T}$ [^1].
*Prova:*
I. A superconsist√™ncia de um estimador implica que ele converge para o seu valor verdadeiro a uma taxa mais r√°pida do que $\sqrt{T}$.
II. Como demonstrado ao longo deste cap√≠tulo, o reescalonamento do estimador da tend√™ncia de tempo $\hat{\delta}_T$ por $T^{3/2}$ garante que ele tenha uma distribui√ß√£o limite n√£o degenerada.
III. Se o estimador fosse reescalonado apenas por $\sqrt{T}$, ele convergeria para zero, o que n√£o √© √∫til para infer√™ncia estat√≠stica.
IV. A necessidade de reescalonar por $T^{3/2}$ demonstra que a taxa de converg√™ncia √© de ordem superior a $\sqrt{T}$, justificando a superconsist√™ncia do estimador da tend√™ncia de tempo.
$\blacksquare$
> üí° **Exemplo Num√©rico:**
> Para demonstrar a superconsist√™ncia do estimador da tend√™ncia de tempo, vamos simular um modelo com tend√™ncia e verificar como a estimativa de $\delta$ converge para o valor verdadeiro em diferentes amostras.
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
> from sklearn.linear_model import LinearRegression
>
> # Par√¢metros
> num_simulations = 200
> T_values = [50, 100, 200, 500, 1000]
> alpha = 2
> delta = 0.5
> sigma = 1.5
>
> # Listas para armazenar resultados
> delta_estimates = {T: [] for T in T_values}
>
> for T in T_values:
>   for _ in range(num_simulations):
>       # Gerar dados
>       t = np.arange(1, T + 1)
>       epsilon = np.random.normal(0, sigma, T)
>       y = alpha + delta * t + epsilon
>       X = np.vstack([np.ones(T), t]).T
>
>       # Estimar modelo
>       model = LinearRegression()
>       model.fit(X, y)
>       delta_estimates[T].append(model.coef_[1])
>
> # Plot dos erros de estimativa
> plt.figure(figsize=(10, 6))
> for T in T_values:
>     errors = np.array(delta_estimates[T]) - delta
>     plt.hist(errors, bins=20, alpha=0.5, label=f'T={T}')
>
> plt.title('Distribui√ß√£o dos Erros de Estimativa de Delta')
> plt.xlabel('Estimativa - Valor Verdadeiro')
> plt.ylabel('Frequ√™ncia')
> plt.legend()
> plt.show()
>
> # Plot dos erros de estimativa com reescalonamento
> plt.figure(figsize=(10, 6))
> for T in T_values:
>     errors = (np.array(delta_estimates[T]) - delta) * T**(3/2)
>     plt.hist(errors, bins=20, alpha=0.5, label=f'T={T}')
>
> plt.title('Distribui√ß√£o dos Erros de Estimativa de Delta (Reescalonado por T^{3/2})')
> plt.xlabel('Estimativa - Valor Verdadeiro')
> plt.ylabel('Frequ√™ncia')
> plt.legend()
> plt.show()
> ```
>
> Os histogramas mostram que, √† medida que $T$ aumenta, a distribui√ß√£o dos erros de estimativa de $\delta$ se concentra cada vez mais em torno de zero. No entanto, observe como a distribui√ß√£o se torna mais concentrada quando multiplicamos o erro por $T^{3/2}$. A distribui√ß√£o dos erros reescalonados tamb√©m se aproxima de uma normal, ilustrando o teorema do limite central. Este resultado demonstra que o estimador da tend√™ncia converge para o verdadeiro valor mais rapidamente do que $\sqrt{T}$, o que caracteriza a superconsist√™ncia.

**Corol√°rio 2:** O TLC para diferen√ßas de martingais √© uma extens√£o do TLC cl√°ssico e √© crucial para lidar com a depend√™ncia temporal que surge naturalmente em modelos de s√©ries temporais.
*Prova:*
I. O TLC cl√°ssico exige que as vari√°veis aleat√≥rias sejam i.i.d. para garantir que a soma, quando reescalonada, convirja para uma distribui√ß√£o normal.
II. Entretanto, em modelos de s√©ries temporais, a depend√™ncia temporal, em geral, faz com que essa premissa n√£o seja v√°lida.
III. As sequ√™ncias de diferen√ßas de martingais, que satisfazem a propriedade de m√©dia condicional zero, s√£o um tipo de depend√™ncia temporal que permite a aplica√ß√£o do TLC.
IV.  Portanto, o uso do TLC para diferen√ßas de martingais garante a validade das distribui√ß√µes assint√≥ticas dos estimadores em uma gama mais ampla de modelos de s√©ries temporais.
$\blacksquare$

**Observa√ß√£o 4:** A an√°lise da distribui√ß√£o assint√≥tica dos estimadores MQO em modelos de tend√™ncia determin√≠stica demonstra que os procedimentos de infer√™ncia baseados no TLC e em propriedades das martingales s√£o aplic√°veis e v√°lidos assintoticamente, mesmo com taxas de converg√™ncia diferentes.

### Refer√™ncias
[^1]: Trechos do cap√≠tulo 16 do livro "Processes with Deterministic Time Trends", conforme fornecido no contexto.
<!-- END -->
