## O Limite da Matriz de Momentos Normalizada em Modelos com Tend√™ncias Temporais Determin√≠sticas

### Introdu√ß√£o
Este cap√≠tulo aprofunda a discuss√£o sobre a an√°lise assint√≥tica dos estimadores de M√≠nimos Quadrados Ordin√°rios (MQO) em modelos com tend√™ncias temporais determin√≠sticas, com foco espec√≠fico no comportamento da matriz de momentos normalizada e em suas implica√ß√µes para a infer√™ncia estat√≠stica [^1]. Como vimos em cap√≠tulos anteriores, a presen√ßa de tend√™ncias temporais introduz peculiaridades na an√°lise assint√≥tica, principalmente devido √†s diferentes taxas de converg√™ncia dos estimadores e √† necessidade de escalonamento adequado das vari√°veis para garantir a converg√™ncia das distribui√ß√µes limites [^1]. Aqui, detalharemos o porqu√™ da matriz de momentos normalizada $(1/T)\sum_{t=1}^T x_t x_t'$ n√£o convergir para uma matriz n√£o-singular em modelos com tend√™ncias temporais, o que justifica a necessidade de abordagens distintas das utilizadas em modelos estacion√°rios [^1]. Em particular, examinaremos como a matriz $(1/T^3)\sum_{t=1}^T x_t x_t'$ se comporta no limite, e por que, apesar de convergir para uma matriz singular, ainda permite a obten√ß√£o de distribui√ß√µes assint√≥ticas √∫teis para os estimadores de MQO quando devidamente escalonados [^1].

### Conceitos Fundamentais
Em modelos de regress√£o com vari√°veis estacion√°rias, a an√°lise assint√≥tica dos estimadores de MQO se baseia na converg√™ncia da matriz de momentos amostrais, $(1/T)\sum_{t=1}^T x_t x_t'$, para uma matriz n√£o-singular $Q$ [^1]. Este resultado √© fundamental para a aplica√ß√£o do Teorema do Limite Central e a obten√ß√£o da distribui√ß√£o assint√≥tica dos estimadores, que √© dada por uma normal multivariada com matriz de covari√¢ncia proporcional a $Q^{-1}$ [^1]. No entanto, em modelos com tend√™ncias temporais determin√≠sticas, como $y_t = \alpha + \delta t + \epsilon_t$, essa matriz de momentos n√£o converge para uma matriz n√£o-singular quando dividida por $T$ [^1].

A Se√ß√£o 16.1 explica que, para o modelo de tend√™ncia temporal simples, o estimador $\hat{\alpha}_T$ converge a uma taxa de $T^{-1/2}$ e o estimador $\hat{\delta}_T$ a uma taxa de $T^{-3/2}$ [^1]. Esta diferen√ßa nas taxas de converg√™ncia reflete-se no comportamento da matriz de momentos. Em particular, a matriz $(1/T)\sum_{t=1}^T x_t x_t'$ cont√©m somat√≥rios como $\sum_{t=1}^T 1$, $\sum_{t=1}^T t$ e $\sum_{t=1}^T t^2$ [^1]. Como os termos dominantes dessas somas s√£o $T$, $T^2/2$ e $T^3/3$, respectivamente, a divis√£o por $T$ n√£o leva a uma matriz limite convergente [^1].

> üí° **Exemplo Num√©rico:** Para o modelo com tend√™ncia simples, $x_t = [1, t]'$, a matriz de momentos $\sum_{t=1}^T x_t x_t'$ √© dada por:
>
> $$
\sum_{t=1}^T x_t x_t' = \begin{bmatrix} \sum_{t=1}^T 1 & \sum_{t=1}^T t \\ \sum_{t=1}^T t & \sum_{t=1}^T t^2 \end{bmatrix} = \begin{bmatrix} T & \frac{T(T+1)}{2} \\ \frac{T(T+1)}{2} & \frac{T(T+1)(2T+1)}{6} \end{bmatrix}
> $$
> Dividindo por $T$, temos:
>
> $$
\frac{1}{T}\sum_{t=1}^T x_t x_t' = \begin{bmatrix} 1 & \frac{T+1}{2} \\ \frac{T+1}{2} & \frac{(T+1)(2T+1)}{6} \end{bmatrix}
> $$
>
> Ao tomar o limite quando $T \to \infty$, a matriz diverge, demonstrando que $1/T$ n√£o √© o fator de normaliza√ß√£o correto. No entanto, se dividirmos a matriz por $T^3$, um termo de ordem maior, a matriz converge, conforme veremos adiante.
>
> Vamos considerar um exemplo com $T = 100$. Nesse caso, a matriz de momentos original √©:
>
> $$\sum_{t=1}^{100} x_t x_t' = \begin{bmatrix} 100 & 5050 \\ 5050 & 338350 \end{bmatrix}$$
>
>  Dividindo por $T = 100$:
>
> $$ \frac{1}{100}\sum_{t=1}^{100} x_t x_t' = \begin{bmatrix} 1 & 50.5 \\ 50.5 & 3383.5 \end{bmatrix}$$
>
>  Como podemos ver, o termo $3383.5$ √© muito grande e cresce com $T^2$ o que faz a matriz divergir quando $T \to \infty$.

A Se√ß√£o 16.1.1 demonstra que, para obter uma matriz limite convergente, a matriz de momentos necessita ser dividida por $T^3$, e n√£o por $T$, no modelo de tend√™ncia linear [^1]. Isso √© consequ√™ncia do fato de que o termo dominante para a soma $\sum_{t=1}^T t^2$ √© $T^3/3$. Ao inv√©s de dividir a matriz de momentos por um mesmo fator, utiliza-se uma matriz de escalonamento diagonal $Y_T$ para escalar os estimadores por suas respectivas taxas de converg√™ncia, que neste caso √© $Y_T=diag(\sqrt{T}, T^{3/2})$ [^1].

**Lema 1:** A matriz de momentos amostrais normalizada por $T^3$ no modelo de tend√™ncia temporal simples, $(1/T^3)\sum_{t=1}^T x_t x_t'$, converge para uma matriz singular $Q$ quando $T \to \infty$, onde:
$$
\lim_{T \to \infty} \frac{1}{T^3} \sum_{t=1}^T x_t x_t' = \begin{bmatrix} 0 & 0 \\ 0 & 1/3 \end{bmatrix}
$$

*Prova:*
I. Para o modelo de tend√™ncia simples, $x_t = [1, t]'$, ent√£o $\sum_{t=1}^T x_t x_t'$ √© dado por:
$$
\sum_{t=1}^T x_t x_t' = \begin{bmatrix} \sum_{t=1}^T 1 & \sum_{t=1}^T t \\ \sum_{t=1}^T t & \sum_{t=1}^T t^2 \end{bmatrix}
$$
II. Substituindo as somas conhecidas, temos:
$$
\sum_{t=1}^T x_t x_t' = \begin{bmatrix} T & \frac{T(T+1)}{2} \\ \frac{T(T+1)}{2} & \frac{T(T+1)(2T+1)}{6} \end{bmatrix}
$$
III. Dividindo por $T^3$, obtemos:
$$
\frac{1}{T^3} \sum_{t=1}^T x_t x_t' = \begin{bmatrix} \frac{1}{T^2} & \frac{1}{2T} + \frac{1}{2T^2} \\ \frac{1}{2T} + \frac{1}{2T^2} & \frac{1}{3} + \frac{1}{2T} + \frac{1}{6T^2} \end{bmatrix}
$$
IV. Tomando o limite quando $T \to \infty$, temos:
$$
\lim_{T \to \infty} \frac{1}{T^3} \sum_{t=1}^T x_t x_t' = \begin{bmatrix} 0 & 0 \\ 0 & 1/3 \end{bmatrix}
$$
‚ñ†
> üí° **Exemplo Num√©rico:** Vamos calcular a matriz $(1/T^3)\sum_{t=1}^T x_t x_t'$ para $T=100$ no modelo com tend√™ncia simples:
>
> $\sum_{t=1}^{100} x_t x_t' =  \begin{bmatrix} 100 & 5050 \\ 5050 & 338350 \end{bmatrix}$
>
> $\frac{1}{100^3}\sum_{t=1}^{100} x_t x_t' = \begin{bmatrix} \frac{100}{100^3} & \frac{5050}{100^3} \\ \frac{5050}{100^3} & \frac{338350}{100^3} \end{bmatrix} = \begin{bmatrix} 0.0001 & 0.00505 \\ 0.00505 & 0.33835 \end{bmatrix}$
>
> Como $T \to \infty$, essa matriz se aproxima da matriz limite singular
>
> $\begin{bmatrix} 0 & 0 \\ 0 & 1/3 \end{bmatrix}$
>
> Observe que os elementos da matriz convergem para 0 (exceto o elemento (2,2) que converge para 1/3), confirmando o resultado te√≥rico. Se usarmos um $T=1000$, a matriz se torna:
>
> $$\frac{1}{1000^3}\sum_{t=1}^{1000} x_t x_t' = \begin{bmatrix} \frac{1000}{1000^3} & \frac{500500}{1000^3} \\ \frac{500500}{1000^3} & \frac{333833500}{1000^3} \end{bmatrix} = \begin{bmatrix} 0.000001 & 0.0005005 \\ 0.0005005 & 0.3338335 \end{bmatrix}$$
>
>  Que est√° ainda mais perto da matriz limite, demonstrando a converg√™ncia com o aumento de $T$.

√â crucial entender que, embora a matriz limite $(1/T^3)\sum_{t=1}^T x_t x_t'$ seja singular, a distribui√ß√£o assint√≥tica dos estimadores, quando escalonados apropriadamente, ainda converge para uma distribui√ß√£o normal multivariada [^1]. A singularidade da matriz de momentos normalizada n√£o impede a aplica√ß√£o do Teorema do Limite Central, desde que os estimadores sejam pr√©-multiplicados pela matriz de escalonamento $Y_T$ [^1]. Este processo √© detalhado na Se√ß√£o 16.1.1, onde a matriz $Y_T$ √© usada para ajustar as taxas de converg√™ncia dos estimadores.

A necessidade de usar uma matriz de escalonamento $Y_T$, ao inv√©s de simplesmente dividir por $T$, surge do fato de que cada componente do vetor $\beta$ tem uma taxa de converg√™ncia diferente [^1]. O estimador do intercepto, $\alpha$, converge a uma taxa de $T^{-1/2}$, enquanto o estimador do coeficiente da tend√™ncia, $\delta$, converge a uma taxa de $T^{-3/2}$ [^1]. Para garantir que ambos os estimadores tenham distribui√ß√µes assint√≥ticas n√£o degeneradas, √© necess√°rio escalon√°-los por $\sqrt{T}$ e $T^{3/2}$, respectivamente. A matriz $Y_T$ realiza esse escalonamento de forma eficiente [^1].
> üí° **Exemplo Num√©rico:** Para o modelo $y_t = \alpha + \delta t + \epsilon_t$, a matriz de escalonamento $Y_T$ √© $Y_T = \begin{bmatrix} \sqrt{T} & 0 \\ 0 & T^{3/2} \end{bmatrix}$. Multiplicar o vetor de estimadores $(\hat{\alpha}_T - \alpha, \hat{\delta}_T - \delta)$ por $Y_T$ resulta nos estimadores escalonados $\sqrt{T}(\hat{\alpha}_T - \alpha)$ e $T^{3/2}(\hat{\delta}_T - \delta)$, que convergem para distribui√ß√µes normais com vari√¢ncias finitas.
>
>  Se considerarmos $T=100$, a matriz $Y_T$ ser√°:
>  $$Y_{100} = \begin{bmatrix} \sqrt{100} & 0 \\ 0 & 100^{3/2} \end{bmatrix} = \begin{bmatrix} 10 & 0 \\ 0 & 1000 \end{bmatrix}$$
>
>  E se considerarmos $T=1000$:
>  $$Y_{1000} = \begin{bmatrix} \sqrt{1000} & 0 \\ 0 & 1000^{3/2} \end{bmatrix} \approx \begin{bmatrix} 31.62 & 0 \\ 0 & 31622.77 \end{bmatrix}$$
>
>  A multiplica√ß√£o de $Y_T$ pelos desvios dos estimadores, garante que as diferentes taxas de converg√™ncia sejam levadas em considera√ß√£o, tornando os estimadores compar√°veis.

A Se√ß√£o 16.1.2 demonstra que as estat√≠sticas $t$ e $F$ para testes de hip√≥teses sobre os par√¢metros tamb√©m t√™m as distribui√ß√µes assint√≥ticas usuais, apesar das diferentes taxas de converg√™ncia e da matriz de momentos singular [^1]. Isso ocorre devido ao comportamento compensat√≥rio dos erros padr√£o, que, quando escalonados adequadamente, levam √† converg√™ncia para distribui√ß√µes normais padr√µes.

**Caixa de destaque:**
>√â fundamental entender que, em modelos com tend√™ncias temporais determin√≠sticas, a matriz de momentos normalizada $(1/T)\sum_{t=1}^T x_t x_t'$ n√£o converge para uma matriz n√£o-singular. A matriz limite $(1/T^3)\sum_{t=1}^T x_t x_t'$ √© singular, mas a aplica√ß√£o de uma matriz de escalonamento $Y_T$ permite obter distribui√ß√µes assint√≥ticas n√£o degeneradas para os estimadores, e as estat√≠sticas de teste, atrav√©s do uso apropriado do Teorema do Limite Central [^1].

### Desenvolvimento
A matriz de momentos $(1/T)\sum_{t=1}^T x_t x_t'$ diverge em modelos com tend√™ncias temporais determin√≠sticas, pois os componentes desse somat√≥rio n√£o convergem quando divididos por $T$. Especificamente, no modelo de tend√™ncia simples, as somas $\sum_{t=1}^T t$ e $\sum_{t=1}^T t^2$ s√£o de ordem $T^2$ e $T^3$, respectivamente, o que justifica a necessidade de escalar a matriz de momentos com $T^3$ (ou a matriz $Y_T$) para obter uma matriz limite finita [^1].

A Se√ß√£o 16.1.1 detalha como a matriz $Y_T$ √© utilizada para ajustar as taxas de converg√™ncia e obter uma distribui√ß√£o assint√≥tica n√£o degenerada para os estimadores. Ao pr√©-multiplicar os desvios dos estimadores $(b_T - \beta)$ pela matriz $Y_T$, obtemos uma nova express√£o que pode ser analisada usando o Teorema do Limite Central [^1]. A matriz $Y_T$ √© definida como:
$$
Y_T = \begin{bmatrix}
\sqrt{T} & 0 \\
0 & T^{3/2}
\end{bmatrix}
$$
A aplica√ß√£o da matriz $Y_T$ √© essencial, pois ela escala os estimadores para que convirjam na mesma taxa (para distribui√ß√µes assint√≥ticas n√£o degeneradas). O estimador de $\alpha$ √© escalonado por $\sqrt{T}$ e o estimador de $\delta$ por $T^{3/2}$. Isso faz com que as distribui√ß√µes assint√≥ticas desses estimadores n√£o degenerem para zero, o que inviabilizaria qualquer infer√™ncia.

A forma da matriz $Y_T$ est√° diretamente ligada aos termos dominantes dos somat√≥rios que aparecem na matriz de momentos, e √†s taxas de converg√™ncia dos estimadores. As somas como $\sum t$ e $\sum t^2$ possuem termos dominantes dados por $T^2/2$ e $T^3/3$ respectivamente, o que justifica a necessidade do escalonamento por $\sqrt{T}$ e $T^{3/2}$. O termo geral √© $\sum_{t=1}^T t^v$ que possui um termo dominante dado por $T^{v+1}/(v+1)$, o que justifica o padr√£o geral da matriz de escalonamento.
> üí° **Exemplo Num√©rico:** Para ilustrar o escalonamento com $Y_T$, vamos considerar o modelo de tend√™ncia simples $y_t = \alpha + \delta t + \epsilon_t$ com $T=100$. A matriz de escalonamento √©
>
> $$
Y_T = \begin{bmatrix}
\sqrt{100} & 0 \\
0 & 100^{3/2}
\end{bmatrix} = \begin{bmatrix}
10 & 0 \\
0 & 1000
\end{bmatrix}
> $$
>
> Os estimadores de MQO, $\hat{\alpha}_T$ e $\hat{\delta}_T$, s√£o tais que, ap√≥s o escalonamento, temos:
>
> $$
\begin{bmatrix}
\sqrt{T}(\hat{\alpha}_T - \alpha) \\
T^{3/2}(\hat{\delta}_T - \delta)
\end{bmatrix} = \begin{bmatrix}
10(\hat{\alpha}_{100} - \alpha) \\
1000(\hat{\delta}_{100} - \delta)
\end{bmatrix}
> $$
>
> Estes estimadores escalonados convergem para uma distribui√ß√£o normal multivariada, o que possibilita a infer√™ncia estat√≠stica.
>
> Suponha que $\hat{\alpha}_{100} = 2.1$ e $\alpha=2$ e que  $\hat{\delta}_{100} = 0.051$ e $\delta=0.05$. Ent√£o:
>
> $$
\begin{bmatrix}
10(2.1 - 2) \\
1000(0.051 - 0.05)
\end{bmatrix} = \begin{bmatrix}
10(0.1) \\
1000(0.001)
\end{bmatrix} = \begin{bmatrix}
1 \\
1
\end{bmatrix}
> $$
>
>  Os valores escalonados convergem para uma distribui√ß√£o normal, e seu valor n√£o tende a zero, o que √© fundamental para a infer√™ncia.

No modelo geral com tend√™ncia polinomial de grau $p$, a matriz de escalonamento √© dada por $Y_T = \text{diag}(T^{1/2}, T^{3/2}, T^{5/2}, \ldots, T^{(2p+1)/2})$, onde os expoentes correspondem √†s taxas de converg√™ncia dos estimadores de cada termo polinomial. A matriz $Q$ √© definida como:
$$
Q = \lim_{T \to \infty} \frac{1}{T} Y_T^{-1} \sum_{t=1}^T x_t x_t' Y_T^{-1}
$$
A matriz $Q$ √© finita e n√£o singular. Os elementos da matriz Q s√£o dados por $Q_{ij} = 1/(i+j-1)$, onde $i$ e $j$ s√£o os √≠ndices dos regressores, por exemplo, para um modelo com tend√™ncia linear, a matriz $Q$ √© dada por:
$$
Q = \begin{bmatrix}
1 & 1/2 \\
1/2 & 1/3
\end{bmatrix}
$$
> üí° **Exemplo Num√©rico:** Para o modelo com tend√™ncia quadr√°tica, $y_t = \beta_0 + \beta_1 t + \beta_2 t^2 + \epsilon_t$, temos que  $x_t = [1, t, t^2]'$,  e a matriz de escalonamento √©  $Y_T = diag(\sqrt{T}, T^{3/2}, T^{5/2})$, e a matriz Q √© dada por
> $$
Q = \begin{bmatrix}
1 & 1/2 & 1/3 \\
1/2 & 1/3 & 1/4 \\
1/3 & 1/4 & 1/5
\end{bmatrix}
$$
> A matriz inversa $Q^{-1}$ √© necess√°ria para construir a matriz de covari√¢ncia da distribui√ß√£o limite dos estimadores escalonados. A inversa dessa matriz $Q$ √©:
>
> $$
Q^{-1} = \begin{bmatrix}
9 & -36 & 30 \\
-36 & 192 & -180 \\
30 & -180 & 180
\end{bmatrix}
$$
>
> Esta matriz $Q^{-1}$ √© utilizada para obter a matriz de covari√¢ncia assint√≥tica dos estimadores quando escalonados corretamente.
A an√°lise da converg√™ncia dos somat√≥rios, juntamente com a utiliza√ß√£o da matriz de escalonamento $Y_T$, permite derivar as distribui√ß√µes assint√≥ticas dos estimadores de MQO e realizar infer√™ncia estat√≠stica em modelos com tend√™ncias temporais determin√≠sticas [^1].

**Teorema 1.1:** Para um modelo com tend√™ncia polinomial de grau $p$,  $y_t = \beta_0 + \beta_1 t + \beta_2 t^2 + \ldots + \beta_p t^p + \epsilon_t$, onde $\epsilon_t$ √© um ru√≠do branco,  os estimadores de MQO, escalonados pela matriz $Y_T = diag(T^{1/2}, T^{3/2}, T^{5/2}, \ldots, T^{(2p+1)/2})$ , convergem em distribui√ß√£o para uma distribui√ß√£o normal multivariada com m√©dia zero e matriz de covari√¢ncia $\sigma^2 Q^{-1}$, onde $Q_{ij} = 1/(i+j-1)$ para $i,j = 1, \ldots, p+1$.
*Prova:*
I. O modelo √© dado por $y_t = X\beta + \epsilon$, onde $X$ √© a matriz de regressores e $\beta = [\beta_0, \beta_1, ..., \beta_p]$.
II. O estimador de MQO √© $\hat{\beta} = (X'X)^{-1}X'y$, e o desvio √© $\hat{\beta} - \beta = (X'X)^{-1}X'\epsilon$.
III. Multiplicando por $Y_T$, temos $Y_T(\hat{\beta} - \beta) = Y_T(X'X)^{-1}X'\epsilon$.
IV. Usando o resultado de que $\frac{1}{T} Y_T^{-1} X' X Y_T^{-1} \rightarrow Q$, onde $Q_{ij} = 1/(i+j-1)$ para $i, j = 1, ..., p+1$, e aplicando o Teorema do Limite Central:
$Y_T (\hat{\beta} - \beta) \xrightarrow{d} N(0, \sigma^2 Q^{-1})$, onde $\sigma^2$ √© a vari√¢ncia do erro $\epsilon_t$.
V. Esse resultado demonstra que, embora a matriz de momentos normalizada $(1/T)\sum_{t=1}^T x_t x_t'$ n√£o convirja para uma matriz n√£o-singular, os estimadores escalonados convergem para uma distribui√ß√£o normal multivariada, o que permite infer√™ncia estat√≠stica. ‚ñ†

**Lema 1.1**  Para um modelo com tend√™ncia polinomial de grau $p$,  a matriz $Q$ definida como $Q = \lim_{T \to \infty} \frac{1}{T} Y_T^{-1} \sum_{t=1}^T x_t x_t' Y_T^{-1}$ tem elementos dados por $Q_{ij} = 1/(i+j-1)$, onde $i$ e $j$ s√£o os √≠ndices dos regressores ($i,j=1,...,p+1$).

*Prova:*
I. Seja $x_t = [1, t, t^2, ..., t^p]'$. Ent√£o, $x_t x_t' $ √© uma matriz de dimens√£o $(p+1) \times (p+1)$, cujos elementos s√£o da forma $t^{i+j-2}$.
II.  A matriz $Y_T$ √© diagonal e seus elementos s√£o dados por $Y_{T,ii}= T^{(2i-1)/2}$ para $i = 1, ..., p+1$.
III. O termo  $(i,j)$ da matriz  $Y_T^{-1} \sum_{t=1}^T x_t x_t' Y_T^{-1} $ √© dado por
$$\frac{1}{T^{(2i-1)/2}} \sum_{t=1}^T t^{i+j-2}  \frac{1}{T^{(2j-1)/2}} = \frac{1}{T^{(i+j-1)/2}} \sum_{t=1}^T t^{i+j-2}  \frac{1}{T^{(j-1/2)}}.$$
IV. Como o termo dominante da soma $\sum_{t=1}^T t^{i+j-2}$ √© $T^{i+j-1}/(i+j-1)$, temos que
$$  \frac{1}{T} \frac{1}{T^{(2i-1)/2}} \frac{T^{i+j-1}}{i+j-1} \frac{1}{T^{(2j-1)/2}} = \frac{T^{i+j-1}}{T^{(i+j-1)/2} T^{(i+j-1)/2} (i+j-1)} = \frac{1}{i+j-1} $$
V. Assim, o elemento $(i,j)$ da matriz $Q$ √© dado por $Q_{ij} = 1/(i+j-1)$.  ‚ñ†

**Corol√°rio 1.1:** A matriz $Q$ definida em Teorema 1.1 √© sempre n√£o-singular.

*Prova:*
I. A matriz $Q$ √© uma matriz de Hilbert, que √© conhecida por ser n√£o-singular.
II. A n√£o-singularidade da matriz $Q$ garante que sua inversa $Q^{-1}$ existe e √© finita, o que √© crucial para a infer√™ncia estat√≠stica sobre os estimadores de MQO. ‚ñ†

### Conclus√£o
Este cap√≠tulo esclareceu o comportamento da matriz de momentos normalizada em modelos de regress√£o com tend√™ncias temporais determin√≠sticas. A matriz $(1/T)\sum_{t=1}^T x_t x_t'$ n√£o converge para uma matriz n√£o-singular, o que impede o uso direto dos resultados da teoria assint√≥tica padr√£o. No entanto, ao dividir por $T^3$ ou usar uma matriz de escalonamento $Y_T$, juntamente com o conhecimento do comportamento assint√≥tico das somas $\sum_{t=1}^T t^v$ √© poss√≠vel obter uma matriz limite e distribui√ß√µes assint√≥ticas para os estimadores. Este cap√≠tulo tamb√©m ressaltou a import√¢ncia da matriz de escalonamento $Y_T$ e como ela est√° relacionada √†s diferentes taxas de converg√™ncia dos estimadores. A utiliza√ß√£o da matriz $Y_T$, juntamente com a aplica√ß√£o do Teorema do Limite Central, permite derivar as distribui√ß√µes assint√≥ticas dos estimadores de MQO, demonstrando que, embora a matriz de momentos normalizada n√£o seja invert√≠vel no limite, ainda √© poss√≠vel fazer infer√™ncia estat√≠stica em modelos com tend√™ncias temporais determin√≠sticas.

### Refer√™ncias
[^1]: Trechos do texto fornecido.
<!-- END -->
