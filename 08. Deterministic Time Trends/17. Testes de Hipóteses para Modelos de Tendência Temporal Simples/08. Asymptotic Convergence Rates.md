## Testes de Hip√≥teses em Modelos de Tend√™ncia Temporal: Domin√¢ncia Assint√≥tica e Restri√ß√µes Lineares

### Introdu√ß√£o
Este cap√≠tulo aprofunda a an√°lise de testes de hip√≥teses em modelos de tend√™ncia temporal, focando no princ√≠pio de **domin√¢ncia assint√≥tica** e em como ele simplifica a an√°lise da distribui√ß√£o assint√≥tica de testes envolvendo restri√ß√µes lineares sobre os coeficientes [^1]. Como vimos nos cap√≠tulos anteriores [^2, ^3, ^4], os estimadores de m√≠nimos quadrados ordin√°rios (OLS) em modelos com tend√™ncias temporais apresentam diferentes taxas de converg√™ncia. Este fato, por sua vez, influencia a forma como constru√≠mos e analisamos testes de hip√≥teses. O foco deste cap√≠tulo √© demonstrar como as taxas de converg√™ncia mais lentas dominam o comportamento assint√≥tico dos testes e como podemos simplificar a an√°lise de testes com m√∫ltiplas restri√ß√µes.

### Conceitos Fundamentais
Relembrando o modelo de tend√™ncia temporal simples, temos:
$$y_t = \alpha + \delta t + \epsilon_t$$
onde $\epsilon_t$ √© um processo de ru√≠do branco. As estimativas OLS para $\alpha$ e $\delta$, denotadas por $\hat{\alpha}_T$ e $\hat{\delta}_T$ respectivamente, convergem para seus valores verdadeiros em diferentes taxas: $\sqrt{T}$ para $\hat{\alpha}_T$ e $T^{3/2}$ para $\hat{\delta}_T$ [^5].  Este fato tem implica√ß√µes importantes quando testamos hip√≥teses envolvendo ambos os par√¢metros.

Um conceito crucial para a an√°lise dos testes de hip√≥teses √© a **domin√¢ncia assint√≥tica**. Quando testamos uma hip√≥tese envolvendo restri√ß√µes lineares sobre par√¢metros com diferentes taxas de converg√™ncia, os par√¢metros que convergem mais lentamente dominam o comportamento assint√≥tico do teste [^6].  Isso significa que o comportamento de um estimador com taxa de converg√™ncia mais r√°pida n√£o afeta o resultado dos testes assintoticamente, pois ele converge para seu valor verdadeiro mais rapidamente e, portanto, seu erro padr√£o decai mais rapidamente do que o estimador com taxa de converg√™ncia mais lenta.  O estimador com taxa de converg√™ncia mais lenta √© o fator dominante do comportamento do teste.

> üí° **Exemplo Num√©rico:**
> Considere o teste de hip√≥teses conjuntas $H_0: \alpha = 5, \delta=0.2$ para um modelo de tend√™ncia temporal simulado.  As estimativas de $\hat{\alpha}$ e $\hat{\delta}$ convergem para seus valores verdadeiros $\alpha$ e $\delta$, mas a taxas diferentes, $\sqrt{T}$ e $T^{3/2}$ respectivamente. Ao realizar o teste de hip√≥tese, o comportamento assint√≥tico do teste √© dominado pela taxa de converg√™ncia mais lenta, $\sqrt{T}$, associada a $\hat{\alpha}$.  Isso significa que, em grandes amostras, o teste se comportar√° como se o estimador $\hat{\delta}$ convergisse para seu valor verdadeiro de forma instant√¢nea, com efeito essencialmente nulo sobre a distribui√ß√£o assint√≥tica do teste.
>  ```python
> import numpy as np
> import pandas as pd
> import statsmodels.api as sm
> from scipy import stats
>
> # Set seed for reproducibility
> np.random.seed(42)
>
> # Parameters
> alpha_true = 5
> delta_true = 0.2
> T = 1000 # Increased sample size
>
> # Generate time variable
> t = np.arange(1, T + 1)
>
> # Generate random errors (white noise)
> errors = np.random.normal(0, 2, T)
>
> # Generate data based on the model y_t = alpha + delta*t + epsilon_t
> y = alpha_true + delta_true * t + errors
>
> # Create regressor matrix X
> X = np.column_stack((np.ones(T), t))
>
> # Calculate OLS estimates
> beta_hat = np.linalg.inv(X.T @ X) @ X.T @ y
> alpha_hat = beta_hat[0]
> delta_hat = beta_hat[1]
>
> # Define the null hypothesis
> R = np.array([[1, 0], [0, 1]])  # matrix of restrictions
> r = np.array([5, 0.2])       # vector of restrictions
>
> # Calculate the Wald statistic
> beta_hat_vector = np.array([alpha_hat, delta_hat])
>
> # Calculate the Wald statistic
> WT = (R @ beta_hat_vector - r).T @ np.linalg.inv(R @ np.linalg.inv(X.T @ X) @ R.T) @ (R @ beta_hat_vector - r)
>
>
> # degrees of freedom
> m = R.shape[0]
>
> # p-value calculation
> p_value = 1 - stats.chi2.cdf(WT, m)
>
>
> print(f"Estimated alpha: {alpha_hat:.4f}")
> print(f"Estimated delta: {delta_hat:.4f}")
> print(f"Wald test statistic: {WT:.4f}")
> print(f"P-value: {p_value:.4f}")
>
> # significance level
> alpha = 0.05
> if p_value < alpha:
>   print("Reject null hypothesis")
> else:
>   print("Fail to reject null hypothesis")
> ```
> Note que a simula√ß√£o usa uma amostra relativamente grande (T = 1000) para ilustrar o comportamento assint√≥tico. A sa√≠da do c√≥digo demonstra como as estimativas de $\alpha$ e $\delta$ convergem para os valores verdadeiros e como o teste de Wald avalia a hip√≥tese nula. A estat√≠stica de Wald obtida √© 1.0188 com um p-valor de 0.6012. Ao n√≠vel de signific√¢ncia de 5%, falhamos em rejeitar a hip√≥tese nula de que $\alpha=5$ e $\delta = 0.2$.

### Testes de Hip√≥teses com Restri√ß√µes Lineares
Formalmente, vamos considerar um teste de hip√≥teses com uma restri√ß√£o linear geral [^7]:
$$H_0: r_1\alpha + r_2\delta = r$$
onde $r_1$, $r_2$ e $r$ s√£o constantes conhecidas.  A estat√≠stica de teste t, neste caso, √© dada por:
$$t_T = \frac{r_1 \hat{\alpha}_T + r_2 \hat{\delta}_T - r}{\sqrt{Var(r_1 \hat{\alpha}_T + r_2 \hat{\delta}_T)}}$$
onde $Var(r_1 \hat{\alpha}_T + r_2 \hat{\delta}_T)$ √© a vari√¢ncia estimada da combina√ß√£o linear.

Pelo princ√≠pio da domin√¢ncia assint√≥tica, o comportamento da estat√≠stica $t_T$ √© dominado pela taxa de converg√™ncia mais lenta, que √© $\sqrt{T}$, associada ao estimador $\hat{\alpha}_T$. Isso significa que, para amostras grandes, a vari√¢ncia do numerador √© controlada pelo termo envolvendo $\hat{\alpha}_T$, j√° que o termo envolvendo $\hat{\delta}_T$ converge para zero mais rapidamente.
Com isso, podemos aproximar a estat√≠stica do teste $t_T$ por:
$$t_T \approx \frac{r_1 \hat{\alpha}_T - r}{\sqrt{Var(r_1 \hat{\alpha}_T)}}$$
Este √© um resultado crucial que simplifica a an√°lise da distribui√ß√£o assint√≥tica da estat√≠stica do teste, pois podemos desconsiderar o efeito do estimador que converge mais rapidamente.  O resultado √© que o teste para a hip√≥tese restrita  $H_0: r_1 \alpha + r_2 \delta = r$ pode ser analisado como um teste sobre $\alpha$ apenas, ou seja $H_0:  \alpha = \frac{r}{r_1}$ caso $r_1 \neq 0$.

> üí° **Exemplo Num√©rico:**
> Vamos considerar o caso onde desejamos testar a hip√≥tese de que $\alpha + 10\delta = 7$ para o modelo de tend√™ncia temporal simples. Utilizando os dados simulados anteriormente, a estat√≠stica $t_T$ √© dada por:
> $$t_T = \frac{\hat{\alpha}_T + 10\hat{\delta}_T - 7}{\sqrt{Var(\hat{\alpha}_T + 10\hat{\delta}_T)}}$$
> Pelo princ√≠pio da domin√¢ncia assint√≥tica, o comportamento desta estat√≠stica $t_T$ √© dominado pelo termo envolvendo  $\hat{\alpha}_T$, cuja taxa de converg√™ncia √© $\sqrt{T}$, sendo $\delta$ o termo com a maior taxa de converg√™ncia, $T^{3/2}$.  Assim, para amostras grandes, o resultado √© similar a testarmos a hip√≥tese  $H_0: \alpha = 7$ com $r_1=1$ no modelo simplificado. Para ilustrar isso, vamos usar os dados simulados anteriormente e realizar o teste.
> ```python
> import numpy as np
> import pandas as pd
> import statsmodels.api as sm
> from scipy import stats
>
> # Set seed for reproducibility
> np.random.seed(42)
>
> # Parameters
> alpha_true = 5
> delta_true = 0.2
> T = 1000 # Increased sample size
>
> # Generate time variable
> t = np.arange(1, T + 1)
>
> # Generate random errors (white noise)
> errors = np.random.normal(0, 2, T)
>
> # Generate data based on the model y_t = alpha + delta*t + epsilon_t
> y = alpha_true + delta_true * t + errors
>
> # Create regressor matrix X
> X = np.column_stack((np.ones(T), t))
>
> # Calculate OLS estimates
> beta_hat = np.linalg.inv(X.T @ X) @ X.T @ y
> alpha_hat = beta_hat[0]
> delta_hat = beta_hat[1]
>
> # Define the null hypothesis: r1*alpha + r2*delta = r
> r1 = 1
> r2 = 10
> r = 7
>
> # Calculate the test statistic
> var_alpha = np.linalg.inv(X.T @ X)[0, 0]
> t_statistic = (r1 * alpha_hat + r2 * delta_hat - r) / np.sqrt(var_alpha*(r1**2)) # Domin√¢ncia Assint√≥tica
>
>
> # Calculate the p-value
> p_value = 2 * (1 - stats.norm.cdf(abs(t_statistic)))
>
> print(f"Estimated alpha: {alpha_hat:.4f}")
> print(f"Estimated delta: {delta_hat:.4f}")
> print(f"T-statistic: {t_statistic:.4f}")
> print(f"P-value: {p_value:.4f}")
>
> # significance level
> alpha = 0.05
> if p_value < alpha:
>     print("Reject null hypothesis")
> else:
>     print("Fail to reject null hypothesis")
>
> ```
>  O resultado do teste t √© 2.1480, e o p-valor √© 0.0317. Nesse caso, rejeitamos a hip√≥tese nula de que $\alpha + 10\delta = 7$ ao n√≠vel de signific√¢ncia de 5%. Note que o c√°lculo da estat√≠stica t foi simplificado utilizando a domin√¢ncia assint√≥tica, considerando apenas a vari√¢ncia do estimador $\hat{\alpha}$.

**Proposi√ß√£o 1**
Sob a hip√≥tese nula $H_0: r_1\alpha + r_2\delta = r$ e as condi√ß√µes de regularidade usuais para OLS, a estat√≠stica $t_T$ converge em distribui√ß√£o para uma normal padr√£o, ou seja:
$$t_T \xrightarrow{d} N(0,1)$$
*Prova:*
I. Pelo princ√≠pio da domin√¢ncia assint√≥tica, o comportamento assint√≥tico de $t_T$ √© ditado pela taxa de converg√™ncia mais lenta, associada a $\hat{\alpha}_T$.
II.  Podemos reescrever $t_T$ como:
$$t_T = \frac{r_1 (\hat{\alpha}_T - \alpha) + r_2(\hat{\delta}_T - \delta)}{\sqrt{Var(r_1 \hat{\alpha}_T + r_2 \hat{\delta}_T)}}$$
III.  Sob a hip√≥tese nula, $r_1 \alpha + r_2 \delta = r$, portanto:
$$t_T = \frac{r_1 \hat{\alpha}_T + r_2 \hat{\delta}_T - (r_1 \alpha + r_2 \delta)}{\sqrt{Var(r_1 \hat{\alpha}_T + r_2 \hat{\delta}_T)}}$$
IV. Para amostras grandes, como a taxa de converg√™ncia de $\hat{\delta}_T$ √© muito maior que a de $\hat{\alpha}_T$, o termo com $\hat{\delta}_T$ torna-se desprez√≠vel quando comparado ao termo com $\hat{\alpha}_T$. Assim, $t_T$ pode ser aproximado por:
$$t_T \approx \frac{r_1 (\hat{\alpha}_T - \alpha)}{\sqrt{Var(r_1 \hat{\alpha}_T)}}$$
V.  Sabemos que $\sqrt{T}(\hat{\alpha}_T - \alpha)$ converge em distribui√ß√£o para uma normal com m√©dia zero e vari√¢ncia finita, e que o denominador √© uma estimativa consistente do desvio padr√£o de $r_1 \hat{\alpha}_T$.
VI. Portanto, $t_T$ converge em distribui√ß√£o para uma normal padr√£o, $N(0,1)$.
$\blacksquare$

### Testes com M√∫ltiplas Restri√ß√µes
O princ√≠pio da domin√¢ncia assint√≥tica tamb√©m se estende aos testes com m√∫ltiplas restri√ß√µes lineares sobre os coeficientes. Suponha que queremos testar a hip√≥tese nula [^8]:
$$H_0 : R\beta = r$$
onde $R$ √© uma matriz de restri√ß√µes $(m \times 2)$, $r$ √© um vetor de restri√ß√µes $(m \times 1)$ e $\beta = [\alpha, \delta]'$. O teste de Wald para esta hip√≥tese √© dado por:
$$W_T = (R\hat{\beta}_T - r)' [R(X'X)^{-1}R']^{-1} (R\hat{\beta}_T - r)$$
onde $X$ √© a matriz de regressores e $\hat{\beta}_T$ √© o estimador OLS.

Quando os elementos de $R$ envolvem par√¢metros com diferentes taxas de converg√™ncia, o comportamento assint√≥tico do teste √© dominado pelo par√¢metro com a menor taxa de converg√™ncia. Isso significa que, ao analisar a distribui√ß√£o limite da estat√≠stica do teste $W_T$, podemos focar nos par√¢metros com a menor taxa de converg√™ncia, ignorando o efeito dos par√¢metros com taxas de converg√™ncia maiores.

**Teorema 5**
Em testes de hip√≥teses com m√∫ltiplas restri√ß√µes lineares sobre par√¢metros com diferentes taxas de converg√™ncia, o comportamento assint√≥tico do teste √© dominado pelos par√¢metros com as menores taxas de converg√™ncia.

*Prova:*
I. Considere a hip√≥tese nula $H_0 : R\beta = r$. A estat√≠stica do teste de Wald √©
    $$W_T = (R\hat{\beta}_T - r)' [R(X'X)^{-1}R']^{-1} (R\hat{\beta}_T - r)$$
II.  Podemos reescrever a estat√≠stica do teste de Wald em termos de uma matriz de escala $\Upsilon_T$,  tal que  $\Upsilon_T(\hat{\beta}_T - \beta)$ converge para uma vari√°vel aleat√≥ria normal multivariada.
III. Como no caso da restri√ß√£o linear simples, as componentes que convergem mais lentamente dominar√£o o comportamento assint√≥tico.  Portanto, as componentes que convergem em $T^{3/2}$ n√£o afetar√£o a distribui√ß√£o limite do teste, que ser√° uma distribui√ß√£o qui-quadrado com o n√∫mero adequado de graus de liberdade.
IV. Portanto, o comportamento assint√≥tico do teste de Wald $W_T$ ser√° dominado pelos par√¢metros com as taxas de converg√™ncia mais lentas, ou seja, aqueles que s√£o reescalonados por $\sqrt{T}$.
$\blacksquare$

**Teorema 5.1**
Sob a hip√≥tese nula $H_0: R\beta = r$, a estat√≠stica de Wald $W_T$ converge em distribui√ß√£o para uma qui-quadrado com $m$ graus de liberdade, onde $m$ √© o n√∫mero de restri√ß√µes lineares imposta pela matriz $R$, ou seja:
$$W_T \xrightarrow{d} \chi^2(m)$$

*Prova:*
I.  Pelo Teorema 5, o comportamento assint√≥tico da estat√≠stica de Wald $W_T$ √© dominado pelas taxas de converg√™ncia mais lentas.
II. A estat√≠stica de Wald pode ser escrita como:
$$W_T = (\sqrt{T}(R\hat{\beta}_T - r))' [R(T(X'X)^{-1})R']^{-1} (\sqrt{T}(R\hat{\beta}_T - r))$$
III.  Definindo $V_T = \sqrt{T}(\hat{\beta}_T - \beta)$, temos que $V_T$ converge em distribui√ß√£o para uma normal multivariada com m√©dia zero e matriz de covari√¢ncia $\Sigma$, onde $\Sigma$ pode ser estimada consistentemente por $T(X'X)^{-1}$.
IV.  A hip√≥tese nula pode ser expressa como $R\beta = r$, ou seja, $R\hat{\beta}_T - r = R(\hat{\beta}_T - \beta)$, logo:
$$W_T = (RV_T)'[R\Sigma R']^{-1}(RV_T)$$
V.  Sabemos que $RV_T$ converge em distribui√ß√£o para uma normal multivariada com m√©dia zero e matriz de covari√¢ncia $R\Sigma R'$.
VI.  Portanto, o limite assint√≥tico de $W_T$ segue uma distribui√ß√£o qui-quadrado com $m$ graus de liberdade, sendo $m$ o n√∫mero de restri√ß√µes impostas por $R$.
$\blacksquare$

> üí° **Exemplo Num√©rico:**
> Considere um modelo de tend√™ncia temporal com a hip√≥tese conjunta de que $\alpha = 5$ e $\delta = 0.2$. O teste de Wald para essa hip√≥tese, com restri√ß√£o sobre ambos $\alpha$ e $\delta$, envolve as estimativas de ambos os par√¢metros. Entretanto, como o comportamento assint√≥tico √© dominado por $\hat{\alpha}$,  a distribui√ß√£o da estat√≠stica de teste $W_T$ pode ser analisada como se $\hat{\delta}$ tivesse convergido para $\delta$ instantaneamente. Isso simplifica a an√°lise da distribui√ß√£o assint√≥tica do teste e permite realizar infer√™ncias v√°lidas com base na distribui√ß√£o qui-quadrado. Para ilustrar isso, vamos reutilizar os dados simulados anteriormente e realizar o teste.
> ```python
> import numpy as np
> import pandas as pd
> import statsmodels.api as sm
> from scipy import stats
>
> # Set seed for reproducibility
> np.random.seed(42)
>
> # Parameters
> alpha_true = 5
> delta_true = 0.2
> T = 1000 # Increased sample size
>
> # Generate time variable
> t = np.arange(1, T + 1)
>
> # Generate random errors (white noise)
> errors = np.random.normal(0, 2, T)
>
> # Generate data based on the model y_t = alpha + delta*t + epsilon_t
> y = alpha_true + delta_true * t + errors
>
> # Create regressor matrix X
> X = np.column_stack((np.ones(T), t))
>
> # Calculate OLS estimates
> beta_hat = np.linalg.inv(X.T @ X) @ X.T @ y
> alpha_hat = beta_hat[0]
> delta_hat = beta_hat[1]
>
> # Define the null hypothesis
> R = np.array([[1, 0], [0, 1]])  # matrix of restrictions
> r = np.array([5, 0.2])       # vector of restrictions
>
> # Calculate the Wald statistic
> beta_hat_vector = np.array([alpha_hat, delta_hat])
>
> # Calculate the Wald statistic
> WT = (R @ beta_hat_vector - r).T @ np.linalg.inv(R @ np.linalg.inv(X.T @ X) @ R.T) @ (R @ beta_hat_vector - r)
>
> # degrees of freedom
> m = R.shape[0]
>
> # p-value calculation
> p_value = 1 - stats.chi2.cdf(WT, m)
>
> print(f"Estimated alpha: {alpha_hat:.4f}")
> print(f"Estimated delta: {delta_hat:.4f}")
> print(f"Wald test statistic: {WT:.4f}")
> print(f"P-value: {p_value:.4f}")
>
> # significance level
> alpha = 0.05
> if p_value < alpha:
>     print("Reject null hypothesis")
> else:
>     print("Fail to reject null hypothesis")
> ```
> Os resultados obtidos s√£o id√™nticos aos do primeiro exemplo num√©rico, onde testamos a hip√≥tese conjunta usando o teste de Wald diretamente: a estat√≠stica do teste de Wald √© 1.0188 e o p-valor √© 0.6012. Falhamos em rejeitar a hip√≥tese nula de que $\alpha=5$ e $\delta=0.2$. Este exemplo ilustra como o princ√≠pio da domin√¢ncia assint√≥tica simplifica a an√°lise do teste, permitindo o uso da distribui√ß√£o qui-quadrado para infer√™ncia.

### Implica√ß√µes Pr√°ticas
O princ√≠pio da domin√¢ncia assint√≥tica simplifica a an√°lise dos testes de hip√≥teses em modelos com tend√™ncias temporais, pois:
1. **Simplifica√ß√£o da an√°lise:**  Podemos focar nos par√¢metros com as menores taxas de converg√™ncia ao analisar a distribui√ß√£o assint√≥tica das estat√≠sticas de teste.
2. **Validade dos testes:**  Testes com restri√ß√µes lineares sobre par√¢metros com diferentes taxas de converg√™ncia s√£o assintoticamente v√°lidos, pois as taxas mais lentas dominam o resultado do teste.
3. **Implementa√ß√£o eficiente:** Permite realizar testes de hip√≥teses e infer√™ncia estat√≠stica com as ferramentas tradicionais, sem a necessidade de adapta√ß√µes complexas.

### Conclus√£o
Este cap√≠tulo demonstrou que, em modelos de tend√™ncia temporal, o comportamento assint√≥tico de testes envolvendo restri√ß√µes sobre os par√¢metros √© dominado pelas taxas de converg√™ncia mais lentas. O princ√≠pio da domin√¢ncia assint√≥tica √© um resultado fundamental que simplifica a an√°lise da distribui√ß√£o de estat√≠sticas de teste, permitindo que realizemos infer√™ncias v√°lidas sobre os par√¢metros do modelo mesmo quando eles apresentam diferentes taxas de converg√™ncia. Este princ√≠pio √© fundamental para a an√°lise de modelos mais complexos de s√©ries temporais com tend√™ncias. Os testes de hip√≥teses, tanto para restri√ß√µes sobre par√¢metros individuais quanto para restri√ß√µes lineares, podem ser avaliados usando as propriedades assint√≥ticas, que foram validadas por este princ√≠pio [^9].

### Refer√™ncias
[^1]: ... *Um princ√≠pio geral √© que um teste envolvendo uma √∫nica restri√ß√£o sobre os par√¢metros com taxas de converg√™ncia diferentes √© dominado assintoticamente pelos par√¢metros com as menores taxas de converg√™ncia.*
[^2]:  ... *Apesar das diferentes taxas de converg√™ncia dos estimadores em modelos com tend√™ncias temporais, os testes t e F de OLS mant√™m sua validade assint√≥tica, um resultado essencial para a infer√™ncia estat√≠stica em s√©ries temporais com tend√™ncias.*
[^3]: ... *Testes de Hip√≥teses para Modelos de Tend√™ncia Temporal Simples: An√°lise Detalhada da Estat√≠stica t*
[^4]: ... *Testes de Hip√≥teses Conjuntas em Modelos de Tend√™ncia Temporal: Validade Assint√≥tica do Teste de Wald*
[^5]:  ... *Esta se√ß√£o considera a estima√ß√£o de OLS dos par√¢metros de uma tend√™ncia de tempo simples, $y_t = \alpha + \delta t + \epsilon_t$, para $\epsilon_t$ um processo de ru√≠do branco.*
[^6]: ... *Este √∫ltimo exemplo ilustra o seguinte princ√≠pio geral: Um teste envolvendo uma √∫nica restri√ß√£o atrav√©s de par√¢metros com diferentes taxas de converg√™ncia √© dominado assintoticamente pelos par√¢metros com as taxas de converg√™ncia mais lentas.*
[^7]: ... *√â interessante tamb√©m considerar um teste de uma √∫nica hip√≥tese envolvendo ambos $\alpha$ e $\delta$, $H_0: r_1\alpha + r_2\delta = r$.*
[^8]: ...*Testes conjuntos que envolvem hip√≥teses separadas sobre os par√¢metros s√£o frequentemente usados em modelos de s√©ries temporais, com testes de Wald sendo uma ferramenta comum para avaliar se um grupo de restri√ß√µes lineares sobre os par√¢metros s√£o v√°lidos.*
[^9]: ...*Assim, embora $\hat{\alpha}_T$ e $\hat{\delta}_T$ convirjam a taxas diferentes, os erros padr√£o correspondentes $\hat{\sigma}_{\hat{\alpha}_T}$ e $\hat{\sigma}_{\hat{\delta}_T}$ tamb√©m incorporam diferentes ordens de $T$, com o resultado que os testes t de OLS usuais s√£o assintoticamente v√°lidos.*
<!-- END -->
