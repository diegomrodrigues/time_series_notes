## Testes de Hip√≥tese com Restri√ß√µes Lineares em Modelos de Tend√™ncia Temporal

### Introdu√ß√£o
Em continuidade aos cap√≠tulos anteriores [^1, ^2], que abordaram a validade assint√≥tica dos testes t e de Wald para modelos de tend√™ncia temporal, este cap√≠tulo se dedica √† an√°lise de testes de hip√≥teses envolvendo restri√ß√µes lineares sobre os par√¢metros do intercepto e da tend√™ncia. Especificamente, exploraremos como construir uma estat√≠stica t generalizada que leve em considera√ß√£o as diferentes taxas de converg√™ncia dos estimadores e como essa estat√≠stica se comporta assintoticamente, garantindo a validade das infer√™ncias em modelos com tend√™ncias temporais.

### Conceitos Fundamentais
Conforme estabelecido anteriormente [^3], o modelo de tend√™ncia temporal simples √© dado por:
$$y_t = \alpha + \delta t + \epsilon_t$$
onde $\epsilon_t$ representa um processo de ru√≠do branco. As estimativas de OLS para $\alpha$ e $\delta$, denotadas por $\hat{\alpha}_T$ e $\hat{\delta}_T$, convergem para seus valores verdadeiros com taxas distintas, sendo $\sqrt{T}$ para $\hat{\alpha}_T$ e $T^{3/2}$ para $\hat{\delta}_T$ [^4].

> üí° **Exemplo Num√©rico:**
> Considere uma s√©rie temporal simulada com $T = 100$, onde o verdadeiro modelo √© $y_t = 2 + 0.5t + \epsilon_t$, com $\epsilon_t \sim N(0,1)$.  Ap√≥s a estima√ß√£o por OLS, obtivemos $\hat{\alpha}_T = 2.1$ e $\hat{\delta}_T = 0.48$. O erro padr√£o de $\hat{\alpha}_T$ ser√° da ordem de $1/\sqrt{100} = 0.1$, enquanto o erro padr√£o de $\hat{\delta}_T$ ser√° da ordem de $1/100^{3/2}=0.001$. Este exemplo ilustra as diferentes taxas de converg√™ncia.
> ```python
> import numpy as np
> import pandas as pd
> import statsmodels.api as sm
> import matplotlib.pyplot as plt
>
> np.random.seed(42)
> T = 100
> t = np.arange(1, T + 1)
> alpha_true = 2
> delta_true = 0.5
> epsilon = np.random.normal(0, 1, T)
> y = alpha_true + delta_true * t + epsilon
>
> X = np.column_stack((np.ones(T), t))
> model = sm.OLS(y, X)
> results = model.fit()
> alpha_hat = results.params[0]
> delta_hat = results.params[1]
> se_alpha = results.bse[0]
> se_delta = results.bse[1]
> print(f"Estimativa de alpha: {alpha_hat:.2f}, Erro padr√£o: {se_alpha:.3f}")
> print(f"Estimativa de delta: {delta_hat:.2f}, Erro padr√£o: {se_delta:.5f}")
>
> # Plotting the data and the fitted line
> plt.figure(figsize=(10, 6))
> plt.plot(t, y, 'o', label='Dados')
> plt.plot(t, results.fittedvalues, 'r-', label='Regress√£o OLS')
> plt.xlabel('Tempo (t)')
> plt.ylabel('y_t')
> plt.title('Dados simulados e ajuste por OLS')
> plt.legend()
> plt.grid(True)
> plt.show()
> ```

Muitas vezes, √© de interesse testar hip√≥teses que imp√µem restri√ß√µes lineares sobre os par√¢metros $\alpha$ e $\delta$. Uma hip√≥tese linear geral pode ser expressa como:
$$H_0 : r_1 \alpha + r_2 \delta = r$$
onde $r_1$, $r_2$ e $r$ s√£o constantes conhecidas. Para testar esta hip√≥tese, construiremos uma estat√≠stica t generalizada que leve em considera√ß√£o as diferentes taxas de converg√™ncia de $\hat{\alpha}_T$ e $\hat{\delta}_T$.

### Constru√ß√£o da Estat√≠stica t Generalizada
A estat√≠stica t generalizada para testar a hip√≥tese linear $H_0$ √© dada por [^5]:
$$t_T = \frac{r_1 \hat{\alpha}_T + r_2 \hat{\delta}_T - r}{\sqrt{Var(r_1 \hat{\alpha}_T + r_2 \hat{\delta}_T)}}$$
onde $Var(r_1 \hat{\alpha}_T + r_2 \hat{\delta}_T)$ √© a vari√¢ncia estimada da combina√ß√£o linear dos estimadores. Essa vari√¢ncia pode ser calculada usando a matriz de covari√¢ncia dos estimadores OLS, denotada por $\hat{Cov}(\hat{\alpha}_T, \hat{\delta}_T)$.

> üí° **Exemplo Num√©rico:**
> Usando as estimativas do exemplo anterior, suponha que $r_1 = 1$, $r_2 = 10$, e $r=7$. Queremos testar $H_0: \alpha + 10\delta = 7$. A vari√¢ncia da combina√ß√£o linear √© calculada como:
>
> $$Var(r_1 \hat{\alpha}_T + r_2 \hat{\delta}_T) = r_1^2 Var(\hat{\alpha}_T) + r_2^2 Var(\hat{\delta}_T) + 2 r_1 r_2 Cov(\hat{\alpha}_T, \hat{\delta}_T)$$
>
> Suponha que $Var(\hat{\alpha}_T) = 0.01$, $Var(\hat{\delta}_T) = 0.00002$, e $Cov(\hat{\alpha}_T, \hat{\delta}_T) = -0.000003$.
> Ent√£o,
> $$Var(\hat{\alpha}_T + 10\hat{\delta}_T) = 1^2 * 0.01 + 10^2 * 0.00002 + 2 * 1 * 10 * (-0.000003) = 0.01 + 0.002 - 0.00006 = 0.01194$$
> O erro padr√£o √© $\sqrt{0.01194} \approx 0.109$.

Para obter uma distribui√ß√£o assint√≥tica conhecida para a estat√≠stica t generalizada, √© necess√°rio realizar um reescalonamento apropriado, como visto anteriormente. Definimos o numerador como:
$$N_T = r_1 \hat{\alpha}_T + r_2 \hat{\delta}_T - r$$
E seu erro padr√£o, $\hat{\sigma}_{N_T} = \sqrt{Var(r_1 \hat{\alpha}_T + r_2 \hat{\delta}_T)}$.
Multiplicamos o numerador e o denominador por $\sqrt{T}$, resultando em:
$$t_T = \frac{\sqrt{T}(r_1 \hat{\alpha}_T + r_2 \hat{\delta}_T - r)}{\sqrt{T} \hat{\sigma}_{N_T}}$$

Para analisar a distribui√ß√£o assint√≥tica da estat√≠stica t, √© √∫til reescrever o numerador usando a matriz de escala $\Upsilon_T$, que √© definida como:
$$\Upsilon_T = \begin{bmatrix} \sqrt{T} & 0 \\ 0 & T^{3/2} \end{bmatrix}$$
Dessa forma, podemos escrever o numerador reescalonado como:
$$\sqrt{T}(r_1 \hat{\alpha}_T + r_2 \hat{\delta}_T - r) = \begin{bmatrix} r_1 & r_2/T \end{bmatrix} \Upsilon_T \Upsilon_T^{-1} \sqrt{T}(\hat{\beta}_T - \beta)$$
onde $\beta = [\alpha, \delta]'$.  Multiplicando e dividindo o denominador por $T^2$:
$$\sqrt{T}\hat{\sigma}_{N_T} = T^2\sqrt{T^{-3}Var(r_1 \hat{\alpha}_T + r_2 T \hat{\delta}_T)} $$
Esses passos s√£o cruciais para garantir que os termos reescalonados convirjam em distribui√ß√£o para quantidades bem definidas.

### An√°lise Assint√≥tica e Converg√™ncia da Estat√≠stica t Generalizada

Para demonstrar que a estat√≠stica t generalizada tem uma distribui√ß√£o assint√≥tica normal padr√£o, recorremos ao Teorema Central do Limite (TCL) e ao Teorema de Slutsky.  Come√ßamos considerando o numerador reescalonado:
$$\sqrt{T}(r_1 \hat{\alpha}_T + r_2 \hat{\delta}_T - r)$$
Este termo pode ser reescrito como:
$$\sqrt{T}(r_1 \hat{\alpha}_T + r_2 \hat{\delta}_T - r) = \begin{bmatrix} r_1 & r_2 \end{bmatrix} \begin{bmatrix} \sqrt{T}(\hat{\alpha}_T - \alpha) \\ \sqrt{T}(\hat{\delta}_T - \delta) \end{bmatrix}$$
**Lema 1**
O termo $\sqrt{T}(\hat{\delta}_T - \delta)$ pode ser reescrito como $T^{-1}\sqrt{T}T^{3/2}(\hat{\delta}_T - \delta)$, com a vantagem de explicitar a taxa de converg√™ncia do estimador.

*Prova:*
I. Multiplicamos e dividimos por $T$:
$$\sqrt{T}(\hat{\delta}_T - \delta) = T^{-1} T \sqrt{T}(\hat{\delta}_T - \delta)$$
II. Reorganizamos os termos:
$$ T^{-1} T \sqrt{T}(\hat{\delta}_T - \delta) = T^{-1} \sqrt{T} T^{3/2} (\hat{\delta}_T - \delta)$$
$\blacksquare$

Continuando, para analisar a converg√™ncia assint√≥tica do numerador, √© conveniente definir $\beta = [\alpha, \delta]'$ e $\hat{\beta}_T = [\hat{\alpha}_T, \hat{\delta}_T]'$, e usar a matriz de escala apropriada $\Upsilon_T$. Com isso, podemos escrever:
$$\begin{bmatrix} \sqrt{T}(\hat{\alpha}_T - \alpha) \\ T^{3/2}(\hat{\delta}_T - \delta) \end{bmatrix} = \Upsilon_T(\hat{\beta}_T - \beta)$$
onde a matriz de escala $\Upsilon_T$ √© dada por:
$$\Upsilon_T = \begin{bmatrix} \sqrt{T} & 0 \\ 0 & T^{3/2} \end{bmatrix}$$
Pelo Teorema Central do Limite Multivariado (TCLM) [^6], sabemos que:
$$\Upsilon_T(\hat{\beta}_T - \beta) \xrightarrow{d} N(0, \sigma^2 Q^{-1})$$
onde $Q$ √© o limite da matriz de informa√ß√£o, conforme definido no cap√≠tulo anterior.

A estat√≠stica t generalizada, ap√≥s ser devidamente reescalonada, pode ser escrita como:
$$t_T = \frac{\begin{bmatrix} r_1 & r_2/T \end{bmatrix} \Upsilon_T(\hat{\beta}_T - \beta)}{\sqrt{\hat{Var} \left(\begin{bmatrix} r_1 & r_2/T \end{bmatrix} \Upsilon_T(\hat{\beta}_T - \beta) \right)}} $$

Sob a hip√≥tese nula, $r_1 \alpha + r_2 \delta = r$. Pelo Teorema Central do Limite, o numerador da estat√≠stica t generalizada converge em distribui√ß√£o para uma vari√°vel aleat√≥ria normal com m√©dia zero e vari√¢ncia $\sigma^2(r_1, r_2)Q^{-1}(r_1, r_2)'$. Ou seja:
$$ \sqrt{T}(r_1 \hat{\alpha}_T + r_2 \hat{\delta}_T - r) \xrightarrow{d} N(0, \sigma^2 \begin{bmatrix} r_1 & r_2/T \end{bmatrix} Q^{-1} \begin{bmatrix} r_1 \\ r_2/T \end{bmatrix})$$

O denominador, ap√≥s a multiplica√ß√£o por $T^2$, converge em probabilidade para a raiz quadrada da vari√¢ncia do numerador. Dessa forma, a estat√≠stica t generalizada, ap√≥s o reescalonamento apropriado, converge em distribui√ß√£o para uma normal padr√£o $N(0,1)$.

**Teorema 4**
Sob a hip√≥tese nula $H_0 : r_1 \alpha + r_2 \delta = r$, a estat√≠stica t generalizada $t_T$ converge em distribui√ß√£o para uma vari√°vel aleat√≥ria normal padr√£o $N(0,1)$.
$$t_T \xrightarrow{d} N(0,1)$$

*Prova:*
I. Partimos da estat√≠stica t generalizada:
$$t_T = \frac{r_1 \hat{\alpha}_T + r_2 \hat{\delta}_T - r}{\sqrt{Var(r_1 \hat{\alpha}_T + r_2 \hat{\delta}_T)}}$$

II. Multiplicamos o numerador e o denominador por $\sqrt{T}$:
$$t_T = \frac{\sqrt{T}(r_1 \hat{\alpha}_T + r_2 \hat{\delta}_T - r)}{\sqrt{T}\sqrt{Var(r_1 \hat{\alpha}_T + r_2 \hat{\delta}_T)}}$$

III. Reescrevemos o numerador usando a matriz $\Upsilon_T$:
$$\sqrt{T}(r_1 \hat{\alpha}_T + r_2 \hat{\delta}_T - r) = \begin{bmatrix} r_1 & r_2/T \end{bmatrix} \Upsilon_T  \Upsilon_T^{-1}\sqrt{T}(\hat{\beta}_T - \beta)$$

IV. Pelo Teorema Central do Limite Multivariado, $\Upsilon_T^{-1} \sqrt{T}(\hat{\beta}_T - \beta)$ converge em distribui√ß√£o para uma vari√°vel aleat√≥ria normal multivariada, com m√©dia zero e matriz de covari√¢ncia $\sigma^2 Q^{-1}$.

V. Assim, o numerador reescalonado converge em distribui√ß√£o para:
$$ \sqrt{T}(r_1 \hat{\alpha}_T + r_2 \hat{\delta}_T - r) \xrightarrow{d} N(0, \sigma^2 \begin{bmatrix} r_1 & r_2/T \end{bmatrix} Q^{-1} \begin{bmatrix} r_1 \\ r_2/T \end{bmatrix})$$

VI. O denominador reescalonado converge em probabilidade para:
$$\sqrt{T}\sqrt{Var(r_1 \hat{\alpha}_T + r_2 \hat{\delta}_T)} \xrightarrow{p} \sqrt{\sigma^2 \begin{bmatrix} r_1 & r_2/T \end{bmatrix} Q^{-1} \begin{bmatrix} r_1 \\ r_2/T \end{bmatrix}}$$

VII. Portanto, a estat√≠stica t generalizada converge para uma distribui√ß√£o normal padr√£o:
$$t_T \xrightarrow{d} N(0,1)$$
$\blacksquare$

**Teorema 4.1**
Uma generaliza√ß√£o do teorema anterior pode ser feita para o caso em que a restri√ß√£o linear envolva m√∫ltiplos par√¢metros. Seja $\beta = [\beta_1, \beta_2, \ldots, \beta_k]^T$ o vetor de par√¢metros de um modelo de tend√™ncia temporal, com $\hat{\beta}_T$ sendo o vetor dos estimadores. Seja $R$ uma matriz $q \times k$ e $r$ um vetor $q \times 1$. Considere a hip√≥tese nula $H_0 : R \beta = r$. Seja $\Upsilon_T$ uma matriz diagonal de escala tal que $\Upsilon_T(\hat{\beta}_T - \beta)$ converge em distribui√ß√£o para uma normal multivariada. Ent√£o, a estat√≠stica t generalizada dada por:

$$t_T = \frac{R\hat{\beta}_T - r}{\sqrt{\hat{Var}(R\hat{\beta}_T)}}$$

reescalonada apropriadamente, converge em distribui√ß√£o para uma normal padr√£o $N(0,1)$.

*Prova:*
A prova segue um racioc√≠nio an√°logo ao do Teorema 4.
I. Partimos da estat√≠stica t generalizada para restri√ß√µes lineares:
$$t_T = \frac{R\hat{\beta}_T - r}{\sqrt{Var(R\hat{\beta}_T)}}$$

II. Multiplicamos o numerador e o denominador por $\sqrt{T}$:
$$t_T = \frac{\sqrt{T}(R\hat{\beta}_T - r)}{\sqrt{T}\sqrt{Var(R\hat{\beta}_T)}}$$

III. Reescrevemos o numerador usando a matriz de escala $\Upsilon_T$:
$$ \sqrt{T}(R\hat{\beta}_T - r) = R \Upsilon_T \Upsilon_T^{-1}\sqrt{T}(\hat{\beta}_T - \beta)$$

IV. Pelo Teorema Central do Limite Multivariado, $\Upsilon_T^{-1}\sqrt{T}(\hat{\beta}_T - \beta)$ converge para uma vari√°vel aleat√≥ria normal multivariada com m√©dia zero e matriz de covari√¢ncia $\sigma^2 Q^{-1}$.

V. Assim, o numerador reescalonado converge em distribui√ß√£o para:
$$\sqrt{T}(R\hat{\beta}_T - r) \xrightarrow{d} N(0, \sigma^2 R Q^{-1} R')$$

VI. O denominador reescalonado converge em probabilidade para:
$$ \sqrt{T}\sqrt{Var(R\hat{\beta}_T)} \xrightarrow{p} \sqrt{\sigma^2 R Q^{-1} R'}$$

VII. Portanto, a estat√≠stica t generalizada, ap√≥s o reescalonamento, converge para uma distribui√ß√£o normal padr√£o:
$$t_T \xrightarrow{d} N(0,1)$$
$\blacksquare$

### Exemplo Num√©rico
Vamos considerar um exemplo pr√°tico. Suponha que tenhamos os seguintes valores estimados para um modelo de tend√™ncia temporal, usando uma amostra de $T=100$:
-   $\hat{\alpha}_T = 5.2$
-   $\hat{\delta}_T = 0.15$
-   $Var(\hat{\alpha}_T) = 0.01$
-   $Var(\hat{\delta}_T) = 0.00002$
-   $Cov(\hat{\alpha}_T, \hat{\delta}_T) = -0.000003$

Queremos testar a hip√≥tese nula $H_0: \alpha + 10\delta = 6.5$. Aqui, $r_1 = 1$, $r_2 = 10$ e $r=6.5$.
O valor estimado da restri√ß√£o √©:
$$r_1 \hat{\alpha}_T + r_2 \hat{\delta}_T = 1*5.2 + 10*0.15 = 6.7$$
O erro padr√£o da combina√ß√£o linear √© dado por:
$$Var(r_1 \hat{\alpha}_T + r_2 \hat{\delta}_T) = r_1^2 Var(\hat{\alpha}_T) + r_2^2 Var(\hat{\delta}_T) + 2 r_1 r_2 Cov(\hat{\alpha}_T, \hat{\delta}_T)$$
$$Var(r_1 \hat{\alpha}_T + r_2 \hat{\delta}_T) = 1^2 * 0.01 + 10^2 * 0.00002 + 2 * 1 * 10 * (-0.000003) = 0.0114$$
O erro padr√£o √© $\hat{\sigma}_{N_T} = \sqrt{0.0114} = 0.1068$.
A estat√≠stica t √©:
$$t_T = \frac{6.7 - 6.5}{0.1068} \approx 1.87$$

Para entender o papel do redimensionamento, vamos calcular o valor do numerador reescalonado $\sqrt{T}(r_1 \hat{\alpha}_T + r_2 \hat{\delta}_T - r)$ e o denominador reescalonado.
$$\sqrt{T}(r_1 \hat{\alpha}_T + r_2 \hat{\delta}_T - r) = \sqrt{100}*(6.7 - 6.5) = 10 * 0.2 = 2$$
$$\sqrt{T}\hat{\sigma}_{N_T} = \sqrt{100} * 0.1068 = 1.068$$

Note que, ao realizar o teste, o valor da estat√≠stica t ser√° o mesmo, mas com a an√°lise separada do numerador e denominador, podemos entender o comportamento assint√≥tico da estat√≠stica de teste. A estat√≠stica t reescalonada √© dada por
$$t_T = \frac{2}{1.068} \approx 1.87$$

Comparando o valor da estat√≠stica t com a distribui√ß√£o normal padr√£o, podemos concluir sobre a signific√¢ncia da hip√≥tese nula. O valor cr√≠tico para um n√≠vel de signific√¢ncia de 5% em um teste bicaudal √© 1.96. Como 1.87 < 1.96, n√£o rejeitamos a hip√≥tese nula.

> üí° **Exemplo Num√©rico (Teste de Hip√≥tese com Dados Simulados):**
> Vamos simular dados e realizar o teste de hip√≥tese em Python:
> ```python
> import numpy as np
> import statsmodels.api as sm
> from scipy.stats import norm
>
> # Par√¢metros verdadeiros
> alpha_true = 5
> delta_true = 0.2
> T = 100
>
> # Simula√ß√£o de dados
> np.random.seed(42)
> t = np.arange(1, T + 1)
> epsilon = np.random.normal(0, 1, T)
> y = alpha_true + delta_true * t + epsilon
>
> # Regress√£o OLS
> X = np.column_stack((np.ones(T), t))
> model = sm.OLS(y, X)
> results = model.fit()
> alpha_hat = results.params[0]
> delta_hat = results.params[1]
>
> # Restri√ß√µes para o teste
> r1 = 1
> r2 = 10
> r = 7
>
> # Vari√¢ncia da combina√ß√£o linear
> var_alpha = results.cov_params().iloc[0, 0]
> var_delta = results.cov_params().iloc[1, 1]
> cov_alpha_delta = results.cov_params().iloc[0, 1]
> var_comb = r1**2 * var_alpha + r2**2 * var_delta + 2 * r1 * r2 * cov_alpha_delta
>
> # Estat√≠stica t
> t_stat = (r1 * alpha_hat + r2 * delta_hat - r) / np.sqrt(var_comb)
>
> # Valor-p
> p_value = 2 * (1 - norm.cdf(np.abs(t_stat)))
>
> print(f"Estimativa de alpha: {alpha_hat:.4f}")
> print(f"Estimativa de delta: {delta_hat:.4f}")
> print(f"Estat√≠stica t: {t_stat:.4f}")
> print(f"Valor-p: {p_value:.4f}")
>
> # Teste de hip√≥tese
> alpha = 0.05
> if p_value < alpha:
>  print("Rejeitamos a hip√≥tese nula")
> else:
>  print("N√£o rejeitamos a hip√≥tese nula")
> ```
> Neste exemplo, simulamos dados, estimamos os par√¢metros via OLS e testamos a hip√≥tese $H_0: \alpha + 10\delta = 7$. O valor-p indica a probabilidade de observar um resultado t√£o extremo quanto o obtido, sob a hip√≥tese nula. Se o valor-p for menor que o n√≠vel de signific√¢ncia (ex: 0.05), rejeitamos a hip√≥tese nula.

### Conclus√£o
Neste cap√≠tulo, exploramos em detalhes como construir e analisar a distribui√ß√£o assint√≥tica de uma estat√≠stica t generalizada para testar hip√≥teses lineares sobre os par√¢metros de intercepto e tend√™ncia em modelos de s√©ries temporais. A estat√≠stica t generalizada, ao incorporar as diferentes taxas de converg√™ncia dos estimadores, converge para uma distribui√ß√£o normal padr√£o sob a hip√≥tese nula, garantindo a validade das infer√™ncias em modelos com tend√™ncias temporais determin√≠sticas [^7]. Os resultados apresentados confirmam que as ferramentas de infer√™ncia estat√≠stica usuais podem ser adaptadas para o contexto de modelos com tend√™ncias temporais, desde que se leve em considera√ß√£o o reescalonamento e as propriedades assint√≥ticas dos estimadores. Os testes de hip√≥teses, tanto para restri√ß√µes sobre par√¢metros individuais quanto para restri√ß√µes lineares, permitem uma an√°lise mais profunda e confi√°vel de dados de s√©ries temporais com tend√™ncias, o que √© fundamental em an√°lises emp√≠ricas onde os par√¢metros n√£o s√£o independentes.

### Refer√™ncias
[^1]:  ... *Apesar das diferentes taxas de converg√™ncia dos estimadores em modelos com tend√™ncias temporais, os testes t e F de OLS mant√™m sua validade assint√≥tica, um resultado essencial para a infer√™ncia estat√≠stica em s√©ries temporais com tend√™ncias.*
[^2]: ... *Testes de Hip√≥teses para Modelos de Tend√™ncia Temporal Simples: An√°lise Detalhada da Estat√≠stica t*
[^3]:  ... *Esta se√ß√£o considera a estima√ß√£o de OLS dos par√¢metros de uma tend√™ncia de tempo simples, $y_t = \alpha + \delta t + \epsilon_t$, para $\epsilon_t$ um processo de ru√≠do branco.*
[^4]: ...*A fim de chegar a distribui√ß√µes assint√≥ticas n√£o degeneradas, $\hat{\alpha}_T$ √© multiplicado por $\sqrt{T}$, enquanto $\hat{\delta}_T$ deve ser multiplicado por $T^{3/2}$!*
[^5]: ...*√â interessante tamb√©m considerar um teste de uma √∫nica hip√≥tese envolvendo ambos $\alpha$ e $\delta$, $H_0: r_1\alpha + r_2\delta = r$.*
[^6]: ...*Pelo teorema central do limite, $\sqrt{T}(\hat{\alpha}_T - \alpha)$ converge para uma vari√°vel aleat√≥ria normal.*
[^7]: ...*Assim, embora $\hat{\alpha}_T$ e $\hat{\delta}_T$ convirjam a taxas diferentes, os erros padr√£o correspondentes $\hat{\sigma}_{\hat{\alpha}_T}$ e $\hat{\sigma}_{\hat{\delta}_T}$ tamb√©m incorporam diferentes ordens de $T$, com o resultado que os testes t de OLS usuais s√£o assintoticamente v√°lidos.*
<!-- END -->
