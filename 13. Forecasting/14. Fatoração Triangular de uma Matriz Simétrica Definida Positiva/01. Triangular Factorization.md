## Fatora√ß√£o Triangular de uma Matriz Sim√©trica Definida Positiva

### Introdu√ß√£o

Este cap√≠tulo explora a t√©cnica de fatora√ß√£o triangular para matrizes sim√©tricas definidas positivas, um conceito essencial em diversas √°reas da matem√°tica, estat√≠stica e econometria, especialmente no contexto de previs√£o e modelagem de s√©ries temporais. A fatora√ß√£o triangular, tamb√©m conhecida como decomposi√ß√£o LDLT ou Cholesky (quando D tem ra√≠zes quadradas), permite decompor uma matriz em um produto de matrizes mais simples e, portanto, mais facilmente manipul√°veis. Esta decomposi√ß√£o √© particularmente √∫til para resolver sistemas lineares, calcular determinantes e realizar proje√ß√µes lineares, como visto em cap√≠tulos anteriores [^4].

### Conceitos Fundamentais

**Defini√ß√£o:** Uma matriz sim√©trica definida positiva (n x n) $\Omega$ tem uma representa√ß√£o √∫nica da forma [^4.4.1]:

$$ \Omega = ADA' $$

onde:

*   A √© uma matriz triangular inferior com 1s ao longo da diagonal principal.
*   D √© uma matriz diagonal.

Essa representa√ß√£o √© conhecida como **fatora√ß√£o triangular** de $\Omega$.

**Observa√ß√£o:** A matriz A √© tamb√©m conhecida como matriz de transforma√ß√£o ou matriz de coeficientes da proje√ß√£o linear, enquanto a matriz D cont√©m a vari√¢ncia dos res√≠duos. Esta interpreta√ß√£o, como ser√° detalhado adiante, estabelece uma ponte entre a √°lgebra matricial e as proje√ß√µes lineares.

**Constru√ß√£o da Fatora√ß√£o:** Para calcular a fatora√ß√£o triangular, considere uma matriz $\Omega$ [^4.4.2]:

$$ \Omega = \begin{bmatrix}
    \Omega_{11} & \Omega_{12} & \Omega_{13} & \cdots & \Omega_{1n} \\
    \Omega_{21} & \Omega_{22} & \Omega_{23} & \cdots & \Omega_{2n} \\
    \Omega_{31} & \Omega_{32} & \Omega_{33} & \cdots & \Omega_{3n} \\
    \vdots & \vdots & \vdots & \ddots & \vdots \\
    \Omega_{n1} & \Omega_{n2} & \Omega_{n3} & \cdots & \Omega_{nn}
\end{bmatrix} $$

1.  **Transforma√ß√£o da Primeira Coluna:** A matriz $\Omega$ √© transformada em uma matriz com zeros na primeira coluna abaixo da diagonal principal atrav√©s da pr√©-multiplica√ß√£o por $E_1$, onde [^4.4.3]:

$$ E_1 = \begin{bmatrix}
    1 & 0 & 0 & \cdots & 0 \\
    -\Omega_{21}\Omega_{11}^{-1} & 1 & 0 & \cdots & 0 \\
    -\Omega_{31}\Omega_{11}^{-1} & 0 & 1 & \cdots & 0 \\
    \vdots & \vdots & \vdots & \ddots & \vdots \\
    -\Omega_{n1}\Omega_{11}^{-1} & 0 & 0 & \cdots & 1
\end{bmatrix} $$
    Essa matriz $E_1$ sempre existe, desde que $\Omega_{11} \neq 0$, o que √© garantido pela defini√ß√£o de matriz definida positiva [^4].
    A matriz resultante, ap√≥s a pr√©-multiplica√ß√£o por $E_1$ e p√≥s-multiplica√ß√£o por $E_1'$, √© dada por $H = E_1\Omega E_1'$ [^4.4.4].
     $$ H = \begin{bmatrix}
    h_{11} & 0 & 0 & \cdots & 0 \\
    0 & h_{22} & h_{23} & \cdots & h_{2n} \\
    0 & h_{32} & h_{33} & \cdots & h_{3n} \\
    \vdots & \vdots & \vdots & \ddots & \vdots \\
    0 & h_{n2} & h_{n3} & \cdots & h_{nn}
\end{bmatrix} $$
> üí° **Exemplo Num√©rico:**
> Vamos considerar uma matriz sim√©trica definida positiva 3x3:
>
> $$ \Omega = \begin{bmatrix}
>     4 & 2 & 1 \\
>     2 & 5 & 2 \\
>     1 & 2 & 6
> \end{bmatrix} $$
>
> $\text{Passo 1: Calcular } E_1$
>
> $$
> E_1 = \begin{bmatrix}
>     1 & 0 & 0 \\
>     -\frac{2}{4} & 1 & 0 \\
>     -\frac{1}{4} & 0 & 1
> \end{bmatrix} =
> \begin{bmatrix}
>     1 & 0 & 0 \\
>     -0.5 & 1 & 0 \\
>     -0.25 & 0 & 1
> \end{bmatrix}
> $$
>
> $\text{Passo 2: Calcular } E_1'$
> $$
> E_1' = \begin{bmatrix}
>     1 & -0.5 & -0.25 \\
>     0 & 1 & 0 \\
>     0 & 0 & 1
> \end{bmatrix}
> $$
>
> $\text{Passo 3: Calcular } H = E_1 \Omega E_1'$
>
> $$
> H =
> \begin{bmatrix}
>     1 & 0 & 0 \\
>     -0.5 & 1 & 0 \\
>     -0.25 & 0 & 1
> \end{bmatrix}
> \begin{bmatrix}
>     4 & 2 & 1 \\
>     2 & 5 & 2 \\
>     1 & 2 & 6
> \end{bmatrix}
>  \begin{bmatrix}
>     1 & -0.5 & -0.25 \\
>     0 & 1 & 0 \\
>     0 & 0 & 1
> \end{bmatrix}
> $$
> $$
> H =
> \begin{bmatrix}
>     4 & 0 & 0 \\
>     0 & 4 & 1.5 \\
>     0 & 1.5 & 5.75
> \end{bmatrix}
> $$
>
> Observe que a primeira coluna de H agora tem zeros abaixo da diagonal principal.

2. **Transforma√ß√£o das Colunas Subsequentes:** O processo √© repetido para as colunas seguintes. Por exemplo, a segunda coluna de H √© transformada usando a matriz $E_2$ [^4.4.6]:

$$ E_2 = \begin{bmatrix}
    1 & 0 & 0 & \cdots & 0 \\
    0 & 1 & 0 & \cdots & 0 \\
    0 & -h_{32}h_{22}^{-1} & 1 & \cdots & 0 \\
    \vdots & \vdots & \vdots & \ddots & \vdots \\
    0 & -h_{n2}h_{22}^{-1} & 0 & \cdots & 1
\end{bmatrix} $$

   A exist√™ncia de $E_2$ √© garantida, pois $h_{22}$ √© positiva, o que √© uma consequ√™ncia da defini√ß√£o de matriz definida positiva. O resultado desta transforma√ß√£o √© a matriz $K = E_2 H E_2'$ [^4.4.6]. O processo continua at√© que todas as colunas tenham zeros abaixo da diagonal.
> üí° **Exemplo Num√©rico (Continuando):**
>
> $\text{Passo 1: Calcular } E_2 \text{ usando a matriz } H \text{ do exemplo anterior}$
>
> $$
> E_2 = \begin{bmatrix}
>     1 & 0 & 0 \\
>     0 & 1 & 0 \\
>     0 & -\frac{1.5}{4} & 1
> \end{bmatrix} =
> \begin{bmatrix}
>     1 & 0 & 0 \\
>     0 & 1 & 0 \\
>     0 & -0.375 & 1
> \end{bmatrix}
> $$
>
> $\text{Passo 2: Calcular } E_2'$
> $$
> E_2' =
> \begin{bmatrix}
>     1 & 0 & 0 \\
>     0 & 1 & -0.375 \\
>     0 & 0 & 1
> \end{bmatrix}
> $$
>
> $\text{Passo 3: Calcular } K = E_2 H E_2'$
>
> $$
> K =
> \begin{bmatrix}
>     1 & 0 & 0 \\
>     0 & 1 & 0 \\
>     0 & -0.375 & 1
> \end{bmatrix}
> \begin{bmatrix}
>     4 & 0 & 0 \\
>     0 & 4 & 1.5 \\
>     0 & 1.5 & 5.75
> \end{bmatrix}
> \begin{bmatrix}
>     1 & 0 & 0 \\
>     0 & 1 & -0.375 \\
>     0 & 0 & 1
> \end{bmatrix}
> $$
> $$
> K =
> \begin{bmatrix}
>     4 & 0 & 0 \\
>     0 & 4 & 0 \\
>     0 & 0 & 5.1875
> \end{bmatrix}
> $$
>
> Observe que a segunda coluna de K agora tamb√©m tem zeros abaixo da diagonal principal.

3.  **Fatora√ß√£o Completa:** Continuando esse processo, existem matrizes $E_1$, $E_2$,..., $E_{n-1}$ tais que [^4.4.7]:

$$ E_{n-1} \cdots E_2 E_1 \Omega E_1' E_2' \cdots E_{n-1}' = D $$

onde D √© uma matriz diagonal. As matrizes $E_i$ s√£o triangulares inferiores com 1's na diagonal principal. Definindo  $A = (E_{n-1} \cdots E_2 E_1)^{-1}$ [^4.4.8], temos
$$ \Omega = ADA' $$.

> üí° **Exemplo Num√©rico (Conclus√£o):**
>
> $\text{Passo 1: Calcular } A = (E_2 E_1)^{-1} = E_1^{-1}E_2^{-1}$
>
> Primeiro, calculemos as inversas de $E_1$ e $E_2$:
>
> $$
> E_1^{-1} = \begin{bmatrix}
>     1 & 0 & 0 \\
>     0.5 & 1 & 0 \\
>     0.25 & 0 & 1
> \end{bmatrix}
> $$
>
> $$
> E_2^{-1} = \begin{bmatrix}
>     1 & 0 & 0 \\
>     0 & 1 & 0 \\
>     0 & 0.375 & 1
> \end{bmatrix}
> $$
>
>  Agora calculemos $A = E_1^{-1}E_2^{-1}$:
> $$
> A =
> \begin{bmatrix}
>     1 & 0 & 0 \\
>     0.5 & 1 & 0 \\
>     0.25 & 0 & 1
> \end{bmatrix}
> \begin{bmatrix}
>     1 & 0 & 0 \\
>     0 & 1 & 0 \\
>     0 & 0.375 & 1
> \end{bmatrix} =
> \begin{bmatrix}
>     1 & 0 & 0 \\
>     0.5 & 1 & 0 \\
>     0.25 & 0.375 & 1
> \end{bmatrix}
> $$
>
> $\text{Passo 2: Identificar a matriz } D$, que √© a matriz K obtida no passo anterior:
>
> $$
> D =
> \begin{bmatrix}
>     4 & 0 & 0 \\
>     0 & 4 & 0 \\
>     0 & 0 & 5.1875
> \end{bmatrix}
> $$
>
> $\text{Passo 3: Verificar a fatora√ß√£o } \Omega = ADA'$:
>
> $$
> A D A' =
> \begin{bmatrix}
>     1 & 0 & 0 \\
>     0.5 & 1 & 0 \\
>     0.25 & 0.375 & 1
> \end{bmatrix}
> \begin{bmatrix}
>     4 & 0 & 0 \\
>     0 & 4 & 0 \\
>     0 & 0 & 5.1875
> \end{bmatrix}
> \begin{bmatrix}
>     1 & 0.5 & 0.25 \\
>     0 & 1 & 0.375 \\
>     0 & 0 & 1
> \end{bmatrix}
> $$
> $$
> A D A' =
> \begin{bmatrix}
>     4 & 2 & 1 \\
>     2 & 5 & 2 \\
>     1 & 2 & 6
> \end{bmatrix} = \Omega
> $$
>
> Assim, demonstramos a fatora√ß√£o triangular para a matriz $\Omega$.

**Lema 1:** As matrizes $E_i$ s√£o invers√≠veis e suas inversas s√£o tamb√©m triangulares inferiores com 1's na diagonal principal.

**Prova:**
I. As matrizes $E_i$ s√£o da forma identidade mais uma matriz com zeros na diagonal e abaixo dela.
II. O determinante de $E_i$ √© portanto 1, o que garante que s√£o invert√≠veis, pois um determinante diferente de zero implica invertibilidade.
III. A inversa de $E_i$ ter√° a mesma estrutura, ou seja, ser√° triangular inferior com 1's na diagonal, pois a inversa de uma matriz elementar (como as $E_i$) mant√©m sua estrutura.
IV. Assim, as matrizes $E_i$ s√£o invert√≠veis e suas inversas tamb√©m s√£o triangulares inferiores com 1's na diagonal principal. ‚ñ†

**Teorema 1:** A matriz A, definida como $A = (E_{n-1} \cdots E_2 E_1)^{-1}$, √© uma matriz triangular inferior com 1s ao longo da diagonal principal.

**Prova:**
I. Pelo Lema 1, cada $E_i^{-1}$ √© triangular inferior com 1's na diagonal principal.
II. O produto de matrizes triangulares inferiores com 1's na diagonal principal tamb√©m resulta em uma matriz triangular inferior com 1's na diagonal principal.
III. Portanto, $A = E_1^{-1} E_2^{-1} \ldots E_{n-1}^{-1}$ √© triangular inferior com 1's na diagonal principal. ‚ñ†

**Unicidade da Fatora√ß√£o:** A fatora√ß√£o triangular √© √∫nica. Suponha que existem duas fatora√ß√µes: $\Omega = A_1D_1A_1' = A_2D_2A_2'$ [^4.4.14].
Multiplicando pela inversa de $A_1$ e $A_2$ temos:
$A_1A_2^{-1} = D_1A_1'A_2^{-1}D_2^{-1}$.
O lado esquerdo √© triangular inferior e o lado direito √© triangular superior. A √∫nica forma de isso ocorrer √© se ambos os lados forem a identidade, provando que $A_1 = A_2$ e consequentemente, $D_1 = D_2$.

**Prova:**
I. Suponha que existem duas fatora√ß√µes: $\Omega = A_1 D_1 A_1' = A_2 D_2 A_2'$.
II. Multiplique ambos os lados por $A_1^{-1}$ √† esquerda e por $(A_2')^{-1}$ √† direita:
$A_1^{-1} A_1 D_1 A_1' (A_2')^{-1} = A_1^{-1} A_2 D_2 A_2' (A_2')^{-1}$
III. Simplificando, obtemos: $D_1 A_1' (A_2')^{-1} = A_1^{-1} A_2 D_2$.
IV. Multiplicando por $D_1^{-1}$ √† esquerda, temos: $A_1' (A_2')^{-1} = D_1^{-1} A_1^{-1} A_2 D_2$.
V. Rearranjando, obtemos: $A_1 A_2^{-1} = D_1 A_1' (A_2')^{-1} D_2^{-1}$.
VI. O lado esquerdo, $A_1 A_2^{-1}$, √© o produto de matrizes triangulares inferiores com 1s na diagonal principal, e portanto tamb√©m √© triangular inferior com 1s na diagonal principal.
VII. O lado direito, $D_1 A_1' (A_2')^{-1} D_2^{-1}$, √© o produto de uma matriz diagonal ($D_1$ e $D_2^{-1}$) com uma matriz triangular superior ($A_1'$ e $(A_2')^{-1}$), portanto, √© triangular superior.
VIII. Para que uma matriz triangular inferior (lado esquerdo) seja igual a uma matriz triangular superior (lado direito), ambas precisam ser diagonais.
IX. Mas, devido ao fato de $A_1$ e $A_2$ terem 1s na diagonal, $A_1 A_2^{-1}$ deve ser triangular inferior com 1s na diagonal, e consequentemente a √∫nica matriz diagonal poss√≠vel para $A_1 A_2^{-1}$ √© a identidade. Portanto $A_1 A_2^{-1} = I$ ou $A_1 = A_2$.
X. Se $A_1 = A_2$, ent√£o voltando a $\Omega = A_1 D_1 A_1' = A_2 D_2 A_2'$ , temos $A_1 D_1 A_1' = A_1 D_2 A_1'$.
XI. Multiplicando por $A_1^{-1}$ √† esquerda e por $(A_1')^{-1}$ √† direita, obtemos $D_1 = D_2$.
XII. Portanto, a fatora√ß√£o triangular √© √∫nica. ‚ñ†

**Fatora√ß√£o de Cholesky:** Uma fatora√ß√£o relacionada √© a fatora√ß√£o de Cholesky, que decomp√µe a matriz $\Omega$ em  $\Omega = PP'$, onde P √© uma matriz triangular inferior. P √© obtida pela multiplica√ß√£o de A por uma matriz com a raiz quadrada dos elementos diagonais de D [^4.4.16]. Essa abordagem √© especialmente √∫til quando o foco √© a raiz quadrada da matriz, como na gera√ß√£o de n√∫meros aleat√≥rios com uma dada matriz de covari√¢ncia.

**Corol√°rio 1:** Se $\Omega$ √© uma matriz sim√©trica definida positiva, ent√£o existe uma matriz triangular inferior P tal que $\Omega=PP'$.
**Prova:**
I. A fatora√ß√£o $\Omega = ADA'$ existe e √© √∫nica, como demonstrado acima.
II. Seja $D^{1/2}$ a matriz diagonal com os elementos diagonais sendo a raiz quadrada dos elementos de D, ou seja, $D^{1/2} = diag(\sqrt{d_{11}},\sqrt{d_{22}}, \ldots ,\sqrt{d_{nn}})$, com $D = diag(d_{11}, d_{22}, \ldots, d_{nn})$.
III. Defina $P=AD^{1/2}$.
IV. Ent√£o, $PP' = (AD^{1/2})(AD^{1/2})' = AD^{1/2}(D^{1/2})'A' = AD^{1/2}D^{1/2}A' = ADA'=\Omega$.
V. Portanto, se $\Omega$ √© uma matriz sim√©trica definida positiva, ent√£o existe uma matriz triangular inferior P tal que $\Omega=PP'$. ‚ñ†
> üí° **Exemplo Num√©rico (Fatora√ß√£o de Cholesky):**
>
> Continuando com a matriz $\Omega$ do exemplo anterior e as matrizes A e D obtidas:
>
> $$
> A =
> \begin{bmatrix}
>     1 & 0 & 0 \\
>     0.5 & 1 & 0 \\
>     0.25 & 0.375 & 1
> \end{bmatrix}
> $$
>
> $$
> D =
> \begin{bmatrix}
>     4 & 0 & 0 \\
>     0 & 4 & 0 \\
>     0 & 0 & 5.1875
> \end{bmatrix}
> $$
>
> 1.  Calcular $D^{1/2}$:
> $$
> D^{1/2} =
> \begin{bmatrix}
>     2 & 0 & 0 \\
>     0 & 2 & 0 \\
>     0 & 0 & \sqrt{5.1875}
> \end{bmatrix} \approx
> \begin{bmatrix}
>     2 & 0 & 0 \\
>     0 & 2 & 0 \\
>     0 & 0 & 2.2776
> \end{bmatrix}
> $$
>
> 2. Calcular $P = A D^{1/2}$:
> $$
> P =
> \begin{bmatrix}
>     1 & 0 & 0 \\
>     0.5 & 1 & 0 \\
>     0.25 & 0.375 & 1
> \end{bmatrix}
> \begin{bmatrix}
>     2 & 0 & 0 \\
>     0 & 2 & 0 \\
>     0 & 0 & 2.2776
> \end{bmatrix} =
> \begin{bmatrix}
>     2 & 0 & 0 \\
>     1 & 2 & 0 \\
>     0.5 & 0.75 & 2.2776
> \end{bmatrix}
> $$
>
> 3. Verificar $PP' = \Omega$:
> $$
> PP' =
> \begin{bmatrix}
>     2 & 0 & 0 \\
>     1 & 2 & 0 \\
>     0.5 & 0.75 & 2.2776
> \end{bmatrix}
> \begin{bmatrix}
>     2 & 1 & 0.5 \\
>     0 & 2 & 0.75 \\
>     0 & 0 & 2.2776
> \end{bmatrix}
>  =
> \begin{bmatrix}
>     4 & 2 & 1 \\
>     2 & 5 & 2 \\
>     1 & 2 & 6
> \end{bmatrix} = \Omega
> $$
>
> Assim, demonstramos a fatora√ß√£o de Cholesky para a matriz $\Omega$.

### Aplica√ß√µes e Conex√µes

A fatora√ß√£o triangular desempenha um papel crucial em diversas √°reas:

1.  **Proje√ß√£o Linear:** Conforme discutido em se√ß√µes anteriores, os elementos da matriz A na fatora√ß√£o triangular s√£o diretamente ligados aos coeficientes de proje√ß√µes lineares [^4.5.9, 4.5.11]. Isso permite uma conex√£o clara entre a decomposi√ß√£o de uma matriz de covari√¢ncia e as proje√ß√µes lineares que usamos na previs√£o de s√©ries temporais, como na atualiza√ß√£o de previs√µes (4.5.14, 4.5.16).
    > üí° **Exemplo Num√©rico (Proje√ß√£o Linear):**
    >
    > Suponha que temos um vetor de vari√°veis Y = [Y‚ÇÅ, Y‚ÇÇ, Y‚ÇÉ], com a matriz de covari√¢ncia $\Omega$ dada como no exemplo anterior. A fatora√ß√£o triangular nos fornece a matriz A:
    >
    > $$
    > A =
    > \begin{bmatrix}
    >     1 & 0 & 0 \\
    >     0.5 & 1 & 0 \\
    >     0.25 & 0.375 & 1
    > \end{bmatrix}
    > $$
    >
    > A proje√ß√£o de Y‚ÇÇ em Y‚ÇÅ √© dada por  $P(Y_2|Y_1) = \frac{\Omega_{21}}{\Omega_{11}}Y_1 = 0.5Y_1$. Este coeficiente corresponde ao elemento (2,1) da matriz A. De maneira semelhante, $P(Y_3|Y_1,Y_2) = 0.25Y_1 + 0.375(Y_2-0.5Y_1)$. Os coeficientes s√£o tirados da matriz A. O termo $(Y_2-0.5Y_1)$ √© a proje√ß√£o do res√≠duo de Y‚ÇÇ ao projetar em Y‚ÇÅ.
    > Os coeficientes da matriz A permitem realizar proje√ß√µes lineares de forma eficiente e est√£o ligados √† estrutura de depend√™ncia das vari√°veis.
2.  **C√°lculo de MSE:** Os elementos diagonais da matriz D representam os erros quadr√°ticos m√©dios (MSE) associados √†s proje√ß√µes lineares. Isso fornece um m√©todo para quantificar a precis√£o de uma previs√£o sequencial (4.5.5).
     > üí° **Exemplo Num√©rico (MSE):**
    >
    >  Usando a matriz D do exemplo anterior:
    >
    > $$
    > D =
    > \begin{bmatrix}
    >     4 & 0 & 0 \\
    >     0 & 4 & 0 \\
    >     0 & 0 & 5.1875
    > \end{bmatrix}
    > $$
    >
    > O MSE da proje√ß√£o de Y‚ÇÅ √© $d_{11} = 4$. O MSE da proje√ß√£o de Y‚ÇÇ dado Y‚ÇÅ √© $d_{22} = 4$, o que indica a vari√¢ncia do res√≠duo quando Y‚ÇÇ √© projetado em Y‚ÇÅ. O MSE da proje√ß√£o de Y‚ÇÉ dado Y‚ÇÅ e Y‚ÇÇ √© $d_{33} = 5.1875$, representando a vari√¢ncia do res√≠duo de Y‚ÇÉ ap√≥s projetar em Y‚ÇÅ e Y‚ÇÇ. Estes valores, encontrados na diagonal da matriz D, fornecem uma medida direta da precis√£o de cada proje√ß√£o sequencial.
3.  **Solu√ß√£o de Sistemas Lineares:** A fatora√ß√£o triangular pode simplificar a solu√ß√£o de sistemas de equa√ß√µes lineares, pois matrizes triangulares s√£o mais f√°ceis de inverter.
4.  **Econometria Estrutural:** O processo de decomposi√ß√£o tamb√©m pode ser visto como uma forma de remover componentes correlacionados, tornando os res√≠duos n√£o correlacionados. Isso pode ser √∫til para estudos de econometria estrutural.

### Conclus√£o

A fatora√ß√£o triangular √© uma ferramenta matem√°tica poderosa que permite decompor matrizes sim√©tricas definidas positivas em produtos de matrizes mais simples, facilitando c√°lculos e an√°lises. Este cap√≠tulo detalhou o processo de fatora√ß√£o, provou sua unicidade, introduziu a fatora√ß√£o de Cholesky e discutiu suas conex√µes com proje√ß√µes lineares, MSE e previs√£o de s√©ries temporais. Este conhecimento √© fundamental para o desenvolvimento de modelos econom√©tricos e previs√µes de s√©ries temporais, permitindo um entendimento mais profundo dos dados e das rela√ß√µes entre as vari√°veis. Os resultados aqui apresentados e as conex√µes com cap√≠tulos anteriores demonstram a import√¢ncia desta ferramenta em m√©todos de previs√£o mais avan√ßados.

### Refer√™ncias
[^4]: Informa√ß√µes extra√≠das do contexto fornecido.
[^4.4.1]:  *Any positive definite symmetric (n √ó n) matrix $\Omega$ has a unique representation of the form $\Omega = ADA'$*.
[^4.4.2]: *To see how the triangular factorization can be calculated, consider...*
[^4.4.3]: *The matrix $\Omega$ can be transformed into a matrix with zero in the (2, 1) position by multiplying the first row of $\Omega$ by $\Omega_{21}\Omega_{11}^{-1}$ and subtracting the resulting row from the second.*
[^4.4.4]:  *When $\Omega$ is premultiplied by $E_1$ and postmultiplied by $E_1'$, the result is $E_1\Omega E_1' = H$.*
[^4.4.6]: *These operations can be represented as premultiplying H by the following matrix: ... This matrix always exists provided that $h_{22} \neq 0$.*
[^4.4.7]:  *Proceeding through each of the columns with the same approach, we see that for any positive definite symmetric matrix $\Omega$ there exist matrices $E_1$, $E_2$,..., $E_{M-1}$ such that ...*
[^4.4.8]:  *Thus each $E_j$ is lower triangular with unit determinant. Hence $E_j^{-1}$ exists, and the following matrix exists: $A = (E_{n-1}...E_2E_1)^{-1} = E_{n-1}^{-1} ... E_2^{-1} E_1^{-1}$*
[^4.4.14]: *We next establish that the triangular factorization is unique. Suppose that $\Omega = A_1D_1A_1' = A_2D_2A_2'$.*
[^4.4.16]: *Expression [4.4.16] is known as the Cholesky factorization of $\Omega$.*
[^4.5.9]: *or, using [4.5.8], $Y_2 = Y_2 ‚Äì \Omega_{21}\Omega_{11}^{-1}Y_1 = Y_2 ‚Äì \alpha Y_1$*
[^4.5.11]: *Substituting in from [4.5.8] and [4.5.9] and rearranging, $Y_3 = Y_3 ‚Äì \Omega_{31}\Omega_{11}^{-1}Y_1 ‚Äì h_{32}h_{22}^{-1}(Y_2 ‚Äì \Omega_{21}\Omega_{11}^{-1}Y_1)$.*
[^4.5.14]:  *$P(Y_3|Y_1) = \Omega_{31}\Omega_{11}^{-1}Y_1...$*
[^4.5.16]:  *$P(Y_3|Y_2,Y_1) = P(Y_3|Y_1) + \{E[Y_3 - P(Y_3|Y_1)][Y_2 - P(Y_2|Y_1)]\} \times \{E[Y_2 - P(Y_2|Y_1)]^2\}^{-1} \times [Y_2 ‚Äì P(Y_2|Y_1)]$*
<!-- END -->
