## A Estrutura e Propriedades das Matrizes A e D na Fatora√ß√£o Triangular
### Introdu√ß√£o
Este cap√≠tulo foca nas propriedades estruturais das matrizes **A** e **D** resultantes da fatora√ß√£o triangular de uma matriz sim√©trica definida positiva ($\Omega$), expressa como $\Omega = ADA'$. Especificamente, detalharemos as caracter√≠sticas da matriz **A**, que √© triangular inferior com 1's na diagonal principal, e da matriz **D**, que √© diagonal com elementos estritamente positivos ao longo de sua diagonal. Este conhecimento √© fundamental para entender a unicidade e aplicabilidade da fatora√ß√£o triangular, conforme discutido em cap√≠tulos anteriores e para aprofundar a nossa compreens√£o sobre como os res√≠duos s√£o gerados e suas vari√¢ncias. [^4]

### Propriedades Estruturais de A
1. **Matriz Triangular Inferior:** A matriz **A**, como j√° mencionado, √© uma matriz *triangular inferior*. Isso significa que todos os elementos acima da diagonal principal s√£o iguais a zero, i.e., $a_{ij} = 0$ para $i < j$. A forma triangular inferior √© uma consequ√™ncia do processo recursivo de transforma√ß√£o da matriz original $\Omega$, em que as matrizes elementares $E_i$ s√£o constru√≠das para zerar os elementos abaixo da diagonal em cada coluna [^4.4.3, 4.4.6, 4.4.7].
2. **Unidade na Diagonal Principal:**  Al√©m de ser triangular inferior, a matriz **A** possui 1's ao longo da diagonal principal.  Isso √© uma caracter√≠stica das matrizes elementares $E_i$, que s√£o constru√≠das para ter essa propriedade, e que se mant√©m pelo produto e invers√£o das matrizes elementares [^4.4.10].
    > üí° **Exemplo Num√©rico (Matriz A):**
    >
    > Reutilizando o exemplo num√©rico dos cap√≠tulos anteriores, a matriz A obtida pela fatora√ß√£o √©:
    >
    > $$
    > A = \begin{bmatrix}
    >     1 & 0 & 0 \\
    >     0.5 & 1 & 0 \\
    >     0.25 & 0.375 & 1
    > \end{bmatrix}
    > $$
    >
    > Observe que esta matriz √© triangular inferior com 1s na diagonal principal.
    >
    > Para ilustrar o conceito de matrizes elementares, consideremos que a matriz $A$ √© o resultado do produto das inversas das matrizes elementares $E_1$ e $E_2$, tal que $A = E_1^{-1} E_2^{-1}$. Se a matriz $\Omega$ original √© 
    >
     $$
    > \Omega = \begin{bmatrix}
    >     4 & 2 & 1 \\
    >     2 & 5 & 2 \\
    >     1 & 2 & 6
    > \end{bmatrix}
    > $$
    >
   > As matrizes elementares e suas inversas podem ser definidas como:
    >
    > $$
    > E_1 = \begin{bmatrix}
    >     1 & 0 & 0 \\
    >     -0.5 & 1 & 0 \\
    >     -0.25 & 0 & 1
    > \end{bmatrix} \quad E_1^{-1} = \begin{bmatrix}
    >     1 & 0 & 0 \\
    >     0.5 & 1 & 0 \\
    >     0.25 & 0 & 1
    > \end{bmatrix}
    > $$
    >
    > $$
     >E_2 = \begin{bmatrix}
    >     1 & 0 & 0 \\
    >     0 & 1 & 0 \\
    >     0 & -0.375 & 1
    > \end{bmatrix} \quad E_2^{-1} = \begin{bmatrix}
    >     1 & 0 & 0 \\
    >     0 & 1 & 0 \\
    >     0 & 0.375 & 1
    > \end{bmatrix}
    > $$
    >
    > Multiplicando $E_1^{-1} E_2^{-1}$, obtemos a matriz $A$ mostrada acima.  A constru√ß√£o de $A$ a partir de $E_i^{-1}$ garante que seja triangular inferior com 1s na diagonal.
3. **Rela√ß√£o com Proje√ß√µes Lineares:** Cada elemento $a_{ij}$ da matriz **A**, com $i > j$, representa o coeficiente da proje√ß√£o linear da i-√©sima vari√°vel sobre a j-√©sima vari√°vel e as anteriores. Em outras palavras, os elementos abaixo da diagonal principal em A correspondem aos coeficientes de regress√£o que expressam o efeito das vari√°veis em uma determinada ordem. Essa caracter√≠stica de A liga a √°lgebra matricial √† interpreta√ß√£o de modelos estat√≠sticos e proje√ß√µes lineares [^4.5.11]. A matriz A pode tamb√©m ser interpretada como a transforma√ß√£o linear que produz os res√≠duos n√£o correlacionados.
    > üí° **Exemplo Num√©rico (Proje√ß√µes Lineares):**
    >
    > Considere um vetor de vari√°veis $Y = [Y_1, Y_2, Y_3]^T$.  A transforma√ß√£o $A^{-1}Y$ gera um novo vetor $e = [e_1, e_2, e_3]^T$ tal que:
    >
    >  $e_1 = Y_1$
    >
    >  $e_2 = Y_2 - 0.5 Y_1$
    >
    >  $e_3 = Y_3 - 0.25 Y_1 - 0.375 Y_2$.
    >
    > Os res√≠duos $e_i$ s√£o os res√≠duos das proje√ß√µes lineares.  $e_2$ √© o res√≠duo da proje√ß√£o de $Y_2$ em $Y_1$ e $e_3$ √© o res√≠duo da proje√ß√£o de $Y_3$ em $Y_1$ e $Y_2$. Os coeficientes 0.5, 0.25 e 0.375 s√£o os elementos da matriz A, que expressam como cada vari√°vel √© projetada sobre as anteriores. Observe que os res√≠duos s√£o n√£o correlacionados, com covari√¢ncia dada pela matriz $D$.
    
    **Proposi√ß√£o 1:** *A matriz A √© triangular inferior e os elementos na i-√©sima coluna representam os coeficientes de proje√ß√£o linear da vari√°vel Y·µ¢ sobre as vari√°veis anteriores, e com o 1 na diagonal principal, e corresponde a transforma√ß√£o linear que transforma as vari√°veis correlacionadas em n√£o correlacionadas (residuos ortogonais)*
    
    *Demonstra√ß√£o:*
  
    I. Como visto em cap√≠tulos anteriores, a aplica√ß√£o das matrizes elementares $E_i$ e suas transpostas sobre uma matriz $\Omega$ resulta em zeros abaixo da diagonal principal em cada coluna.
    
    II. A matriz A √© constru√≠da como o inverso do produto das matrizes $E_i$, ou seja, $A = (E_{n-1} \cdots E_2 E_1)^{-1} = E_1^{-1} E_2^{-1} \cdots E_{n-1}^{-1}$.
    
    III. Os elementos da matriz $E_i^{-1}$ correspondem aos coeficientes que, ao serem aplicados recursivamente, projetam a i-√©sima vari√°vel sobre as vari√°veis anteriores. Especificamente, o elemento $a_{ij}$ corresponde ao coeficiente de proje√ß√£o linear da vari√°vel $Y_i$ sobre a vari√°vel $Y_j$, ap√≥s remover a depend√™ncia de $Y_i$ em rela√ß√£o √†s vari√°veis anteriores a $Y_j$.
    
    IV. O produto de matrizes elementares $E_i^{-1}$ cria um processo em cascata, que gera os res√≠duos por proje√ß√µes lineares, onde os res√≠duos da √∫ltima proje√ß√£o s√£o ortogonais (n√£o correlacionados) √†s vari√°veis de proje√ß√£o.
    
    V. A presen√ßa de 1s na diagonal principal garante que a transforma√ß√£o preserve a pr√≥pria vari√°vel, sem altera√ß√µes, e representa tamb√©m a preserva√ß√£o do res√≠duo da transforma√ß√£o, sendo esse o ponto de partida.
    
    VI. Portanto, a matriz A √© triangular inferior com 1s na diagonal principal, onde os elementos abaixo da diagonal principal representam os coeficientes de proje√ß√£o linear das vari√°veis, e a matriz representa a transforma√ß√£o que produz res√≠duos n√£o correlacionados. $\blacksquare$
    
    **Lema 1.1:** *A inversa de uma matriz triangular inferior com 1s na diagonal tamb√©m √© uma matriz triangular inferior com 1s na diagonal.*

    *Demonstra√ß√£o:*
    I. Seja $A$ uma matriz triangular inferior com 1s na diagonal. Isso implica que $a_{ii} = 1$ para todo $i$, e $a_{ij} = 0$ para $i < j$.
    II. Seja $B = A^{-1}$. Devemos mostrar que $B$ √© tamb√©m triangular inferior com 1s na diagonal. Isso significa que $b_{ii} = 1$ e $b_{ij} = 0$ para $i < j$.
    III. A identidade $AB=I$  implica que o produto $AB$ resulta na matriz identidade.
    IV. Analisando a diagonal, $1 = \sum_{k=1}^n a_{ik}b_{ki}$. Como $a_{ij} = 0$ para $j>i$, essa soma se reduz a $1 = a_{ii}b_{ii}$. Como $a_{ii}=1$, segue que $b_{ii} = 1$.
    V.  Considerando os elementos acima da diagonal, a identidade $AB=I$ implica que $0= \sum_{k=1}^n a_{ik}b_{kj}$ para $i < j$. Expandindo essa soma, temos que $0=a_{i1}b_{1j}+\ldots+a_{ii}b_{ij}$. Dado que $a_{ik} = 0$ para $k>i$, ent√£o $0=\sum_{k=1}^i a_{ik}b_{kj}$ para $i<j$.
    VI.  Assumindo por indu√ß√£o que para toda matriz triangular inferior com 1s na diagonal  $A$, a inversa $B$ tem $b_{ij}=0$ para $i<j$ at√© a linha $n-1$, ent√£o para a linha $n$, teremos $0=a_{n1}b_{1j}+a_{n2}b_{2j}+\ldots+a_{nn}b_{nj}$, o que implica que $b_{nj} = 0$. Isso ocorre porque $a_{nn}=1$, e $a_{nk}=0$ para $k>n$. Se $j>n$, ent√£o $b_{nj}=0$, e como $a_{nk} = 0$ para $k>n$, ent√£o $0= \sum_{k=1}^n a_{ik}b_{kj} = \sum_{k=1}^i a_{ik}b_{kj}$. Assim, para $i<j$, todos os $b_{ij} = 0$. Portanto, a inversa de uma matriz triangular inferior com 1s na diagonal tamb√©m √© uma matriz triangular inferior com 1s na diagonal. $\blacksquare$

### Propriedades Estruturais de D

1. **Matriz Diagonal:** A matriz **D** √© uma matriz *diagonal*, o que significa que todos os elementos fora da diagonal principal s√£o iguais a zero, i.e., $d_{ij} = 0$ para $i \neq j$. Isso resulta do processo de fatora√ß√£o, em que as opera√ß√µes de linha e coluna s√£o aplicadas at√© que a matriz resultante se torne diagonal [^4.4.7].
2.  **Elementos Positivos na Diagonal:** Os elementos na diagonal principal da matriz **D**, denotados por $d_{ii}$, s√£o *estritamente positivos*. Esta propriedade √© uma consequ√™ncia direta do fato de que $\Omega$ √© uma matriz definida positiva, ou seja, $x'\Omega x > 0$ para todo vetor $x \neq 0$. Durante o processo de fatora√ß√£o, cada elemento $d_{ii}$ √© um res√≠duo ao projetar sucessivamente uma vari√°vel nas anteriores. Em particular, o elemento $d_{ii}$ √© a vari√¢ncia do res√≠duo resultante da proje√ß√£o da vari√°vel Y·µ¢ sobre as vari√°veis anteriores.
    > üí° **Exemplo Num√©rico (Matriz D):**
    >
    > Utilizando novamente o exemplo num√©rico:
    >
    > $$
    > D = \begin{bmatrix}
    >     4 & 0 & 0 \\
    >     0 & 4 & 0 \\
    >     0 & 0 & 5.1875
    > \end{bmatrix}
    > $$
    >
    > Observe que esta matriz √© diagonal e tem elementos estritamente positivos na diagonal.
    >
    >  Para ilustrar a constru√ß√£o da matriz $D$, o produto $E_{2}E_{1}\Omega E_{1}'E_{2}'$  ir√° resultar na matriz diagonal $D$, onde as matrizes $E_i$ s√£o definidas anteriormente.
3. **MSE de Proje√ß√µes Lineares:** Os elementos diagonais da matriz D correspondem aos *erros quadr√°ticos m√©dios (MSE)* das proje√ß√µes lineares. O elemento $d_{ii}$ representa o MSE associado √† proje√ß√£o da vari√°vel $Y_i$ sobre as vari√°veis anteriores (Y‚ÇÅ at√© $Y_{i-1}$). Isto estabelece uma liga√ß√£o direta entre a fatora√ß√£o triangular e as proje√ß√µes lineares utilizadas na previs√£o de s√©ries temporais, como visto em cap√≠tulos anteriores [^4.5.5, 4.5.13].
    > üí° **Exemplo Num√©rico (MSE):**
    >
    >  Considerando o exemplo anterior, $d_{11} = 4$ √© o MSE da proje√ß√£o de $Y_1$ sobre si mesmo (que √© 0, pois n√£o h√° proje√ß√£o), $d_{22}=4$ √© o MSE da proje√ß√£o de $Y_2$ sobre $Y_1$, e $d_{33}=5.1875$ √© o MSE da proje√ß√£o de $Y_3$ sobre $Y_1$ e $Y_2$.
    >
    > O c√°lculo do MSE da proje√ß√£o de $Y_2$ sobre $Y_1$ seria dado por:
    >
    > $MSE(Y_2|Y_1) = Var(Y_2 - \frac{Cov(Y_1,Y_2)}{Var(Y_1)}Y_1)$.
    >
    >  Com os dados da matriz $\Omega$, temos  $Var(Y_1)=4$, $Cov(Y_1,Y_2) = 2$. O coeficiente de proje√ß√£o de $Y_2$ sobre $Y_1$ √© $\frac{2}{4}=0.5$. Assim, $MSE(Y_2|Y_1) = Var(Y_2-0.5Y_1) = Var(Y_2) + 0.25Var(Y_1) - 2*0.5Cov(Y_1,Y_2) = 5 + 0.25*4 - 2*0.5*2 = 5+1-2=4$.
    >
    > O c√°lculo do MSE da proje√ß√£o de $Y_3$ sobre $Y_1$ e $Y_2$ √© mais complexo, mas o resultado final √© o elemento $d_{33}=5.1875$. O processo de fatora√ß√£o calcula esses valores de forma recursiva, utilizando a informa√ß√£o de $\Omega$.

    
    **Proposi√ß√£o 2:** *Os elementos na diagonal principal da matriz D, denotados por $d_{ii}$, correspondem aos erros quadr√°ticos m√©dios (MSE) das proje√ß√µes lineares.*
    
    *Demonstra√ß√£o:*
    
    I. No processo de fatora√ß√£o, cada matriz $E_i$ corresponde a uma opera√ß√£o de proje√ß√£o, que retira a depend√™ncia linear da vari√°vel na i-√©sima coluna em rela√ß√£o √†s vari√°veis anteriores.
    
    II. O elemento $d_{ii}$ na diagonal de D corresponde ao res√≠duo ap√≥s essas opera√ß√µes, o que significa que a transforma√ß√£o de $\Omega$ em $D$  est√° em um espa√ßo onde as vari√°veis n√£o t√™m correla√ß√£o.
  
    III. Este res√≠duo, $y_i$, tem a interpreta√ß√£o de diferen√ßa entre a vari√°vel observada e sua proje√ß√£o linear, $y_i - P(y_i|y_1,\ldots,y_{i-1})$.
    
    IV. O valor $d_{ii}$ corresponde ao valor de $E(y_i^2)$, que √© a vari√¢ncia desse res√≠duo, ou seja, o erro quadr√°tico m√©dio da proje√ß√£o linear da vari√°vel $Y_i$ nas anteriores.
    
    V. Portanto, $d_{ii}$ representa o MSE da proje√ß√£o linear da vari√°vel $Y_i$ sobre as vari√°veis anteriores. $\blacksquare$
    
    **Lema 2.1:** *A matriz D √© a matriz de covari√¢ncia dos res√≠duos gerados pela transforma√ß√£o linear A aplicada √†s vari√°veis originais.*
    
    *Demonstra√ß√£o:*
    
    I.  Seja $Y$ um vetor de vari√°veis originais, e $e$ o vetor de res√≠duos obtido por $e = A^{-1}Y$, que implica em $Y = Ae$
    
    II. A matriz de covari√¢ncia das vari√°veis originais √© $\Omega = E[YY']$.
    
    III. Substituindo $Y$ por $Ae$, temos $\Omega = E[(Ae)(Ae)'] = E[Aee'A'] = AE[ee']A'$.
    
    IV.  A fatora√ß√£o triangular estabelece que $\Omega = ADA'$. Comparando essa express√£o com a equa√ß√£o anterior, vemos que $D = E[ee']$, e portanto, a matriz D √© a matriz de covari√¢ncia dos res√≠duos. Dado que $D$ √© diagonal, os res√≠duos s√£o n√£o correlacionados. $\blacksquare$
     
 ### Exist√™ncia das Matrizes A e D
 
 A exist√™ncia das matrizes A e D, com as propriedades descritas, √© garantida pelo processo recursivo de fatora√ß√£o.  O processo recursivo que resulta na fatora√ß√£o $ADA'$ garante que, a cada etapa, a matriz intermedi√°ria mant√©m a propriedade de ser sim√©trica definida positiva, assegurando que os elementos da diagonal da matriz D sejam estritamente positivos. Em outras palavras, a aplica√ß√£o sucessiva das matrizes $E_i$ e $E_i'$ preserva as propriedades que garantem a validade da fatora√ß√£o, sem gerar indetermina√ß√µes.
    
   **Teorema 1:** *O processo de fatora√ß√£o triangular garante a exist√™ncia de matrizes A triangular inferior com 1s na diagonal principal, e D diagonal com entradas estritamente positivas que satisfazem $\Omega=ADA'$.*

   *Demonstra√ß√£o:*

   I. A matriz $\Omega$ √© sim√©trica definida positiva.

   II. A constru√ß√£o recursiva da fatora√ß√£o triangular se inicia com a pre-multiplica√ß√£o de $\Omega$ por $E_1$, e a pos-multiplica√ß√£o por $E_1'$, resultando em uma matriz $H = E_1 \Omega E_1'$.

   III. Cada matriz $E_i$ √© constru√≠da para zerar os elementos abaixo da diagonal principal da i-√©sima coluna da matriz intermedi√°ria.

   IV. A matriz resultante $H$ √© sim√©trica e definida positiva pois foi obtida atrav√©s de transforma√ß√£o de matriz sim√©trica definida positiva, preservando as propriedades da matriz original.

   V. Cada $E_i$ possui elementos abaixo da diagonal calculados com base nos elementos da matriz intermedi√°ria, e o elemento diagonal  $h_{ii}$ tamb√©m √© garantidamente positivo por ser obtido por $h_{ii} = e_iHe_i'$, onde $e_i$ √© o vetor com 1 na posi√ß√£o i e zero nas demais,  $h_{ii} = e_iE_1\Omega E_1'e_i'$, e dado que a matriz $\Omega$ √© definida positiva, $e_iE_1\Omega E_1'e_i'$ √© necessariamente positivo.

   VI. O processo recursivo continua at√© que a matriz seja diagonal, resultando em $D =  E_{n-1} \cdots E_2 E_1 \Omega E_1' E_2' \cdots E_{n-1}'$.

   VII. Como todas as transforma√ß√µes preservam a propriedade de matriz definida positiva, e $D = E \Omega E'$, para $E = E_{n-1} \cdots E_2 E_1$, ent√£o $D$ √© tamb√©m definida positiva e, portanto, os elementos diagonais de $D$ s√£o estritamente positivos.

   VIII. A matriz A √© definida como $A = E^{-1}$. Dado que as matrizes $E_i$ s√£o triangulares inferiores com 1s na diagonal, o produto $A = E_1^{-1} \cdots E_{n-1}^{-1}$ tamb√©m ser√° uma matriz triangular inferior com 1s na diagonal.

   IX. Portanto, a fatora√ß√£o triangular garante a exist√™ncia de uma matriz $A$ triangular inferior com 1s na diagonal principal e uma matriz $D$ diagonal com elementos estritamente positivos, tal que $\Omega = ADA'$. $\blacksquare$

    **Teorema 1.1:** *A fatora√ß√£o triangular de uma matriz sim√©trica definida positiva √© √∫nica.*
    
    *Demonstra√ß√£o:*
    
    I. Suponha que existam duas fatora√ß√µes da matriz $\Omega$, tal que $\Omega = ADA' = A_1D_1A_1'$, onde $A$ e $A_1$ s√£o triangulares inferiores com 1s na diagonal, e $D$ e $D_1$ s√£o diagonais com elementos estritamente positivos.
    
    II. Multiplicando ambos os lados por $A^{-1}$ e $(A')^{-1}$, obtemos $A^{-1} \Omega (A')^{-1} = A^{-1}ADA'(A')^{-1} = D$. Similarmente, $A_1^{-1} \Omega (A_1')^{-1} = D_1$.
    
    III. Portanto, temos $D = A^{-1} \Omega (A')^{-1}$ e $D_1 = A_1^{-1} \Omega (A_1')^{-1}$. Isso implica que $D = A^{-1} A_1 D_1 A_1' (A')^{-1}$.
    
    IV.  Reorganizando, temos $A_1^{-1} A D = D_1 A_1' (A')^{-1}$.  Seja $M=A_1^{-1} A$, que √© uma matriz triangular inferior com 1s na diagonal, pois √© produto de duas matrizes com essas propriedades (Lema 1.1). Seja tamb√©m $N=(A_1' A'^{-1}) = M'$. Portanto, $MD=D_1N$.
    
    V. Analisando a matriz $MD$, o elemento $(MD)_{ij} = \sum_k m_{ik}d_{kj}$. Dado que $D$ √© diagonal, $(MD)_{ij} = m_{ij}d_{jj}$. Similarmente,  $(D_1N)_{ij} = d_{ii}n_{ij}$. Ent√£o, temos que $m_{ij}d_{jj}=d_{ii}n_{ij}$.
    
    VI. Dado que $m_{ij} = n_{ji}$, temos $m_{ij}d_{jj}=d_{ii}m_{ji}$. Para $i=j$, temos $m_{ii}d_{ii}=d_{ii}m_{ii}$. Como $m_{ii}=1$ isso √© consistente. Para $i \neq j$, temos $m_{ij}d_{jj}=d_{ii}m_{ji}$. Como $M$ √© uma matriz triangular inferior, $m_{ij}=0$ para $i<j$. Logo $m_{ij}d_{jj}=0$. Dado que $d_{jj}$ √© estritamente positiva, ent√£o $m_{ij} =0$ para $i<j$. Como $M$ √© triangular inferior, temos $m_{ij}=0$ para $i \neq j$. Como os elementos diagonais s√£o iguais a 1, temos que $M$ √© a matriz identidade, o que implica que $A=A_1$.
    
   VII. Voltando √† express√£o $\Omega = ADA' = A_1D_1A_1'$, como $A=A_1$, temos $ADA' = AD_1A'$. Multiplicando por $A^{-1}$ a esquerda e $(A')^{-1}$ a direita, temos que $D=D_1$.
   
   VIII. Portanto, $A=A_1$ e $D=D_1$, e a fatora√ß√£o triangular √© √∫nica. $\blacksquare$
### Conclus√£o

Este cap√≠tulo explorou detalhadamente as propriedades estruturais das matrizes **A** e **D** na fatora√ß√£o triangular de uma matriz sim√©trica definida positiva ($\Omega$).  A matriz **A** √© triangular inferior com 1's na diagonal principal, onde os elementos abaixo da diagonal representam os coeficientes das proje√ß√µes lineares que transformam as vari√°veis em res√≠duos n√£o correlacionados. A matriz **D** √© diagonal com elementos estritamente positivos, representando os erros quadr√°ticos m√©dios associados a essas proje√ß√µes. O processo recursivo de fatora√ß√£o garante a exist√™ncia e a unicidade dessas matrizes,  consolidando a fundamenta√ß√£o te√≥rica da fatora√ß√£o triangular como ferramenta essencial em estat√≠stica, matem√°tica e √°reas relacionadas. O conhecimento sobre a estrutura e propriedades das matrizes A e D permite interpretar o significado da fatora√ß√£o triangular e utiliz√°-la de forma eficaz em aplica√ß√µes pr√°ticas, especialmente nas √°reas de proje√ß√£o linear, previs√£o de s√©ries temporais e modelagem de dados.

### Refer√™ncias
[^4]: Informa√ß√µes extra√≠das do contexto fornecido.
[^4.4.1]:  *Any positive definite symmetric (n √ó n) matrix $\Omega$ has a unique representation of the form $\Omega = ADA'$*.
[^4.4.3]: *The matrix $\Omega$ can be transformed into a matrix with zero in the (2, 1) position by multiplying the first row of $\Omega$ by $\Omega_{21}\Omega_{11}^{-1}$ and subtracting the resulting row from the second.*
[^4.4.6]: *These operations can be represented as premultiplying H by the following matrix: ... This matrix always exists provided that $h_{22} \neq 0$.*
[^4.4.7]:  *Proceeding through each of the columns with the same approach, we see that for any positive definite symmetric matrix $\Omega$ there exist matrices $E_1$, $E_2$,..., $E_{M-1}$ such that ...*
[^4.4.10]: *Thus $E_i^{-1} = ...$*
[^4.5.5]: *From [4.5.5], the MSE from a linear projection of $Y_3$ on $Y_1$ and $Y_2$ can be calculated from $E(Y_3^2) = d_{33} = h_{33} - h_{32}^2 h_{22}^{-1}$*
[^4.5.11]: *Substituting in from [4.5.8] and [4.5.9] and rearranging, $Y_3 = Y_3 ‚Äì \Omega_{31}\Omega_{11}^{-1}Y_1 ‚Äì h_{32}h_{22}^{-1}(Y_2 ‚Äì \Omega_{21}\Omega_{11}^{-1}Y_1)$.*
[^4.5.13]: *The MSE of the linear projection is the variance of $Y_3$, which from [4.5.5] is given by $d_{33}$: $E[Y_3 - P(Y_3|Y_2,Y_1)]^2 = h_{33} - h_{32}^2 h_{22}^{-1}$*
<!-- END -->
