## O Erro Quadr√°tico M√©dio (MSE) da Previs√£o no Processo AR(1): An√°lise e Implica√ß√µes Computacionais

### Introdu√ß√£o
Continuando nossa explora√ß√£o do modelo **Autorregressivo de ordem 1 (AR(1))** [^1], suas propriedades de previs√£o [^2], e considera√ß√µes computacionais [^3] e [^4], este cap√≠tulo se dedica √† an√°lise detalhada do **Erro Quadr√°tico M√©dio (MSE)** da previs√£o no AR(1). O MSE √© uma m√©trica fundamental para avaliar a qualidade das previs√µes, medindo o erro m√©dio ao quadrado entre os valores previstos e os valores reais. Exploraremos como o MSE se comporta em fun√ß√£o do horizonte de previs√£o no AR(1), o que destaca as limita√ß√µes na previsibilidade no longo prazo, e como a formula√ß√£o do MSE permite uma r√°pida computa√ß√£o e an√°lise, refor√ßando as caracter√≠sticas de efici√™ncia computacional do AR(1).

### O Comportamento do MSE em Fun√ß√£o do Horizonte de Previs√£o
O modelo AR(1), definido pela equa√ß√£o [4.2.14]:
$$ (1 - \phi L)(Y_t - \mu) = \epsilon_t, $$
onde $Y_t$ √© a vari√°vel no tempo *t*, $\mu$ √© a m√©dia do processo, $\phi$ √© o **coeficiente autoregressivo**, $L$ √© o operador de defasagem, e $\epsilon_t$ √© o ru√≠do branco, possui uma previs√£o √≥tima dada por [4.2.19]:
$$ \hat{Y}_{t+s|t} = \mu + \phi^s(Y_t - \mu), $$
onde $\hat{Y}_{t+s|t}$ √© a previs√£o de $Y_{t+s}$ no tempo *t*. O Erro Quadr√°tico M√©dio (MSE) associado a essa previs√£o para um horizonte *s* √© dado por [4.2.6] e o *Lema 1* [^2]:
$$ E[(Y_{t+s} - \hat{Y}_{t+s|t})^2] = \sigma^2 \frac{1 - \phi^{2s}}{1 - \phi^2} $$
Onde $\sigma^2$ √© a vari√¢ncia do ru√≠do branco $\epsilon_t$. O MSE quantifica o erro m√©dio ao quadrado da previs√£o para o horizonte *s*.

O comportamento do MSE como fun√ß√£o de *s* √© crucial para entender a previsibilidade do modelo. Em particular, observamos que:
1. **MSE no curto prazo:** Quando *s = 1*, o MSE √© dado por $E[(Y_{t+1} - \hat{Y}_{t+1|t})^2] = \sigma^2$, que √© a vari√¢ncia do ru√≠do branco. Isto significa que, para previs√µes de um per√≠odo √† frente, o erro m√©dio ao quadrado √© igual √† vari√¢ncia do ru√≠do do processo.
2. **MSE no longo prazo:** Quando o horizonte de previs√£o *s* cresce, o termo $\phi^{2s}$ tende a zero (j√° que $|\phi| < 1$ para estacionariedade). Nesse caso, o MSE converge para um limite:
    $$ \lim_{s \to \infty} E[(Y_{t+s} - \hat{Y}_{t+s|t})^2] = \frac{\sigma^2}{1 - \phi^2}, $$
    que representa a vari√¢ncia incondicional do processo AR(1). Este resultado significa que, para horizontes de longo prazo, o erro de previs√£o se estabiliza na vari√¢ncia incondicional do processo, destacando que a informa√ß√£o do passado perde o valor preditivo.

> üí° **Exemplo Num√©rico:** Considere um processo AR(1) onde $\phi = 0.8$ e $\sigma^2 = 4$. Vamos calcular o MSE para diferentes horizontes de previs√£o *s*.
>
> - Para $s=1$:
> $$ MSE(1) = 4 \cdot \frac{1-0.8^{2}}{1-0.8^{2}} = 4 $$
> Isto significa que, para previs√µes de um passo √† frente, o erro m√©dio ao quadrado √© igual √† vari√¢ncia do ru√≠do branco, ou seja, 4.
>
> - Para $s=2$:
> $$ MSE(2) = 4 \cdot \frac{1-0.8^{4}}{1-0.8^{2}} = 4 \cdot \frac{1-0.4096}{1-0.64} = 4 \cdot \frac{0.5904}{0.36} \approx 6.56$$
> O MSE aumenta para 6.56 para uma previs√£o de dois passos √† frente, indicando maior incerteza em compara√ß√£o com uma previs√£o de um passo.
>
> - Para $s=5$:
> $$ MSE(5) = 4 \cdot \frac{1-0.8^{10}}{1-0.8^{2}} = 4 \cdot \frac{1-0.1074}{0.36} \approx 10.02 $$
> O MSE continua a crescer, atingindo 10.02 quando o horizonte de previs√£o √© 5.
>
> - Para $s \rightarrow \infty$:
>  $$ MSE(\infty) =  \frac{4}{1 - 0.8^2} = \frac{4}{1 - 0.64} = \frac{4}{0.36} \approx 11.11 $$
> O MSE converge para a vari√¢ncia incondicional do processo AR(1), aproximadamente 11.11, mostrando que a precis√£o da previs√£o se estabiliza no longo prazo, atingindo um limite. Isso indica que, em horizontes de previs√£o muito longos, a previs√£o se aproxima da m√©dia do processo com uma incerteza constante.

> üí° **Exemplo Num√©rico:** Agora, considere um outro processo AR(1) onde $\phi = -0.5$ e $\sigma^2 = 1$. Vamos calcular o MSE para diferentes horizontes de previs√£o *s*.
>
> - Para $s=1$:
> $$ MSE(1) = 1 \cdot \frac{1-(-0.5)^{2}}{1-(-0.5)^{2}} = 1 $$
>
> - Para $s=2$:
> $$ MSE(2) = 1 \cdot \frac{1-(-0.5)^{4}}{1-(-0.5)^{2}} = 1 \cdot \frac{1-0.0625}{1-0.25} = \frac{0.9375}{0.75} = 1.25 $$
>
> - Para $s=3$:
> $$ MSE(3) = 1 \cdot \frac{1-(-0.5)^{6}}{1-(-0.5)^{2}} = 1 \cdot \frac{1-0.015625}{0.75} = \frac{0.984375}{0.75} \approx 1.3125 $$
>
> - Para $s \rightarrow \infty$:
>  $$ MSE(\infty) =  \frac{1}{1 - (-0.5)^2} = \frac{1}{1 - 0.25} = \frac{1}{0.75} \approx 1.333 $$
>
> Nesse caso, mesmo com um $\phi$ negativo, o MSE ainda aumenta com *s*, por√©m, a converg√™ncia para a vari√¢ncia incondicional √© mais r√°pida.

A natureza do crescimento do MSE com o horizonte de previs√£o ilustra um compromisso fundamental na modelagem de s√©ries temporais: quanto maior o horizonte de previs√£o, menor √© a precis√£o da previs√£o. Este compromisso surge da natureza inerente da depend√™ncia temporal da s√©rie: informa√ß√µes mais recentes s√£o mais relevantes para prever o futuro do que informa√ß√µes mais antigas. O modelo AR(1) captura a depend√™ncia temporal de primeira ordem (i.e., com apenas um lag), o que torna sua previs√£o eficiente no curto prazo, mas a precis√£o decai √† medida que o horizonte de previs√£o se estende.

**Lema 1.1:** O MSE da previs√£o de um processo AR(1) √© n√£o-negativo para qualquer horizonte de previs√£o *s*.

*Prova:*
I. O MSE para um horizonte *s* √© dado por:
    $MSE(s) = E[(Y_{t+s} - \hat{Y}_{t+s|t})^2] = \sigma^2 \frac{1 - \phi^{2s}}{1 - \phi^2}$
II. Sabemos que a vari√¢ncia do ru√≠do branco $\sigma^2$ √© sempre n√£o-negativa.
III. Para um processo AR(1) estacion√°rio, temos que $|\phi| < 1$, portanto, $0 \leq \phi^2 < 1$ e $0 < (1 - \phi^2) \leq 1$.
IV. Dado que $|\phi| < 1$, temos que $0 \leq \phi^{2s} < 1$, o que implica que $0 \leq 1 - \phi^{2s} \leq 1$.
V. Portanto, todos os termos da express√£o do MSE s√£o n√£o-negativos, o que implica que $MSE(s) \geq 0$.
‚ñ†

**Lema 1.2:** O MSE da previs√£o de um processo AR(1) sempre cresce monotonicamente com o horizonte de previs√£o *s*, e converge para a vari√¢ncia incondicional do processo, $\frac{\sigma^2}{1 - \phi^2}$, quando *s* tende para o infinito.

*Prova:*
I. O MSE para um horizonte *s* √© dado por:
    $MSE(s) = E[(Y_{t+s} - \hat{Y}_{t+s|t})^2] = \sigma^2 \frac{1 - \phi^{2s}}{1 - \phi^2}$
II. Para demonstrar que o MSE cresce monotonicamente com *s*, podemos analisar a diferen√ßa entre $MSE(s+1)$ e $MSE(s)$:
    $MSE(s+1) - MSE(s) = \sigma^2 \frac{1 - \phi^{2(s+1)}}{1 - \phi^2} - \sigma^2 \frac{1 - \phi^{2s}}{1 - \phi^2}$
III. Simplificando, temos:
    $MSE(s+1) - MSE(s) = \frac{\sigma^2}{1 - \phi^2} (\phi^{2s} - \phi^{2s+2}) = \frac{\sigma^2}{1 - \phi^2} \phi^{2s}(1 - \phi^2)$.
IV. Para um processo AR(1) estacion√°rio, temos que $|\phi| < 1$, portanto,  $0 \leq \phi^2 < 1$ e $0 < (1 - \phi^2) \leq 1$.
V. Como todos os termos s√£o n√£o-negativos, $MSE(s+1) - MSE(s) \geq 0$, demonstrando que o MSE √© uma fun√ß√£o n√£o-decrescente de *s*.
VI. J√° vimos [^1] que $\lim_{s \to \infty} E[(Y_{t+s} - \hat{Y}_{t+s|t})^2] = \frac{\sigma^2}{1 - \phi^2}$.
VII. Portanto, o MSE cresce monotonicamente com *s* e converge para a vari√¢ncia incondicional do processo quando *s* tende a infinito.
‚ñ†

### Implica√ß√µes Computacionais da Formula√ß√£o do MSE
A formula√ß√£o do MSE no processo AR(1) oferece uma estrutura que permite sua r√°pida computa√ß√£o e an√°lise. A express√£o
$$ E[(Y_{t+s} - \hat{Y}_{t+s|t})^2] = \sigma^2 \frac{1 - \phi^{2s}}{1 - \phi^2} $$
√© composta de termos que podem ser calculados de forma eficiente. Em particular:
1.  $\sigma^2$ √© um par√¢metro do modelo, que √© estimado a partir dos dados e pode ser armazenado em mem√≥ria.
2.  $\phi$ √© o coeficiente autoregressivo, tamb√©m um par√¢metro do modelo, e tamb√©m armazenado em mem√≥ria.
3.  $s$ √© o horizonte de previs√£o, e como usualmente se est√° interessado em uma s√©rie de previs√µes para um conjunto finito de horizontes, o c√°lculo de $\phi^{2s}$ pode ser pr√©-computado para um conjunto de valores de *s* e armazenado em mem√≥ria.

Em contraste, o c√°lculo do MSE para modelos mais complexos, como os modelos ARMA(p,q), pode ser mais custoso computacionalmente, j√° que envolve somas infinitas ou c√°lculos recursivos mais complexos. A formula√ß√£o do MSE no AR(1) tamb√©m permite que o comportamento do erro de previs√£o em fun√ß√£o do horizonte possa ser facilmente analisado atrav√©s de simula√ß√µes ou por meio da an√°lise direta da equa√ß√£o. A capacidade de rapidamente calcular o MSE permite que os analistas e modeladores avaliem e comparem modelos, e determinem as limita√ß√µes de previsibilidade para cen√°rios e horizontes espec√≠ficos.

> üí° **Exemplo Num√©rico:**  Suponha que em uma aplica√ß√£o, seja necess√°rio calcular o MSE para diferentes horizontes de previs√£o *s* de 1 a 5 para um processo AR(1) com $\phi=0.7$ e $\sigma^2 = 2$. O c√°lculo do MSE pode ser feito previamente, armazenando os valores de $\phi^{2s}$ em uma lista e aplicando a f√≥rmula para cada horizonte. Vamos calcular manualmente para alguns casos e ent√£o mostrar uma implementa√ß√£o eficiente em Python.
>
> - Para $s=1$:
> $$ MSE(1) = 2 \cdot \frac{1-0.7^{2}}{1-0.7^{2}} = 2 $$
>
> - Para $s=2$:
>  $$ MSE(2) = 2 \cdot \frac{1-0.7^{4}}{1-0.7^{2}} = 2 \cdot \frac{1-0.2401}{0.51} =  2 \cdot \frac{0.7599}{0.51} \approx 2.98 $$
>
> - Para $s=5$:
>  $$ MSE(5) = 2 \cdot \frac{1-0.7^{10}}{1-0.7^{2}} = 2 \cdot \frac{1-0.0282}{0.51} = 2 \cdot \frac{0.9718}{0.51} \approx 3.81 $$
>
> Agora, vamos apresentar o c√≥digo Python a seguir que demonstra esta implementa√ß√£o eficiente para os primeiros 5 horizontes:
> ```python
> import numpy as np
>
> def calculate_mse_ar1(phi, sigma2, max_horizon):
>  mse_values = []
>  for s in range(1, max_horizon + 1):
>    mse = sigma2 * (1 - phi ** (2 * s)) / (1 - phi**2)
>    mse_values.append(mse)
>  return mse_values
>
> # Parameters
> phi = 0.7
> sigma2 = 2
> max_horizon = 5
>
> # Calculate MSEs
> mse_results = calculate_mse_ar1(phi, sigma2, max_horizon)
>
> # Print results
> for s, mse in enumerate(mse_results):
>   print(f"MSE para s = {s+1}: {mse:.4f}")
> ```
> A execu√ß√£o deste c√≥digo demonstra como o MSE pode ser calculado rapidamente para diferentes valores de *s*.
> ```
> MSE para s = 1: 2.0000
> MSE para s = 2: 2.9804
> MSE para s = 3: 3.5337
> MSE para s = 4: 3.7972
> MSE para s = 5: 3.9306
> ```

**Teorema 2:**  A complexidade computacional para calcular o MSE de previs√£o para os primeiros *s* passos √† frente em um processo AR(1) √© O(s).

*Prova:*
I.  O MSE para um horizonte *s* √© dado por: $MSE(s) = \sigma^2 \frac{1 - \phi^{2s}}{1 - \phi^2}$.
II.  Para calcular o MSE para os primeiros *s* horizontes (de 1 at√© *s*), a express√£o do MSE deve ser avaliada *s* vezes.
III.  O c√°lculo de $\sigma^2$, $\phi$ e $\phi^2$ envolve um n√∫mero constante de opera√ß√µes aritm√©ticas e devem ser feitas uma √∫nica vez.
IV.   O c√°lculo de $\phi^{2s}$ pode ser feito em tempo constante para cada passo ou pode ser reutilizado recursivamente $\phi^{2(s+1)} = \phi^2 * \phi^{2s}$
V. Cada avalia√ß√£o da f√≥rmula do MSE, ent√£o, envolve um n√∫mero fixo de opera√ß√µes (subtra√ß√£o, potencia√ß√£o, divis√£o e multiplica√ß√£o).
VI. Portanto, o n√∫mero total de opera√ß√µes √© proporcional ao n√∫mero de horizontes de previs√£o, *s*.
VII. Assim, a complexidade computacional do c√°lculo do MSE √© $O(s)$.
‚ñ†

This theorem shows that the computational complexity of computing the MSE for a range of forecast horizons grows linearly with the number of forecast steps, reinforcing the computational efficiency of the AR(1).

**Corol√°rio 2.1:** A complexidade computacional para calcular o MSE de previs√£o para um √∫nico horizonte *s* em um processo AR(1) √© O(1).

*Prova:*
I.  O MSE para um horizonte *s* √© dado por: $MSE(s) = \sigma^2 \frac{1 - \phi^{2s}}{1 - \phi^2}$.
II.  O c√°lculo de $\sigma^2$, $\phi$, e $\phi^2$ envolve um n√∫mero constante de opera√ß√µes aritm√©ticas e devem ser feitas uma √∫nica vez.
III.  Para um dado *s*, o c√°lculo de $\phi^{2s}$ envolve um n√∫mero constante de opera√ß√µes (potencia√ß√£o).
IV. A avalia√ß√£o da f√≥rmula do MSE envolve um n√∫mero fixo de opera√ß√µes (subtra√ß√£o, divis√£o e multiplica√ß√£o).
V. Portanto, o n√∫mero total de opera√ß√µes para um √∫nico horizonte *s* √© constante, independente de *s*.
VI. Assim, a complexidade computacional do c√°lculo do MSE para um √∫nico horizonte *s* √© O(1).
‚ñ†

This corollary highlights that while calculating the MSE for many forecast horizons has linear complexity, computing the MSE for any single horizon is of constant complexity, due to the simple structure of the AR(1) model.

### Conclus√£o
O MSE da previs√£o no modelo AR(1) aumenta com o horizonte de previs√£o, o que demonstra claramente a limita√ß√£o na previsibilidade a longo prazo. A converg√™ncia do MSE para a vari√¢ncia incondicional do processo destaca como a informa√ß√£o de observa√ß√µes atuais perde seu poder preditivo em horizontes mais distantes. No entanto, a formula√ß√£o matem√°tica do MSE permite uma r√°pida computa√ß√£o e an√°lise, o que facilita a avalia√ß√£o e compara√ß√£o do modelo. A efici√™ncia computacional e a capacidade de analisar o MSE s√£o vantagens do modelo AR(1), que, apesar de sua simplicidade, continua a ser uma ferramenta valiosa para modelagem e previs√£o de s√©ries temporais. O entendimento do trade-off entre computa√ß√£o e previsibilidade √© fundamental para a escolha adequada do modelo e para o uso inteligente da informa√ß√£o dispon√≠vel para previs√£o.

### Refer√™ncias
[^1]:  Refer√™ncia ao contexto onde o modelo AR(1) e sua defini√ß√£o matem√°tica foram apresentados.
[^2]: Refer√™ncia ao contexto onde as propriedades de previs√£o do AR(1) e a deriva√ß√£o da previs√£o linear √≥tima foram detalhadas, incluindo o decaimento geom√©trico para a m√©dia.
[^3]: Refer√™ncia ao contexto onde a efici√™ncia computacional do modelo AR(1) foi discutida, incluindo a implementa√ß√£o recursiva.
[^4]: Refer√™ncia ao contexto onde foi explorada a adequa√ß√£o da recursividade do modelo AR(1) para sistemas de alta performance.
<!-- END -->
