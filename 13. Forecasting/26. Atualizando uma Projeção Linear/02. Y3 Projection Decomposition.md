## Decomposi√ß√£o da Proje√ß√£o de Y3 em Y1 e Y2

### Introdu√ß√£o
Este cap√≠tulo continua a explora√ß√£o das proje√ß√µes lineares, com foco na decomposi√ß√£o da proje√ß√£o de $Y_3$ com base em $Y_1$ e $Y_2$. Em continuidade ao t√≥pico anterior, que estabeleceu como proje√ß√µes lineares podem ser atualizadas usando a fatora√ß√£o triangular da matriz de momentos, este cap√≠tulo se aprofunda na estrutura dessa atualiza√ß√£o, mostrando que a proje√ß√£o de $Y_3$ em $Y_1$ e $Y_2$ pode ser decomposta na proje√ß√£o de $Y_3$ sobre $Y_1$ mais um termo de corre√ß√£o que envolve a novidade da informa√ß√£o em $Y_2$ [^4.5.14].

### Conceitos Fundamentais

Como estabelecido anteriormente, a fatora√ß√£o triangular da matriz de covari√¢ncia $\Omega$, expressa como $\Omega = ADA'$, nos permite decompor as vari√°veis originais $Y$ em vari√°veis transformadas e n√£o correlacionadas $\tilde{Y}$ atrav√©s da rela√ß√£o $\tilde{Y} = A^{-1}Y$ [^4.5.2]. Essa transforma√ß√£o √© crucial para entender como a proje√ß√£o de $Y_3$ pode ser expressa em fun√ß√£o de proje√ß√µes mais simples [^4.5.6].

#### Decompondo a Proje√ß√£o de Y3
A proje√ß√£o de $Y_3$ sobre $Y_1$ e $Y_2$ √© dada por [^4.5.12]:
$$P(Y_3|Y_2, Y_1) = \Omega_{31} \Omega_{11}^{-1} Y_1 + h_{32}h_{22}^{-1} [Y_2 - \Omega_{21} \Omega_{11}^{-1} Y_1].$$
Esta equa√ß√£o mostra que a proje√ß√£o de $Y_3$ com base em $Y_1$ e $Y_2$ pode ser expressa como a proje√ß√£o de $Y_3$ sobre $Y_1$, mais um termo de corre√ß√£o. Este termo de corre√ß√£o envolve o componente n√£o antecipado de $Y_2$, ou seja, a diferen√ßa entre $Y_2$ e a proje√ß√£o de $Y_2$ sobre $Y_1$, multiplicada por um fator de atualiza√ß√£o $h_{32}h_{22}^{-1}$.

**Teorema 2:** *A proje√ß√£o de $Y_3$ em $Y_1$ e $Y_2$ pode ser decomposta na proje√ß√£o de $Y_3$ sobre $Y_1$ mais um produto do componente n√£o antecipado de $Y_2$ pelo fator de atualiza√ß√£o $h_{32}h_{22}^{-1}$ :*
$$
P(Y_3|Y_2,Y_1) = P(Y_3|Y_1) + \frac{E\{[Y_3 - P(Y_3|Y_1)][Y_2 - P(Y_2|Y_1)]\}}{E[Y_2 - P(Y_2|Y_1)]^2} [Y_2 - P(Y_2|Y_1)].
$$
*Demonstra√ß√£o:*
I. Definimos $P(Y_3|Y_1) = \Omega_{31}\Omega_{11}^{-1}Y_1$.
II. Definimos $P(Y_2|Y_1) = \Omega_{21}\Omega_{11}^{-1}Y_1$.
III. Da equa√ß√£o [^4.5.11] temos
$$
Y_3 = \Omega_{31}\Omega_{11}^{-1}Y_1 + h_{32}h_{22}^{-1}(Y_2 - \Omega_{21}\Omega_{11}^{-1}Y_1) + \tilde{Y_3}
$$
IV. Tomando a proje√ß√£o de ambos os lados em rela√ß√£o a $Y_1$ e $Y_2$
$$
P(Y_3|Y_1, Y_2) = \Omega_{31}\Omega_{11}^{-1}Y_1 + h_{32}h_{22}^{-1}(Y_2 - \Omega_{21}\Omega_{11}^{-1}Y_1)
$$
V. Substituindo $P(Y_3|Y_1)$ e $P(Y_2|Y_1)$, obtemos
$$P(Y_3|Y_2, Y_1) = P(Y_3|Y_1) +  h_{32}h_{22}^{-1} [Y_2 - P(Y_2|Y_1)]$$
VI. Pelas defini√ß√µes de $h_{32}$ e $h_{22}$ temos o resultado desejado.
   Note que $h_{32} = E\{[Y_3 - P(Y_3|Y_1)][Y_2 - P(Y_2|Y_1)]\}$ e $h_{22} = E[Y_2 - P(Y_2|Y_1)]^2$. Assim, $h_{32}h_{22}^{-1} = \frac{E\{[Y_3 - P(Y_3|Y_1)][Y_2 - P(Y_2|Y_1)]\}}{E[Y_2 - P(Y_2|Y_1)]^2}$
VII. Portanto, $P(Y_3|Y_2,Y_1) = P(Y_3|Y_1) + \frac{E\{[Y_3 - P(Y_3|Y_1)][Y_2 - P(Y_2|Y_1)]\}}{E[Y_2 - P(Y_2|Y_1)]^2} [Y_2 - P(Y_2|Y_1)]$.‚ñ†
> üí° **Exemplo Num√©rico:** Retomando o exemplo anterior, com $\Omega_{11} = 4$, $\Omega_{31} = 2$, $\Omega_{21} = 1$, $\Omega_{22} = 2$, $\Omega_{32} = 0.5$, $h_{22} = 1.75$ e $h_{32} = 0.375$:
> $$P(Y_3|Y_2,Y_1) = P(Y_3|Y_1) +  \frac{0.375}{1.75} [Y_2 - P(Y_2|Y_1)]$$
> E sabemos que $P(Y_3|Y_1) = \frac{2}{4}Y_1 = 0.5Y_1$ e $P(Y_2|Y_1) = \frac{1}{4}Y_1 = 0.25Y_1$, logo
> $$P(Y_3|Y_2,Y_1) = 0.5Y_1 + 0.214 [Y_2 - 0.25Y_1]$$
> E se $Y_1=3$ e $Y_2=1$, $P(Y_3|Y_2,Y_1) = 0.5 \cdot 3 + 0.214 [1 - 0.25\cdot 3] = 1.5 + 0.214[1-0.75] = 1.5 + 0.214 \cdot 0.25 = 1.5 + 0.0535 = 1.5535$.
> Isso significa que a proje√ß√£o de $Y_3$ dado $Y_1=3$ e $Y_2=1$ √© 1.5535. Inicialmente a proje√ß√£o usando apenas $Y_1$ era 1.5, e o novo valor de $Y_2$ ajusta a proje√ß√£o em 0.0535.

**Lema 2.1:** *O fator de atualiza√ß√£o $h_{32}h_{22}^{-1}$ pode ser expresso em termos das matrizes $\Omega$ da seguinte forma:*
$$h_{32}h_{22}^{-1} = \frac{\Omega_{32} - \Omega_{31}\Omega_{11}^{-1}\Omega_{12}}{\Omega_{22} - \Omega_{21}\Omega_{11}^{-1}\Omega_{12}}.$$
*Demonstra√ß√£o:*
I.  Recordamos que $h_{32} = \text{cov}(Y_3 - P(Y_3|Y_1), Y_2 - P(Y_2|Y_1))$ e $h_{22} = \text{var}(Y_2 - P(Y_2|Y_1))$.
II. Substituindo as proje√ß√µes, temos $h_{32} = \text{cov}(Y_3 - \Omega_{31}\Omega_{11}^{-1}Y_1, Y_2 - \Omega_{21}\Omega_{11}^{-1}Y_1)$.
III. Expandindo a covari√¢ncia, $h_{32} = \text{cov}(Y_3, Y_2) - \text{cov}(Y_3, \Omega_{21}\Omega_{11}^{-1}Y_1) - \text{cov}(\Omega_{31}\Omega_{11}^{-1}Y_1, Y_2) + \text{cov}(\Omega_{31}\Omega_{11}^{-1}Y_1, \Omega_{21}\Omega_{11}^{-1}Y_1)$.
IV. Usando as propriedades da covari√¢ncia e as defini√ß√µes da matriz $\Omega$, temos $h_{32} = \Omega_{32} - \Omega_{31}\Omega_{11}^{-1}\Omega_{12} - \Omega_{31}\Omega_{11}^{-1}\Omega_{12} + \Omega_{31}\Omega_{11}^{-1}\Omega_{11}\Omega_{11}^{-1}\Omega_{12} = \Omega_{32} - \Omega_{31}\Omega_{11}^{-1}\Omega_{12}$.
V. Analogamente, $h_{22} = \text{var}(Y_2 - \Omega_{21}\Omega_{11}^{-1}Y_1) = \Omega_{22} - \Omega_{21}\Omega_{11}^{-1}\Omega_{12}$.
VI. Assim, $h_{32}h_{22}^{-1} = \frac{\Omega_{32} - \Omega_{31}\Omega_{11}^{-1}\Omega_{12}}{\Omega_{22} - \Omega_{21}\Omega_{11}^{-1}\Omega_{12}}$. ‚ñ†
> üí° **Exemplo Num√©rico:**
> Suponha que tenhamos a seguinte matriz de covari√¢ncia:
> $$\Omega = \begin{bmatrix}
> 4 & 1 & 2 \\
> 1 & 2 & 0.5 \\
> 2 & 0.5 & 5
> \end{bmatrix}$$
>  Ent√£o, $\Omega_{11} = 4$, $\Omega_{12} = \Omega_{21} = 1$, $\Omega_{31} = 2$, $\Omega_{22} = 2$, $\Omega_{32} = 0.5$. Usando o Lema 2.1, podemos calcular o fator de atualiza√ß√£o $h_{32}h_{22}^{-1}$:
>
> $$h_{32}h_{22}^{-1} = \frac{0.5 - 2 \cdot \frac{1}{4} \cdot 1}{2 - 1 \cdot \frac{1}{4} \cdot 1} = \frac{0.5 - 0.5}{2 - 0.25} = \frac{0}{1.75} = 0$$
>
> Neste caso, o fator de atualiza√ß√£o √© 0, indicando que a informa√ß√£o em $Y_2$ n√£o ajusta a proje√ß√£o de $Y_3$ ap√≥s considerar $Y_1$, o que significa que $Y_2$ n√£o adiciona informa√ß√£o sobre $Y_3$ al√©m do que $Y_1$ j√° prov√™.

#### O Fator de Atualiza√ß√£o
O termo $h_{32}h_{22}^{-1}$ atua como um fator de atualiza√ß√£o, indicando o quanto a proje√ß√£o de $Y_3$ deve ser ajustada com base na nova informa√ß√£o $Y_2$. Esse termo tamb√©m pode ser expresso em termos das matrizes $A$ e $D$ da fatora√ß√£o triangular. Especificamente, $h_{22}$ √© o elemento (2,2) de $D$, e $h_{32}$ √© o produto de um elemento de $A$ com a vari√¢ncia do res√≠duo de $Y_2$ ap√≥s a proje√ß√£o em $Y_1$. De maneira geral, $h_{ij}$ representa a covari√¢ncia entre os res√≠duos de $Y_i$ e $Y_j$ ap√≥s a proje√ß√£o linear em suas vari√°veis anteriores, e $h_{ii}$ representa a vari√¢ncia do res√≠duo de $Y_i$.
> üí° **Exemplo Num√©rico:**  Do exemplo anterior, $h_{22} = 1.75$ √© a vari√¢ncia do res√≠duo de $Y_2$ depois de projetado em $Y_1$. Al√©m disso, sabemos que $h_{32}$ √© a covari√¢ncia entre o res√≠duo de $Y_3$ depois de projetado em $Y_1$ e o res√≠duo de $Y_2$ depois de projetado em $Y_1$. Assim, o fator de atualiza√ß√£o √© $h_{32}h_{22}^{-1} = 0.375 / 1.75 = 0.214$. Se $h_{32} = 0$ como no exemplo acima, ent√£o o fator de atualiza√ß√£o √© 0.

**Corol√°rio 2.1:** *Se $Y_1$ e $Y_2$ forem ortogonais, ent√£o $P(Y_3|Y_2, Y_1) = P(Y_3|Y_1) + P(Y_3|Y_2)$.*
*Demonstra√ß√£o:*
I. Se $Y_1$ e $Y_2$ s√£o ortogonais, ent√£o $\Omega_{12} = \Omega_{21} = 0$.
II. Do Lema 2.1,  $h_{32}h_{22}^{-1} = \frac{\Omega_{32} - \Omega_{31}\Omega_{11}^{-1}\cdot 0}{\Omega_{22} - \Omega_{21}\Omega_{11}^{-1}\cdot 0} = \frac{\Omega_{32}}{\Omega_{22}}$.
III. A proje√ß√£o $P(Y_2|Y_1) = \Omega_{21}\Omega_{11}^{-1}Y_1 = 0$.
IV. Logo, $P(Y_3|Y_2, Y_1) = P(Y_3|Y_1) + \frac{\Omega_{32}}{\Omega_{22}} Y_2$.
V. Como $\frac{\Omega_{32}}{\Omega_{22}} Y_2$ √© a proje√ß√£o de $Y_3$ em $Y_2$ quando $Y_1$ e $Y_2$ s√£o ortogonais, temos $P(Y_3|Y_2, Y_1) = P(Y_3|Y_1) + P(Y_3|Y_2)$. ‚ñ†
> üí° **Exemplo Num√©rico:**
> Suponha que $Y_1$ e $Y_2$ sejam ortogonais, e temos:
>
> $\Omega_{11} = 4$, $\Omega_{22} = 2$, $\Omega_{31} = 2$, $\Omega_{32} = 1$ e $\Omega_{12} = \Omega_{21} = 0$.
>
> Ent√£o:
>
> $P(Y_3|Y_1) = \frac{\Omega_{31}}{\Omega_{11}} Y_1 = \frac{2}{4} Y_1 = 0.5 Y_1$
>
> $P(Y_3|Y_2) = \frac{\Omega_{32}}{\Omega_{22}} Y_2 = \frac{1}{2} Y_2 = 0.5 Y_2$
>
> Como $Y_1$ e $Y_2$ s√£o ortogonais,
> $P(Y_3|Y_2, Y_1) = P(Y_3|Y_1) + P(Y_3|Y_2) = 0.5Y_1 + 0.5Y_2$.
>
> Se $Y_1=2$ e $Y_2=3$, ent√£o
> $P(Y_3|Y_2, Y_1) = 0.5 \cdot 2 + 0.5 \cdot 3 = 1 + 1.5 = 2.5$. A proje√ß√£o de $Y_3$ √© simplesmente a soma das proje√ß√µes em $Y_1$ e $Y_2$ quando s√£o ortogonais.

#### Interpreta√ß√£o da Decomposi√ß√£o
A decomposi√ß√£o da proje√ß√£o de $Y_3$ em $Y_1$ e $Y_2$ nos permite interpretar a contribui√ß√£o de cada fonte de informa√ß√£o para a previs√£o de $Y_3$. O termo $P(Y_3|Y_1)$ representa a previs√£o base de $Y_3$ com base apenas em $Y_1$, enquanto o termo $h_{32}h_{22}^{-1} [Y_2 - P(Y_2|Y_1)]$ representa o ajuste que deve ser feito nessa previs√£o base com base na nova informa√ß√£o contida em $Y_2$. Este ajuste √© proporcional ao componente n√£o antecipado em $Y_2$, ou seja, a diferen√ßa entre $Y_2$ e sua pr√≥pria proje√ß√£o linear em $Y_1$.
> üí° **Exemplo Num√©rico:**
>
> Voltando ao primeiro exemplo num√©rico:
> $$P(Y_3|Y_2,Y_1) = 0.5Y_1 + 0.214 [Y_2 - 0.25Y_1]$$
>
> Se $Y_1=3$ e $Y_2=1$, $P(Y_3|Y_2,Y_1) = 1.5535$.
>
> Aqui, $P(Y_3|Y_1) = 0.5 * 3 = 1.5$. Este √© o valor previsto de $Y_3$ usando apenas $Y_1$.
>
> O termo de corre√ß√£o √© $0.214 * (1 - 0.25 * 3) = 0.214 * 0.25 = 0.0535$.
>
> Assim, $1.5535 = 1.5 + 0.0535$. O valor predito para $Y_3$ √© ajustado para cima em 0.0535 quando se incorpora a informa√ß√£o de $Y_2$ e a depend√™ncia entre $Y_2$ e $Y_1$.

### Conclus√£o
A decomposi√ß√£o da proje√ß√£o de $Y_3$ em $Y_1$ e $Y_2$ revela a natureza incremental da atualiza√ß√£o de proje√ß√µes lineares. O fator de atualiza√ß√£o $h_{32}h_{22}^{-1}$ desempenha um papel crucial nesse processo, determinando como a nova informa√ß√£o $Y_2$ deve modificar a proje√ß√£o inicial $P(Y_3|Y_1)$. A fatora√ß√£o triangular da matriz de momentos oferece um m√©todo eficiente para computar os elementos necess√°rios desta decomposi√ß√£o, facilitando a atualiza√ß√£o cont√≠nua de proje√ß√µes lineares em cen√°rios onde informa√ß√µes novas se tornam dispon√≠veis. Os resultados apresentados aqui, junto com as demonstra√ß√µes formais, lan√ßam as bases para uma compreens√£o mais profunda das propriedades de proje√ß√µes lineares, bem como as t√©cnicas de filtragem recursiva como o filtro de Kalman que se baseiam nestes conceitos.

### Refer√™ncias
[^4.1.10]: *Se√ß√£o 4.1, p√°gina 73*
[^4.4.1]: *Se√ß√£o 4.4, p√°gina 87*
[^4.5.2]: *Se√ß√£o 4.5, p√°gina 92*
[^4.5.6]: *Se√ß√£o 4.5, p√°gina 92*
[^4.5.7]: *Se√ß√£o 4.5, p√°gina 93*
[^4.5.11]: *Se√ß√£o 4.5, p√°gina 93*
[^4.5.12]: *Se√ß√£o 4.5, p√°gina 93*
[^4.5.14]: *Se√ß√£o 4.5, p√°gina 94*
<!-- END -->
