## Impacto da N√£o Invertibilidade na Previs√£o com Amostras Finitas

### Introdu√ß√£o
Construindo sobre o t√≥pico anterior, que abordou previs√µes com um n√∫mero finito de observa√ß√µes, esta se√ß√£o explora as limita√ß√µes da abordagem quando o operador de m√©dia m√≥vel se aproxima da n√£o invertibilidade [^4.3]. A aproxima√ß√£o que estabelecemos previamente [^4.3], usando itera√ß√µes recursivas e tratando erros de pr√©-amostra como zero, oferece um m√©todo conveniente para previs√µes em s√©ries temporais com amostras finitas. No entanto, a efic√°cia dessa aproxima√ß√£o diminui conforme o par√¢metro de m√©dia m√≥vel se aproxima de um valor que torna o modelo n√£o invert√≠vel. Esta se√ß√£o examina essa quest√£o em detalhes, fornecendo uma compreens√£o mais profunda das limita√ß√µes pr√°ticas da abordagem aproximada.

### Conceitos Fundamentais
#### A Proximidade da N√£o-Invertibilidade
A se√ß√£o anterior estabeleceu que para modelos MA(q), ao aproximarmos a previs√£o √≥tima para um n√∫mero finito de amostras, n√≥s estimamos os erros passados por itera√ß√£o recursiva, usando  a seguinte express√£o [^4.3]:
$$
\hat{\epsilon}_{t} = (Y_{t} - \mu) - \sum_{j=1}^{q} \theta_j \hat{\epsilon}_{t-j}
$$

onde $\hat{\epsilon}_{k} = 0$ para $k < t-m+1$. Para um modelo MA(1), a previs√£o de s per√≠odos √† frente, condicionada at√© $t$, √© dada por [^4.3]:
$$
\hat{Y}_{t+s|t} = \mu + \sum_{k=0}^{q-s}\psi_{s+k}\hat{\epsilon}_{t-k}
$$

A aproxima√ß√£o que usamos nesse cen√°rio pode ser expressa como:
$$
\hat{Y}_{t+1|t} = \mu + \theta(Y_t - \mu) - \theta^2(Y_{t-1} - \mu) + \ldots + (-1)^{m-1}\theta^m(Y_{t-m+1} - \mu)
$$

Conforme mencionado anteriormente em [^4.3], esta express√£o pode ser simplificada utilizando um somat√≥rio:
$$
\hat{Y}_{t+1|t} = \mu + \sum_{k=1}^{m} (-\theta)^{k-1} \theta (Y_{t-k+1} - \mu)
$$
onde $m$ √© o tamanho da amostra usada para a previs√£o.

No entanto, quando $|\theta|$ se aproxima de 1 (ou seja, o operador da m√©dia m√≥vel se aproxima da n√£o-invertibilidade), a aproxima√ß√£o se torna menos precisa [^4.3]. A converg√™ncia dessa s√©rie, em rela√ß√£o √† previs√£o √≥tima, torna-se mais lenta ou pode n√£o ocorrer, pois os termos $(- \theta)^{k-1}$ n√£o diminuem rapidamente com o aumento de $k$. Isso ocorre porque a condi√ß√£o para invertibilidade dos modelos MA requer que as ra√≠zes do polin√¥mio $\theta(L)$ estejam fora do c√≠rculo unit√°rio. Conforme $\theta$ se aproxima da n√£o-invertibilidade, os termos passados de $Y_t$ recebem um peso maior na previs√£o, o que aumenta o erro de previs√£o.

> üí° **Intui√ß√£o:** Pense no termo $(- \theta)^{k-1} \theta$. Quando $\theta$ √© pequeno, os termos para valores maiores de $k$ decaem rapidamente para zero. Quando $\theta$ se aproxima de 1, esse decaimento √© mais lento e os valores passados de $Y_t$ ganham um peso maior, resultando em uma maior influ√™ncia da inicializa√ß√£o dos erros para zero, na performance da aproxima√ß√£o.

> üí° **Exemplo Num√©rico:** Vamos considerar um modelo MA(1) com $\mu = 10$ e vamos explorar o impacto de diferentes valores de $\theta$ em uma amostra de tamanho $m=5$. Suponha que temos as seguintes observa√ß√µes $Y_t$: $Y_1 = 11$, $Y_2 = 9$, $Y_3 = 12$, $Y_4 = 8$, $Y_5 = 10.5$. Vamos calcular $\hat{Y}_{6|5}$ usando a aproxima√ß√£o com $\theta = 0.5$ (invert√≠vel) e $\theta = 0.9$ (pr√≥ximo da n√£o-invertibilidade).
>
> Para $\theta = 0.5$:
> $\hat{Y}_{6|5} = 10 + 0.5(10.5 - 10) - 0.5^2(8 - 10) + 0.5^3(12 - 10) - 0.5^4(9-10) + 0.5^5(11-10)$
> $\hat{Y}_{6|5} = 10 + 0.25 + 0.5 + 0.25 - 0.0625 + 0.03125 \approx 11.0$
>
> Para $\theta = 0.9$:
> $\hat{Y}_{6|5} = 10 + 0.9(10.5 - 10) - 0.9^2(8 - 10) + 0.9^3(12 - 10) - 0.9^4(9-10) + 0.9^5(11-10)$
> $\hat{Y}_{6|5} = 10 + 0.45 + 1.62 + 1.458 + 0.6561 + 0.59049 \approx 14.8$
>
>  Observe que, com $\theta=0.9$, os termos passados t√™m um peso maior na previs√£o comparado a $\theta=0.5$. Se o valor real de $Y_6$ fosse pr√≥ximo de 11, a previs√£o com $\theta=0.5$ seria melhor, ilustrando que valores de $\theta$ pr√≥ximos de 1 amplificam erros devido a inicializa√ß√£o com 0, tornando a previs√£o menos precisa.
>
> Podemos visualizar esse comportamento em um gr√°fico com o peso dos termos em fun√ß√£o de k:
>
> ```mermaid
>  graph LR
>     A[k] --> B(Weights for theta=0.5);
>     A --> C(Weights for theta=0.9);
>     B --> D(Decaying rapidly);
>     C --> E(Decaying slowly);
> ```
> O gr√°fico ilustra que os pesos com $\theta = 0.5$ decaem rapidamente com o aumento de k, enquanto os pesos com $\theta = 0.9$ decaem de forma muito mais lenta, demonstrando que, quando $\theta$ √© pr√≥ximo de 1, valores de observa√ß√µes mais passadas influenciam de maneira relevante a previs√£o.

#### Problemas com Operadores de M√©dia M√≥vel N√£o Invert√≠veis

Quando o operador da m√©dia m√≥vel se torna n√£o invert√≠vel (ou seja, quando a raiz do polin√¥mio caracter√≠stico est√° dentro ou sobre o c√≠rculo unit√°rio), a aproxima√ß√£o de previs√£o [^4.3.1] se torna inadequada. Em ess√™ncia, a s√©rie infinita que representa a rela√ß√£o entre os erros e os valores passados de $Y_t$ n√£o converge.

Em geral, um modelo MA(q) √© considerado invert√≠vel se as ra√≠zes do polin√¥mio $\theta(L) = 1 + \theta_1 L + \theta_2 L^2 + \ldots + \theta_q L^q$ estiverem fora do c√≠rculo unit√°rio no plano complexo. Quando essa condi√ß√£o n√£o √© atendida, a rela√ß√£o entre o presente erro e os valores passados de $Y_t$ n√£o pode ser representada por uma s√©rie convergente e, por isso, a aproxima√ß√£o de previs√£o baseada em erros iniciais iguais a zero pode levar a resultados ruins.

> üí° **Exemplo:** Para um modelo MA(1) temos que $Y_t = \mu + \epsilon_t + \theta \epsilon_{t-1}$. Se o valor de $|\theta| \ge 1$, ent√£o o modelo MA(1) √© n√£o invert√≠vel.

**Lema 2** *Para um modelo MA(1), quando o par√¢metro $\theta$ se aproxima de um valor n√£o invert√≠vel, a influ√™ncia dos erros iniciais n√£o decai rapidamente com o tempo, resultando em aproxima√ß√µes de previs√µes menos precisas.*

*Prova:*
I. Consideramos a previs√£o de um modelo MA(1):
$$
\hat{Y}_{t+1|t} = \mu + \theta(Y_t - \mu) - \theta^2(Y_{t-1} - \mu) + \ldots + (-1)^{m-1}\theta^m(Y_{t-m+1} - \mu)
$$
II.  Para $|\theta| < 1$, a import√¢ncia de $(Y_{t-k+1} - \mu)$ diminui exponencialmente com $k$, dado pelo termo $\theta^k$. Assim, para um grande $m$, apenas os valores mais recentes de $Y$ afetam a previs√£o.
III. Quando $|\theta| \ge 1$, no entanto, o termo $\theta^k$ n√£o decai rapidamente e a import√¢ncia dos termos passados de Y n√£o √© depreciada rapidamente, levando a uma influ√™ncia maior da inicializa√ß√£o $\hat{\epsilon}_{t-m} = 0$  na qualidade da aproxima√ß√£o.  Essa influ√™ncia prolongada dos erros anteriores torna a previs√£o menos precisa, pois a aproxima√ß√£o da previs√£o √≥tima, usando os erros iniciais como zero, n√£o converge para o valor correto em um n√∫mero razo√°vel de amostras.
‚ñ†

Esse lema demonstra que o desempenho da aproxima√ß√£o de previs√£o torna-se cada vez mais sens√≠vel ao valor de $\theta$ √† medida que $\theta$ se aproxima de valores n√£o invert√≠veis.

**Lema 2.1** *A taxa de converg√™ncia da previs√£o aproximada para a previs√£o √≥tima em um modelo MA(1) √© inversamente proporcional √† magnitude de $|\theta|$ quando $|\theta|$ se aproxima de 1.*

*Prova:*
I. A previs√£o √≥tima, utilizando informa√ß√µes de toda a hist√≥ria, pode ser escrita como:
$$
\hat{Y}_{t+1|t}^* = \mu + \sum_{k=0}^{\infty} \theta \epsilon_{t-k}
$$
II. A previs√£o aproximada, usando uma amostra finita de tamanho $m$, pode ser escrita como:
$$
\hat{Y}_{t+1|t} = \mu + \sum_{k=0}^{m-1} (-\theta)^k \theta (Y_{t-k} - \mu)
$$
III. Ao subtrair as duas equa√ß√µes e usar a rela√ß√£o entre os erros e as observa√ß√µes $Y_t$, podemos escrever o erro de aproxima√ß√£o como:
$$
\hat{Y}_{t+1|t}^* - \hat{Y}_{t+1|t} = \sum_{k=m}^{\infty} \theta \epsilon_{t-k} -  \sum_{k=m}^{\infty} (-\theta)^k \theta(Y_{t-k} - \mu)
$$
IV. Observando a parte da soma da previs√£o √≥tima, temos que o erro de previs√£o se reduz a  $\sum_{k=m}^{\infty} \theta \epsilon_{t-k} $, para a previs√£o √≥tima.  Para a previs√£o aproximada, devido √† inicializa√ß√£o dos erros como 0, o termo  $\sum_{k=m}^{\infty} (-\theta)^k \theta(Y_{t-k} - \mu)$ n√£o converge rapidamente quando $|\theta|$ se aproxima de 1, pois a magnitude de $(-\theta)^k$ n√£o diminui rapidamente. Desta forma, a taxa de converg√™ncia da previs√£o aproximada para a previs√£o √≥tima √© inversamente proporcional a $|\theta|$.

‚ñ†

Este lema complementa o lema anterior, demonstrando que n√£o apenas a precis√£o da aproxima√ß√£o √© afetada pela n√£o-invertibilidade, mas tamb√©m a rapidez com que essa aproxima√ß√£o converge para a previs√£o √≥tima.

> üí° **Exemplo Num√©rico:** Considere um modelo MA(1) com $\mu = 0$, $\theta = 0.95$ e erro padr√£o $\sigma = 1$.  Vamos simular um processo com $n=100$ e realizar previs√µes para $t=101$ usando $m=20$ e $m=50$, para demonstrar que aumentar $m$ n√£o melhora muito a previs√£o, devido √† proximidade da n√£o-invertibilidade.

```python
import numpy as np
import matplotlib.pyplot as plt

np.random.seed(42)
mu = 0
theta = 0.95
sigma = 1
n = 100
m_values = [20, 50]

errors = np.random.normal(0, sigma, n+100)
Y = np.zeros(n+100)

for t in range(1,n+100):
  Y[t] = mu + errors[t] + theta*errors[t-1]

def approximate_forecast(Y,mu, theta, m, t):
  forecast = mu
  for k in range(1,m+1):
    forecast += ((-theta)**(k-1)) * theta * (Y[t-k+1]-mu)
  return forecast

forecasts = {}
for m in m_values:
    forecasts[m] = approximate_forecast(Y, mu, theta, m, n)

print(f"Previs√£o para m = {m_values[0]}: {forecasts[m_values[0]]:.2f}")
print(f"Previs√£o para m = {m_values[1]}: {forecasts[m_values[1]]:.2f}")
print(f"Valor real de Y[101]: {Y[101]:.2f}")
```

> O c√≥digo acima mostra que, embora aumentemos *m*, a previs√£o n√£o se aproxima muito do valor real de Y[101], que √© $Y_{101} = 0 + \epsilon_{101} + 0.95 \epsilon_{100}$. Isso acontece porque os erros passados t√™m um peso muito grande na previs√£o, devido ao valor de $\theta$ ser pr√≥ximo de 1. A previs√£o para m=20 √© 1.57 e para m=50 √© 1.59, enquanto o valor real de $Y_{101}$ foi 0.71 (esses valores ir√£o mudar devido a aleatoriedade da simula√ß√£o). A diferen√ßa entre as previs√µes com m=20 e m=50 s√£o pequenas, demostrando que aumentar o tamanho da amostra n√£o garante uma redu√ß√£o significativa do erro de previs√£o.

**Corol√°rio 2.1** *Em um modelo MA(1) com $|\theta|$ pr√≥ximo de 1, aumentar o tamanho da amostra $m$ usada para a previs√£o n√£o garante uma redu√ß√£o significativa no erro de previs√£o.*

*Prova:*
Este corol√°rio segue diretamente do Lema 2.1. Mesmo que aumentemos $m$, a converg√™ncia lenta em dire√ß√£o √† previs√£o √≥tima, quando $|\theta|$ est√° pr√≥ximo de 1, implica que o erro de previs√£o n√£o ser√° reduzido rapidamente, pois os termos passados continuam a ter grande influ√™ncia na previs√£o aproximada. ‚ñ†

Este corol√°rio enfatiza ainda mais as limita√ß√µes pr√°ticas de usar a aproxima√ß√£o com erros iniciais iguais a zero quando o operador de m√©dia m√≥vel se aproxima da n√£o invertibilidade, mesmo ao usar uma quantidade maior de dados hist√≥ricos.

### Conclus√£o
Esta se√ß√£o demonstrou que, embora a abordagem de tratamento de erros de pr√©-amostra como zero ofere√ßa uma maneira pr√°tica de realizar previs√µes com um n√∫mero finito de observa√ß√µes, sua efic√°cia √© reduzida quando o operador da m√©dia m√≥vel se aproxima da n√£o invertibilidade. Em particular, quanto mais perto o par√¢metro de m√©dia m√≥vel se aproxima de um valor que torne o modelo n√£o invert√≠vel, menos precisa se torna a aproxima√ß√£o. A converg√™ncia da previs√£o aproximada em dire√ß√£o √† previs√£o √≥tima torna-se mais lenta ou pode n√£o acontecer, pois a import√¢ncia dos erros anteriores n√£o desaparece rapidamente. Portanto, √© essencial considerar a invertibilidade do modelo MA ao aplicar esse m√©todo de previs√£o. Essa an√°lise serve como um lembrete de que a adequa√ß√£o das aproxima√ß√µes de previs√£o pode variar significativamente dependendo dos par√¢metros do modelo e dos dados.

Ao abordar as limita√ß√µes da aproxima√ß√£o, este cap√≠tulo fornece uma vis√£o equilibrada das vantagens e desvantagens de t√©cnicas de previs√£o com amostras finitas. Ao destacar como as previs√µes podem se comportar em cen√°rios menos ideais, refor√ßa ainda mais as considera√ß√µes pr√°ticas envolvidas na aplica√ß√£o de tais m√©todos na an√°lise de s√©ries temporais.

### Refer√™ncias
[^4.3]: Se√ß√£o 4.3 do documento original.
<!-- END -->
