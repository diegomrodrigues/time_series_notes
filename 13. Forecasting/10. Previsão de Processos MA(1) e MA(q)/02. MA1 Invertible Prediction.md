## Previs√£o em Processos MA(1) Invert√≠veis: Uma An√°lise Detalhada

### Introdu√ß√£o
Expandindo o conceito de previs√£o em modelos de m√©dias m√≥veis, este cap√≠tulo foca na an√°lise de previs√µes para processos MA(1) invert√≠veis, explorando a fundo a express√£o recursiva que emerge dessas previs√µes. Partindo do conhecimento estabelecido sobre previs√µes √≥timas e a utiliza√ß√£o do operador de retardo, nosso objetivo √© dissecar a natureza do erro de previs√£o como uma fun√ß√£o de valores passados de $Y$, conectando-o ao formalismo do operador de retardo [^4.2.16] e aos conceitos j√° abordados [^4.2.28].

### Express√£o Recursiva para Previs√µes MA(1)
Como j√° introduzido, para um processo MA(1) invert√≠vel, temos:

$$Y_t - \mu = (1 + \theta L)\epsilon_t$$ [^4.2.28]

Onde $\mu$ √© a m√©dia do processo, $L$ √© o operador de retardo e $\epsilon_t$ √© o ru√≠do branco. A previs√£o √≥tima de um per√≠odo √† frente ($\hat{Y}_{t+1|t}$) √© dada por:
$$\hat{Y}_{t+1|t} = \mu + \theta \hat{\epsilon}_t$$ [^4.2.32]

A previs√£o para um horizonte de previs√£o maior que um per√≠odo ($s > 1$), torna-se simplesmente a m√©dia incondicional $\mu$ do processo.

A chave para entender a previs√£o MA(1) est√° na estimativa do ru√≠do branco atual, $\hat{\epsilon}_t$. Ao contr√°rio de modelos AR, onde a previs√£o √© baseada diretamente em valores passados de $Y$, modelos MA estimam $\epsilon_t$ a partir dos valores passados de $Y$ e, como demonstrado anteriormente, pode ser expresso recursivamente como:

$$\hat{\epsilon}_t = (Y_t - \mu) - \theta \hat{\epsilon}_{t-1}$$ [^4.2.31]

**Observa√ß√£o 1:** Esta equa√ß√£o recursiva revela que o ru√≠do branco estimado no tempo $t$, $\hat{\epsilon}_t$, √© uma fun√ß√£o dos valores passados e presentes de $Y$. Essa rela√ß√£o √© crucial para a previs√£o em modelos MA(1). Note que para inicializar a recurs√£o, precisamos de um valor inicial $\hat{\epsilon}_{t-1}$, o que pode ser feito atribuindo o valor 0 para um valor passado suficiente, como $\hat{\epsilon}_{-m}=0$, com $m$ grande.

Substituindo $\hat{\epsilon}_t$ na previs√£o de um passo √† frente, temos:
$$ \hat{Y}_{t+1|t} = \mu + \theta[(Y_t - \mu) - \theta \hat{\epsilon}_{t-1}] $$

Continuando a recurs√£o de $\hat{\epsilon}_{t-1}$, obtemos:
$$\hat{\epsilon}_t = (Y_t - \mu) - \theta[(Y_{t-1} - \mu) - \theta \hat{\epsilon}_{t-2}] = (Y_t - \mu) - \theta(Y_{t-1} - \mu) + \theta^2 \hat{\epsilon}_{t-2}$$
Substituindo recursivamente, e utilizando o Lema 1, podemos expressar $\hat{\epsilon}_t$ como:
$$ \hat{\epsilon}_t = \frac{1}{1 + \theta L}(Y_t - \mu) = (Y_t - \mu) - \theta(Y_{t-1} - \mu) + \theta^2(Y_{t-2} - \mu) - \theta^3(Y_{t-3} - \mu) + \ldots $$
que √© a mesma representa√ß√£o expandida que derivamos da express√£o [^4.2.30].

> üí° **Exemplo Num√©rico:** Vamos considerar um processo MA(1) com m√©dia $\mu = 10$ e par√¢metro $\theta = 0.6$.  Suponha que temos os seguintes valores observados de $Y$: $Y_1 = 11$, $Y_2 = 12$, $Y_3 = 9$, $Y_4 = 11.5$. Inicializamos a recurs√£o com $\hat{\epsilon}_0 = 0$. Vamos calcular recursivamente os valores de $\hat{\epsilon}_t$ e as previs√µes $\hat{Y}_{t+1|t}$.
>
> *   **Passo 1 (t=1):**
>     $\hat{\epsilon}_1 = (Y_1 - \mu) - \theta \hat{\epsilon}_0 = (11 - 10) - 0.6(0) = 1$.
>     $\hat{Y}_{2|1} = \mu + \theta \hat{\epsilon}_1 = 10 + 0.6(1) = 10.6$.
>
> *   **Passo 2 (t=2):**
>     $\hat{\epsilon}_2 = (Y_2 - \mu) - \theta \hat{\epsilon}_1 = (12 - 10) - 0.6(1) = 2 - 0.6 = 1.4$.
>     $\hat{Y}_{3|2} = \mu + \theta \hat{\epsilon}_2 = 10 + 0.6(1.4) = 10.84$.
>
> *   **Passo 3 (t=3):**
>     $\hat{\epsilon}_3 = (Y_3 - \mu) - \theta \hat{\epsilon}_2 = (9 - 10) - 0.6(1.4) = -1 - 0.84 = -1.84$.
>     $\hat{Y}_{4|3} = \mu + \theta \hat{\epsilon}_3 = 10 + 0.6(-1.84) = 10 - 1.104 = 8.896$.
>
> *   **Passo 4 (t=4):**
>      $\hat{\epsilon}_4 = (Y_4 - \mu) - \theta \hat{\epsilon}_3 = (11.5 - 10) - 0.6(-1.84) = 1.5 + 1.104 = 2.604$.
>       $\hat{Y}_{5|4} = \mu + \theta \hat{\epsilon}_4 = 10 + 0.6(2.604) = 10 + 1.5624 = 11.5624$.
>
> Este exemplo ilustra como a previs√£o de um passo √† frente em um processo MA(1) depende recursivamente dos valores passados de $Y$ atrav√©s da estimativa do ru√≠do branco $\hat{\epsilon}_t$.

**Lema 1:** A expans√£o do operador $(1+\theta L)^{-1}$ √© dada por
$$(1+\theta L)^{-1} = 1 - \theta L + \theta^2 L^2 - \theta^3 L^3 + \ldots = \sum_{j=0}^{\infty} (-\theta)^j L^j.$$
*Proof:*
Essa expans√£o pode ser verificada pela multiplica√ß√£o da s√©rie por $(1 + \theta L)$, resultando em
$$(1+\theta L)(1 - \theta L + \theta^2 L^2 - \theta^3 L^3 + \ldots) = 1 + \theta L - \theta L - \theta^2 L^2 + \theta^2 L^2 + \ldots = 1.$$
Essa representa√ß√£o √© v√°lida se $|\theta L| < 1$, ou seja, $|\theta|<1$ para que a s√©rie convirja. ‚ñ†

**Teorema 1:** A previs√£o de um passo √† frente em um processo MA(1) invert√≠vel pode ser expressa como uma fun√ß√£o infinita de valores passados de $Y$.
*Proof:*
I.   Substitu√≠mos a express√£o expandida para $\hat{\epsilon}_t$ na previs√£o de um passo √† frente:
$$\hat{Y}_{t+1|t} = \mu + \theta[(Y_t - \mu) - \theta (Y_{t-1} - \mu) + \theta^2(Y_{t-2} - \mu) - \theta^3(Y_{t-3} - \mu) + \ldots]$$
II. Rearranjamos os termos:
$$\hat{Y}_{t+1|t} = \mu + \theta(Y_t - \mu) - \theta^2(Y_{t-1} - \mu) + \theta^3(Y_{t-2} - \mu) - \theta^4(Y_{t-3} - \mu) + \ldots$$
III. Esta express√£o demonstra que a previs√£o de um passo √† frente $\hat{Y}_{t+1|t}$ depende de uma fun√ß√£o infinita de valores passados de $Y$, com pesos que decaem geometricamente com o par√¢metro $\theta$.
Portanto, demonstramos que a previs√£o de um passo √† frente em um processo MA(1) invert√≠vel pode ser expressa como uma fun√ß√£o infinita de valores passados de $Y$, onde o peso de cada valor passado decai exponencialmente a uma taxa de $|\theta|$. ‚ñ†

> üí° **Exemplo Num√©rico:** Retomando o exemplo anterior com $\mu=10$ e $\theta=0.6$, podemos visualizar a influ√™ncia dos valores passados de $Y$ na previs√£o $\hat{Y}_{t+1|t}$. Usando a express√£o expandida para  $\hat{Y}_{t+1|t}$, vamos calcular a previs√£o $\hat{Y}_{5|4}$ de forma alternativa, utilizando os valores de $Y$ at√© o instante $t=4$:
>
> $$\hat{Y}_{5|4} = 10 + 0.6(11.5 - 10) - 0.6^2(9 - 10) + 0.6^3(12 - 10) - 0.6^4(11 - 10) + \dots $$
>
> $$\hat{Y}_{5|4} = 10 + 0.6(1.5) - 0.36(-1) + 0.216(2) - 0.1296(1) + \dots $$
>
> $$\hat{Y}_{5|4} = 10 + 0.9 + 0.36 + 0.432 - 0.1296 + \dots $$
>
> Como os pesos decaem geometricamente com a pot√™ncia de $\theta$, para esse caso, $\theta=0.6$, a contribui√ß√£o dos termos mais antigos de $Y$ rapidamente se torna insignificante. Calculando os primeiros 4 termos, temos $\hat{Y}_{5|4} \approx 11.5624$, resultado que concorda com a previs√£o calculada recursivamente. Este exemplo ilustra que, embora a express√£o para $\hat{Y}_{t+1|t}$ envolva uma soma infinita, na pr√°tica, podemos aproximar com uma quantidade finita de termos, dada a r√°pida converg√™ncia da s√©rie.

**Teorema 1.1:** A previs√£o de um passo √† frente $\hat{Y}_{t+1|t}$ pode tamb√©m ser expressa em termos do erro de previs√£o do passo anterior $\hat{\epsilon}_{t-1}$ como:
$$ \hat{Y}_{t+1|t} = \mu + \theta(Y_t - \mu) - \theta^2\hat{\epsilon}_{t-1} $$
*Proof:*
Essa express√£o decorre diretamente da substitui√ß√£o da defini√ß√£o recursiva de $\hat{\epsilon}_t$ na express√£o para $\hat{Y}_{t+1|t}$. Substituindo $\hat{\epsilon}_t = (Y_t - \mu) - \theta\hat{\epsilon}_{t-1}$ na equa√ß√£o $\hat{Y}_{t+1|t} = \mu + \theta\hat{\epsilon}_t$ , temos:
$$ \hat{Y}_{t+1|t} = \mu + \theta[(Y_t - \mu) - \theta\hat{\epsilon}_{t-1}] = \mu + \theta(Y_t - \mu) - \theta^2\hat{\epsilon}_{t-1}. $$
‚ñ†

A representa√ß√£o expandida do erro de previs√£o ($\hat{\epsilon}_t$) como uma fun√ß√£o infinita de valores passados de $Y$ revela a depend√™ncia intr√≠nseca do processo MA(1) em rela√ß√£o ao seu pr√≥prio hist√≥rico. Essa depend√™ncia √© mais sutil do que em modelos auto-regressivos (AR), onde os valores de $Y$ passados afetam diretamente os valores futuros de $Y$. Em modelos MA(1), os valores passados de $Y$ afetam a *estimativa* do ru√≠do branco atual, que, por sua vez, influencia a previs√£o.

> üí° **Exemplo Num√©rico:** Usando os mesmos valores do exemplo anterior ($\mu = 10$, $\theta = 0.6$) e os valores de $Y$, vamos calcular a previs√£o $\hat{Y}_{5|4}$ usando a express√£o com o erro do passo anterior:
>
> Temos $Y_4 = 11.5$ e $\hat{\epsilon}_3 = -1.84$ (calculado anteriormente). Assim:
>
> $$ \hat{Y}_{5|4} = \mu + \theta(Y_4 - \mu) - \theta^2\hat{\epsilon}_{3} = 10 + 0.6(11.5 - 10) - 0.6^2(-1.84) $$
> $$ \hat{Y}_{5|4} = 10 + 0.6(1.5) - 0.36(-1.84) = 10 + 0.9 + 0.6624 = 11.5624 $$
>
> Este resultado coincide com as previs√µes anteriores. Esta forma de calcular a previs√£o mostra como o erro do passo anterior, $\hat{\epsilon}_{t-1}$, contribui diretamente para a previs√£o atual, $\hat{Y}_{t+1|t}$.

Para horizontes de previs√£o $s>1$, a previs√£o √© simplesmente a m√©dia do processo, isto √© $\hat{Y}_{t+s|t}=\mu$, pois o erro estimado do ru√≠do, $\hat{\epsilon}_{t+s}$ para $s>0$ √© zero.

### Implica√ß√µes da Invertibilidade
A invertibilidade √© uma condi√ß√£o essencial para garantir que a previs√£o seja est√°vel e que os pesos dos valores passados de $Y$ na express√£o para $\hat{\epsilon}_t$ decaiam com o tempo. Se o processo n√£o for invert√≠vel ($|\theta| \ge 1$), os pesos dos valores passados de $Y$ aumentariam em magnitude, tornando a previs√£o inst√°vel e pouco confi√°vel.

*  A condi√ß√£o de invertibilidade ($|\theta| < 1$) garante que os valores passados de $Y$ tenham um impacto cada vez menor na estimativa do ru√≠do branco atual, $\hat{\epsilon}_t$. Conforme os pesos decaem geometricamente a uma taxa de $|\theta|$, o efeito de valores $Y$ muito passados torna-se desprez√≠vel.

*  A estabilidade da previs√£o √© garantida pela converg√™ncia da s√©rie infinita que define o ru√≠do estimado $\hat{\epsilon}_t$ como uma fun√ß√£o dos valores passados.

**Observa√ß√£o 2:**  A condi√ß√£o de invertibilidade tamb√©m garante a unicidade da representa√ß√£o MA(1) de um processo estacion√°rio. Um processo MA(1) n√£o invert√≠vel pode ser representado por outro processo MA(1) com um par√¢metro $\theta^*$ tal que $|\theta^*| < 1$.

### Conclus√£o
Em resumo, a previs√£o de um passo √† frente em um processo MA(1) invert√≠vel envolve o uso da express√£o recursiva para $\hat{\epsilon}_t$, com o erro sendo uma fun√ß√£o infinita dos valores passados de $Y$. O operador de retardo fornece uma forma compacta de representar essa rela√ß√£o, e a condi√ß√£o de invertibilidade garante a estabilidade e converg√™ncia da previs√£o. Esta an√°lise detalhada solidifica nossa compreens√£o sobre a natureza das previs√µes em modelos MA(1) e como elas diferem de outros modelos de s√©ries temporais.

### Refer√™ncias
[^4.2.16]: *$\hat{E}[Y_{t+s}|\epsilon_t, \epsilon_{t-1}, \ldots] = \mu + \left[\frac{\psi(L)}{L^s}\right]_+ \frac{1}{\psi(L)} (Y_t - \mu)$*
[^4.2.28]: *Considere uma representa√ß√£o invert√≠vel MA(1), $Y_t - \mu = (1 + \theta L)\epsilon_t$, com $|\theta| < 1$.*
[^4.2.30]: *$\hat{Y}_{t+1|t} = \mu + \frac{\theta}{1 + \theta L}(Y_t - \mu) = \mu + \theta(Y_t - \mu) - \theta^2(Y_{t-1} - \mu) + \theta^3(Y_{t-2} - \mu) - \ldots $.*
[^4.2.31]:  *$\hat{\epsilon}_t = (Y_t - \mu) - \theta\hat{\epsilon}_{t-1}$*
[^4.2.32]: *A previs√£o de um per√≠odo a frente $\hat{Y}_{t+1|t} = \mu + \theta\hat{\epsilon}_t$*
<!-- END -->
