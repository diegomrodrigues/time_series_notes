## O Erro QuadrÃ¡tico MÃ©dio e a Matriz Diagonal D na ProjeÃ§Ã£o Linear

### IntroduÃ§Ã£o
Este capÃ­tulo estabelece a relaÃ§Ã£o entre o Erro QuadrÃ¡tico MÃ©dio (MSE) e os elementos diagonais da matriz *D* obtida na fatoraÃ§Ã£o triangular de uma matriz de covariÃ¢ncia. Construindo sobre os capÃ­tulos anteriores sobre projeÃ§Ãµes lineares, fatoraÃ§Ã£o triangular e sua aplicaÃ§Ã£o na atualizaÃ§Ã£o de projeÃ§Ãµes [^4], detalharemos como o MSE do resÃ­duo de cada projeÃ§Ã£o linear corresponde a um elemento especÃ­fico da matriz diagonal *D*. AlÃ©m disso, vamos conectar o MSE do erro de previsÃ£o Ã  variÃ¢ncia do resÃ­duo, calculada a partir de elementos de *D*. O objetivo Ã© elucidar como a fatoraÃ§Ã£o triangular oferece uma forma sistemÃ¡tica para calcular e interpretar os erros de projeÃ§Ã£o, fornecendo uma base sÃ³lida para a avaliaÃ§Ã£o de modelos preditivos.

### MSE e os Elementos Diagonais da Matriz D
Como vimos em capÃ­tulos anteriores [^4], a fatoraÃ§Ã£o triangular de uma matriz de covariÃ¢ncia $\Omega$ Ã© dada por $\Omega = ADA'$, onde *A* Ã© uma matriz triangular inferior com 1s na diagonal principal e *D* Ã© uma matriz diagonal. Esta fatoraÃ§Ã£o permite expressar o vetor de variÃ¡veis transformadas $\hat{Y} = A^{-1}Y$ de tal forma que $E(\hat{Y}\hat{Y}')=D$, ou seja, as componentes de $\hat{Y}$ sÃ£o descorrelacionadas, e os elementos da diagonal de *D* correspondem Ã  variÃ¢ncia de cada elemento do vetor transformado $\hat{Y}$, que sÃ£o os resÃ­duos das projeÃ§Ãµes sequenciais. Em outras palavras, cada elemento $d_{ii}$ da matriz diagonal *D* representa o Erro QuadrÃ¡tico MÃ©dio (MSE) do resÃ­duo da projeÃ§Ã£o de $Y_i$ nas variÃ¡veis anteriores $Y_1, \ldots, Y_{i-1}$ [^4, ^4.5.5]. Isso significa que a matriz *D* nÃ£o apenas diagonaliza a matriz de covariÃ¢ncia original, mas tambÃ©m fornece informaÃ§Ãµes sobre os erros de previsÃ£o em cada etapa da projeÃ§Ã£o sequencial.
Vamos agora formalizar essa relaÃ§Ã£o. O MSE do resÃ­duo da projeÃ§Ã£o de $Y_i$ em $Y_1, \ldots, Y_{i-1}$ Ã© definido como $E[(Y_i - P(Y_i|Y_1,\ldots,Y_{i-1}))^2]$, onde $P(Y_i|Y_1,\ldots,Y_{i-1})$ Ã© a projeÃ§Ã£o linear de $Y_i$ no espaÃ§o gerado por $Y_1,\ldots,Y_{i-1}$. Na fatoraÃ§Ã£o triangular, o resÃ­duo $\hat{Y_i}$ Ã© definido como $\hat{Y_i} = Y_i - P(Y_i|Y_1,\ldots,Y_{i-1})$, e a matriz de covariÃ¢ncia dos resÃ­duos Ã© a matriz diagonal $D$, onde cada elemento $d_{ii}$ Ã© a variÃ¢ncia de $\hat{Y_i}$. Portanto, $d_{ii} = E[\hat{Y_i}^2] = E[(Y_i - P(Y_i|Y_1,\ldots,Y_{i-1}))^2]$, estabelecendo a ligaÃ§Ã£o entre o MSE do resÃ­duo e o elemento diagonal da matriz *D*.

> ðŸ’¡ **Exemplo NumÃ©rico:**
>
> Vamos considerar nosso exemplo recorrente com as variÃ¡veis $Y = (Y_1, Y_2, Y_3)'$ e a matriz de covariÃ¢ncia:
>
> $$\Omega = \begin{bmatrix} 4 & 2 & 1 \\ 2 & 5 & 2 \\ 1 & 2 & 6 \end{bmatrix}$$
>
> JÃ¡ calculamos as matrizes da fatoraÃ§Ã£o triangular:
>
> $$A = \begin{bmatrix} 1 & 0 & 0 \\ 0.5 & 1 & 0 \\ 0.25 & 0.375 & 1 \end{bmatrix}$$
>
> $$D = \begin{bmatrix} 4 & 0 & 0 \\ 0 & 4 & 0 \\ 0 & 0 & 5.1875 \end{bmatrix}$$
>
> As variÃ¡veis transformadas, os resÃ­duos sequenciais, sÃ£o:
> -  $\hat{Y}_1 = Y_1$
> -  $\hat{Y}_2 = Y_2 - 0.5Y_1$
> -  $\hat{Y}_3 = Y_3 - 0.375Y_2 + 0.125Y_1$
>
> **MSE e Elementos Diagonais de D:**
>
> -  O elemento $d_{11} = 4$ da matriz *D* Ã© a variÃ¢ncia de $Y_1$, que corresponde ao MSE da projeÃ§Ã£o de $Y_1$ nele mesmo.
> -  O elemento $d_{22} = 4$ Ã© o MSE do resÃ­duo da projeÃ§Ã£o de $Y_2$ em $Y_1$, ou seja, $E[(Y_2 - 0.5Y_1)^2] = E[\hat{Y}_2^2] = 4$.
> - O elemento $d_{33} = 5.1875$ Ã© o MSE do resÃ­duo da projeÃ§Ã£o de $Y_3$ em $Y_1$ e $Y_2$, ou seja, $E[(Y_3 - 0.375Y_2 + 0.125Y_1)^2] = E[\hat{Y_3}^2] = 5.1875$.
>
>  Esses resultados ilustram como os elementos diagonais da matriz *D* correspondem ao erro quadrÃ¡tico mÃ©dio dos resÃ­duos das projeÃ§Ãµes lineares sequenciais.
>
>  Vamos detalhar o cÃ¡lculo do MSE para $\hat{Y_2}$:
>
> $\text{MSE}(\hat{Y}_2) = E[(Y_2 - 0.5Y_1)^2] = E[Y_2^2 - Y_1Y_2 + 0.25Y_1^2]$.
>
> Usando as informaÃ§Ãµes da matriz de covariÃ¢ncia $\Omega$, temos:
>
> $E[Y_2^2] = 5$
>
> $E[Y_1Y_2] = 2$
>
> $E[Y_1^2] = 4$
>
> $\text{MSE}(\hat{Y}_2) = 5 - 2 + 0.25 * 4 = 5 - 2 + 1 = 4$
>
>  Este valor corresponde ao elemento $d_{22}$ da matriz *D*.
>
>  Similarmente, para $\hat{Y_3}$, o cÃ¡lculo do MSE Ã©:
>
> $\text{MSE}(\hat{Y_3}) = E[(Y_3 - 0.375Y_2 + 0.125Y_1)^2]$
>
> $\text{MSE}(\hat{Y_3}) = E[Y_3^2 + 0.140625Y_2^2 + 0.015625Y_1^2 - 0.75Y_2Y_3 + 0.25Y_1Y_3 - 0.09375Y_1Y_2]$
>
> Usando as informaÃ§Ãµes da matriz de covariÃ¢ncia $\Omega$, temos:
>
> $E[Y_3^2] = 6$
>
> $E[Y_2^2] = 5$
>
> $E[Y_1^2] = 4$
>
> $E[Y_2Y_3] = 2$
>
> $E[Y_1Y_3] = 1$
>
> $E[Y_1Y_2] = 2$
>
> $\text{MSE}(\hat{Y}_3) = 6 + 0.140625*5 + 0.015625*4 - 0.75*2 + 0.25*1 - 0.09375*2 = 6 + 0.703125 + 0.0625 - 1.5 + 0.25 - 0.1875 = 5.1875$
>
> Este valor corresponde ao elemento $d_{33}$ da matriz *D*.

**Lema 6.1**
O Erro QuadrÃ¡tico MÃ©dio (MSE) do resÃ­duo da projeÃ§Ã£o linear de $Y_i$ nas variÃ¡veis anteriores $Y_1,\ldots,Y_{i-1}$, denotado por $E[(Y_i - P(Y_i|Y_1,\ldots,Y_{i-1}))^2]$, Ã© precisamente igual ao elemento diagonal $d_{ii}$ da matriz $D$ obtida pela fatoraÃ§Ã£o triangular de $\Omega = ADA'$.
*Proof:*
I.  Definimos o resÃ­duo $\hat{Y_i}$ da projeÃ§Ã£o linear de $Y_i$ sobre o espaÃ§o gerado por $Y_1, \ldots, Y_{i-1}$ como $\hat{Y_i} = Y_i - P(Y_i|Y_1,\ldots,Y_{i-1})$.
II.  O MSE da projeÃ§Ã£o Ã© definido como $E[\hat{Y_i}^2] = E[(Y_i - P(Y_i|Y_1,\ldots,Y_{i-1}))^2]$.
III.  A fatoraÃ§Ã£o triangular nos dÃ¡ que $E(\hat{Y}\hat{Y}')=D$, onde $\hat{Y} = A^{-1}Y$, e os elementos diagonais de $D$ sÃ£o $d_{ii} = E[\hat{Y_i}^2]$.
IV.  Portanto, $E[(Y_i - P(Y_i|Y_1,\ldots,Y_{i-1}))^2] = E[\hat{Y_i}^2] = d_{ii}$, estabelecendo a igualdade entre o MSE do resÃ­duo e o elemento diagonal da matriz $D$.
â– 
Este lema formaliza a relaÃ§Ã£o entre o MSE dos resÃ­duos de projeÃ§Ã£o e a matriz $D$. Cada elemento $d_{ii}$ quantifica o erro que resta apÃ³s projetar $Y_i$ nas variÃ¡veis anteriores. Esse erro Ã© a menor variÃ¢ncia possÃ­vel que se obtÃ©m ao aproximar $Y_i$ com uma funÃ§Ã£o linear das variÃ¡veis anteriores.

**Lema 6.2**
A matriz *D*, obtida atravÃ©s da fatoraÃ§Ã£o triangular de $\Omega=ADA'$, Ã© Ãºnica para uma dada matriz de covariÃ¢ncia $\Omega$.
*Proof:*
I. Assuma que existam duas fatoraÃ§Ãµes triangulares de $\Omega$, tal que $\Omega = A_1D_1A_1' = A_2D_2A_2'$.
II. PrÃ©-multiplicando por $A_2^{-1}$ e pÃ³s-multiplicando por $(A_1')^{-1}$, temos $A_2^{-1}A_1D_1 = D_2A_2^{-1}A_1$.
III. Definimos $B = A_2^{-1}A_1$. Note que $B$ Ã© uma matriz triangular inferior com 1's na diagonal, pois Ã© produto de matrizes triangulares inferiores com 1's na diagonal.
IV. Assim, a equaÃ§Ã£o se torna $BD_1 = D_2B$.
V.  Olhando para a entrada $(i,j)$ da matriz $BD_1$ temos $b_{ij}d_{jj}$  enquanto a entrada $(i,j)$ da matriz $D_2B$ Ã© $d_{ii}b_{ij}$.
VI.  Assim, para $i \neq j$  temos $b_{ij}d_{jj} = d_{ii}b_{ij}$, que implica em $b_{ij}(d_{jj}-d_{ii})=0$. Como $D_1$ e $D_2$ sÃ£o matrizes diagonais de entradas positivas, se $i \neq j$, entÃ£o $d_{ii} \neq d_{jj}$, o que implica que $b_{ij}=0$.
VII. Como $B$ Ã© triangular inferior com 1's na diagonal, $b_{ij}=0$ para todo $i \neq j$ implica que $B=I$.
VIII. Segue que $A_2^{-1}A_1 = I$, o que implica que $A_1=A_2$, e, portanto, $D_1 = D_2$. A unicidade da fatoraÃ§Ã£o triangular implica na unicidade da matriz *D*.
â– 
Este lema garante que, para uma matriz de covariÃ¢ncia especÃ­fica, a matriz *D* obtida por meio da fatoraÃ§Ã£o triangular Ã© Ãºnica, o que torna a anÃ¡lise e interpretaÃ§Ã£o do MSE consistente e bem definida.

### MSE do Erro de PrevisÃ£o e a VariÃ¢ncia do ResÃ­duo
O MSE do erro de previsÃ£o, que mede a precisÃ£o de uma projeÃ§Ã£o linear, estÃ¡ diretamente relacionado com a variÃ¢ncia do resÃ­duo da projeÃ§Ã£o. De forma geral, o erro de previsÃ£o Ã© o resÃ­duo da projeÃ§Ã£o linear. Por exemplo, se temos a projeÃ§Ã£o de $Y_{n+1}$ em $Y_1,\ldots, Y_n$, o erro de previsÃ£o Ã© definido como $\epsilon = Y_{n+1} - P(Y_{n+1}|Y_1, \ldots, Y_n)$, e o erro quadrÃ¡tico mÃ©dio de previsÃ£o Ã© dado por $MSE = E[\epsilon^2]$.  Em termos dos resÃ­duos $\hat{Y_i}$ obtidos da fatoraÃ§Ã£o triangular, o erro de previsÃ£o Ã© igual ao resÃ­duo do passo final, que denominamos $\hat{Y}_{n+1}$.  Da seÃ§Ã£o anterior sabemos que $E[\hat{Y_i}^2]=d_{ii}$. Portanto, o MSE do erro de previsÃ£o corresponde Ã  variÃ¢ncia do resÃ­duo $\hat{Y}_{n+1}$ que Ã© dada por  $Var(\hat{Y}_{n+1})=d_{n+1,n+1}$.
A fatoraÃ§Ã£o triangular nos permite conectar o MSE do erro de previsÃ£o com os elementos diagonais da matriz *D*.  Se $Y_{n+1}$ Ã© a variÃ¡vel a ser prevista e temos as variÃ¡veis $Y_1,\ldots,Y_n$ para usar na previsÃ£o, a projeÃ§Ã£o linear $P(Y_{n+1}|Y_1, \ldots, Y_n)$ Ã© construÃ­da de forma recursiva com os resÃ­duos das projeÃ§Ãµes anteriores. O resÃ­duo da projeÃ§Ã£o de $Y_{n+1}$ Ã©  $\hat{Y}_{n+1}$.  Da fatoraÃ§Ã£o triangular, a variÃ¢ncia de $\hat{Y}_{n+1}$ Ã© dada por $d_{n+1,n+1}$, o elemento correspondente da matriz diagonal *D* que Ã© tambÃ©m igual ao MSE do erro da projeÃ§Ã£o.

> ðŸ’¡ **Exemplo NumÃ©rico:**
>
> Vamos usar o mesmo exemplo com as variÃ¡veis  $Y = (Y_1, Y_2, Y_3)'$, matriz de covariÃ¢ncia $\Omega$ e fatoraÃ§Ã£o triangular:
>
> $$A = \begin{bmatrix} 1 & 0 & 0 \\ 0.5 & 1 & 0 \\ 0.25 & 0.375 & 1 \end{bmatrix}$$
>
> $$D = \begin{bmatrix} 4 & 0 & 0 \\ 0 & 4 & 0 \\ 0 & 0 & 5.1875 \end{bmatrix}$$
>
> e os resÃ­duos:
> - $\hat{Y_1} = Y_1$
> - $\hat{Y_2} = Y_2 - 0.5Y_1$
> - $\hat{Y_3} = Y_3 - 0.375Y_2 + 0.125Y_1$
>
> **RelaÃ§Ã£o entre MSE e VariÃ¢ncia do ResÃ­duo**
>
> Se queremos prever $Y_3$ a partir de $Y_1$ e $Y_2$, o erro de previsÃ£o Ã© $\hat{Y_3}$ e o MSE de previsÃ£o Ã© $E[\hat{Y_3}^2]$, que Ã© igual a $d_{33} = 5.1875$.   Esta Ã© tambÃ©m a variÃ¢ncia do resÃ­duo da projeÃ§Ã£o de $Y_3$ em $Y_1$ e $Y_2$.
>  Se quisermos projetar $Y_2$ em $Y_1$ o erro de previsÃ£o serÃ¡ $\hat{Y_2}$ e a variÃ¢ncia do resÃ­duo, que Ã© igual ao MSE de previsÃ£o, serÃ¡ $d_{22} = 4$.
>  Se quisermos projetar $Y_1$ em um valor constante (a mÃ©dia), o erro de previsÃ£o serÃ¡ $Y_1$, e o erro quadrÃ¡tico mÃ©dio, que Ã© o MSE da projeÃ§Ã£o Ã©  $d_{11} = 4$, que corresponde Ã  variÃ¢ncia de $Y_1$.
>
> Portanto, vemos que o MSE do erro de previsÃ£o, interpretado como a variÃ¢ncia do resÃ­duo da projeÃ§Ã£o, Ã© dada diretamente pelos elementos da diagonal de *D*.
>
>
> **Exemplo com Dados:**
>
> Suponha que temos dados de uma sÃ©rie temporal, e queremos projetar o valor de $Y_4$ usando os valores de $Y_1, Y_2, Y_3$. Digamos que, a partir de dados histÃ³ricos, a matriz de covariÃ¢ncia estimada seja:
>
> $$\Omega = \begin{bmatrix} 4 & 2 & 1 & 0.8 \\ 2 & 5 & 2 & 1.5 \\ 1 & 2 & 6 & 2.5 \\ 0.8 & 1.5 & 2.5 & 7 \end{bmatrix}$$
>
>
> Podemos fatorar $\Omega = ADA'$, onde:
>
> $$A = \begin{bmatrix} 1 & 0 & 0 & 0 \\ 0.5 & 1 & 0 & 0 \\ 0.25 & 0.375 & 1 & 0 \\ 0.2 & 0.35 & 0.44 & 1 \end{bmatrix}$$
>
> $$D = \begin{bmatrix} 4 & 0 & 0 & 0 \\ 0 & 4 & 0 & 0 \\ 0 & 0 & 5.1875 & 0 \\ 0 & 0 & 0 & 5.695 \end{bmatrix}$$
>
> EntÃ£o, o MSE do erro de previsÃ£o ao prever $Y_4$ usando $Y_1$, $Y_2$, e $Y_3$ Ã© $d_{44} = 5.695$.  Este valor representa o quanto a previsÃ£o de $Y_4$ Ã© imprecisa em termos de erro quadrÃ¡tico mÃ©dio, ou a variÃ¢ncia do resÃ­duo da projeÃ§Ã£o de $Y_4$ em $Y_1$, $Y_2$ e $Y_3$.

**Teorema 6.1**
O Erro QuadrÃ¡tico MÃ©dio (MSE) do erro de previsÃ£o, que Ã© o resÃ­duo da projeÃ§Ã£o linear de $Y_{n+1}$ no espaÃ§o gerado por $Y_1, \ldots, Y_n$, Ã© igual Ã  variÃ¢ncia do resÃ­duo $\hat{Y}_{n+1}$ da projeÃ§Ã£o, e esse valor Ã© dado pelo elemento diagonal $d_{n+1,n+1}$ da matriz $D$ resultante da fatoraÃ§Ã£o triangular da matriz de covariÃ¢ncia das variÃ¡veis $Y_1, \dots, Y_{n+1}$.
*Prova:*
I. Definimos o erro de previsÃ£o como o resÃ­duo $\epsilon = Y_{n+1} - P(Y_{n+1}|Y_1, \ldots, Y_n)$, onde $P(Y_{n+1}|Y_1, \ldots, Y_n)$ Ã© a projeÃ§Ã£o linear de $Y_{n+1}$ em $Y_1,\ldots,Y_n$.
II.  A fatoraÃ§Ã£o triangular de $\Omega$ (a matriz de covariÃ¢ncia de $Y_1, \ldots, Y_{n+1}$) fornece os resÃ­duos sequenciais, e define $\hat{Y}_{n+1}$ como o resÃ­duo da projeÃ§Ã£o linear de $Y_{n+1}$ no espaÃ§o gerado por $Y_1,\ldots,Y_n$.
III. O MSE do erro de previsÃ£o Ã© definido como $E[\epsilon^2] = E[(Y_{n+1} - P(Y_{n+1}|Y_1, \ldots, Y_n))^2]$.
IV.  Na fatoraÃ§Ã£o triangular, o resÃ­duo da projeÃ§Ã£o Ã© $\hat{Y}_{n+1}$, e $d_{n+1,n+1}$ Ã© definido como a variÃ¢ncia do resÃ­duo $\hat{Y}_{n+1}$.
V.  Portanto, $MSE = E[\hat{Y}_{n+1}^2] = Var(\hat{Y}_{n+1}) = d_{n+1,n+1}$. Ou seja, o MSE do erro de previsÃ£o, interpretado como a variÃ¢ncia do resÃ­duo da projeÃ§Ã£o, Ã© dado por $d_{n+1,n+1}$.
â– 
Este teorema demonstra que a matriz *D* fornece nÃ£o apenas os erros de cada projeÃ§Ã£o linear sequencial, mas tambÃ©m o erro da projeÃ§Ã£o final, dado pelo Ãºltimo elemento da matriz diagonal. Isso simplifica a avaliaÃ§Ã£o da qualidade das projeÃ§Ãµes e permite conectar a teoria da projeÃ§Ã£o linear com a prÃ¡tica da modelagem preditiva.

**Teorema 6.2**
Se o vetor $Y$ for uma realizaÃ§Ã£o de um processo estocÃ¡stico estacionÃ¡rio, entÃ£o os elementos da diagonal de $D$, obtidos pela fatoraÃ§Ã£o de $\Omega$, corresponderÃ£o aos erros de previsÃ£o quando se projeta uma variÃ¡vel do processo usando informaÃ§Ãµes sobre os seus valores passados.
*Proof:*
I. Em um processo estocÃ¡stico estacionÃ¡rio, as propriedades estatÃ­sticas (como a mÃ©dia e a covariÃ¢ncia) nÃ£o variam com o tempo.
II.  Ao aplicar a fatoraÃ§Ã£o triangular sequencial em uma amostra de um processo estacionÃ¡rio, o resultado Ã© equivalente a construir um modelo preditivo linear.
III. Cada elemento $d_{ii}$ da matriz diagonal *D* representa o MSE do resÃ­duo da projeÃ§Ã£o de $Y_i$ em $Y_1, \ldots, Y_{i-1}$.
IV. No contexto de um processo estacionÃ¡rio, este MSE corresponde ao erro de previsÃ£o ao usar os valores passados de $Y$ para prever o valor atual, uma vez que as estatÃ­sticas do processo sÃ£o invariantes com o tempo. Assim,  $d_{ii}$ quantifica o erro de previsÃ£o ao projetar uma variÃ¡vel usando informaÃ§Ãµes de seus valores passados.
â– 
Este teorema conecta a anÃ¡lise do MSE, a fatoraÃ§Ã£o triangular e o conceito de previsÃ£o em sÃ©ries temporais. Ele estabelece que, para processos estacionÃ¡rios, os elementos da matriz *D* sÃ£o diretamente interpretÃ¡veis como erros de previsÃ£o.

### ImplicaÃ§Ãµes para Modelagem e PrevisÃ£o
A conexÃ£o entre o MSE e a matriz diagonal *D* tem implicaÃ§Ãµes importantes para a modelagem e a previsÃ£o. Em primeiro lugar, permite que os analistas calculem os erros de projeÃ§Ã£o sem precisar avaliar diretamente os momentos populacionais, mas utilizando os resultados da fatoraÃ§Ã£o triangular. Em segundo lugar, essa abordagem fornece uma forma sistemÃ¡tica para avaliar o impacto de adicionar novas variÃ¡veis ao modelo, porque a matriz *D* permite verificar o quanto o MSE de projeÃ§Ã£o Ã© reduzido em cada etapa da projeÃ§Ã£o sequencial.  Por Ãºltimo, a interpretaÃ§Ã£o do erro quadrÃ¡tico mÃ©dio como a variÃ¢ncia do resÃ­duo da projeÃ§Ã£o permite conectar a precisÃ£o da previsÃ£o com a qualidade da informaÃ§Ã£o utilizada para a previsÃ£o.

**CorolÃ¡rio 6.1**
O MSE do erro de previsÃ£o ao projetar $Y_{n+1}$ sobre $Y_1, \dots, Y_n$ representa a variÃ¢ncia do resÃ­duo, que Ã© o elemento diagonal $d_{n+1,n+1}$ da matriz $D$ obtida na fatoraÃ§Ã£o triangular da matriz de covariÃ¢ncia do vetor expandido $[Y_1, \dots, Y_{n+1}]$.

*Prova:*
I. Pelo Teorema 6.1, sabemos que o MSE do erro de previsÃ£o, ao projetar $Y_{n+1}$ sobre $Y_1, \dots, Y_n$, Ã© igual a $Var(\hat{Y}_{n+1})$, onde $\hat{Y}_{n+1}$ Ã© o resÃ­duo da projeÃ§Ã£o de $Y_{n+1}$ sobre $Y_1, \dots, Y_n$.
II.  A fatoraÃ§Ã£o triangular garante que $E(\hat{Y}\hat{Y}')=D$, e que os elementos na diagonal de $D$ sÃ£o as variÃ¢ncias dos resÃ­duos.
III.  Assim, $Var(\hat{Y}_{n+1})$ Ã© dado pelo elemento diagonal $d_{n+1,n+1}$ da matriz $D$.
IV. Portanto, o MSE do erro de previsÃ£o Ã© dado pelo elemento $d_{n+1,n+1}$ da matriz diagonal $D$ na fatoraÃ§Ã£o triangular da matriz de covariÃ¢ncia expandida.
â– 
**CorolÃ¡rio 6.2**
A soma dos elementos diagonais da matriz *D*, $\sum_{i=1}^n d_{ii}$, representa a soma total dos erros quadrÃ¡ticos mÃ©dios das projeÃ§Ãµes sequenciais,  e tambÃ©m corresponde Ã  soma total das variÃ¢ncias dos resÃ­duos obtidos no processo de projeÃ§Ã£o.
*Proof:*
I. Pelo Lema 6.1, cada elemento diagonal $d_{ii}$ da matriz D Ã© igual ao MSE do resÃ­duo da projeÃ§Ã£o de $Y_i$ nas variÃ¡veis anteriores.
II. A soma dos elementos diagonais da matriz D Ã© $\sum_{i=1}^n d_{ii}$.
III. Como $d_{ii} = E[\hat{Y_i}^2]$, a soma $\sum_{i=1}^n d_{ii}$ representa a soma dos erros quadrÃ¡ticos mÃ©dios de cada projeÃ§Ã£o.
IV. Cada $d_{ii}$ tambÃ©m Ã© igual a $Var(\hat{Y_i})$, a variÃ¢ncia do resÃ­duo da projeÃ§Ã£o.
V. Portanto, $\sum_{i=1}^n d_{ii}$ tambÃ©m representa a soma total das variÃ¢ncias dos resÃ­duos das projeÃ§Ãµes sequenciais.
â– 
Este corolÃ¡rio fornece uma interpretaÃ§Ã£o adicional dos elementos da matriz *D*, mostrando que sua soma estÃ¡ relacionada com o erro total no processo de projeÃ§Ã£o sequencial, consolidando ainda mais o papel da fatoraÃ§Ã£o triangular na anÃ¡lise de modelos preditivos.

### ConclusÃ£o
Neste capÃ­tulo, exploramos a relaÃ§Ã£o fundamental entre o Erro QuadrÃ¡tico MÃ©dio (MSE) dos resÃ­duos das projeÃ§Ãµes lineares e os elementos diagonais da matriz *D* obtida na fatoraÃ§Ã£o triangular da matriz de covariÃ¢ncia. Demonstramos que cada elemento $d_{ii}$ de *D* representa o MSE do resÃ­duo correspondente, e que o MSE do erro de previsÃ£o pode ser interpretado como a variÃ¢ncia do resÃ­duo da projeÃ§Ã£o, calculado a partir do elemento diagonal da matriz *D*. Esta compreensÃ£o Ã© essencial para avaliar e otimizar modelos preditivos, alÃ©m de fundamentar a conexÃ£o entre a fatoraÃ§Ã£o triangular e a interpretaÃ§Ã£o dos erros de previsÃ£o em um contexto mais amplo. O resultado Ã© uma maneira sistemÃ¡tica e eficiente para obter informaÃ§Ãµes sobre a qualidade das projeÃ§Ãµes e a significÃ¢ncia de novas variÃ¡veis na previsÃ£o de modelos lineares.

### ReferÃªncias
[^4]: SeÃ§Ãµes do CapÃ­tulo 4 do livro texto fornecido.
<!-- END -->
