## Previs√£o para um Processo ARMA(1,1) com Horizonte de *s* Per√≠odos

### Introdu√ß√£o
Este cap√≠tulo expande os conceitos de previs√£o apresentados anteriormente, concentrando-se especificamente na deriva√ß√£o da previs√£o de *s* per√≠odos √† frente para um processo **ARMA(1,1)**. Conforme vimos anteriormente, o processo **ARMA(1,1)** √© definido pela combina√ß√£o de um componente autorregressivo de primeira ordem e um componente de m√©dia m√≥vel de primeira ordem [^4.2.13]. Vamos agora explorar como expressar a previs√£o futura desse processo em termos dos dados atuais e do operador de retardo *L*.

### Conceitos Fundamentais
Um processo **ARMA(1,1)** √© definido como [^4.2.37]:
$$ (1 - \phi L)(Y_t - \mu) = (1 + \theta L)\epsilon_t, $$
onde $\phi$ representa o par√¢metro autorregressivo, $\theta$ representa o par√¢metro da m√©dia m√≥vel, $Y_t$ √© o valor da s√©rie temporal no tempo *t*, $\mu$ √© a m√©dia da s√©rie temporal, $\epsilon_t$ √© o ru√≠do branco no tempo *t*, e *L* √© o operador de retardo.
O objetivo √© calcular a previs√£o de $Y_{t+s}$ dado as informa√ß√µes dispon√≠veis at√© o tempo *t*, denotado por $ \hat{Y}_{t+s|t} $. A equa√ß√£o [^4.2.16] nos fornece a forma geral da previs√£o:
$$ \hat{Y}_{t+s|t} = \mu + \left[ \frac{\psi(L)}{L^s} \right]_+ \frac{1}{\phi(L)} (Y_t - \mu) $$
onde $\psi(L)$ √© o polin√¥mio da m√©dia m√≥vel e $\phi(L)$ √© o polin√¥mio autorregressivo.

No caso de um processo **ARMA(1,1)**, temos $\phi(L) = (1-\phi L)$ e $\psi(L) = (1+\theta L)$. Assim, a previs√£o de *s* per√≠odos √† frente se torna:
$$ \hat{Y}_{t+s|t} = \mu + \left[ \frac{1+\theta L}{L^s} \right]_+ \frac{1}{1 - \phi L} (Y_t - \mu) $$
A an√°lise detalhada da componente $(1+\theta L)/(1-\phi L)$ √© essencial para entender a din√¢mica de longo prazo da previs√£o. A express√£o para $\left[ \frac{1+\theta L}{L^s} \right]_+$  √© dada por [^4.2.38]:
$$ \left[ \frac{1+\theta L}{(1-\phi L)L^s} \right]_+  = \frac{\phi^s+\theta\phi^{s-1}}{1-\phi L} - \frac{\theta\phi^{s-1}}{1-\phi L} $$
Substituindo essa express√£o na equa√ß√£o de previs√£o, obtemos:
$$ \hat{Y}_{t+s|t} = \mu + \left[ \frac{\phi^s + \theta \phi^{s-1}}{1-\phi L} \right]_+ (Y_t - \mu) $$
$$ \hat{Y}_{t+s|t} = \mu + \frac{\phi^s + \theta \phi^{s-1}}{1-\phi L} (Y_t - \mu) $$

Para o caso espec√≠fico de *s* = 1, a previs√£o se torna [^4.2.40]:
$$ \hat{Y}_{t+1|t} = \mu + \frac{\phi + \theta}{1 + \theta L}(Y_t - \mu) $$
Essa equa√ß√£o indica que a previs√£o de um per√≠odo √† frente √© uma combina√ß√£o ponderada da m√©dia $\mu$ e do desvio de $Y_t$ em rela√ß√£o √† sua m√©dia, ponderada pelo termo $\frac{\phi + \theta}{1 + \theta L}$.

> üí° **Exemplo Num√©rico:**
> Vamos supor um processo ARMA(1,1) com $\mu = 10$, $\phi = 0.7$, e $\theta = 0.3$. Se o valor atual da s√©rie temporal √© $Y_t = 12$, ent√£o a previs√£o para um per√≠odo √† frente ($s=1$) √© calculada como:
> $$ \hat{Y}_{t+1|t} = 10 + \frac{0.7 + 0.3}{1 - 0.7L} (12 - 10) $$
> Expandindo $\frac{1}{1 - 0.7L}$ utilizando o Lema 1 (considerando alguns termos da expans√£o para fins ilustrativos):
> $$\frac{1}{1 - 0.7L} \approx 1 + 0.7L + 0.7^2L^2 + \ldots$$
> Considerando apenas os termos at√© $L^1$, e aplicando a $Y_t- \mu$, teremos:
> $$ \hat{Y}_{t+1|t} \approx 10 + (0.7+0.3)(1+0.7L)(12-10) = 10 + 1(1 + 0.7L)2 = 10 + 2 + 1.4L $$
> Considerando que $L(Y_t - \mu) = Y_{t-1} - \mu$, e que para este exemplo $Y_{t-1}$ n√£o est√° definido, iremos considerar $Y_{t-1}-\mu = 0$ para efeito de c√°lculo. Ent√£o:
> $$ \hat{Y}_{t+1|t} \approx 10 + 2 + 1.4 \cdot 0 = 12 $$
>  Note que esta √© uma aproxima√ß√£o e que na verdade a expans√£o do termo $\frac{1}{1-0.7L}$ √© uma s√©rie infinita.
>  No entanto, se expandirmos a equa√ß√£o para $\hat{Y}_{t+1|t}$ diretamente temos:
> $$\hat{Y}_{t+1|t} = 10 + \frac{0.7 + 0.3}{1 - 0.7L}(12 - 10) = 10 + \frac{1}{1-0.7L}2$$
> Usando a expans√£o do Lema 1:
> $$\hat{Y}_{t+1|t} = 10 + 2\sum_{k=0}^{\infty} (0.7)^k L^k$$
> Considerando que a expans√£o de $\frac{1}{1-0.7L}$ resulta em $1 + 0.7 L + 0.7^2 L^2 + 0.7^3 L^3 + ...$, e para simplifica√ß√£o, mantendo apenas o termo da itera√ß√£o atual:
> $$ \hat{Y}_{t+1|t} = 10 + 2(1) = 12 $$
> Este exemplo demonstra como os par√¢metros $\phi$ e $\theta$ influenciam a previs√£o, e como o valor atual da s√©rie temporal $Y_t$ √© utilizado para calcular a previs√£o para o pr√≥ximo per√≠odo.

**Lema 1**  
A express√£o $\frac{1}{1 - \phi L}$ pode ser expandida em uma s√©rie geom√©trica como:
$$ \frac{1}{1 - \phi L} = 1 + \phi L + \phi^2 L^2 + \phi^3 L^3 + \ldots = \sum_{k=0}^{\infty} \phi^k L^k $$
*Proof:* This is a standard result for geometric series. By multiplying both sides by $(1 - \phi L)$, we obtain
$(1 - \phi L)\sum_{k=0}^{\infty} \phi^k L^k = (1 - \phi L)(1 + \phi L + \phi^2 L^2 + \ldots) = 1 + \phi L + \phi^2 L^2 + \ldots - \phi L - \phi^2 L^2 - \ldots = 1$.

### Desenvolvimento
Expandindo a previs√£o para o caso geral de s per√≠odos √† frente [^4.2.39]:
$$ \hat{Y}_{t+s|t} = \mu + \frac{\phi^s + \theta \phi^{s-1}}{1 - \phi L} (Y_t - \mu) $$
Essa express√£o indica que a previs√£o de *s* per√≠odos √† frente √© uma combina√ß√£o da m√©dia $\mu$ e uma combina√ß√£o linear das observa√ß√µes passadas ponderadas pelo termo $\frac{\phi^s+\theta\phi^{s-1}}{1-\phi L}$. Notavelmente, este termo cont√©m pot√™ncias de $\phi$, o que indica que a previs√£o se torna mais dependente de $\mu$ √† medida que *s* aumenta e que o peso das observa√ß√µes passadas declina geometricamente em $\phi$. A intui√ß√£o √© de que, √† medida que o horizonte de previs√£o cresce, o peso dos dados passados diminui, e a previs√£o converge para a m√©dia $\mu$ no limite [^4.2.19].

**Teorema 1**
Utilizando a expans√£o do Lema 1, podemos reescrever a previs√£o de *s* per√≠odos √† frente como:
$$ \hat{Y}_{t+s|t} = \mu +  (\phi^s + \theta \phi^{s-1}) \sum_{k=0}^{\infty} \phi^k (Y_{t-k} - \mu) $$
*Prova:*
I.  Come√ßamos com a equa√ß√£o de previs√£o:
    $$ \hat{Y}_{t+s|t} = \mu + \frac{\phi^s + \theta \phi^{s-1}}{1 - \phi L} (Y_t - \mu) $$

II. Aplicamos o resultado do Lema 1, que afirma que $\frac{1}{1 - \phi L} = \sum_{k=0}^{\infty} \phi^k L^k$:
    $$ \hat{Y}_{t+s|t} = \mu +  (\phi^s + \theta \phi^{s-1}) \sum_{k=0}^{\infty} \phi^k L^k (Y_t - \mu) $$

III. Distribu√≠mos o operador de retardo $L^k$  no termo $(Y_t - \mu)$, o que significa que $L^k(Y_t - \mu) = (Y_{t-k} - \mu)$.
  $$ \hat{Y}_{t+s|t} = \mu +  (\phi^s + \theta \phi^{s-1}) \sum_{k=0}^{\infty} \phi^k (Y_{t-k} - \mu) $$
    
IV. Portanto, a previs√£o de *s* per√≠odos √† frente pode ser escrita como:
  $$ \hat{Y}_{t+s|t} = \mu +  (\phi^s + \theta \phi^{s-1}) \sum_{k=0}^{\infty} \phi^k (Y_{t-k} - \mu) $$
    ‚ñ†

Este resultado mostra que a previs√£o √© uma soma ponderada das observa√ß√µes passadas, onde os pesos diminuem exponencialmente com o tempo.

> üí° **Exemplo Num√©rico:**
> Continuando com o exemplo anterior, onde $\mu = 10$, $\phi = 0.7$, e $\theta = 0.3$, vamos calcular a previs√£o para dois per√≠odos √† frente ($s=2$). Usando a f√≥rmula:
> $$ \hat{Y}_{t+2|t} = 10 +  (0.7^2 + 0.3 \cdot 0.7^{2-1}) \sum_{k=0}^{\infty} 0.7^k (Y_{t-k} - 10) $$
> $$ \hat{Y}_{t+2|t} = 10 + (0.49 + 0.21) \sum_{k=0}^{\infty} 0.7^k (Y_{t-k} - 10) $$
> $$ \hat{Y}_{t+2|t} = 10 + 0.7 \sum_{k=0}^{\infty} 0.7^k (Y_{t-k} - 10) $$
> Vamos considerar para fins de exemplo apenas os dois termos mais recentes da s√©rie temporal, $Y_t = 12$ e $Y_{t-1} = 11$:
> $$ \hat{Y}_{t+2|t} \approx 10 + 0.7[0.7^0(12 - 10) + 0.7^1(11 - 10)] $$
> $$ \hat{Y}_{t+2|t} \approx 10 + 0.7[1(2) + 0.7(1)]$$
> $$ \hat{Y}_{t+2|t} \approx 10 + 0.7[2 + 0.7] = 10 + 0.7[2.7] = 10 + 1.89 = 11.89 $$
> Este exemplo mostra como a previs√£o para *s* = 2 incorpora dados passados com pesos decrescentes, e como o valor da previs√£o tende a se aproximar da m√©dia $\mu$ √† medida que o horizonte de previs√£o aumenta. Observe que estamos usando uma aproxima√ß√£o com poucos termos da s√©rie infinita, e que o resultado final ser√° mais preciso com o uso de mais termos.

Em situa√ß√µes pr√°ticas, √© mais √∫til expressar a previs√£o iterativamente:
$$ \hat{Y}_{t+s|t} = \mu + \phi (\hat{Y}_{t+s-1|t} - \mu) +  \theta \epsilon_{t+s-1} $$
A previs√£o para $s = 1$ resulta em
$$ \hat{Y}_{t+1|t} = \mu + \phi(Y_t - \mu) + \theta\epsilon_{t}  $$
onde $\epsilon_t$ representa o erro do per√≠odo anterior. Em termos de previs√µes, o termo de erro no futuro $\epsilon_{t+s-1}$ √© igual a zero, j√° que o erro √© por defini√ß√£o n√£o antecip√°vel.

**Corol√°rio 1.1**
Para o caso de previs√£o de s per√≠odos √† frente, quando $s > 1$, temos  $\epsilon_{t+s-1}=0$, logo a express√£o iterativa se simplifica para:
$$ \hat{Y}_{t+s|t} = \mu + \phi (\hat{Y}_{t+s-1|t} - \mu)  $$
*Proof:*
I. Come√ßamos com a equa√ß√£o iterativa geral:
    $$ \hat{Y}_{t+s|t} = \mu + \phi (\hat{Y}_{t+s-1|t} - \mu) +  \theta \epsilon_{t+s-1} $$

II. Para previs√µes com horizonte $s > 1$, o erro futuro $\epsilon_{t+s-1}$ √© igual a zero, uma vez que n√£o √© poss√≠vel prever erros no futuro:
    $$ \epsilon_{t+s-1} = 0 $$

III. Substitu√≠mos $\epsilon_{t+s-1} = 0$ na equa√ß√£o geral:
    $$ \hat{Y}_{t+s|t} = \mu + \phi (\hat{Y}_{t+s-1|t} - \mu) +  \theta \cdot 0 $$

IV. Simplificamos a equa√ß√£o:
    $$ \hat{Y}_{t+s|t} = \mu + \phi (\hat{Y}_{t+s-1|t} - \mu)  $$
    ‚ñ†

> üí° **Exemplo Num√©rico:**
> Usando os mesmos par√¢metros do exemplo anterior ($\mu = 10$, $\phi = 0.7$, e $\theta = 0.3$), e os valores $Y_t = 12$, e $Y_{t-1} = 11$, vamos calcular a previs√£o iterativamente para $s=1$ e $s=2$:
> Primeiro, calculamos a previs√£o para $s=1$:
> $$\hat{Y}_{t+1|t} = \mu + \phi(Y_t - \mu) + \theta\epsilon_{t}$$
> Precisamos calcular $\epsilon_t$. Usando a equa√ß√£o do processo ARMA(1,1):
> $$ \epsilon_t = (Y_t - \mu) - \phi (Y_{t-1} - \mu) - \theta \epsilon_{t-1} $$
> Assumindo $\epsilon_{t-1} = 0$, temos:
> $$ \epsilon_t = (12 - 10) - 0.7 (11 - 10) - 0.3(0) = 2 - 0.7 = 1.3$$
> Assim, a previs√£o para $s=1$ √©:
> $$\hat{Y}_{t+1|t} = 10 + 0.7(12 - 10) + 0.3(1.3) = 10 + 1.4 + 0.39 = 11.79 $$
> Agora, para $s=2$, usamos a previs√£o iterativa com $\epsilon_{t+1} = 0$:
> $$\hat{Y}_{t+2|t} = \mu + \phi (\hat{Y}_{t+1|t} - \mu) $$
> $$\hat{Y}_{t+2|t} = 10 + 0.7(11.79 - 10) = 10 + 0.7(1.79) = 10 + 1.253 = 11.253$$
> Este exemplo ilustra como a previs√£o iterativa √© usada na pr√°tica e como a previs√£o de um per√≠odo √© utilizada para calcular a previs√£o do per√≠odo seguinte.

Uma vez que $\epsilon_t$ pode ser obtido de forma recursiva a partir da equa√ß√£o de processo ARMA(1,1)
$$ \epsilon_t = (Y_t - \mu) - \phi (Y_{t-1} - \mu) - \theta \epsilon_{t-1} $$

Substituindo $\epsilon_t$ na express√£o de previs√£o, obtemos a forma recursiva do processo de previs√£o:
$$ \hat{Y}_{t+1|t} =  \mu + (\phi + \theta) (Y_t - \mu) - \theta\phi(Y_{t-1} - \mu) - \theta^2 \epsilon_{t-1} $$
*Proof:*
I. Come√ßamos com a equa√ß√£o de previs√£o de um per√≠odo √† frente:
    $$ \hat{Y}_{t+1|t} = \mu + \phi(Y_t - \mu) + \theta\epsilon_{t}  $$
II. Substitu√≠mos $\epsilon_t$ pela sua defini√ß√£o em termos de $Y_t$, $Y_{t-1}$ e $\epsilon_{t-1}$:
    $$ \hat{Y}_{t+1|t} = \mu + \phi(Y_t - \mu) + \theta\left[(Y_t - \mu) - \phi (Y_{t-1} - \mu) - \theta \epsilon_{t-1}\right]  $$
III. Expandimos a express√£o:
$$ \hat{Y}_{t+1|t} = \mu + \phi(Y_t - \mu) + \theta(Y_t - \mu) - \theta\phi (Y_{t-1} - \mu) - \theta^2 \epsilon_{t-1}  $$
IV. Simplificamos a express√£o para obter a forma recursiva:
    $$ \hat{Y}_{t+1|t} =  \mu + (\phi + \theta) (Y_t - \mu) - \theta\phi(Y_{t-1} - \mu) - \theta^2 \epsilon_{t-1} $$
    ‚ñ†

> üí° **Exemplo Num√©rico:**
> Utilizando novamente os par√¢metros $\mu = 10$, $\phi = 0.7$, $\theta = 0.3$, $Y_t = 12$, e $Y_{t-1} = 11$, e $\epsilon_{t-1} = 0$, vamos calcular a previs√£o $\hat{Y}_{t+1|t}$ usando a forma recursiva:
> $$ \hat{Y}_{t+1|t} = 10 + (0.7 + 0.3) (12 - 10) - 0.3 \cdot 0.7 (11 - 10) - 0.3^2 (0) $$
> $$ \hat{Y}_{t+1|t} = 10 + (1)(2) - 0.21(1) - 0 = 10 + 2 - 0.21 = 11.79 $$
> Este resultado coincide com o resultado da previs√£o para $s=1$ obtido atrav√©s da abordagem iterativa, demonstrando a equival√™ncia entre as duas formas de calcular a previs√£o.

### Conclus√£o
Neste cap√≠tulo, detalhamos como obter a previs√£o de *s* per√≠odos √† frente para um processo **ARMA(1,1)** em termos das observa√ß√µes passadas e do operador de retardo. A f√≥rmula obtida revela a import√¢ncia dos par√¢metros $\phi$ e $\theta$ na determina√ß√£o do comportamento de longo prazo da previs√£o. A forma recursiva derivada tamb√©m √© pr√°tica para computa√ß√£o. A an√°lise das express√µes obtidas fornece uma compreens√£o mais profunda da din√¢mica do processo **ARMA(1,1)**, e como ele √© adequado para modelar dados de s√©ries temporais onde os dados presentes s√£o afetados pelos valores passados da s√©rie.

### Refer√™ncias
[^4.2.13]:  Equa√ß√£o que define o processo MA(q).
[^4.2.16]:  F√≥rmula geral para proje√ß√£o linear.
[^4.2.19]:  F√≥rmula da previs√£o linear para um processo AR(1).
[^4.2.37]:  Equa√ß√£o que define o processo ARMA(1,1).
[^4.2.38]: Express√£o para  $(1+\theta L)/(1-\phi L)$.
[^4.2.39]: Express√£o de previs√£o para s per√≠odos √† frente em um ARMA(1,1)
[^4.2.40]:  Express√£o de previs√£o para um per√≠odo √† frente em um ARMA(1,1).
<!-- END -->
