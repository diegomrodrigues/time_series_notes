## Somas de Processos ARMA e Fun√ß√µes Geradoras de Autocovari√¢ncia

### Introdu√ß√£o
Este cap√≠tulo continua a explora√ß√£o das propriedades de s√©ries temporais resultantes da combina√ß√£o linear de processos estoc√°sticos, com foco na an√°lise das fun√ß√µes geradoras de autocovari√¢ncia (FGAC). Como visto anteriormente, a soma de processos pode resultar em novos processos com estruturas mais complexas [^4.7.1], [^4.7.2], [^4.7.3], [^4.7.5], [^4.7.7], [^4.7.15], [^4.7.16], [^4.7.21], [^4.7.27]. O objetivo principal deste cap√≠tulo √© demonstrar formalmente que a fun√ß√£o geradora de autocovari√¢ncia de uma soma de processos √© a soma das fun√ß√µes geradoras de autocovari√¢ncia de cada processo individualmente. Esta propriedade, derivada da √°lgebra formal de s√©ries, fornece uma ferramenta poderosa para analisar e compreender as propriedades espectrais da soma de processos estoc√°sticos e para derivar resultados sobre a ordem do processo resultante da soma.

### Conceitos Fundamentais

#### Fun√ß√µes Geradoras de Autocovari√¢ncia
A fun√ß√£o geradora de autocovari√¢ncia (FGAC) de um processo estacion√°rio $X_t$, denotada por $g_X(z)$, √© definida como a transformada Z das suas autocovari√¢ncias $\gamma_j^x$:
$$g_X(z) = \sum_{j=-\infty}^{\infty} \gamma_j^x z^j,$$
onde $\gamma_j^x = E[(X_t - \mu_X)(X_{t-j} - \mu_X)]$ √© a autocovari√¢ncia de $X_t$ no lag $j$, sendo $\mu_X$ a m√©dia do processo. A FGAC oferece uma forma concisa de representar todas as autocovari√¢ncias de um processo, e tamb√©m permite a manipula√ß√£o de propriedades temporais usando √°lgebra formal de s√©ries. Para um processo de m√©dia m√≥vel, MA(q), a FGAC √© dada por:
$$g_X(z) = \sigma^2 \theta(z)\theta(z^{-1})$$
onde $\theta(z)$ √© o polin√¥mio em z correspondente aos par√¢metros do processo MA. Similarmente, para um processo autorregressivo, AR(p), a FGAC pode ser deduzida a partir de suas equa√ß√µes.
> üí° **Exemplo Num√©rico:** Para um processo MA(1) $X_t = u_t + \delta u_{t-1}$, onde $u_t$ √© ru√≠do branco com vari√¢ncia $\sigma^2$, a FGAC √© dada por:
> $$g_X(z) = \sigma^2(1 + \delta z)(1 + \delta z^{-1}) = \sigma^2(1 + \delta z + \delta z^{-1} + \delta^2).$$
> Para um processo AR(1) $X_t = \phi X_{t-1} + u_t$, a FGAC √© dada por:
> $$g_X(z) = \frac{\sigma^2}{(1-\phi z)(1-\phi z^{-1})}.$$
>
>  **Exemplo Num√©rico (MA(1)):**
>  Considere um processo MA(1) com $\delta = 0.8$ e $\sigma^2 = 1$. A FGAC seria:
>  $$g_X(z) = 1 \cdot (1 + 0.8z)(1 + 0.8z^{-1}) = 1 \cdot (1 + 0.8z + 0.8z^{-1} + 0.64) = 1.64 + 0.8z + 0.8z^{-1}$$
>  Isso implica que $\gamma_0^x = 1.64$, $\gamma_1^x = \gamma_{-1}^x = 0.8$, e $\gamma_j^x = 0$ para $|j| > 1$.
>
>  **Exemplo Num√©rico (AR(1)):**
>  Considere um processo AR(1) com $\phi = 0.6$ e $\sigma^2 = 2$. A FGAC seria:
>  $$g_X(z) = \frac{2}{(1 - 0.6z)(1 - 0.6z^{-1})} = \frac{2}{1 - 0.6z - 0.6z^{-1} + 0.36}$$
>  Expandindo em s√©rie de pot√™ncias, ter√≠amos:
> $$g_X(z) = 2 (1 + 0.6z + 0.36z^2 + 0.216z^3 + \ldots)(1 + 0.6z^{-1} + 0.36z^{-2} + 0.216z^{-3} + \ldots)$$
>  Os coeficientes de $z^j$ corresponderiam √†s autocovari√¢ncias. Por exemplo, o coeficiente de $z^0$ corresponde a $\gamma_0 = 2 / (1 - 0.36) \approx 3.125$, a vari√¢ncia do processo.

#### Soma de Processos e suas FGACs
Considere dois processos estacion√°rios por covari√¢ncia, $X_t$ e $W_t$, com m√©dias $\mu_X$ e $\mu_W$, autocovari√¢ncias $\gamma_j^x$ e $\gamma_j^w$, e FGACs $g_X(z)$ e $g_W(z)$, respectivamente.  Seja $Y_t$ a soma desses dois processos:
$$Y_t = X_t + W_t.$$
Assumimos que $X_t$ e $W_t$ s√£o n√£o correlacionados, ou seja, $E[(X_t - \mu_X)(W_{t-j} - \mu_W)] = 0$ para todos os lags $j$. Como visto anteriormente, a autocovari√¢ncia de $Y_t$ √© dada por:
$$\gamma_j^y = E[(Y_t - \mu_Y)(Y_{t-j} - \mu_Y)] = E[(X_t - \mu_X + W_t - \mu_W)(X_{t-j} - \mu_X + W_{t-j} - \mu_W)] = \gamma_j^x + \gamma_j^w$$
onde $\mu_Y = \mu_X + \mu_W$ e $\gamma_j^y$ √© a autocovari√¢ncia de $Y_t$ no lag $j$.

> üí° **Exemplo Num√©rico:**
> Considere um processo $X_t$ com autocovari√¢ncias $\gamma_0^x = 2$, $\gamma_1^x = 1$, $\gamma_j^x = 0$ para $|j| > 1$, e um processo $W_t$ com autocovari√¢ncias $\gamma_0^w = 3$, $\gamma_1^w = -0.5$, $\gamma_2^w = 0.2$ e $\gamma_j^w = 0$ para $|j| > 2$. As autocovari√¢ncias do processo resultante $Y_t= X_t+W_t$ ser√£o dadas por $\gamma_0^y = 2+3=5$, $\gamma_1^y = 1-0.5=0.5$ e $\gamma_2^y = 0+0.2=0.2$ e $\gamma_j^y = 0$ para $|j| > 2$.
>
> **Observa√ß√£o 1.1:** √â importante notar que, se os processos $X_t$ e $W_t$ s√£o correlacionados, ent√£o a autocovari√¢ncia resultante de $Y_t$ incluir√° termos de covari√¢ncia cruzada, ou seja, termos do tipo $Cov(X_t, W_{t-j})$. Especificamente, se $Cov(X_t, W_{t-j}) = \gamma_{j}^{xw}$, ent√£o
>  $$\gamma_j^y = \gamma_j^x + \gamma_j^w + \gamma_j^{xw} + \gamma_{-j}^{xw}$$.
>  Este resultado √© uma consequ√™ncia direta da bilinearidade da covari√¢ncia.  A an√°lise de processos correlacionados, entretanto, foge do escopo principal deste cap√≠tulo.

#### A Fun√ß√£o Geradora de Autocovari√¢ncia da Soma
Agora, vamos determinar a fun√ß√£o geradora de autocovari√¢ncia de $Y_t$. Usando a defini√ß√£o, temos:
$$g_Y(z) = \sum_{j=-\infty}^{\infty} \gamma_j^y z^j = \sum_{j=-\infty}^{\infty} (\gamma_j^x + \gamma_j^w)z^j$$
Pela linearidade da soma, podemos reescrever a equa√ß√£o anterior como:
$$g_Y(z) = \sum_{j=-\infty}^{\infty} \gamma_j^x z^j + \sum_{j=-\infty}^{\infty} \gamma_j^w z^j$$
Portanto,
$$g_Y(z) = g_X(z) + g_W(z)$$
Este resultado crucial demonstra que a fun√ß√£o geradora de autocovari√¢ncia de uma soma de processos estacion√°rios independentes √© a soma das fun√ß√µes geradoras de autocovari√¢ncia dos processos individuais [^4.7.19]. Este resultado, derivado diretamente da √°lgebra formal de s√©ries, √© uma ferramenta poderosa para analisar processos de s√©ries temporais resultantes da combina√ß√£o linear de outros processos. A ordem do processo resultante √© dada pelo m√°ximo da ordem dos processos individuais, como demonstrado em outros cap√≠tulos.

> üí° **Exemplo Num√©rico:** Considerando o exemplo anterior, a fun√ß√£o geradora de autocovari√¢ncia de $X_t$ √© $g_X(z) = 2+z+z^{-1}$ e de $W_t$ √© $g_W(z) = 3-0.5z -0.5z^{-1} + 0.2z^2+0.2z^{-2}$. A FGAC de $Y_t$ ser√° a soma $g_Y(z) = 5+0.5z + 0.5z^{-1} + 0.2z^2 + 0.2z^{-2}$ onde os coeficientes s√£o as autocovari√¢ncias do processo $Y_t$ que, como vimos, s√£o a soma das autocovari√¢ncias de $X_t$ e $W_t$.
>
> **Observa√ß√£o 1.2:**  √â fundamental reconhecer que a propriedade $g_Y(z) = g_X(z) + g_W(z)$ se mant√©m apenas se $X_t$ e $W_t$ forem n√£o correlacionados. No caso geral de processos correlacionados, como mencionado em Observa√ß√£o 1.1,  a FGAC da soma envolver√° tamb√©m os termos de covari√¢ncia cruzada, resultando em uma express√£o mais complexa.

### Formaliza√ß√£o Matem√°tica

**Lema 1.1:**
Se $X_t$ e $W_t$ s√£o processos estoc√°sticos independentes, e $Y_t = X_t + W_t$, ent√£o a fun√ß√£o geradora de autocovari√¢ncia de $Y_t$, $g_Y(z)$, √© a soma das fun√ß√µes geradoras de autocovari√¢ncia de $X_t$ e $W_t$:
$$g_Y(z) = g_X(z) + g_W(z)$$
*Prova:*
I. Pela defini√ß√£o, $g_Y(z) = \sum_{j=-\infty}^{\infty} \gamma_j^y z^j$, onde $\gamma_j^y = Cov(Y_t, Y_{t-j})$ √© a autocovari√¢ncia de $Y_t$ no lag $j$.
II. Dado que $Y_t = X_t + W_t$, temos
$$\gamma_j^y = Cov(X_t + W_t, X_{t-j} + W_{t-j})$$
III. Devido √† n√£o correla√ß√£o entre $X_t$ e $W_t$, temos:
$$\gamma_j^y = Cov(X_t, X_{t-j}) + Cov(W_t, W_{t-j}) = \gamma_j^x + \gamma_j^w$$
IV. Substituindo esta rela√ß√£o na express√£o para $g_Y(z)$:
$$g_Y(z) = \sum_{j=-\infty}^{\infty} (\gamma_j^x + \gamma_j^w) z^j$$
V. Pela linearidade da soma, obtemos:
$$g_Y(z) = \sum_{j=-\infty}^{\infty} \gamma_j^x z^j + \sum_{j=-\infty}^{\infty} \gamma_j^w z^j = g_X(z) + g_W(z)$$
VI. Portanto, a FGAC de $Y_t$ √© a soma das FGACs de $X_t$ e $W_t$. $\blacksquare$

**Teorema 1**
A fun√ß√£o geradora de autocovari√¢ncia de uma soma de processos estacion√°rios por covari√¢ncia n√£o correlacionados √© a soma das fun√ß√µes geradoras de autocovari√¢ncia dos processos individuais.
*Prova:*
I. Sejam $X_t$ e $W_t$ dois processos estacion√°rios por covari√¢ncia, n√£o correlacionados.
II. Defina $Y_t = X_t + W_t$.
III. A autocovari√¢ncia de $Y_t$ no lag $j$ √© $\gamma_j^y = Cov(Y_t, Y_{t-j}) = Cov(X_t + W_t, X_{t-j} + W_{t-j})$.
IV. Como $X_t$ e $W_t$ s√£o n√£o correlacionados, $Cov(X_t, W_{t-j}) = Cov(W_t, X_{t-j}) = 0$.
V. Portanto, $\gamma_j^y = Cov(X_t, X_{t-j}) + Cov(W_t, W_{t-j}) = \gamma_j^x + \gamma_j^w$.
VI. A fun√ß√£o geradora de autocovari√¢ncia de $Y_t$ √© definida como $g_Y(z) = \sum_{j=-\infty}^{\infty} \gamma_j^y z^j$.
VII. Substituindo $\gamma_j^y$, obtemos:
$$g_Y(z) = \sum_{j=-\infty}^{\infty} (\gamma_j^x + \gamma_j^w)z^j = \sum_{j=-\infty}^{\infty} \gamma_j^x z^j + \sum_{j=-\infty}^{\infty} \gamma_j^w z^j = g_X(z) + g_W(z)$$
VIII. Portanto, a FGAC de $Y_t$ √© a soma das FGACs de $X_t$ e $W_t$. $\blacksquare$
Este teorema generaliza o Lema 1.1 para dois processos estacion√°rios por covari√¢ncia.

> üí° **Exemplo Num√©rico:** Considere que $X_t$ √© um processo MA(1), com par√¢metro $\delta = 0.7$ e ru√≠do branco com vari√¢ncia $\sigma_u^2 = 1$ e $W_t$ √© um processo AR(1), com par√¢metro $\rho = 0.4$ e ru√≠do branco com vari√¢ncia $\sigma_v^2 = 2$. Ent√£o,
> $$g_X(z) = (1 + 0.7z)(1 + 0.7z^{-1}) = 1 + 0.7z + 0.7z^{-1} + 0.49$$
> $$g_W(z) = \frac{2}{(1-0.4z)(1-0.4z^{-1})} = \frac{2}{1 - 0.4z - 0.4z^{-1} + 0.16}$$
> A FGAC de $Y_t = X_t + W_t$ ser√° a soma dessas fun√ß√µes:
> $$g_Y(z) = g_X(z) + g_W(z) = 1 + 0.7z + 0.7z^{-1} + 0.49 + \frac{2}{1 - 0.4z - 0.4z^{-1} + 0.16}$$
> Note que o coeficiente de $z^0$ da FGAC,  √© a soma das vari√¢ncias (autocovari√¢ncias no lag zero) de cada processo: $1 + 0.49 + \frac{2}{1 - 0.16}$. A an√°lise dos termos em $z$ e $z^{-1}$ indicar√° os par√¢metros do processo ARMA resultante.
>
>  **Exemplo Num√©rico:** Para exemplificar, vamos calcular explicitamente alguns termos.
> Suponha $X_t$ √© MA(1) com $\delta = 0.5$ e $\sigma_u^2 = 1$ e $W_t$ √© um ru√≠do branco com vari√¢ncia $\sigma_v^2 = 0.5$.
>  $$g_X(z) = (1+0.5z)(1+0.5z^{-1}) = 1 + 0.5z + 0.5z^{-1} + 0.25 = 1.25 + 0.5z + 0.5z^{-1}$$
>  $$g_W(z) = 0.5$$
> Ent√£o
> $$g_Y(z) = g_X(z) + g_W(z) = 1.25 + 0.5z + 0.5z^{-1} + 0.5 = 1.75 + 0.5z + 0.5z^{-1}$$
>  As autocovari√¢ncias de $Y_t$ s√£o $\gamma_0^y = 1.75$, $\gamma_1^y = \gamma_{-1}^y = 0.5$, e $\gamma_j^y = 0$ para $|j|>1$.
>  Podemos verificar isso diretamente com:
>  $\gamma_0^x = 1 + 0.5^2 = 1.25$, $\gamma_1^x = 0.5$, $\gamma_j^x = 0$ para $|j|>1$,
>  $\gamma_0^w = 0.5$ e $\gamma_j^w = 0$ para $|j|>0$.
>  Ent√£o $\gamma_0^y = \gamma_0^x + \gamma_0^w = 1.25 + 0.5 = 1.75$, $\gamma_1^y = \gamma_1^x + \gamma_1^w = 0.5 + 0 = 0.5$ e $\gamma_j^y = 0$ para $|j|>1$.

**Teorema 1.1** (Generaliza√ß√£o para n processos)
A fun√ß√£o geradora de autocovari√¢ncia de uma soma de *n* processos estacion√°rios por covari√¢ncia n√£o correlacionados √© a soma das fun√ß√µes geradoras de autocovari√¢ncia dos processos individuais.
*Prova:*
A prova segue por indu√ß√£o. J√° estabelecemos o caso base com dois processos no Teorema 1. Suponha que a propriedade se mant√©m para *k* processos, ou seja, $g_{Y_k}(z) = \sum_{i=1}^{k} g_{X_i}(z)$, onde $Y_k = \sum_{i=1}^k X_i$ e todos os processos $X_i$ s√£o n√£o correlacionados. Agora, considere a soma de *k+1* processos $Y_{k+1} = Y_k + X_{k+1}$. Pelo Teorema 1, e dado que $X_{k+1}$ √© n√£o correlacionado com cada $X_i$ e portanto n√£o correlacionado com a soma $Y_k$, temos
$$g_{Y_{k+1}}(z) = g_{Y_k}(z) + g_{X_{k+1}}(z) = \sum_{i=1}^{k} g_{X_i}(z) + g_{X_{k+1}}(z) = \sum_{i=1}^{k+1} g_{X_i}(z)$$.
Portanto, por indu√ß√£o, a propriedade se mant√©m para qualquer n√∫mero finito de processos n√£o correlacionados.  $\blacksquare$

**Observa√ß√£o 1**
A propriedade de que a fun√ß√£o geradora de autocovari√¢ncia de uma soma √© a soma das fun√ß√µes geradoras de autocovari√¢ncia dos processos individuais depende crucialmente da n√£o correla√ß√£o dos processos. Se $X_t$ e $W_t$ forem correlacionados, os termos cruzados $Cov(X_t, W_{t-j})$ n√£o se anulam e a fun√ß√£o geradora de autocovari√¢ncia resultante seria mais complexa.

### Implica√ß√µes e Interpreta√ß√µes
A propriedade de que a fun√ß√£o geradora de autocovari√¢ncia da soma de processos √© a soma das fun√ß√µes geradoras de autocovari√¢ncia individuais, al√©m de ser um resultado da √°lgebra formal de s√©ries, tem importantes implica√ß√µes pr√°ticas na an√°lise de s√©ries temporais. Ao somar dois processos estoc√°sticos, a estrutura da fun√ß√£o geradora de autocovari√¢ncia resultante revela que as caracter√≠sticas temporais dos processos originais s√£o preservadas, e as autocovari√¢ncias s√£o combinadas de forma aditiva. Esta propriedade √© fundamental para entender as caracter√≠sticas espectrais de processos resultantes de combina√ß√µes lineares.
Em particular, quando os processos s√£o n√£o correlacionados, a an√°lise das ra√≠zes dos polin√¥mios em $z$ presentes na fun√ß√£o geradora de autocovari√¢ncia da soma, podem ser usadas para obter informa√ß√µes sobre a ordem e os par√¢metros do processo resultante, como visto nos cap√≠tulos anteriores [^4.7.12], [^4.7.20], [^4.7.21], [^4.7.27], [^4.8.4]. Em termos pr√°ticos, esta propriedade permite a an√°lise da estrutura temporal dos processos resultantes de opera√ß√µes lineares, como somas, de forma mais eficiente e sistem√°tica.

### Conclus√£o
Este cap√≠tulo explorou as propriedades da fun√ß√£o geradora de autocovari√¢ncia em rela√ß√£o √† soma de processos estoc√°sticos, demonstrando que a FGAC da soma √© a soma das FGACs dos processos individuais. Este resultado √© uma consequ√™ncia da √°lgebra formal de s√©ries, e oferece uma ferramenta poderosa para analisar a estrutura temporal de processos resultantes de combina√ß√µes lineares, como a combina√ß√£o de processos MA, AR, e outros processos lineares. A demonstra√ß√£o formal da propriedade de soma de FGACs oferece uma base s√≥lida para o estudo de modelos de s√©ries temporais resultantes da combina√ß√£o de processos, e tamb√©m auxilia na compreens√£o das propriedades espectrais dos processos resultantes.
### Refer√™ncias
[^4.7.1]: ... *[Defini√ß√£o de um processo MA(1)]*
[^4.7.2]: ... *[Autocovari√¢ncias de um processo MA(1)]*
[^4.7.3]: ... *[Defini√ß√£o de ru√≠do branco]*
[^4.7.5]: ... *[Defini√ß√£o da s√©rie Y como soma de MA(1) e ru√≠do branco]*
[^4.7.7]: ... *[Representa√ß√£o MA(1) para Y]*
[^4.7.15]: ... *[Reescrita da representa√ß√£o MA(1) com u e v]*
[^4.7.16]: ... *[Lag distribu√≠do da serie epsilon]*
[^4.7.21]: ... *[Soma de MA resulta em MA]*
[^4.7.27]: ... *[Soma de AR(1) com AR(1) resulta em um ARMA(2,1)]*
[^4.8.4]: ... *[Representa√ß√£o de processos com polin√¥mios]*
<!-- END -->
