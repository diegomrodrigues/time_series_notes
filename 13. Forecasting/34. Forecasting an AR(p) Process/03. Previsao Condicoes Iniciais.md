## Representa√ß√£o da Previs√£o AR(p) em Termos de Condi√ß√µes Iniciais e Choques Futuros
### Introdu√ß√£o
Em continuidade aos estudos sobre previs√£o de processos autorregressivos (AR(p)), este cap√≠tulo aborda a representa√ß√£o da previs√£o em termos de condi√ß√µes iniciais e choques futuros, utilizando operadores de defasagem. Anteriormente, estabelecemos a lei das proje√ß√µes iteradas como um m√©todo eficiente para o c√°lculo de previs√µes multi-step-ahead, com foco em sua natureza recursiva [^2]. Agora, exploraremos como os operadores de defasagem facilitam uma representa√ß√£o compacta e computacionalmente eficiente da previs√£o, essencial para processamento de grandes conjuntos de dados, oferecendo uma alternativa √† abordagem recursiva direta.

### Representa√ß√£o da Previs√£o com Operadores de Defasagem
A representa√ß√£o de um processo AR(p) utilizando operadores de defasagem √© uma forma concisa e eficaz de expressar a din√¢mica da s√©rie temporal. Um processo AR(p) pode ser escrito como [^2]:
$$ (1 - \phi_1L - \phi_2L^2 - \dots - \phi_pL^p)(Y_t - \mu) = \epsilon_t $$
onde $L$ √© o operador de defasagem, tal que $L^k Y_t = Y_{t-k}$. Reorganizando a equa√ß√£o acima, podemos expressar $Y_t$ como uma fun√ß√£o de seus valores passados e do choque atual:
$$ Y_t - \mu = \phi_1(Y_{t-1} - \mu) + \phi_2(Y_{t-2} - \mu) + \dots + \phi_p(Y_{t-p} - \mu) + \epsilon_t $$

Esta representa√ß√£o, no entanto, n√£o √© diretamente √∫til para expressar a previs√£o de s per√≠odos √† frente em termos de condi√ß√µes iniciais (os valores $Y_t, Y_{t-1}, \dots$ no tempo $t$) e os choques futuros $(\epsilon_{t+1}, \epsilon_{t+2}, \dots)$. Para isso, precisamos derivar uma forma que explicite essa rela√ß√£o.
A equa√ß√£o [4.2.20] do contexto anterior fornece uma base para expressar $Y_{t+s}-\mu$ em termos de condi√ß√µes iniciais e choques futuros:
$$ Y_{t+s} - \mu = f_1^{(s)}(Y_t - \mu) + f_2^{(s)}(Y_{t-1} - \mu) + \dots + f_p^{(s)}(Y_{t-p+1} - \mu) + \epsilon_{t+s} + \psi_1\epsilon_{t+s-1} + \dots + \psi_{s-1}\epsilon_{t+1} $$
onde $f_i^{(s)}$ s√£o os coeficientes que dependem dos par√¢metros do modelo, como demonstrado no Lema 1 do contexto anterior. Esta equa√ß√£o √© fundamental pois separa explicitamente os componentes que afetam $Y_{t+s}$ e permite identificar a contribui√ß√£o de cada um na previs√£o √≥tima.
A previs√£o √≥tima no instante $t$ para $Y_{t+s}$ √© dada por:
$$ \hat{Y}_{t+s|t} = \mu + f_1^{(s)}(Y_t - \mu) + f_2^{(s)}(Y_{t-1} - \mu) + \dots + f_p^{(s)}(Y_{t-p+1} - \mu) $$
Note que a previs√£o √≥tima exclui os choques futuros, j√° que ela se baseia nas informa√ß√µes dispon√≠veis no tempo *t*. Os choques futuros, $\epsilon_{t+1}, \epsilon_{t+2}, ..., \epsilon_{t+s}$, s√£o imprevis√≠veis no instante *t* e n√£o fazem parte da previs√£o √≥tima, mas sim do erro de previs√£o.
Essa separa√ß√£o √© essencial para a an√°lise da precis√£o da previs√£o, j√° que podemos agora analisar os impactos das inova√ß√µes na incerteza da previs√£o.
Formalmente, esta express√£o corresponde a aplicar o operador de aniquila√ß√£o do operador de defasagem, indicado por $[.]_+$ e definido em [4.2.8] do contexto anterior [^2].
Essa forma da previs√£o √© extremamente √∫til para computa√ß√£o em *datasets* grandes, j√° que ela permite o c√°lculo direto da previs√£o sem a necessidade de um ciclo de proje√ß√µes recursivas.

> üí° **Exemplo Num√©rico:**
> Vamos considerar um processo AR(2) com $\mu = 2$, $\phi_1 = 0.5$ e $\phi_2 = 0.2$. Suponha que temos os valores $Y_t=3$, $Y_{t-1} = 2.5$ e $Y_{t-2} = 2$. Utilizaremos operadores de defasagem para representar as previs√µes de 1 e 2 passos √† frente.
>
>1.  **Representa√ß√£o da previs√£o de 1 passo √† frente:**
>$$ Y_{t+1} - 2 = 0.5(Y_t - 2) + 0.2(Y_{t-1} - 2) + \epsilon_{t+1} $$
>A previs√£o √≥tima √©:
> $$ \hat{Y}_{t+1|t} - 2 = 0.5(3 - 2) + 0.2(2.5 - 2) $$
> $$ \hat{Y}_{t+1|t} - 2 = 0.5(1) + 0.2(0.5) = 0.5 + 0.1 = 0.6 $$
> $$ \hat{Y}_{t+1|t} = 2.6 $$
>
>2.  **Representa√ß√£o da previs√£o de 2 passos √† frente:**
> Utilizando a lei das proje√ß√µes iteradas e substituindo recursivamente, obtemos:
> $$ Y_{t+2} - 2 = 0.5(Y_{t+1} - 2) + 0.2(Y_t - 2) + \epsilon_{t+2} $$
> Para expressar esta equa√ß√£o em termos de $Y_t$ e $Y_{t-1}$, precisamos expandir $Y_{t+1}$:
> $$ Y_{t+1} - 2 = 0.5(Y_t - 2) + 0.2(Y_{t-1} - 2) + \epsilon_{t+1} $$
> Substituindo na equa√ß√£o para $Y_{t+2}$:
> $$ Y_{t+2} - 2 = 0.5[0.5(Y_t - 2) + 0.2(Y_{t-1} - 2) + \epsilon_{t+1}] + 0.2(Y_t - 2) + \epsilon_{t+2} $$
> $$ Y_{t+2} - 2 = (0.5^2 + 0.2)(Y_t - 2) + 0.5*0.2(Y_{t-1} - 2) + 0.5\epsilon_{t+1} + \epsilon_{t+2} $$
> $$ Y_{t+2} - 2 = 0.45(Y_t - 2) + 0.1(Y_{t-1} - 2) + 0.5\epsilon_{t+1} + \epsilon_{t+2} $$
> A previs√£o √≥tima √©:
> $$ \hat{Y}_{t+2|t} - 2 = 0.45(3 - 2) + 0.1(2.5 - 2) $$
> $$ \hat{Y}_{t+2|t} - 2 = 0.45(1) + 0.1(0.5) = 0.45 + 0.05 = 0.5 $$
> $$ \hat{Y}_{t+2|t} = 2.5 $$
>
> Note que os coeficientes multiplicando os valores passados na previs√£o de dois passos √† frente ($0.45$ e $0.1$) s√£o diferentes daqueles na previs√£o de um passo √† frente ($0.5$ e $0.2$), o que √© esperado devido a depend√™ncia do horizonte de previs√£o. A representa√ß√£o em termos de condi√ß√µes iniciais e choques futuros explicita a estrutura dos componentes da previs√£o.

**Proposi√ß√£o 1**
A representa√ß√£o da previs√£o de um processo AR(p) pode ser expressa de forma matricial, facilitando a implementa√ß√£o computacional e a an√°lise da estrutura do modelo. Dado um processo AR(p) com a representa√ß√£o
$$Y_t - \mu = \phi_1(Y_{t-1} - \mu) + \phi_2(Y_{t-2} - \mu) + \dots + \phi_p(Y_{t-p} - \mu) + \epsilon_t$$
podemos definir o vetor de estados $\mathbf{X}_t = [Y_t-\mu, Y_{t-1}-\mu, \dots, Y_{t-p+1}-\mu]^T$. A din√¢mica do processo pode ser reescrita como:
$$ \mathbf{X}_{t+1} = \mathbf{A}\mathbf{X}_t + \mathbf{B}\epsilon_{t+1} $$
Onde $\mathbf{A}$ √© a matriz de companheira de dimens√£o $p \times p$:
$$ \mathbf{A} = \begin{bmatrix}
\phi_1 & \phi_2 & \dots & \phi_{p-1} & \phi_p \\
1 & 0 & \dots & 0 & 0 \\
0 & 1 & \dots & 0 & 0 \\
\vdots & \vdots & \ddots & \vdots & \vdots \\
0 & 0 & \dots & 1 & 0
\end{bmatrix}
$$
e $\mathbf{B}$ √© um vetor $p \times 1$:
$$ \mathbf{B} = \begin{bmatrix}
1 \\ 0 \\ 0 \\ \vdots \\ 0
\end{bmatrix}
$$

*Proof.*
Vamos provar a Proposi√ß√£o 1:

I. Definimos o vetor de estados $\mathbf{X}_t$ como $\mathbf{X}_t = [Y_t-\mu, Y_{t-1}-\mu, \dots, Y_{t-p+1}-\mu]^T$.

II. Queremos expressar $\mathbf{X}_{t+1}$ em fun√ß√£o de $\mathbf{X}_t$ e $\epsilon_{t+1}$. O vetor $\mathbf{X}_{t+1}$ √© dado por $\mathbf{X}_{t+1} = [Y_{t+1}-\mu, Y_{t}-\mu, \dots, Y_{t-p+2}-\mu]^T$.

III. A primeira componente de $\mathbf{X}_{t+1}$ √© $Y_{t+1}-\mu$. Do processo AR(p), temos:
    $$ Y_{t+1} - \mu = \phi_1(Y_t - \mu) + \phi_2(Y_{t-1} - \mu) + \dots + \phi_p(Y_{t-p+1} - \mu) + \epsilon_{t+1} $$

IV. As componentes restantes de $\mathbf{X}_{t+1}$ s√£o apenas defasagens dos componentes de $\mathbf{X}_t$, ou seja,  $Y_{t}-\mu, Y_{t-1}-\mu, \dots, Y_{t-p+2}-\mu$.

V. Podemos escrever $\mathbf{X}_{t+1}$ como:
$$ \begin{bmatrix}
Y_{t+1}-\mu \\
Y_t-\mu \\
Y_{t-1}-\mu \\
\vdots \\
Y_{t-p+2}-\mu
\end{bmatrix} = 
\begin{bmatrix}
\phi_1 & \phi_2 & \dots & \phi_{p-1} & \phi_p \\
1 & 0 & \dots & 0 & 0 \\
0 & 1 & \dots & 0 & 0 \\
\vdots & \vdots & \ddots & \vdots & \vdots \\
0 & 0 & \dots & 1 & 0
\end{bmatrix}
\begin{bmatrix}
Y_{t}-\mu \\
Y_{t-1}-\mu \\
\vdots \\
Y_{t-p+1}-\mu
\end{bmatrix} +
\begin{bmatrix}
1 \\
0 \\
0 \\
\vdots \\
0
\end{bmatrix} \epsilon_{t+1}
$$
VI.  Essa equa√ß√£o corresponde √† forma matricial $\mathbf{X}_{t+1} = \mathbf{A}\mathbf{X}_t + \mathbf{B}\epsilon_{t+1}$, onde $\mathbf{A}$ √© a matriz companheira e $\mathbf{B}$ √© o vetor indicado.
    
Portanto, provamos que a representa√ß√£o do processo AR(p) pode ser expressa na forma matricial dada. ‚ñ†

> üí° **Exemplo Num√©rico:**
> Vamos ilustrar a representa√ß√£o matricial para um processo AR(2) com $\mu=0$, $\phi_1 = 0.6$ e $\phi_2 = 0.3$. Suponha que em $t=5$, temos $Y_5 = 2$ e $Y_4 = 1.5$. Ent√£o, $\mathbf{X}_5 = [2, 1.5]^T$.
> A matriz $\mathbf{A}$ e o vetor $\mathbf{B}$ s√£o dados por:
>$$ \mathbf{A} = \begin{bmatrix}
>0.6 & 0.3 \\
>1 & 0 
>\end{bmatrix}
>$$
>
>$$ \mathbf{B} = \begin{bmatrix}
>1 \\ 0
>\end{bmatrix}
>$$
>
>A previs√£o para o pr√≥ximo per√≠odo (t=6) √© dada por:
>
>$$ \mathbf{X}_{6} = \mathbf{A}\mathbf{X}_5 + \mathbf{B}\epsilon_{6} $$
>
>$$ \begin{bmatrix}
>Y_{6} \\
>Y_{5}
>\end{bmatrix} = \begin{bmatrix}
>0.6 & 0.3 \\
>1 & 0 
>\end{bmatrix} \begin{bmatrix}
>2 \\
>1.5
>\end{bmatrix} + \begin{bmatrix}
>1 \\ 0
>\end{bmatrix} \epsilon_{6}
>$$
>
>$$ \begin{bmatrix}
>Y_{6} \\
>Y_{5}
>\end{bmatrix} = \begin{bmatrix}
>0.6*2 + 0.3*1.5 \\
>2
>\end{bmatrix} + \begin{bmatrix}
>1 \\ 0
>\end{bmatrix} \epsilon_{6}
>$$
>
>$$ \begin{bmatrix}
>Y_{6} \\
>Y_{5}
>\end{bmatrix} = \begin{bmatrix}
>1.65 \\
>2
>\end{bmatrix} + \begin{bmatrix}
>1 \\ 0
>\end{bmatrix} \epsilon_{6}
>$$
>
>A previs√£o √≥tima para $Y_6$ √© $\hat{Y}_{6|5} = 1.65$, j√° que o valor de $\epsilon_6$ √© desconhecido no instante t=5. A representa√ß√£o matricial facilita a implementa√ß√£o computacional e a an√°lise da evolu√ß√£o do sistema.

### Operadores de Defasagem e a Representa√ß√£o da Previs√£o
A utiliza√ß√£o de operadores de defasagem permite uma representa√ß√£o concisa e facilita a manipula√ß√£o alg√©brica de modelos de s√©ries temporais. Podemos escrever um processo AR(p) genericamente como:
$$ \phi(L)(Y_t - \mu) = \epsilon_t $$
onde $\phi(L) = 1 - \phi_1 L - \phi_2 L^2 - \dots - \phi_p L^p$.
Para obter a previs√£o de *s* per√≠odos √† frente, expressamos $Y_{t+s}$ em termos de valores passados e choques futuros [^2]:
$$ Y_{t+s} = \mu + [\phi(L)]^{-1} \epsilon_{t+s} $$
O operador $[\phi(L)]^{-1}$ pode ser expresso como um polin√¥mio infinito em $L$ quando o processo √© estacion√°rio.
A previs√£o √≥tima de $Y_{t+s}$, dado a informa√ß√£o at√© *t* ($Y_t$, $Y_{t-1}$, ...) √© dada por:
$$ \hat{Y}_{t+s|t} = \mu + \left[ \frac{\phi(L)^{-1}}{L^s} \right]_+ \epsilon_t $$
O operador $\left[ \frac{\phi(L)^{-1}}{L^s} \right]_+$ significa que estamos retendo apenas os termos com expoentes n√£o negativos do operador de defasagem $L$. Isto equivale a aniquilar os termos futuros e incluir apenas os valores passados e o componente de inova√ß√£o no tempo *t* para a previs√£o, como demonstrado na se√ß√£o 4.2 do contexto anterior [^2]. Essa forma da previs√£o separa claramente as condi√ß√µes iniciais (presentes nos valores passados) e os choques futuros na previs√£o, facilitando a interpreta√ß√£o do modelo.

> üí° **Exemplo Num√©rico:**
> Considere um processo AR(1) dado por $Y_t - \mu = \phi_1(Y_{t-1} - \mu) + \epsilon_t$ ou $(1-\phi_1L)(Y_t-\mu)=\epsilon_t$. Vamos usar operadores de defasagem para expressar a previs√£o de $s$ per√≠odos √† frente, onde $s > 0$.
>
> I. Expressar $Y_t$ em termos de $\epsilon_t$ usando operadores de defasagem:
>
> $$ Y_t - \mu = (1 - \phi_1 L)^{-1}\epsilon_t = (1 + \phi_1L + \phi_1^2L^2 + \phi_1^3L^3 + \dots) \epsilon_t $$
> $$ Y_t - \mu = \epsilon_t + \phi_1 \epsilon_{t-1} + \phi_1^2\epsilon_{t-2} + \dots $$
>  O operador $(1 - \phi_1 L)^{-1}$ √© um expans√£o infinita em L.
>
> II. Expressar $Y_{t+s}$:
>
> $$ Y_{t+s} - \mu = \epsilon_{t+s} + \phi_1 \epsilon_{t+s-1} + \phi_1^2\epsilon_{t+s-2} + \dots $$
>
> III. Obter a previs√£o de s-passos √† frente, considerando a informa√ß√£o no instante $t$, ou seja, anulando termos futuros:
>
>$$ \hat{Y}_{t+s|t} - \mu = [\epsilon_{t+s} + \phi_1 \epsilon_{t+s-1} + \phi_1^2\epsilon_{t+s-2} + \dots ]_+ $$
>$$ \hat{Y}_{t+s|t} - \mu = \phi_1^s \epsilon_t + \phi_1^{s+1} \epsilon_{t-1} + \dots$$
>  Como, $Y_t - \mu = \epsilon_t + \phi_1 \epsilon_{t-1} + \phi_1^2\epsilon_{t-2} + ...$, multiplicando por $\phi_1^s$ temos:
>
>$$ \phi_1^s(Y_t - \mu) = \phi_1^s \epsilon_t + \phi_1^{s+1} \epsilon_{t-1} + \phi_1^{s+2}\epsilon_{t-2} + \dots$$
>
> Portanto:
> $$\hat{Y}_{t+s|t} = \mu + \phi_1^s(Y_t-\mu)$$
>  Essa equa√ß√£o √© consistente com o resultado encontrado no Lema 2, mostrando que a previs√£o de s-passos √† frente se torna uma fun√ß√£o dos valores passados, no caso do AR(1).
>
> üí° **Exemplo Num√©rico:**
> Suponha um processo AR(1) com $\mu = 5$ e $\phi_1 = 0.8$, e que $Y_t = 8$. Vamos calcular as previs√µes para 1, 2 e 3 per√≠odos √† frente usando a f√≥rmula derivada acima:
>
> Para s = 1:
> $$ \hat{Y}_{t+1|t} = 5 + 0.8^1 (8-5) = 5 + 0.8 * 3 = 5 + 2.4 = 7.4 $$
>
> Para s = 2:
> $$ \hat{Y}_{t+2|t} = 5 + 0.8^2 (8-5) = 5 + 0.64 * 3 = 5 + 1.92 = 6.92 $$
>
> Para s = 3:
> $$ \hat{Y}_{t+3|t} = 5 + 0.8^3 (8-5) = 5 + 0.512 * 3 = 5 + 1.536 = 6.536 $$
>
> Observamos que a previs√£o converge para a m√©dia do processo (5) √† medida que o horizonte de previs√£o aumenta. Isso demonstra como os choques passados v√£o perdendo relev√¢ncia para previs√µes mais distantes.

**Lema 1**
A representa√ß√£o da previs√£o em termos de condi√ß√µes iniciais pode ser expressa de forma concisa utilizando os coeficientes $\psi_j$ da representa√ß√£o de m√©dia m√≥vel infinita do processo AR(p). Especificamente, se $\phi(L)(Y_t - \mu) = \epsilon_t$, onde $\phi(L) = 1 - \phi_1L - \dots - \phi_pL^p$, e $\phi(L)^{-1} = \psi(L) = 1 + \psi_1L + \psi_2L^2 + \dots $, ent√£o:
$$ Y_{t+s} - \mu = \sum_{j=0}^{\infty} \psi_j \epsilon_{t+s-j} = \sum_{j=0}^{s-1}\psi_j \epsilon_{t+s-j} +  \sum_{j=s}^{\infty}\psi_j \epsilon_{t+s-j}$$
A previs√£o √≥tima de $Y_{t+s}$ no tempo $t$ √© dada por:
$$\hat{Y}_{t+s|t} - \mu = \sum_{j=s}^\infty \psi_j \epsilon_{t+s-j} = \sum_{j=0}^{\infty} \psi_{s+j}\epsilon_{t-j}  $$
A prova segue da expans√£o do operador $\phi(L)^{-1}$ na representa√ß√£o de m√©dia m√≥vel infinita e da aplica√ß√£o do operador de aniquila√ß√£o $[.]_+$ que descarta os termos $\epsilon_{t+j}$ para $j >0$ na previs√£o.

Vamos provar o Lema 1:

I. Dado um processo AR(p) na forma $\phi(L)(Y_t - \mu) = \epsilon_t$, onde $\phi(L) = 1 - \phi_1L - \dots - \phi_pL^p$.
II. Podemos expressar a rela√ß√£o inversa como $(Y_t - \mu) = \phi(L)^{-1}\epsilon_t$. Se o processo for estacion√°rio, $\phi(L)^{-1}$ pode ser expresso como um polin√¥mio de m√©dia m√≥vel infinita $\psi(L) = 1 + \psi_1L + \psi_2L^2 + \dots$, onde os coeficientes $\psi_j$ s√£o fun√ß√µes dos $\phi_i$.
III. Portanto, $Y_t - \mu = \psi(L)\epsilon_t = \sum_{j=0}^{\infty} \psi_j \epsilon_{t-j}$.
IV. Substituindo $t$ por $t+s$, temos $Y_{t+s} - \mu = \sum_{j=0}^{\infty} \psi_j \epsilon_{t+s-j}$.
V. Separando a soma em termos de choques futuros e passados (em rela√ß√£o a *t*), temos:
$Y_{t+s} - \mu = \sum_{j=0}^{s-1}\psi_j \epsilon_{t+s-j} +  \sum_{j=s}^{\infty}\psi_j \epsilon_{t+s-j}$.
VI. A previs√£o √≥tima $\hat{Y}_{t+s|t}$ √© obtida anulando os termos que envolvem choques futuros, ou seja,  $\epsilon_{t+1}, \epsilon_{t+2}, \dots, \epsilon_{t+s}$.
VII. Portanto, a previs√£o √≥tima √© dada por:
$\hat{Y}_{t+s|t} - \mu = \sum_{j=s}^\infty \psi_j \epsilon_{t+s-j}$.
VIII. Mudando o √≠ndice da soma, temos:  $\hat{Y}_{t+s|t} - \mu = \sum_{j=0}^{\infty} \psi_{s+j}\epsilon_{t-j}$.

Portanto, provamos o Lema 1. ‚ñ†

**Lema 1.1**
A previs√£o √≥tima pode ser reescrita em termos dos valores da s√©rie temporal em vez dos choques passados. Usando a representa√ß√£o de m√©dia m√≥vel infinita do processo, temos que
$$Y_t - \mu = \sum_{j=0}^{\infty} \psi_j \epsilon_{t-j}$$
e multiplicando por $\psi_s$, obtemos que
$$\psi_s (Y_t - \mu) = \psi_s \epsilon_t + \psi_s\psi_1\epsilon_{t-1} + \psi_s\psi_2\epsilon_{t-2} + \dots$$
Assim, podemos expressar a previs√£o √≥tima como
$$\hat{Y}_{t+s|t} - \mu = \sum_{j=0}^{\infty} f_j^{(s)}(Y_{t-j}-\mu)$$
onde os coeficientes $f_j^{(s)}$ s√£o fun√ß√µes dos coeficientes $\psi_j$. Os coeficientes $f_j^{(s)}$ correspondem aos coeficientes da expans√£o do polin√¥mio obtido de $\phi(L)^{-1}$ truncado.

Vamos provar o Lema 1.1:

I. Do Lema 1, temos que $\hat{Y}_{t+s|t} - \mu = \sum_{j=0}^{\infty} \psi_{s+j}\epsilon_{t-j}$.
II. Sabemos que o processo AR(p) pode ser expresso como $Y_t - \mu = \sum_{j=0}^{\infty} \psi_j \epsilon_{t-j}$.
III. Nosso objetivo √© expressar $\epsilon_{t-j}$ em termos dos valores passados $Y_{t-j}-\mu$.
IV. Reorganizando a express√£o do passo II para expressar $\epsilon_{t-j}$, obtemos $\epsilon_{t-j} = (Y_{t-j} - \mu) - \sum_{k=1}^{\infty} \psi_k \epsilon_{t-j-k}$.
V. Substituindo esta express√£o na previs√£o √≥tima, obtemos:
    $\hat{Y}_{t+s|t} - \mu = \sum_{j=0}^{\infty} \psi_{s+j} \left[(Y_{t-j} - \mu) - \sum_{k=1}^{\infty} \psi_k \epsilon_{t-j-k}\right]$.
VI. Esta express√£o √© recursiva e demonstra que a previs√£o √≥tima pode ser expressa em termos de valores passados da s√©rie temporal $Y_{t-j}-\mu$.
VII. Podemos expressar $\hat{Y}_{t+s|t}$ como uma combina√ß√£o linear dos valores passados $Y_{t-j}-\mu$, ou seja $\hat{Y}_{t+s|t} - \mu = \sum_{j=0}^{\infty} f_j^{(s)}(Y_{t-j}-\mu)$, onde os coeficientes $f_j^{(s)}$ s√£o fun√ß√µes dos $\psi_j$.
VIII. Os coeficientes $f_j^{(s)}$ s√£o obtidos da expans√£o do polin√¥mio resultante de $\phi(L)^{-1}$ truncado ap√≥s os termos de ordem *s*.

Portanto, provamos o Lema 1.1. ‚ñ†

### Benef√≠cios da Representa√ß√£o com Operadores de Defasagem
1.  **Computa√ß√£o Eficiente**: A representa√ß√£o com operadores de defasagem permite o c√°lculo direto da previs√£o sem o uso de proje√ß√µes iteradas, facilitando o processamento de grandes conjuntos de dados [^2]. Opera√ß√µes com polin√¥mios de defasagem s√£o eficientes e bem estabelecidas na literatura.
2.  **An√°lise da Estrutura do Modelo**: A representa√ß√£o explicita a rela√ß√£o entre os valores passados da s√©rie temporal, os choques futuros e os coeficientes do modelo, permitindo uma an√°lise detalhada da din√¢mica do processo [^2].
3.  **Generaliza√ß√£o Simples**: Os operadores de defasagem facilitam a generaliza√ß√£o da an√°lise para diferentes tipos de modelos ARMA, tornando a abordagem mais vers√°til e aplic√°vel a diversos cen√°rios.
4.  **Facilidade na Interpreta√ß√£o**: A representa√ß√£o separa as informa√ß√µes do passado e do futuro na previs√£o, auxiliando na compreens√£o da contribui√ß√£o de cada componente na previs√£o √≥tima.
5.  **Implementa√ß√£o Algor√≠tmica**: A estrutura com operadores de defasagem se traduz em algoritmos eficientes e f√°ceis de implementar, com bom desempenho para previs√µes multi-step-ahead [^2].

### Conclus√£o
A representa√ß√£o da previs√£o AR(p) em termos de condi√ß√µes iniciais e choques futuros, usando operadores de defasagem, oferece uma abordagem poderosa para o c√°lculo e an√°lise de previs√µes. Ao explicitar a rela√ß√£o entre os valores passados, choques futuros e coeficientes do modelo, essa representa√ß√£o facilita o processamento eficiente de grandes *datasets* e permite uma compreens√£o profunda da din√¢mica do processo. A aplica√ß√£o dos operadores de defasagem resulta em algoritmos de previs√£o mais eficientes e vers√°teis, consolidando sua relev√¢ncia no campo da an√°lise de s√©ries temporais.

### Refer√™ncias
[^1]: Express√£o [4.1.1] e seguintes
[^2]: Se√ß√µes 4.2 e seguintes
<!-- END -->
