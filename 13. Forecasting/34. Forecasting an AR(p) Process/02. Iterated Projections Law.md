## Previs√£o Iterativa em Processos AR(p): A Lei das Proje√ß√µes Iteradas
### Introdu√ß√£o
Em continuidade ao estudo de processos autorregressivos (AR) e suas propriedades de previs√£o, este cap√≠tulo explora em detalhes a aplica√ß√£o da lei das proje√ß√µes iteradas para a obten√ß√£o de previs√µes multi-step-ahead em processos AR(p). Como vimos anteriormente, a previs√£o √≥tima de um processo AR(p) se baseia em uma estrutura recursiva, que utiliza valores passados da s√©rie temporal [^2]. O presente cap√≠tulo visa aprofundar a compreens√£o desta t√©cnica iterativa, mostrando como ela minimiza a necessidade de c√°lculos complexos, permitindo a deriva√ß√£o eficiente de previs√µes para diversos horizontes temporais, ao mesmo tempo que utiliza a otimiza√ß√£o do erro quadr√°tico m√©dio [^1].

### Conceitos Fundamentais
A lei das proje√ß√µes iteradas √© um conceito essencial para a previs√£o de processos estoc√°sticos, especialmente quando se consideram horizontes temporais maiores que um passo √† frente [^2]. Esta lei estabelece que a proje√ß√£o de uma vari√°vel aleat√≥ria $Y_{t+s}$, no tempo $t+s$, sobre o conjunto de informa√ß√µes dispon√≠veis at√© o tempo $t$, denotada por $P(Y_{t+s}|Y_t, Y_{t-1},\ldots)$, pode ser obtida iterativamente atrav√©s da proje√ß√£o das previs√µes intermedi√°rias. Ou seja, para cada passo de proje√ß√£o √† frente, utilizamos os resultados do passo anterior, aplicando o modelo AR(p) de forma recursiva [^2].

Formalmente, para um processo AR(p) com m√©dia $\mu$, a previs√£o de um passo √† frente $(s = 1)$ √© dada por [^2]:
$$ (Y_{t+1|t} - \mu) = \phi_1(Y_t - \mu) + \phi_2(Y_{t-1} - \mu) + \dots + \phi_p(Y_{t-p+1} - \mu) $$
Aqui, $Y_{t+1|t}$ representa a previs√£o de $Y_{t+1}$ com base nas informa√ß√µes dispon√≠veis at√© o tempo $t$, e $\phi_1, \phi_2, \dots, \phi_p$ s√£o os coeficientes autorregressivos do modelo. A lei das proje√ß√µes iteradas se torna evidente quando se considera a previs√£o para dois per√≠odos √† frente $(s = 2)$ [^2]:
$$ (Y_{t+2|t} - \mu) = \phi_1(Y_{t+1|t} - \mu) + \phi_2(Y_t - \mu) + \dots + \phi_p(Y_{t-p+2} - \mu) $$
Nesta equa√ß√£o, $Y_{t+1|t}$ √© a previs√£o de um passo √† frente, calculada previamente e utilizada para obter a previs√£o de dois passos √† frente. A aplica√ß√£o repetida desta l√≥gica leva √† previs√£o de *s* per√≠odos √† frente [^2]:
$$ (Y_{t+s|t} - \mu) = \phi_1(Y_{t+s-1|t} - \mu) + \phi_2(Y_{t+s-2|t} - \mu) + \dots + \phi_p(Y_{t+s-p|t} - \mu) $$
Em cada etapa de proje√ß√£o, se o √≠ndice $t+j$ for menor ou igual a $t$, o valor $Y_{t+j|t}$ √© substitu√≠do pelo valor observado $Y_{t+j}$. Caso contr√°rio, se $t+j > t$, utiliza-se a previs√£o calculada anteriormente. Este processo iterativo elimina a necessidade de c√°lculos complexos e repetitivos, facilitando a previs√£o para horizontes temporais longos [^2].

> üí° **Exemplo Num√©rico:**
> Para exemplificar a aplica√ß√£o da lei das proje√ß√µes iteradas, considere um processo AR(2) com $\mu = 5$, $\phi_1 = 0.6$ e $\phi_2 = 0.3$. Suponha que temos as observa√ß√µes $Y_t = 7$, $Y_{t-1} = 6$ e $Y_{t-2} = 4$.
>
>1.  **Previs√£o de um passo √† frente ($s=1$):**
>  $$ Y_{t+1|t} - 5 = 0.6(7 - 5) + 0.3(6 - 5) $$
>  $$ Y_{t+1|t} - 5 = 0.6(2) + 0.3(1) = 1.2 + 0.3 = 1.5 $$
>  $$ Y_{t+1|t} = 5 + 1.5 = 6.5 $$
>
>2.  **Previs√£o de dois passos √† frente ($s=2$):**
>  $$ Y_{t+2|t} - 5 = 0.6(Y_{t+1|t} - 5) + 0.3(Y_t - 5) $$
>  $$ Y_{t+2|t} - 5 = 0.6(6.5 - 5) + 0.3(7 - 5) $$
>  $$ Y_{t+2|t} - 5 = 0.6(1.5) + 0.3(2) = 0.9 + 0.6 = 1.5 $$
>  $$ Y_{t+2|t} = 5 + 1.5 = 6.5 $$
>
>3. **Previs√£o de tr√™s passos √† frente ($s=3$):**
>$$ Y_{t+3|t} - 5 = 0.6(Y_{t+2|t} - 5) + 0.3(Y_{t+1|t} - 5) $$
>$$ Y_{t+3|t} - 5 = 0.6(6.5 - 5) + 0.3(6.5 - 5) $$
>$$ Y_{t+3|t} - 5 = 0.6(1.5) + 0.3(1.5) = 0.9 + 0.45 = 1.35 $$
>$$ Y_{t+3|t} = 5 + 1.35 = 6.35 $$
>
> Este exemplo demonstra como as previs√µes futuras s√£o calculadas utilizando os resultados das previs√µes anteriores, de forma iterativa.

A previs√£o √≥tima de *s* per√≠odos √† frente pode ser formalmente expressa como [^2]:
$$ \hat{Y}_{t+s|t} = \mu + f_1^{(s)}(Y_t - \mu) + f_2^{(s)}(Y_{t-1} - \mu) + \dots + f_p^{(s)}(Y_{t-p+1} - \mu) $$
Os coeficientes $f_i^{(s)}$ s√£o fun√ß√µes dos coeficientes autorregressivos $\phi_i$ e do horizonte de previs√£o *s*, demonstrando a depend√™ncia da previs√£o √≥tima na estrutura do modelo e no horizonte temporal [^2]. Estes coeficientes podem ser calculados recursivamente a partir dos coeficientes do modelo AR(p).

> üí° **Exemplo Num√©rico:**
> Continuando o exemplo anterior, vamos calcular os coeficientes $f_i^{(s)}$ para o modelo AR(2) com $\phi_1 = 0.6$ e $\phi_2 = 0.3$ para as previs√µes de 1, 2 e 3 passos √† frente.
>
> Para $s=1$:
> $f_1^{(1)} = \phi_1 = 0.6$
> $f_2^{(1)} = \phi_2 = 0.3$
>
> Para $s=2$:
> $f_1^{(2)} = \phi_1 f_1^{(1)} + \phi_2 f_0^{(1)} = 0.6(0.6) + 0.3(0) = 0.36$
> $f_2^{(2)} = \phi_1 f_0^{(1)} + \phi_2 f_1^{(1)} = 0.6(0) + 0.3(0.6) = 0.18$
>
> Para $s=3$:
> $f_1^{(3)} = \phi_1 f_1^{(2)} + \phi_2 f_0^{(2)} = 0.6(0.36) + 0.3(0) = 0.216$
> $f_2^{(3)} = \phi_1 f_0^{(2)} + \phi_2 f_1^{(2)} = 0.6(0) + 0.3(0.36) = 0.108$
>
> Assim, a previs√£o √≥tima para $s=1$ √©:
>  $$ \hat{Y}_{t+1|t} = 5 + 0.6(Y_t - 5) + 0.3(Y_{t-1} - 5) $$
> Para $s=2$:
>  $$ \hat{Y}_{t+2|t} = 5 + 0.36(Y_t - 5) + 0.18(Y_{t-1} - 5) $$
> Para $s=3$:
>  $$ \hat{Y}_{t+3|t} = 5 + 0.216(Y_t - 5) + 0.108(Y_{t-1} - 5) $$
>
> Note que os coeficientes $f_i^{(s)}$ s√£o usados para ponderar as observa√ß√µes passadas na previs√£o, e eles s√£o calculados recursivamente.

**Lema 1**
Os coeficientes $f_i^{(s)}$ na express√£o para a previs√£o √≥tima de *s* per√≠odos √† frente, $\hat{Y}_{t+s|t}$, podem ser calculados recursivamente da seguinte forma:
$$ f_i^{(1)} = \phi_i, \quad i = 1, 2, \dots, p $$
$$ f_i^{(s)} = \sum_{j=1}^{p} \phi_j f_{i-j}^{(s-1)} $$
com $f_i^{(s)} = 0$ se $i \le 0$ ou $i > p$ e $f_i^{(1)} = \phi_i$
*Proof.*
I. Para $s=1$ temos, por defini√ß√£o, que $f_i^{(1)} = \phi_i$
II. Para $s>1$, temos:
$$ \hat{Y}_{t+s|t} - \mu = \sum_{i=1}^{p} \phi_i (\hat{Y}_{t+s-i|t} - \mu) $$
III. Expandindo $\hat{Y}_{t+s-i|t}$ utilizando a express√£o para previs√£o de s-1 passos:
$$ \hat{Y}_{t+s|t} - \mu = \sum_{i=1}^{p} \phi_i \left( \sum_{j=1}^{p} f_j^{(s-i)} (Y_{t-j+s-i} - \mu) \right) $$
IV. Rearranjando os termos e utilizando a defini√ß√£o de $f_i^{(s)}$, obtemos a express√£o recursiva para $f_i^{(s)}$:
$$ f_i^{(s)} = \sum_{j=1}^{p} \phi_j f_{i-j}^{(s-1)} $$
com $f_i^{(s)} = 0$ se $i \le 0$ ou $i > p$ e $f_i^{(1)} = \phi_i$. $\blacksquare$

**Lema 2**
A previs√£o de *s* per√≠odos √† frente, $\hat{Y}_{t+s|t}$, pode ser expressa como uma combina√ß√£o linear dos valores passados da s√©rie temporal, isto √©, $\hat{Y}_{t+s|t} = \sum_{j=0}^{\infty} a_j Y_{t-j}$, onde $a_j$ s√£o coeficientes que dependem dos par√¢metros do modelo AR(p) e de *s*.

*Proof.*
I. Sabemos que a previs√£o de um passo √† frente pode ser expressa como:
   $$ \hat{Y}_{t+1|t} = \mu + \phi_1(Y_t - \mu) + \phi_2(Y_{t-1} - \mu) + \dots + \phi_p(Y_{t-p+1} - \mu) $$
II. Substituindo recursivamente as previs√µes de *s-1* passos √† frente, podemos expressar $\hat{Y}_{t+s|t}$ em termos dos valores passados da s√©rie temporal.
   Por exemplo, para um processo AR(1):
   $$\hat{Y}_{t+2|t} = \mu + \phi_1(\hat{Y}_{t+1|t} - \mu) = \mu + \phi_1(\phi_1 (Y_t - \mu) + \mu - \mu) = \mu + \phi_1^2 (Y_t - \mu)$$
   E, de forma geral, para um processo AR(1):
   $$\hat{Y}_{t+s|t} = \mu + \phi_1^s (Y_t - \mu)$$
   Assim, para um processo AR(1) temos que: $a_0=\phi_1^s$ e $a_i = 0 \forall i > 0$
III. No caso de um AR(p), a mesma abordagem recursiva pode ser aplicada, demonstrando que $\hat{Y}_{t+s|t}$ pode ser expresso como uma soma ponderada dos valores passados da s√©rie temporal.
IV. Formalmente, o processo de substitui√ß√£o recursiva leva √† forma:
   $$\hat{Y}_{t+s|t} = \sum_{j=0}^{\infty} a_j Y_{t-j} $$
onde os coeficientes $a_j$ dependem dos par√¢metros do modelo AR(p) (isto √©, os $\phi_i$) e do horizonte de previs√£o *s*. $\blacksquare$
> üí° **Exemplo Num√©rico:**
> Vamos ilustrar o Lema 2 com um exemplo num√©rico. Considere um processo AR(1) com $\mu = 10$ e $\phi_1 = 0.7$. Vamos calcular a previs√£o para dois passos √† frente, $\hat{Y}_{t+2|t}$, em termos de valores passados.
>
> Primeiro, para um passo √† frente ($s=1$):
> $$\hat{Y}_{t+1|t} = 10 + 0.7(Y_t - 10)$$
>
> Agora, para dois passos √† frente ($s=2$):
> $$\hat{Y}_{t+2|t} = 10 + 0.7(\hat{Y}_{t+1|t} - 10)$$
> Substituindo a express√£o de $\hat{Y}_{t+1|t}$ na equa√ß√£o acima:
> $$\hat{Y}_{t+2|t} = 10 + 0.7(10 + 0.7(Y_t - 10) - 10)$$
> $$\hat{Y}_{t+2|t} = 10 + 0.7(0.7(Y_t - 10))$$
> $$\hat{Y}_{t+2|t} = 10 + 0.7^2(Y_t - 10)$$
> $$\hat{Y}_{t+2|t} = 10 + 0.49(Y_t - 10)$$
>
> Se expandirmos a equa√ß√£o:
> $$\hat{Y}_{t+2|t} = 10 + 0.49Y_t - 4.9$$
> $$\hat{Y}_{t+2|t} = 5.1 + 0.49Y_t$$
>  Comparando com a forma do Lema 2: $\hat{Y}_{t+s|t} = \sum_{j=0}^{\infty} a_j Y_{t-j}$, temos:
>  $a_0 = 0.49$ e $a_j = 0$ for $j > 0$ (j√° que n√£o h√° mais termos $Y_{t-j}$).
>
>  O exemplo mostra que a previs√£o para dois passos √† frente pode ser expressa como uma combina√ß√£o linear dos valores passados ($Y_t$ neste caso), confirmando o Lema 2. Para um AR(p) geral, essa combina√ß√£o linear incluiria mais valores passados.

**Teorema 1.1** (Converg√™ncia da Previs√£o)
Para um processo AR(p) estacion√°rio, √† medida que o horizonte de previs√£o *s* aumenta, a previs√£o $\hat{Y}_{t+s|t}$ converge para a m√©dia do processo, $\mu$. Isto √©, $\lim_{s \to \infty} \hat{Y}_{t+s|t} = \mu$.

*Proof.*
I. Do Lema 2, sabemos que $\hat{Y}_{t+s|t}$ pode ser expresso como uma combina√ß√£o linear dos valores passados da s√©rie temporal: $\hat{Y}_{t+s|t} = \sum_{j=0}^{\infty} a_j Y_{t-j}$.
II. Para um processo AR(p) estacion√°rio, as ra√≠zes do polin√¥mio caracter√≠stico associado ao modelo encontram-se dentro do c√≠rculo unit√°rio.
III. Esta condi√ß√£o de estacionariedade implica que, √† medida que *s* aumenta, os coeficientes $f_i^{(s)}$ tendem a zero. Consequentemente, os coeficientes $a_j$ tamb√©m tendem a zero quando *j* √© pequeno e *s* √© grande.
IV. Como o processo √© estacion√°rio e as pondera√ß√µes dos valores passados tendem a zero quando o horizonte de previs√£o se torna muito grande, o efeito dos valores observados $Y_{t-j}$ no valor previsto $\hat{Y}_{t+s|t}$ torna-se cada vez menor.
V. Portanto, a previs√£o converge para a m√©dia do processo, $\mu$:
$$\lim_{s \to \infty} \hat{Y}_{t+s|t} = \mu$$. $\blacksquare$
> üí° **Exemplo Num√©rico:**
> Para ilustrar o Teorema 1.1, vamos considerar o mesmo processo AR(1) com $\mu = 10$ e $\phi_1 = 0.7$ usado no exemplo do Lema 2. Vimos que para previs√£o de *s* passos √† frente, temos:
>
>  $$\hat{Y}_{t+s|t} = \mu + \phi_1^s (Y_t - \mu)$$
>
>  No nosso exemplo:
>
> $$\hat{Y}_{t+s|t} = 10 + 0.7^s(Y_t - 10)$$
>
>  Vamos calcular previs√µes para diferentes valores de *s*, assumindo um valor $Y_t = 20$.
>
> | s  | $\hat{Y}_{t+s|t}$ |
> |----|--------------------|
> | 1  | $10 + 0.7^1(20-10) = 17$    |
> | 2  | $10 + 0.7^2(20-10) = 14.9$   |
> | 5  | $10 + 0.7^5(20-10) = 11.68$   |
> | 10 | $10 + 0.7^{10}(20-10) = 10.28$  |
> | 20 | $10 + 0.7^{20}(20-10) = 10.008$  |
>
> Como podemos observar, √† medida que *s* aumenta, o termo $0.7^s$ se aproxima de zero, e, portanto, a previs√£o $\hat{Y}_{t+s|t}$ converge para a m√©dia do processo, que √© 10. Isto ilustra numericamente a converg√™ncia da previs√£o para a m√©dia conforme demonstrado no Teorema 1.1.

### Vantagens da Previs√£o Iterativa
1.  **Simplicidade Computacional**: A lei das proje√ß√µes iteradas simplifica significativamente o processo de c√°lculo das previs√µes. Ao usar os resultados das previs√µes anteriores, evita-se a necessidade de recalcular todo o processo desde o in√≠cio [^2]. Isso resulta em um aumento da efici√™ncia computacional, especialmente para horizontes de previs√£o maiores.
2.  **Implementa√ß√£o F√°cil**: A abordagem recursiva se traduz em algoritmos simples e f√°ceis de implementar, tornando-a acess√≠vel para uma variedade de aplica√ß√µes pr√°ticas [^2]. A natureza iterativa permite que a previs√£o seja calculada passo a passo, adaptando-se a diferentes requisitos de modelagem.
3.  **Otimiza√ß√£o do Erro Quadr√°tico M√©dio**: Como derivado do Teorema 1, a previs√£o obtida por este m√©todo minimiza o erro quadr√°tico m√©dio, garantindo uma qualidade √≥tima na previs√£o sob o crit√©rio de minimiza√ß√£o da vari√¢ncia dos erros de previs√£o [^1].
4.  **Adaptabilidade**: O m√©todo se adapta bem a diferentes horizontes de previs√£o, permitindo a deriva√ß√£o eficiente de previs√µes para v√°rios per√≠odos √† frente [^2].
5.  **Transpar√™ncia**: A forma recursiva da previs√£o permite uma f√°cil interpreta√ß√£o de como as informa√ß√µes do passado afetam as previs√µes futuras [^2], fornecendo insights sobre o comportamento da s√©rie temporal.

### Conclus√£o
A lei das proje√ß√µes iteradas √© um m√©todo poderoso para a previs√£o multi-step-ahead em processos AR(p). Ela oferece uma forma eficiente e computacionalmente trat√°vel para gerar previs√µes, minimizando a necessidade de c√°lculos complexos e repetitivos. A natureza recursiva do m√©todo, combinada com a otimiza√ß√£o do erro quadr√°tico m√©dio, o torna uma ferramenta valiosa para an√°lise e previs√£o de s√©ries temporais. A estrutura do modelo AR(p), juntamente com a aplica√ß√£o da lei das proje√ß√µes iteradas, permite derivar previs√µes para qualquer horizonte temporal, tornando esta abordagem amplamente aplic√°vel em diversas √°reas da ci√™ncia e engenharia.

### Refer√™ncias
[^1]: Express√£o [4.1.1] e seguintes
[^2]: Se√ß√µes 4.2 e seguintes
<!-- END -->
