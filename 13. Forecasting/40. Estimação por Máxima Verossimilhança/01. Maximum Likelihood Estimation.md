## Estima√ß√£o por M√°xima Verossimilhan√ßa: Um Mergulho Profundo
### Introdu√ß√£o
Como explorado nos cap√≠tulos anteriores, a an√°lise de s√©ries temporais frequentemente se baseia em modelos que dependem de par√¢metros desconhecidos. A estimativa desses par√¢metros √© crucial para a previs√£o e compreens√£o do comportamento da s√©rie temporal. Como vimos anteriormente [^5.1], o princ√≠pio da m√°xima verossimilhan√ßa (MLE) oferece um m√©todo poderoso para essa finalidade. Este cap√≠tulo se dedica a detalhar o processo de estimativa por m√°xima verossimilhan√ßa, com foco em modelos ARMA e em t√©cnicas de otimiza√ß√£o num√©rica. A import√¢ncia da MLE reside em sua capacidade de gerar estimativas de par√¢metros que tornam os dados observados os mais prov√°veis, dado um modelo estat√≠stico espec√≠fico.

### Conceitos Fundamentais
O princ√≠pio da m√°xima verossimilhan√ßa [^5.1] busca, essencialmente, encontrar os valores dos par√¢metros de um modelo estat√≠stico que maximizam a probabilidade dos dados amostrais observados. Formalmente, dado um vetor de par√¢metros $\theta$ e uma amostra observada $Y = (y_1, y_2, \ldots, y_T)$, o objetivo √© encontrar $\hat{\theta}$ tal que a fun√ß√£o de verossimilhan√ßa $f_{y_T, y_{T-1}, \ldots, y_1}(y_T, y_{T-1}, \ldots, y_1; \theta)$ seja maximizada [^5.1.4]. A fun√ß√£o de verossimilhan√ßa, neste contexto, √© interpretada como a probabilidade de observar a amostra espec√≠fica, dado um valor de $\theta$. A implementa√ß√£o computacional da MLE envolve a otimiza√ß√£o desta fun√ß√£o de verossimilhan√ßa, frequentemente utilizando m√©todos num√©ricos [^5.1].

> üí° **Exemplo Num√©rico:** Imagine que temos uma s√©rie temporal de retornos de a√ß√µes. Queremos ajustar um modelo AR(1) da forma $y_t = \phi y_{t-1} + \epsilon_t$. A MLE buscaria o valor de $\phi$ que torna os retornos observados (nossa amostra $Y$) o mais prov√°vel poss√≠vel, dado esse modelo AR(1). Se $\phi = 0.7$ gera uma maior probabilidade de observar a nossa amostra em compara√ß√£o com $\phi = 0.3$, ent√£o $\hat{\phi} = 0.7$ seria a nossa estimativa por m√°xima verossimilhan√ßa.
>
> ```mermaid
> graph LR
>     A[Dados observados (Y)] --> B(Modelo AR(1): y_t = œÜy_{t-1} + Œµ_t);
>     B --> C{Variar œÜ};
>     C --> D[Calcular fun√ß√£o de verossimilhan√ßa L(œÜ; Y)];
>     D --> E{Maximizar L(œÜ; Y)};
>     E --> F[Obter œÜ_hat (estimativa MLE)];
> ```

A abordagem da MLE, de forma geral, assume que os dados observados s√£o provenientes de um processo estoc√°stico que pode ser descrito por um modelo param√©trico. No contexto de s√©ries temporais, geralmente assumimos que o processo de erro ($\epsilon_t$) segue uma distribui√ß√£o normal com m√©dia zero e vari√¢ncia $\sigma^2$, ou seja, $\epsilon_t \sim i.i.d. N(0, \sigma^2)$ [^5.1.5]. Esta hip√≥tese, embora possa ser considerada forte, muitas vezes leva a estimativas razo√°veis, mesmo quando a distribui√ß√£o real dos erros n√£o √© exatamente normal.

**Lema 1:** *A hip√≥tese de erros gaussianos simplifica consideravelmente a forma da fun√ß√£o de verossimilhan√ßa, permitindo uma manipula√ß√£o matem√°tica mais direta. Especificamente, a fun√ß√£o de densidade conjunta dos erros $\epsilon_1, \epsilon_2, \ldots, \epsilon_T$ √© dada por:*
$$ f(\epsilon_1, \epsilon_2, \ldots, \epsilon_T) = \prod_{t=1}^{T} \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{\epsilon_t^2}{2\sigma^2}\right) $$
*Essa forma facilita a deriva√ß√£o da fun√ß√£o de verossimilhan√ßa para modelos lineares, como os modelos ARMA.*

**Prova do Lema 1:**
I. Assumimos que os erros $\epsilon_t$ s√£o independentes e identicamente distribu√≠dos (i.i.d.) com uma distribui√ß√£o normal com m√©dia zero e vari√¢ncia $\sigma^2$, ou seja, $\epsilon_t \sim N(0, \sigma^2)$.
II. A fun√ß√£o de densidade de probabilidade (PDF) para uma √∫nica vari√°vel aleat√≥ria $\epsilon_t$ com distribui√ß√£o normal √© dada por:
$$ f(\epsilon_t) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{\epsilon_t^2}{2\sigma^2}\right) $$
III. Como os erros $\epsilon_1, \epsilon_2, \ldots, \epsilon_T$ s√£o independentes, a fun√ß√£o de densidade conjunta √© o produto das densidades marginais:
$$ f(\epsilon_1, \epsilon_2, \ldots, \epsilon_T) = \prod_{t=1}^{T} f(\epsilon_t) $$
IV. Substituindo a PDF de cada $\epsilon_t$, obtemos:
$$ f(\epsilon_1, \epsilon_2, \ldots, \epsilon_T) = \prod_{t=1}^{T} \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{\epsilon_t^2}{2\sigma^2}\right) $$
Portanto, provamos que a fun√ß√£o de densidade conjunta dos erros √© dada pela express√£o no Lema 1. ‚ñ†

A constru√ß√£o da fun√ß√£o de verossimilhan√ßa em [^5.1.4] e a busca por seu m√°ximo envolvem dois passos cruciais: primeiro, especificar a forma da fun√ß√£o de verossimilhan√ßa e, segundo, encontrar os valores dos par√¢metros que a maximizam. No contexto de modelos ARMA, esses passos requerem considera√ß√µes adicionais. Como mencionado anteriormente, assumimos que os erros s√£o gaussianos, o que nos permite utilizar ferramentas matem√°ticas e estat√≠sticas para derivar uma forma para a fun√ß√£o de verossimilhan√ßa. Em seguida, √© preciso usar t√©cnicas de otimiza√ß√£o para encontrar os valores dos par√¢metros que maximizam a fun√ß√£o.

#### C√°lculo da Fun√ß√£o de Verossimilhan√ßa para modelos ARMA
A determina√ß√£o da fun√ß√£o de verossimilhan√ßa para modelos ARMA requer um tratamento detalhado. Como vimos anteriormente [^5.1], assumimos que o processo de erro $\epsilon_t$ √© white noise gaussiano, o que implica que podemos derivar express√µes anal√≠ticas para a fun√ß√£o de verossimilhan√ßa.  Em geral, esta fun√ß√£o √© obtida a partir da fun√ß√£o de densidade conjunta da amostra observada, que por sua vez √© constru√≠da com base nas caracter√≠sticas dos erros e na estrutura do modelo ARMA.

**Teorema 1:** *Para um modelo ARMA(p,q), onde* $y_t = \phi_1 y_{t-1} + \ldots + \phi_p y_{t-p} + \epsilon_t + \theta_1 \epsilon_{t-1} + \ldots + \theta_q \epsilon_{t-q}$, *a fun√ß√£o de verossimilhan√ßa pode ser expressa, condicionalmente em valores iniciais, como uma fun√ß√£o das inova√ß√µes (res√≠duos) $\epsilon_t$ , dada a distribui√ß√£o gaussiana dos erros:*

$$L(\theta; Y) = f(y_1, y_2, \ldots, y_T; \theta) \propto \prod_{t=1}^{T} \frac{1}{\sigma} \exp\left(-\frac{\epsilon_t^2}{2\sigma^2}\right)$$

*Onde $\theta = (\phi_1, \ldots, \phi_p, \theta_1, \ldots, \theta_q, \sigma^2)$  representa todos os par√¢metros do modelo, e  os $\epsilon_t$ s√£o os res√≠duos, calculados recursivamente usando os dados observados e os valores atuais dos par√¢metros.*

**Prova do Teorema 1:**
I. O modelo ARMA(p, q) √© definido como $y_t = \phi_1 y_{t-1} + \ldots + \phi_p y_{t-p} + \epsilon_t + \theta_1 \epsilon_{t-1} + \ldots + \theta_q \epsilon_{t-q}$. Podemos reescrever essa equa√ß√£o para obter $\epsilon_t$ em fun√ß√£o dos dados observados $y_t$ e dos par√¢metros do modelo, resultando em $\epsilon_t = y_t - \phi_1 y_{t-1} - \ldots - \phi_p y_{t-p} - \theta_1 \epsilon_{t-1} - \ldots - \theta_q \epsilon_{t-q}$.
II. A fun√ß√£o de verossimilhan√ßa $L(\theta; Y)$ √© definida como a probabilidade da amostra observada $Y = (y_1, y_2, \ldots, y_T)$ dado os par√¢metros $\theta$. Sob a suposi√ß√£o de que os erros $\epsilon_t$ s√£o gaussianos e independentes, a probabilidade conjunta da amostra pode ser escrita como:
$$ f(y_1, y_2, \ldots, y_T; \theta) = f(\epsilon_1, \epsilon_2, \ldots, \epsilon_T; \theta) $$
III. Usando o resultado do Lema 1, sabemos que a fun√ß√£o de densidade conjunta dos erros √© dada por:
$$ f(\epsilon_1, \epsilon_2, \ldots, \epsilon_T) = \prod_{t=1}^{T} \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{\epsilon_t^2}{2\sigma^2}\right) $$
IV. Ignorando as constantes que n√£o dependem dos par√¢metros $\theta$, podemos escrever a fun√ß√£o de verossimilhan√ßa como:
$$ L(\theta; Y) \propto \prod_{t=1}^{T} \frac{1}{\sigma} \exp\left(-\frac{\epsilon_t^2}{2\sigma^2}\right) $$
Portanto, provamos que a fun√ß√£o de verossimilhan√ßa para o modelo ARMA pode ser expressa como uma fun√ß√£o dos res√≠duos. ‚ñ†

> üí° **Exemplo Num√©rico:** Considere um modelo AR(1): $y_t = 0.7y_{t-1} + \epsilon_t$, onde $\epsilon_t \sim N(0, \sigma^2)$. Suponha que temos os primeiros tr√™s valores da s√©rie temporal: $y_1 = 1, y_2 = 1.5, y_3 = 2.2$.
> Para calcular a fun√ß√£o de verossimilhan√ßa, precisamos calcular os res√≠duos (ou inova√ß√µes):
> $\epsilon_1 = y_1 - 0.7y_0$. Assumindo $y_0=0$, $\epsilon_1 = 1$.
> $\epsilon_2 = y_2 - 0.7y_1 = 1.5 - 0.7(1) = 0.8$
> $\epsilon_3 = y_3 - 0.7y_2 = 2.2 - 0.7(1.5) = 1.15$
>
> Se a vari√¢ncia dos erros $\sigma^2 = 0.2$, ent√£o a fun√ß√£o de verossimilhan√ßa (ignorando as constantes) √© proporcional a:
>
> $L(\phi=0.7; Y) \propto \frac{1}{\sqrt{0.2}^3} \exp\left(-\frac{1^2}{2(0.2)}\right) \exp\left(-\frac{0.8^2}{2(0.2)}\right) \exp\left(-\frac{1.15^2}{2(0.2)}\right) \approx 0.00087$
>
>  Repetir√≠amos o processo para diferentes valores de $\phi$ e $\sigma^2$, buscando aqueles que maximizam a fun√ß√£o de verossimilhan√ßa.

**Teorema 1.1:** *Em particular, quando se assume que a distribui√ß√£o de erros √© normal, o logaritmo da fun√ß√£o de verossimilhan√ßa (log-verossimilhan√ßa) para um modelo ARMA(p,q) pode ser expresso como:*

$$ \log L(\theta; Y) =  -\frac{T}{2} \log(2\pi\sigma^2) - \frac{1}{2\sigma^2} \sum_{t=1}^{T} \epsilon_t^2 $$

*A maximiza√ß√£o desta fun√ß√£o √© equivalente a minimizar a soma dos quadrados dos res√≠duos, penalizada pela vari√¢ncia do erro, e √© frequentemente usada na pr√°tica.*

**Prova do Teorema 1.1:**
I.  Partimos da fun√ß√£o de verossimilhan√ßa obtida no Teorema 1:
$$L(\theta; Y) \propto \prod_{t=1}^{T} \frac{1}{\sigma} \exp\left(-\frac{\epsilon_t^2}{2\sigma^2}\right)$$
II. Tomando o logaritmo natural de ambos os lados, obtemos o log-verossimilhan√ßa:
$$ \log L(\theta; Y) = \log \left( \prod_{t=1}^{T} \frac{1}{\sigma} \exp\left(-\frac{\epsilon_t^2}{2\sigma^2}\right) \right) $$
III. Usando as propriedades do logaritmo, transformamos o produto em uma soma:
$$ \log L(\theta; Y) =  \sum_{t=1}^{T} \log \left( \frac{1}{\sigma} \exp\left(-\frac{\epsilon_t^2}{2\sigma^2}\right) \right) $$
IV. Expandindo o logaritmo, obtemos:
$$ \log L(\theta; Y) =  \sum_{t=1}^{T} \left[ \log\left(\frac{1}{\sigma}\right) + \log\left(\exp\left(-\frac{\epsilon_t^2}{2\sigma^2}\right)\right) \right] $$
V. Simplificando a express√£o:
$$ \log L(\theta; Y) =  \sum_{t=1}^{T} \left[ -\log(\sigma) -\frac{\epsilon_t^2}{2\sigma^2} \right] $$
VI. Como a soma √© sobre $T$ termos, podemos escrever:
$$ \log L(\theta; Y) =  -T\log(\sigma) - \frac{1}{2\sigma^2} \sum_{t=1}^{T} \epsilon_t^2 $$
VII. Adicionando o termo constante que foi omitido na deriva√ß√£o do Teorema 1 e usando a rela√ß√£o $\sigma = \sqrt{\sigma^2}$, obtemos:
$$ \log L(\theta; Y) = -\frac{T}{2} \log(2\pi\sigma^2) - \frac{1}{2\sigma^2} \sum_{t=1}^{T} \epsilon_t^2 $$
Portanto, provamos que o log-verossimilhan√ßa para um modelo ARMA com erros gaussianos pode ser expresso como na equa√ß√£o do Teorema 1.1. ‚ñ†

> üí° **Exemplo Num√©rico:** Usando o exemplo anterior, com $T=3$, $\epsilon_1 = 1, \epsilon_2 = 0.8, \epsilon_3 = 1.15$ e  $\sigma^2=0.2$, o log-verossimilhan√ßa √©:
>
> $ \log L(\theta; Y) = -\frac{3}{2} \log(2\pi(0.2)) - \frac{1}{2(0.2)} (1^2 + 0.8^2 + 1.15^2) \approx -1.83-10.58  \approx -12.41$
>
> Ao maximizar esta fun√ß√£o (ou minimizar seu negativo), estar√≠amos otimizando os par√¢metros do nosso modelo AR(1). Note que para encontrar os par√¢metros √≥timos, precisar√≠amos iterar este c√°lculo v√°rias vezes, testando diferentes valores de $\phi$ e $\sigma^2$.

#### T√©cnicas de Otimiza√ß√£o Num√©rica
A maximiza√ß√£o da fun√ß√£o de verossimilhan√ßa frequentemente n√£o pode ser realizada analiticamente. Deste modo, m√©todos de otimiza√ß√£o num√©rica s√£o usados para encontrar valores de $\theta$ que maximizem a fun√ß√£o de verossimilhan√ßa. Estes m√©todos iterativos incluem algoritmos de gradiente e outros mais avan√ßados.  Em resumo, a estima√ß√£o por m√°xima verossimilhan√ßa em s√©ries temporais √© uma combina√ß√£o de modelos estat√≠sticos bem definidos com ferramentas de otimiza√ß√£o num√©rica.

**Proposi√ß√£o 1:** *Para modelos ARMA, o algoritmo de otimiza√ß√£o de Newton-Raphson, um m√©todo iterativo de segunda ordem, pode ser usado para maximizar a fun√ß√£o de verossimilhan√ßa. Este m√©todo utiliza informa√ß√µes sobre a primeira e segunda derivada da fun√ß√£o de verossimilhan√ßa, levando a uma converg√™ncia mais r√°pida em compara√ß√£o com m√©todos de primeira ordem.*

> üí° **Exemplo Num√©rico:** Suponha que estamos usando o m√©todo de Newton-Raphson para estimar o par√¢metro $\phi$ de um modelo AR(1) e que, em uma itera√ß√£o, temos uma estimativa inicial $\phi_0 = 0.5$. O m√©todo de Newton-Raphson envolve calcular a primeira e segunda derivada da log-verossimilhan√ßa em rela√ß√£o a $\phi$. Seja $\ell(\phi)$ a log-verossimilhan√ßa. Ent√£o, a atualiza√ß√£o de $\phi$ em cada itera√ß√£o √© dada por:
>
> $\phi_{i+1} = \phi_i - \frac{\ell'(\phi_i)}{\ell''(\phi_i)}$, onde $\ell'(\phi)$ e $\ell''(\phi)$ s√£o a primeira e segunda derivadas da log-verossimilhan√ßa em rela√ß√£o ao par√¢metro $\phi$.
>
> 1.  **C√°lculo das Derivadas:** As derivadas s√£o computadas usando c√°lculo diferencial e dependem do modelo espec√≠fico (no caso, AR(1)).
> 2.  **Itera√ß√£o:**
>
>     a. Suponha que $\ell'(\phi_0) = -1.2$ e $\ell''(\phi_0) = -3.5$ para $\phi_0 = 0.5$.
>
>     b.  $\phi_1 = 0.5 - \frac{-1.2}{-3.5} = 0.5 - 0.343 \approx 0.157$.
>
>     c. Este processo iterativo continua (recalculando as derivadas com o novo valor de $\phi_1$) at√© que a mudan√ßa em $\phi$ seja muito pequena (converg√™ncia). A cada passo, a verossimilhan√ßa aumenta.
>
> A escolha do m√©todo de otimiza√ß√£o e dos par√¢metros iniciais pode influenciar o n√∫mero de itera√ß√µes e o ponto de converg√™ncia. Outros m√©todos, como o algoritmo de gradiente descendente, poderiam ser usados, mas a converg√™ncia seria, em geral, mais lenta.
>

### Conclus√£o
A estimativa de m√°xima verossimilhan√ßa (MLE) √© um m√©todo fundamental para a an√°lise de s√©ries temporais, que se baseia na ideia de encontrar os par√¢metros que tornam a amostra observada a mais prov√°vel. Este cap√≠tulo delineou os princ√≠pios b√°sicos da MLE, destacando a import√¢ncia da fun√ß√£o de verossimilhan√ßa e as t√©cnicas num√©ricas para sua otimiza√ß√£o. A pr√≥xima se√ß√£o abordar√° o c√°lculo da fun√ß√£o de verossimilhan√ßa para diferentes tipos de modelos ARMA, bem como o desenvolvimento de m√©todos para maximiz√°-la. Como vimos anteriormente, a an√°lise de s√©ries temporais √© um campo que frequentemente exige um equil√≠brio entre teoria e pr√°tica, e a MLE √© um exemplo proeminente de como essas duas vertentes se complementam.

### Refer√™ncias
[^5.1]: ... *[Trecho do contexto que introduz o princ√≠pio da MLE]*
[^5.1.4]: ... *[Trecho do contexto que define a fun√ß√£o de verossimilhan√ßa]*
[^5.1.5]: ... *[Trecho do contexto que define a distribui√ß√£o dos erros]*
<!-- END -->
