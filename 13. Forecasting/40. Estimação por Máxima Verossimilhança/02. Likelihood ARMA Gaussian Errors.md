## A Fun√ß√£o de Verossimilhan√ßa e sua Maximiza√ß√£o em Modelos ARMA Gaussianos

### Introdu√ß√£o
Como exploramos no cap√≠tulo anterior, a estimativa de m√°xima verossimilhan√ßa (MLE) √© uma ferramenta crucial para determinar os par√¢metros de modelos de s√©ries temporais. A ess√™ncia da MLE reside na constru√ß√£o e subsequente maximiza√ß√£o da fun√ß√£o de verossimilhan√ßa, que quantifica a probabilidade dos dados observados, dado um conjunto de par√¢metros. Neste cap√≠tulo, vamos nos aprofundar na constru√ß√£o da fun√ß√£o de verossimilhan√ßa para modelos ARMA (Autoregressive Moving Average) com erros Gaussianos e discutir os m√©todos para maximizar essa fun√ß√£o, com foco no c√°lculo de derivadas parciais e no uso de algoritmos iterativos. A discuss√£o anterior sobre MLE [^5.1] introduziu os conceitos gerais, e este cap√≠tulo constr√≥i sobre essa base, fornecendo detalhes t√©cnicos e matem√°ticos essenciais para a aplica√ß√£o pr√°tica da MLE em modelos ARMA.

### A Fun√ß√£o de Verossimilhan√ßa para Modelos ARMA Gaussianos
Como discutido anteriormente [^Lema 1], sob a hip√≥tese de erros gaussianos, a fun√ß√£o de verossimilhan√ßa para um modelo ARMA pode ser expressa em termos dos res√≠duos (ou inova√ß√µes) $\epsilon_t$. Especificamente, a fun√ß√£o de verossimilhan√ßa √© dada por [^Teorema 1]:
$$L(\theta; Y) \propto \prod_{t=1}^{T} \frac{1}{\sigma} \exp\left(-\frac{\epsilon_t^2}{2\sigma^2}\right)$$
onde $\theta = (\phi_1, \ldots, \phi_p, \theta_1, \ldots, \theta_q, \sigma^2)$ representa os par√¢metros do modelo, e $\epsilon_t$ s√£o os res√≠duos, que, como vimos [^Teorema 1], dependem recursivamente dos dados observados e dos par√¢metros do modelo. A maximiza√ß√£o desta fun√ß√£o de verossimilhan√ßa √© equivalente a minimizar a soma dos quadrados dos res√≠duos, penalizada pela vari√¢ncia do erro [^Teorema 1.1], o que √© uma forma pr√°tica de encontrar os valores √≥timos dos par√¢metros.

> üí° **Exemplo Num√©rico:** Suponha que temos uma s√©rie temporal de 3 observa√ß√µes (T=3) e um modelo com apenas um par√¢metro de vari√¢ncia $\sigma^2$. Se os res√≠duos calculados para cada observa√ß√£o forem $\epsilon_1 = 1$, $\epsilon_2 = -2$, e $\epsilon_3 = 1.5$ e temos uma estimativa inicial para $\sigma^2 = 2$, a fun√ß√£o de verossimilhan√ßa seria proporcional a:
>
> $$L(\sigma^2; Y) \propto \frac{1}{\sqrt{2}} \exp\left(-\frac{1^2}{2*2}\right) * \frac{1}{\sqrt{2}} \exp\left(-\frac{(-2)^2}{2*2}\right) * \frac{1}{\sqrt{2}} \exp\left(-\frac{1.5^2}{2*2}\right)$$
>
> $$L(\sigma^2; Y) \propto \frac{1}{2\sqrt{2}} \exp(-0.125) * \exp(-1) * \exp(-0.5625) \approx 0.0061$$
>
> Maximizar esta fun√ß√£o de verossimilhan√ßa significa encontrar o valor de $\sigma^2$ que torna essa probabilidade a maior poss√≠vel.

A fun√ß√£o de log-verossimilhan√ßa, que facilita a manipula√ß√£o matem√°tica e a otimiza√ß√£o, √© dada por [^Teorema 1.1]:
$$ \log L(\theta; Y) =  -\frac{T}{2} \log(2\pi\sigma^2) - \frac{1}{2\sigma^2} \sum_{t=1}^{T} \epsilon_t^2 $$

Esta fun√ß√£o √© o ponto de partida para o processo de estima√ß√£o de m√°xima verossimilhan√ßa. Para modelos ARMA espec√≠ficos, a express√£o dos res√≠duos  $\epsilon_t$ pode ser escrita em fun√ß√£o dos par√¢metros do modelo e dos dados observados, tornando o processo de maximiza√ß√£o fact√≠vel. A depend√™ncia dos res√≠duos nos par√¢metros introduz a necessidade de t√©cnicas de otimiza√ß√£o num√©rica para encontrar o m√°ximo da fun√ß√£o de verossimilhan√ßa.

> üí° **Exemplo Num√©rico:** Usando os mesmos valores do exemplo anterior, a fun√ß√£o de log-verossimilhan√ßa para os res√≠duos $\epsilon_1 = 1$, $\epsilon_2 = -2$, e $\epsilon_3 = 1.5$ e $\sigma^2 = 2$, com $T=3$ √©:
>
> $$\log L(\sigma^2; Y) = -\frac{3}{2} \log(2\pi*2) - \frac{1}{2*2} (1^2 + (-2)^2 + 1.5^2)$$
> $$\log L(\sigma^2; Y) = -\frac{3}{2} \log(4\pi) - \frac{1}{4} (1 + 4 + 2.25)$$
> $$\log L(\sigma^2; Y) \approx -5.216$$
> Maximizar esta fun√ß√£o de log-verossimilhan√ßa (que equivale a maximizar a fun√ß√£o de verossimilhan√ßa) nos permite encontrar o valor √≥timo de $\sigma^2$.

#### C√°lculo de Derivadas Parciais
A maximiza√ß√£o da fun√ß√£o de log-verossimilhan√ßa envolve encontrar os valores dos par√¢metros $\theta$ que maximizam a fun√ß√£o. Frequentemente, isso √© realizado calculando as derivadas parciais da fun√ß√£o de log-verossimilhan√ßa em rela√ß√£o a cada par√¢metro e, em seguida, buscando os pontos onde essas derivadas se anulam. No entanto, em modelos ARMA, a fun√ß√£o de verossimilhan√ßa √©, em geral, n√£o-linear nos par√¢metros, e, portanto, a otimiza√ß√£o anal√≠tica geralmente n√£o √© poss√≠vel.

**Lema 2:** *Para um modelo AR(1) $y_t = \phi y_{t-1} + \epsilon_t$, a derivada parcial da log-verossimilhan√ßa em rela√ß√£o a $\phi$ √© dada por:*
$$\frac{\partial \log L}{\partial \phi} = \frac{1}{\sigma^2} \sum_{t=1}^T \epsilon_t y_{t-1} $$

**Prova do Lema 2:**
I.  A log-verossimilhan√ßa para o modelo AR(1), usando [^Teorema 1.1], √© dada por:
$$ \log L(\phi, \sigma^2; Y) = -\frac{T}{2} \log(2\pi\sigma^2) - \frac{1}{2\sigma^2} \sum_{t=1}^{T} \epsilon_t^2 $$
II. Para o modelo AR(1), $\epsilon_t = y_t - \phi y_{t-1}$. Substituindo isso na log-verossimilhan√ßa, temos:
$$ \log L(\phi, \sigma^2; Y) = -\frac{T}{2} \log(2\pi\sigma^2) - \frac{1}{2\sigma^2} \sum_{t=1}^{T} (y_t - \phi y_{t-1})^2 $$
III. Calculamos a derivada parcial em rela√ß√£o a $\phi$:
$$ \frac{\partial \log L}{\partial \phi} = -\frac{1}{2\sigma^2} \sum_{t=1}^T 2(y_t - \phi y_{t-1})(-y_{t-1}) $$
IV. Simplificando a express√£o, obtemos:
$$ \frac{\partial \log L}{\partial \phi} = \frac{1}{\sigma^2} \sum_{t=1}^T (y_t - \phi y_{t-1}) y_{t-1} $$
V.  Usando que $\epsilon_t = y_t - \phi y_{t-1}$, a derivada parcial da log-verossimilhan√ßa em rela√ß√£o a $\phi$ √©:
$$ \frac{\partial \log L}{\partial \phi} = \frac{1}{\sigma^2} \sum_{t=1}^T \epsilon_t y_{t-1} $$
Portanto, provamos o Lema 2.  ‚ñ†

> üí° **Exemplo Num√©rico:**  Considere um modelo AR(1) com os seguintes dados: $y_1 = 2$, $y_2 = 3$, $y_3 = 4$ e $\phi = 0.5$, e $\sigma^2 = 1$.  Podemos calcular os res√≠duos como:
>  $\epsilon_1 = y_1 - \phi*0 = 2 - 0.5*0 = 2$, pois assumimos $y_0=0$, $\epsilon_2 = y_2 - \phi y_1 = 3 - 0.5*2 = 2$ e $\epsilon_3 = y_3 - \phi y_2 = 4 - 0.5*3 = 2.5$. Usando o Lema 2, a derivada parcial da log-verossimilhan√ßa em rela√ß√£o a $\phi$ seria:
>
>  $$ \frac{\partial \log L}{\partial \phi} = \frac{1}{1} ( \epsilon_1 * 0 + \epsilon_2 * y_1 + \epsilon_3 * y_2) = 1 * ( 2 * 0 + 2 * 2 + 2.5 * 3 ) = 0 + 4 + 7.5 = 11.5$$
> Este valor da derivada indica que aumentar o valor de $\phi$ aumentaria a verossimilhan√ßa.

Para modelos ARMA mais complexos, o c√°lculo das derivadas parciais pode ser mais envolvido, mas o processo geral envolve derivar a fun√ß√£o de log-verossimilhan√ßa em rela√ß√£o a cada par√¢metro e igualar essas derivadas a zero.

**Lema 2.1:** *Para um modelo MA(1) $y_t = \epsilon_t + \theta \epsilon_{t-1}$, a derivada parcial da log-verossimilhan√ßa em rela√ß√£o a $\theta$ √© dada por:*

$$\frac{\partial \log L}{\partial \theta} = \frac{1}{\sigma^2} \sum_{t=1}^T \epsilon_t \frac{\partial \epsilon_t}{\partial \theta} $$

**Prova do Lema 2.1:**
I.  A log-verossimilhan√ßa para o modelo MA(1), usando [^Teorema 1.1], √© dada por:
$$ \log L(\theta, \sigma^2; Y) = -\frac{T}{2} \log(2\pi\sigma^2) - \frac{1}{2\sigma^2} \sum_{t=1}^{T} \epsilon_t^2 $$
II.  Para o modelo MA(1), $\epsilon_t = y_t - \theta \epsilon_{t-1}$. Note que $\epsilon_t$ depende de $\theta$ e tamb√©m de valores de $\epsilon_{t-1}$, que tamb√©m dependem de $\theta$ e assim por diante, logo, a derivada de $\epsilon_t$ em rela√ß√£o a $\theta$ √© n√£o trivial.
III.  Calculamos a derivada parcial em rela√ß√£o a $\theta$:
$$ \frac{\partial \log L}{\partial \theta} = -\frac{1}{2\sigma^2} \sum_{t=1}^T 2\epsilon_t \frac{\partial \epsilon_t}{\partial \theta} $$
IV. Simplificando a express√£o, obtemos:
$$ \frac{\partial \log L}{\partial \theta} = \frac{1}{\sigma^2} \sum_{t=1}^T \epsilon_t \frac{\partial \epsilon_t}{\partial \theta} $$

Note que para modelos MA(1) $\frac{\partial \epsilon_t}{\partial \theta} = -\epsilon_{t-1} - \theta\frac{\partial \epsilon_{t-1}}{\partial \theta}$, o que implica recurs√£o. Portanto, provamos o Lema 2.1.  ‚ñ†

> üí° **Exemplo Num√©rico:** Para um modelo MA(1) com $y_1 = 1, y_2=2, y_3=1.5$,  $\theta = 0.3$ e $\sigma^2 = 0.5$, precisamos calcular os res√≠duos recursivamente e suas derivadas parciais em rela√ß√£o a $\theta$. Assumindo $\epsilon_0=0$, temos:
>   - $\epsilon_1 = y_1 - \theta \epsilon_0 = 1 - 0.3 * 0 = 1$
>   - $\epsilon_2 = y_2 - \theta \epsilon_1 = 2 - 0.3 * 1 = 1.7$
>   - $\epsilon_3 = y_3 - \theta \epsilon_2 = 1.5 - 0.3 * 1.7 = 0.99$
>   As derivadas parciais em rela√ß√£o a $\theta$ s√£o:
>    - $\frac{\partial \epsilon_1}{\partial \theta} = 0$ (j√° que $\epsilon_0$ √© constante)
>    - $\frac{\partial \epsilon_2}{\partial \theta} = -\epsilon_1 - \theta \frac{\partial \epsilon_1}{\partial \theta} = -1 - 0.3 * 0 = -1$
>    - $\frac{\partial \epsilon_3}{\partial \theta} = -\epsilon_2 - \theta \frac{\partial \epsilon_2}{\partial \theta} = -1.7 - 0.3 * (-1) = -1.4$
>   Finalmente, usamos o Lema 2.1 para calcular a derivada parcial da log-verossimilhan√ßa em rela√ß√£o a $\theta$:
>   $$\frac{\partial \log L}{\partial \theta} = \frac{1}{0.5} (1*0 + 1.7*(-1) + 0.99 * (-1.4)) = 2 * (0 -1.7 - 1.386) = -6.172$$
>   O valor negativo da derivada sugere que diminuir $\theta$ aumentaria a verossimilhan√ßa.

### Algoritmos Iterativos para Maximiza√ß√£o
Como a solu√ß√£o anal√≠tica para as derivadas parciais geralmente n√£o √© poss√≠vel, m√©todos num√©ricos iterativos s√£o usados.  Esses m√©todos come√ßam com um palpite inicial para os par√¢metros e, em seguida, iterativamente, atualizam esses valores at√© que a fun√ß√£o de log-verossimilhan√ßa seja maximizada (ou seja, as derivadas parciais se aproximem de zero). Os algoritmos de otimiza√ß√£o comumente usados incluem m√©todos de gradiente e m√©todos de Newton-Raphson.

**Proposi√ß√£o 2:** *O m√©todo de Newton-Raphson, um m√©todo iterativo de segunda ordem, pode ser usado para maximizar a fun√ß√£o de log-verossimilhan√ßa. A atualiza√ß√£o do vetor de par√¢metros $\theta$ em cada itera√ß√£o i √© dada por:*
$$\theta_{i+1} = \theta_i - [H(\theta_i)]^{-1} \nabla L(\theta_i)$$
*onde $\nabla L(\theta_i)$ √© o vetor gradiente da fun√ß√£o de log-verossimilhan√ßa avaliada em $\theta_i$, e $H(\theta_i)$ √© a matriz Hessiana (matriz das segundas derivadas parciais) da fun√ß√£o de log-verossimilhan√ßa, tamb√©m avaliada em $\theta_i$.*

> üí° **Exemplo Num√©rico:**  Considere um modelo AR(1) com um √∫nico par√¢metro $\phi$,  e suponha que temos calculado que o gradiente $\nabla L(\phi_i) = -2$ e a Hessiana $H(\phi_i) = -5$ para uma estimativa inicial $\phi_i = 0.5$. De acordo com a Proposi√ß√£o 2, a nova estimativa $\phi_{i+1}$ seria:
>
> $\phi_{i+1} = \phi_i - (H(\phi_i))^{-1} \nabla L(\phi_i) = 0.5 - \frac{-2}{-5} = 0.5 - 0.4 = 0.1$. Este processo iterativo continua at√© que a altera√ß√£o em $\phi_i$ seja muito pequena.

A escolha de um bom valor inicial para os par√¢metros √© crucial para a converg√™ncia r√°pida de algoritmos iterativos. M√©todos de primeira ordem, como o gradiente descendente, utilizam apenas a primeira derivada da fun√ß√£o de log-verossimilhan√ßa. Apesar de mais simples, esses m√©todos podem levar a uma converg√™ncia mais lenta do que os m√©todos de segunda ordem, que utilizam tanto a primeira como a segunda derivadas.
Algoritmos como o BFGS (Broyden‚ÄìFletcher‚ÄìGoldfarb‚ÄìShanno) s√£o varia√ß√µes do m√©todo de Newton-Raphson, que aproximam a matriz Hessiana e s√£o preferidos em muitos casos pr√°ticos devido √† sua efici√™ncia e estabilidade num√©rica.

**Proposi√ß√£o 2.1:** *O m√©todo de gradiente descendente, um m√©todo iterativo de primeira ordem, pode ser usado para maximizar a fun√ß√£o de log-verossimilhan√ßa. A atualiza√ß√£o do vetor de par√¢metros $\theta$ em cada itera√ß√£o i √© dada por:*
$$\theta_{i+1} = \theta_i + \alpha \nabla L(\theta_i)$$
*onde $\nabla L(\theta_i)$ √© o vetor gradiente da fun√ß√£o de log-verossimilhan√ßa avaliada em $\theta_i$, e $\alpha$ √© a taxa de aprendizado, um escalar que controla o tamanho do passo na dire√ß√£o do gradiente.*

> üí° **Exemplo Num√©rico:**  Considere novamente o modelo AR(1) com um √∫nico par√¢metro $\phi$, e suponha que temos calculado que o gradiente $\nabla L(\phi_i) = -2$ para uma estimativa inicial $\phi_i = 0.5$. Se escolhermos uma taxa de aprendizado $\alpha = 0.1$, de acordo com a Proposi√ß√£o 2.1, a nova estimativa $\phi_{i+1}$ seria:
>
> $\phi_{i+1} = \phi_i + \alpha \nabla L(\phi_i) = 0.5 + 0.1*(-2) = 0.5 - 0.2 = 0.3$. Este processo iterativo continua at√© que a altera√ß√£o em $\phi_i$ seja muito pequena. A escolha de $\alpha$ √© crucial: um valor muito alto pode levar a oscila√ß√µes e n√£o converg√™ncia, enquanto um valor muito baixo pode levar a uma converg√™ncia muito lenta.

#### Considera√ß√µes Pr√°ticas
√â importante notar que, ao maximizar a fun√ß√£o de log-verossimilhan√ßa, √© comum que os algoritmos de otimiza√ß√£o sejam executados at√© que um crit√©rio de converg√™ncia seja atingido. O crit√©rio pode ser uma altera√ß√£o pequena nos par√¢metros estimados ou uma altera√ß√£o pequena na fun√ß√£o de log-verossimilhan√ßa. Al√©m disso, a escolha da forma funcional da distribui√ß√£o dos erros √© uma etapa crucial, e embora a suposi√ß√£o gaussiana seja comum, outros tipos de distribui√ß√£o podem ser mais apropriados dependendo da aplica√ß√£o. √â crucial tamb√©m avaliar a signific√¢ncia estat√≠stica dos par√¢metros estimados, geralmente atrav√©s do c√°lculo dos desvios padr√£o usando a matriz Hessiana. Isso permite construir intervalos de confian√ßa para os par√¢metros, e verificar se os par√¢metros s√£o significativamente diferentes de zero.

### Conclus√£o
Este cap√≠tulo explorou em detalhes o processo de constru√ß√£o e maximiza√ß√£o da fun√ß√£o de verossimilhan√ßa para modelos ARMA com erros gaussianos. Vimos que, embora a fun√ß√£o de verossimilhan√ßa seja um conceito fundamental, a pr√°tica de encontrar os valores √≥timos dos par√¢metros geralmente envolve o uso de algoritmos iterativos, como os m√©todos de Newton-Raphson e suas varia√ß√µes. A combina√ß√£o da deriva√ß√£o matem√°tica da fun√ß√£o de verossimilhan√ßa e as ferramentas de otimiza√ß√£o num√©rica formam a base para a estima√ß√£o de m√°xima verossimilhan√ßa. No pr√≥ximo cap√≠tulo, detalharemos a aplica√ß√£o da MLE em diferentes modelos ARMA e avaliaremos as propriedades das estimativas obtidas por este m√©todo.

### Refer√™ncias
[^5.1]: ... *[Trecho do contexto que introduz o princ√≠pio da MLE]*
[^Lema 1]: ... *[Trecho do contexto que explicita a forma da fun√ß√£o de densidade conjunta dos erros gaussianos]*
[^Teorema 1]: ... *[Trecho do contexto que define a fun√ß√£o de verossimilhan√ßa para modelos ARMA]*
[^Teorema 1.1]: ... *[Trecho do contexto que apresenta a forma da log-verossimilhan√ßa]*
<!-- END -->
