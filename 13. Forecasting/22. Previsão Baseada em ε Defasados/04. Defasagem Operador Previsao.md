## Previs√£o com Operador de Defasagem e Fun√ß√£o de Aniquila√ß√£o

### Introdu√ß√£o
Em continuidade √† discuss√£o sobre previs√£o de s√©ries temporais, este cap√≠tulo aborda o uso do operador de defasagem (lag operator) e de uma fun√ß√£o de aniquila√ß√£o para representar as previs√µes, particularmente em situa√ß√µes onde se deseja expressar a previs√£o como uma fun√ß√£o dos erros passados [^8]. Essa abordagem √© fundamental quando se trabalha com representa√ß√µes de m√©dia m√≥vel (MA), ou representa√ß√µes em que o termo de erro n√£o √© diretamente observ√°vel, mas sim constru√≠do recursivamente. A aplica√ß√£o da fun√ß√£o de aniquila√ß√£o aos coeficientes associados a pot√™ncias negativas do operador de defasagem garante que apenas os termos relevantes para a previs√£o sejam considerados.

### O Operador de Defasagem e a Previs√£o
O operador de defasagem, denotado por $L$, √© uma ferramenta poderosa para manipular express√µes envolvendo defasagens temporais [^7]. Ele √© definido de modo que $L^j Y_t = Y_{t-j}$, onde $Y_t$ √© uma s√©rie temporal e $j$ √© o n√∫mero de defasagens. O uso de polin√¥mios de defasagem permite representar rela√ß√µes complexas entre os valores de uma s√©rie temporal em diferentes instantes de tempo de forma concisa [^7].

Como vimos anteriormente, quando temos uma representa√ß√£o MA, como $Y_t - \mu = \psi(L)\epsilon_t$, a previs√£o de $Y_{t+s}$ no tempo $t$, denotada por $\hat{Y}_{t+s|t}$, pode ser expressa usando o operador de defasagem e uma fun√ß√£o de aniquila√ß√£o [^8]:
$$
\hat{Y}_{t+s|t} = \mu + \left[ \frac{\psi(L)}{L^s} \right]_+ \epsilon_{t+s}
$$
Nessa express√£o, o termo $\frac{\psi(L)}{L^s}$ representa um polin√¥mio de defasagem que, quando expandido, pode conter pot√™ncias tanto positivas quanto negativas de $L$. No entanto, como estamos interessados na previs√£o no tempo $t$, apenas os termos correspondentes a defasagens presentes ou passadas (i.e., coeficientes de $L$ com expoentes n√£o negativos) s√£o relevantes. √â aqui que a fun√ß√£o de aniquila√ß√£o entra em jogo.

### A Fun√ß√£o de Aniquila√ß√£o
A fun√ß√£o de aniquila√ß√£o, denotada por $[\cdot]_+$, √© um operador que atua sobre um polin√¥mio de defasagem e substitui por zero os coeficientes associados a pot√™ncias negativas de $L$ [^8]. Formalmente, para um polin√¥mio de defasagem gen√©rico $A(L) = \sum_{j=-\infty}^{\infty} a_j L^j$, a aplica√ß√£o da fun√ß√£o de aniquila√ß√£o √© definida como:
$$
[A(L)]_+ = \sum_{j=0}^{\infty} a_j L^j
$$
Essa opera√ß√£o garante que apenas os coeficientes das defasagens para frente (i.e., aquelas que representam valores passados ou atuais do processo) sejam inclu√≠dos no c√°lculo da previs√£o, eliminando os coeficientes correspondentes ao futuro (i.e., pot√™ncias negativas de L) [^8].

**Lema 4:**
Para um polin√¥mio de defasagem $A(L) = \sum_{j=-\infty}^{\infty} a_j L^j$, a fun√ß√£o de aniquila√ß√£o √© definida como:
$$
[A(L)]_+ = \sum_{j=0}^{\infty} a_j L^j
$$
*Prova:*
I. A fun√ß√£o de aniquila√ß√£o, por defini√ß√£o, elimina as pot√™ncias negativas do operador de defasagem $L$.
II. Assim, apenas as pot√™ncias n√£o negativas (zero ou positivas) permanecem na soma.
III. Portanto, o resultado √© a soma dos termos com expoentes n√£o negativos de $L$: $\sum_{j=0}^{\infty} a_j L^j$.
‚ñ†

**Lema 4.1:**
Se $A(L)$ e $B(L)$ s√£o polin√¥mios de defasagem, ent√£o $[A(L) + B(L)]_+ = [A(L)]_+ + [B(L)]_+$.
*Prova:*
Sejam $A(L) = \sum_{j=-\infty}^{\infty} a_j L^j$ e $B(L) = \sum_{j=-\infty}^{\infty} b_j L^j$. Ent√£o,
$$
\begin{aligned}
[A(L) + B(L)]_+ &= \left[ \sum_{j=-\infty}^{\infty} a_j L^j + \sum_{j=-\infty}^{\infty} b_j L^j \right]_+ \\
&= \left[ \sum_{j=-\infty}^{\infty} (a_j + b_j) L^j \right]_+ \\
&= \sum_{j=0}^{\infty} (a_j + b_j) L^j \\
&= \sum_{j=0}^{\infty} a_j L^j + \sum_{j=0}^{\infty} b_j L^j \\
&= [A(L)]_+ + [B(L)]_+
\end{aligned}
$$
‚ñ†
Essa propriedade √© essencial para o c√°lculo das previs√µes, uma vez que ela garante que os coeficientes que est√£o relacionados com valores futuros sejam eliminados.

> üí° **Exemplo Num√©rico:** Seja $A(L) = L^{-2} + 2L^{-1} + 3 + 4L + 5L^2$. Ent√£o, a aplica√ß√£o da fun√ß√£o de aniquila√ß√£o resulta em:
> $$
> [A(L)]_+ = [L^{-2} + 2L^{-1} + 3 + 4L + 5L^2]_+ = 3 + 4L + 5L^2
> $$
>  Note que apenas os termos com pot√™ncias n√£o-negativas de L s√£o preservados, enquanto os termos com pot√™ncias negativas s√£o anulados.
>
> üí° **Exemplo Num√©rico:** Sejam $A(L) = 1 + 2L^{-1} + 3L$ e $B(L) = L^{-1} + 4 + 5L^2$. Ent√£o:
>
>  $[A(L)]_+ = [1 + 2L^{-1} + 3L]_+ = 1 + 3L$
>
>  $[B(L)]_+ = [L^{-1} + 4 + 5L^2]_+ = 4 + 5L^2$
>
>  $[A(L) + B(L)]_+ = [1 + 3L^{-1} + 4 + 3L + 5L^2]_+ = 1 + 4 + 3L + 5L^2 = 5 + 3L + 5L^2$
>
>  $[A(L)]_+ + [B(L)]_+ = (1 + 3L) + (4 + 5L^2) = 5 + 3L + 5L^2$
>
>  Confirmando que $[A(L) + B(L)]_+ = [A(L)]_+ + [B(L)]_+$.
### Previs√£o com Operador de Defasagem e Fun√ß√£o de Aniquila√ß√£o
A combina√ß√£o do operador de defasagem e da fun√ß√£o de aniquila√ß√£o √© particularmente √∫til na previs√£o de processos representados como m√©dia m√≥vel (MA), onde o valor presente da s√©rie temporal √© expresso como uma combina√ß√£o linear de erros defasados [^8]. Consideremos um processo MA(q) dado por:
$$
Y_t - \mu = \theta(L)\epsilon_t = (1 + \theta_1 L + \theta_2 L^2 + \ldots + \theta_q L^q)\epsilon_t
$$
onde $\epsilon_t$ √© um ru√≠do branco [^7].  Para obter a previs√£o de $Y_{t+s}$ dado o hist√≥rico da s√©rie temporal at√© o tempo $t$, expressamos $Y_{t+s}$ como:
$$
Y_{t+s} - \mu = \theta(L)\epsilon_{t+s}
$$
Multiplicando ambos os lados por $L^{-s}$ e aplicando o operador de aniquila√ß√£o [^8], obtemos:
$$
\hat{Y}_{t+s|t} - \mu = \left[ \frac{\theta(L)}{L^s} \right]_+ \epsilon_{t+s}
$$
Onde
$$ \frac{\theta(L)}{L^s} = \frac{1 + \theta_1 L + \theta_2 L^2 + \ldots + \theta_q L^q}{L^s} = L^{-s} + \theta_1 L^{1-s} + \theta_2 L^{2-s} + \ldots + \theta_q L^{q-s}  $$
A fun√ß√£o de aniquila√ß√£o elimina os termos com pot√™ncias negativas de $L$, o que faz com que, para  $s > q$,  $\hat{Y}_{t+s|t} = \mu$.
Na pr√°tica, os erros $\epsilon_t$ n√£o s√£o observ√°veis e, portanto, √© necess√°rio expressar a previs√£o em termos de valores defasados de $Y$. Isso pode ser feito utilizando a propriedade $\eta(L) = 1/\psi(L)$ vista no cap√≠tulo anterior, ou seja, usando a representa√ß√£o AR(‚àû) [^7]. Obtemos assim o resultado geral para a previs√£o de s passos a frente:
$$
\hat{Y}_{t+s|t} = \mu + \left[ \frac{\psi(L)}{L^s} \right]_+ \frac{1}{\eta(L)} (Y_t - \mu)
$$

**Teorema 3:**
Para um processo estacion√°rio com representa√ß√£o $Y_t-\mu = \psi(L)\epsilon_t$, onde $\psi(L) = \sum_{j=0}^{\infty} \psi_j L^j$ e $\epsilon_t$ √© um ru√≠do branco, a previs√£o de $Y_{t+s}$ no tempo $t$ √© dada por:
$$
\hat{Y}_{t+s|t} = \mu + \left[ \frac{\psi(L)}{L^s} \right]_+ \frac{1}{\eta(L)} (Y_t - \mu)
$$
*Prova:*
I. Come√ßamos com a representa√ß√£o do processo:
$$
Y_t - \mu = \psi(L) \epsilon_t
$$
II. Para prever $Y_{t+s}$, temos:
$$
Y_{t+s} - \mu = \psi(L) \epsilon_{t+s}
$$
III. Multiplicando ambos os lados por $L^{-s}$, temos:
$$
L^{-s}(Y_{t+s} - \mu) = L^{-s} \psi(L) \epsilon_{t+s}
$$
IV. Aplicando o operador de aniquila√ß√£o $[ \cdot ]_+$ no lado direito e expressando $\epsilon_{t+s}$ em termos de $Y_t$ usando a rela√ß√£o $\epsilon_t = \frac{1}{\psi(L)}(Y_t-\mu)$, e o fato de que $\hat{\epsilon}_{t+j|t} = 0$ para $j>0$, obtemos:
$$
\hat{Y}_{t+s|t} - \mu = \left[ \frac{\psi(L)}{L^s} \right]_+ \epsilon_{t+s} = \left[ \frac{\psi(L)}{L^s} \right]_+ \frac{1}{\eta(L)}(Y_t-\mu)
$$
V.  Rearranjando a equa√ß√£o, obtemos o resultado desejado:
$$
\hat{Y}_{t+s|t} = \mu + \left[ \frac{\psi(L)}{L^s} \right]_+ \frac{1}{\eta(L)} (Y_t - \mu)
$$
‚ñ†
Note que, dependendo do contexto e da informa√ß√£o dispon√≠vel, $\frac{1}{\eta(L)} $ pode ser computado usando a expans√£o em s√©rie, a representa√ß√£o ARMA ou AR(‚àû).

**Teorema 3.1**
Para um processo MA(q) dado por $Y_t - \mu = \theta(L)\epsilon_t$, onde $\theta(L) = 1 + \theta_1 L + \theta_2 L^2 + \ldots + \theta_q L^q$, a previs√£o de $Y_{t+s}$ no tempo $t$ para $s > q$ √© $\hat{Y}_{t+s|t} = \mu$.
*Prova:*
I.  A partir do Teorema 3, temos:
$$ \hat{Y}_{t+s|t} = \mu + \left[ \frac{\theta(L)}{L^s} \right]_+ \frac{1}{\eta(L)}(Y_t - \mu) $$
II. Como $\theta(L)$ √© um polin√¥mio de grau $q$, quando dividimos por $L^s$ com $s > q$, todos os termos resultantes ter√£o pot√™ncias negativas de $L$.
III. Assim, a fun√ß√£o de aniquila√ß√£o elimina todos os termos, resultando em:
$$ \left[ \frac{\theta(L)}{L^s} \right]_+ = 0 $$
IV. Portanto,
$$ \hat{Y}_{t+s|t} = \mu + 0 \cdot \frac{1}{\eta(L)}(Y_t - \mu) = \mu $$
‚ñ†

> üí° **Exemplo Num√©rico:**  Considere o modelo MA(1) dado por $(Y_t - \mu) = (1 + 0.7L)\epsilon_t$, onde $\mu = 10$  e queremos prever $Y_{t+2}$ sabendo que $Y_t = 15$. Temos que $\psi(L) = 1 + 0.7L$ e $\eta(L) = 1/\psi(L)$.  Usando o operador de defasagem e fun√ß√£o de aniquila√ß√£o, temos:
>  $$
>  \begin{aligned}
>   \hat{Y}_{t+2|t} &=  \mu + \left[ \frac{1 + 0.7L}{L^2} \right]_+  \frac{1}{\eta(L)}(Y_t - \mu)\\
>   &=  \mu + \left[ \frac{1 + 0.7L}{L^2} \right]_+  (1 + 0.7L)^{-1} (Y_t - \mu)\\
>   &= \mu + \left[L^{-2} + 0.7L^{-1}  \right]_+ (1 - 0.7L + 0.49L^2 - \ldots)(Y_t - \mu)\\
>   &= \mu + 0 = 10
>   \end{aligned}
>  $$
>  Pois  $\frac{1 + 0.7L}{L^2}$  tem apenas termos com expoentes negativos de L, que s√£o eliminados pelo operador de aniquila√ß√£o. Note que a expans√£o $(1+0.7L)^{-1} = 1 - 0.7L + 0.49L^2 - \dots$ converge para $|0.7L| < 1$, o que √© consistente com a estacionaridade do processo MA(1). Por outro lado, para prever um per√≠odo a frente, temos
>  $$
>  \begin{aligned}
>   \hat{Y}_{t+1|t} &=  \mu + \left[ \frac{1 + 0.7L}{L} \right]_+  \frac{1}{\eta(L)}(Y_t - \mu)\\
>   &=  \mu + \left[ \frac{1 + 0.7L}{L} \right]_+  (1 + 0.7L)^{-1}(Y_t - \mu)\\
>   &=  \mu + \left[ L^{-1} + 0.7 \right]_+ (1 - 0.7L + 0.49L^2 - \ldots)(Y_t - \mu)\\
>   &=  \mu + 0.7 (Y_t-\mu) = 10 + 0.7(15 - 10) = 13.5
>   \end{aligned}
>  $$
>  Note que a previs√£o de dois per√≠odos a frente se reduz √† m√©dia, enquanto que a previs√£o de um passo a frente usa o valor corrente de $Y$.
>
> üí° **Exemplo Num√©rico:** Considere um modelo MA(2) dado por $Y_t - 5 = (1 + 0.5L + 0.2L^2)\epsilon_t$, onde $\mu = 5$. Queremos prever $Y_{t+3}$ e $Y_{t+1}$ dado que $Y_t = 12$. Temos que $\theta(L) = 1 + 0.5L + 0.2L^2$. Para prever tr√™s per√≠odos √† frente, calculamos:
> $$
> \hat{Y}_{t+3|t} = 5 + \left[ \frac{1 + 0.5L + 0.2L^2}{L^3} \right]_+ \epsilon_{t+3} = 5 + [L^{-3} + 0.5L^{-2} + 0.2L^{-1}]_+ \epsilon_{t+3} = 5 + 0 = 5
> $$
>  A previs√£o √© igual √† m√©dia do processo, pois o horizonte de previs√£o √© maior que a ordem do MA(q), $s > q$. Para prever um per√≠odo √† frente, precisamos usar a representa√ß√£o AR(‚àû) de $\frac{1}{\eta(L)} = (1 + 0.5L + 0.2L^2)^{-1}$, cuja expans√£o em s√©rie √© $(1-0.5L-0.2L^2 + 0.25L^2 + 0.1L^3 + ...)$. Portanto,
>
>  $\hat{Y}_{t+1|t} = 5 + \left[ \frac{1 + 0.5L + 0.2L^2}{L} \right]_+ \frac{1}{\eta(L)} (Y_t - 5)$
>  $\hat{Y}_{t+1|t} = 5 + [L^{-1} + 0.5 + 0.2L]_+ (1 -0.5L -0.2L^2 + 0.05L^2 + ...)(Y_t - 5)$
>
>  $\hat{Y}_{t+1|t} = 5 + (0.5)(12 - 5) = 5 + 3.5 = 8.5$
>
>  Note que a previs√£o de um per√≠odo √† frente n√£o √© igual √† m√©dia do processo, pois $s \leq q$.

#### Expressando o Erro em Termos dos Ys
A partir da defini√ß√£o da representa√ß√£o AR(‚àû) como $\eta(L)(Y_t-\mu) = \epsilon_t$, onde  $\eta(L) =  1 - \eta_1L - \eta_2L^2 - \ldots$, o erro $\epsilon_t$ pode ser expresso em termos dos valores defasados de $Y$ atrav√©s da expans√£o em s√©rie de $\eta(L)$:
$$
\epsilon_t = (Y_t-\mu) - \eta_1(Y_{t-1}-\mu) - \eta_2(Y_{t-2}-\mu) - \ldots
$$
Essa representa√ß√£o √© √∫til para computar os erros recursivamente, e √© usada, por exemplo, para computar os erros associados a modelos ARMA(p,q). Na pr√°tica,  essa expans√£o pode ser truncada em um n√∫mero finito de termos.

**Proposi√ß√£o 1:**
Se $\eta(L) = 1 - \sum_{j=1}^{\infty} \eta_j L^j$ ent√£o $\epsilon_t$ pode ser escrito recursivamente como
$$
\epsilon_t = (Y_t - \mu) - \sum_{j=1}^{\infty} \eta_j (Y_{t-j} - \mu)
$$
*Prova:*
I. Dado que $\eta(L)(Y_t - \mu) = \epsilon_t$ e $\eta(L) = 1 - \sum_{j=1}^{\infty} \eta_j L^j$, podemos escrever:
$$
\left( 1 - \sum_{j=1}^{\infty} \eta_j L^j \right) (Y_t - \mu) = \epsilon_t
$$
II. Expandindo a express√£o, obtemos
$$
(Y_t - \mu) - \sum_{j=1}^{\infty} \eta_j L^j (Y_t - \mu) = \epsilon_t
$$
III. Aplicando o operador de defasagem, temos
$$
(Y_t - \mu) - \sum_{j=1}^{\infty} \eta_j (Y_{t-j} - \mu) = \epsilon_t
$$
IV.  Rearranjando, chegamos √† representa√ß√£o desejada:
$$
\epsilon_t = (Y_t - \mu) - \sum_{j=1}^{\infty} \eta_j (Y_{t-j} - \mu)
$$
‚ñ†
> üí° **Exemplo Num√©rico:** Considere o modelo AR(1) dado por $Y_t = 0.8Y_{t-1} + \epsilon_t$, onde $\mu = 0$ (para simplificar). Ent√£o $\eta(L) = 1 - 0.8L$. Podemos expressar $\epsilon_t$ como:
> $$
> \epsilon_t = Y_t - 0.8Y_{t-1}
> $$
> Suponha que $Y_t = 10$ e $Y_{t-1} = 8$. Ent√£o, $\epsilon_t = 10 - 0.8 \times 8 = 10 - 6.4 = 3.6$.
> Para o caso geral, se temos um modelo AR(2) $Y_t = 0.5Y_{t-1} - 0.3Y_{t-2} + \epsilon_t$.  Ent√£o $\eta(L) = 1-0.5L + 0.3L^2$ e
> $$
> \epsilon_t = Y_t - 0.5Y_{t-1} + 0.3Y_{t-2}
> $$
>  Se $Y_t = 10$, $Y_{t-1} = 8$ e $Y_{t-2} = 6$, temos $\epsilon_t = 10 - 0.5 \times 8 + 0.3 \times 6 = 10 - 4 + 1.8 = 7.8$
>
> Essa forma de expressar os erros √© crucial quando os erros n√£o s√£o diretamente observ√°veis e √© a base para estimar modelos ARMA.

### Conclus√£o
O uso do operador de defasagem e da fun√ß√£o de aniquila√ß√£o oferece uma maneira concisa e eficaz para representar e calcular previs√µes em modelos de s√©ries temporais [^8]. A aplica√ß√£o da fun√ß√£o de aniquila√ß√£o garante que apenas os termos relevantes sejam inclu√≠dos no c√°lculo da previs√£o, o que √© especialmente importante em modelos com estruturas complexas [^8]. A combina√ß√£o dessas ferramentas proporciona uma abordagem flex√≠vel e robusta para a previs√£o, permitindo que os modelos sejam manipulados de forma pr√°tica e te√≥rica, e que o erro possa ser expresso em termos de valores defasados da s√©rie temporal.

### Refer√™ncias
[^7]: Se√ß√£o 4.2 - *Forecasts Based on Lagged Y's*
[^8]: Se√ß√£o 4.2 - *Forecasting Based on Lagged e's*
<!-- END -->
