## A Fatoração Triangular e Operações de Alto Desempenho
### Introdução
Este capítulo continua a exploração da fatoração triangular de uma matriz simétrica definida positiva, com foco em como essa técnica se desdobra em um produto do tipo $E\Omega E'$, onde $E$ são matrizes triangulares inferiores com 1s na diagonal. Este desdobramento, como veremos, não só esclarece a construção da fatoração, mas também possibilita a aplicação de operações de alto desempenho em diversas áreas, incluindo otimização numérica e análise de dados [^4].

### Desenvolvimento da Fatoração Triangular
Como estabelecido anteriormente, a fatoração triangular de uma matriz simétrica definida positiva $\Omega$ é expressa como $\Omega = ADA'$, onde $A$ é uma matriz triangular inferior com uns na diagonal principal e $D$ é uma matriz diagonal com entradas positivas. A obtenção desta fatoração envolve uma série de operações nas linhas de $\Omega$ que são representadas por matrizes elementares, denotadas por $E$. Estas matrizes $E$ são cruciais para transformar $\Omega$ numa matriz diagonal $D$ de forma sistemática.

**Matrizes de Transformação Elementares**
As matrizes de transformação elementares $E_k$ são construídas para introduzir zeros abaixo da diagonal principal em cada coluna da matriz $\Omega$. Cada matriz $E_k$ é uma matriz triangular inferior com 1s na diagonal, com a forma geral dada por:

$$
E_k = \begin{bmatrix}
1 & 0 & \cdots & 0 & \cdots & 0 \\
0 & 1 & \cdots & 0 & \cdots & 0 \\
\vdots & \vdots & \ddots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & 1 & \cdots & 0 \\
0 & 0 & \cdots & -h_{ik}h_{kk}^{-1} & \cdots & 0 \\
\vdots & \vdots & \ddots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & 0 & \cdots & 1
\end{bmatrix}
$$
onde $-h_{ik}h_{kk}^{-1}$ é o elemento na posição $(i, k)$ abaixo da diagonal principal, sendo $h_{ik}$ os elementos da matriz resultante da operação anterior e $h_{kk}$ o elemento diagonal na posição $(k,k)$. As matrizes elementares, quando multiplicadas por $\Omega$, modificam sequencialmente as colunas, resultando em uma matriz com zeros abaixo da diagonal principal [^4.4.3, ^4.4.6].

> 💡 **Exemplo Numérico:** Para ilustrar, considere uma matriz $\Omega$ 3x3:
>
> $$
\Omega = \begin{bmatrix}
4 & 2 & 2 \\
2 & 5 & 3 \\
2 & 3 & 6
\end{bmatrix}
$$
>
>  A primeira matriz elementar $E_1$ deve zerar os elementos abaixo do primeiro pivô (o elemento na posição (1,1)). Calculamos $h_{21}h_{11}^{-1} = 2/4 = 0.5$ e $h_{31}h_{11}^{-1} = 2/4 = 0.5$. Portanto, $E_1$ é:
>
>$$
E_1 = \begin{bmatrix}
1 & 0 & 0 \\
-0.5 & 1 & 0 \\
-0.5 & 0 & 1
\end{bmatrix}
$$
>  E a transposta de $E_1$ é:
>
>$$
E_1' = \begin{bmatrix}
1 & -0.5 & -0.5 \\
0 & 1 & 0 \\
0 & 0 & 1
\end{bmatrix}
$$
>  O produto $E_1\Omega E_1'$ resulta em:
>
>$$
H = E_1\Omega E_1' = \begin{bmatrix}
1 & 0 & 0 \\
-0.5 & 1 & 0 \\
-0.5 & 0 & 1
\end{bmatrix} \begin{bmatrix}
4 & 2 & 2 \\
2 & 5 & 3 \\
2 & 3 & 6
\end{bmatrix} \begin{bmatrix}
1 & -0.5 & -0.5 \\
0 & 1 & 0 \\
0 & 0 & 1
\end{bmatrix} = \begin{bmatrix}
4 & 0 & 0 \\
0 & 4 & 2 \\
0 & 2 & 5
\end{bmatrix}
$$
>  Observe que os elementos abaixo do primeiro pivô foram zerados.

**Processo Iterativo de Transformação**

O processo de fatoração triangular é iterativo:
1. A matriz $\Omega$ é pré-multiplicada por $E_1$ e pós-multiplicada por $E_1'$, resultando em uma matriz $H$:
 $$H = E_1\Omega E_1'$$
   Aqui, $E_1$ introduz zeros na primeira coluna de $\Omega$ abaixo da diagonal principal.
2. A matriz $H$ é então pré-multiplicada por $E_2$ e pós-multiplicada por $E_2'$, resultando em uma nova matriz $K$:
$$K = E_2HE_2'$$
  Aqui, $E_2$ introduz zeros na segunda coluna de $H$ abaixo da diagonal principal.
3. Este processo é repetido até que a matriz resultante seja diagonal, que denotamos por $D$:
$$D = E_{n-1} \cdots E_2 E_1 \Omega E_1'E_2' \cdots E_{n-1}'$$
   Assim, a matriz $D$ é obtida após $n-1$ transformações.

> 💡 **Exemplo Numérico (Continuação):** Continuando o exemplo anterior, precisamos agora zerar o elemento na posição (3,2) da matriz $H$. Calculamos $h_{32}h_{22}^{-1} = 2/4 = 0.5$. A matriz $E_2$ é:
>
>$$
E_2 = \begin{bmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & -0.5 & 1
\end{bmatrix}
$$
>E a transposta de $E_2$ é:
>
>$$
E_2' = \begin{bmatrix}
1 & 0 & 0 \\
0 & 1 & -0.5 \\
0 & 0 & 1
\end{bmatrix}
$$
> O produto $E_2HE_2'$ resulta em:
>
>$$
K = E_2HE_2' = \begin{bmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & -0.5 & 1
\end{bmatrix} \begin{bmatrix}
4 & 0 & 0 \\
0 & 4 & 2 \\
0 & 2 & 5
\end{bmatrix} \begin{bmatrix}
1 & 0 & 0 \\
0 & 1 & -0.5 \\
0 & 0 & 1
\end{bmatrix} = \begin{bmatrix}
4 & 0 & 0 \\
0 & 4 & 0 \\
0 & 0 & 4
\end{bmatrix} = D
$$
>  Agora, a matriz resultante $K$ é a matriz diagonal $D$.

**Observação:** É crucial entender que a ordem em que as transformações são aplicadas é fundamental para obter a fatoração triangular. As matrizes $E$ são projetadas para introduzir zeros nas posições abaixo da diagonal principal, operando sequencialmente nas colunas da matriz.

**A Matriz A e suas Propriedades**

A matriz $A$ na fatoração triangular $\Omega = ADA'$ é obtida através das inversas das matrizes de transformação elementares. Ou seja:
$A = (E_{n-1} \cdots E_2E_1)^{-1}$  [^4.4.8]

Como cada $E_k$ é uma matriz triangular inferior com 1s na diagonal, suas inversas também são matrizes triangulares inferiores com 1s na diagonal, obtidas simplesmente trocando o sinal dos elementos fora da diagonal principal [Lema 1]. Além disso, o produto das inversas dessas matrizes elementares resulta em uma matriz $A$ triangular inferior com 1s na diagonal e com os elementos da coluna $j$ correspondentes a matriz $E_j^{-1}$ [Lema 1.1]. Este fato é fundamental para a eficiência computacional, pois permite que a matriz A seja obtida diretamente a partir dos resultados das transformações aplicadas à matriz $\Omega$.

> 💡 **Exemplo Numérico (Continuação):**  A partir do exemplo anterior, $E_1^{-1}$ e $E_2^{-1}$ são dadas por:
>
>$$
E_1^{-1} = \begin{bmatrix}
1 & 0 & 0 \\
0.5 & 1 & 0 \\
0.5 & 0 & 1
\end{bmatrix}
$$
>
>$$
E_2^{-1} = \begin{bmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0.5 & 1
\end{bmatrix}
$$
>A matriz A é o produto de $E_1^{-1}$ e $E_2^{-1}$:
>
>$$
A = E_1^{-1}E_2^{-1} = \begin{bmatrix}
1 & 0 & 0 \\
0.5 & 1 & 0 \\
0.5 & 0 & 1
\end{bmatrix} \begin{bmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0.5 & 1
\end{bmatrix} = \begin{bmatrix}
1 & 0 & 0 \\
0.5 & 1 & 0 \\
0.5 & 0.5 & 1
\end{bmatrix}
$$

**Lema 1**
A inversa de uma matriz elementar $E_k$, denotada por $E_k^{-1}$, é obtida trocando o sinal dos elementos fora da diagonal principal de $E_k$.

*Prova:* 
I. Seja $E_k$ uma matriz elementar com 1s na diagonal e um elemento não nulo $-h_{ik}h_{kk}^{-1}$ na posição $(i, k)$ abaixo da diagonal principal.
II.  Definimos $E_k^{-1}$ como uma matriz com 1s na diagonal e o elemento $h_{ik}h_{kk}^{-1}$ na posição $(i, k)$, o oposto do elemento em $E_k$.
III.  Calculamos o produto $E_k E_k^{-1}$: Ao multiplicar $E_k$ por $E_k^{-1}$, todos os elementos da diagonal serão 1, e o elemento na posição $(i,k)$ será  $-h_{ik}h_{kk}^{-1} + h_{ik}h_{kk}^{-1} = 0$.
IV. Verificamos que $E_k E_k^{-1} = I$, onde $I$ é a matriz identidade. De forma semelhante, $E_k^{-1}E_k = I$
V. Portanto, a inversa de $E_k$ é obtida trocando o sinal do elemento fora da diagonal. $\blacksquare$

**Lema 1.1**
O produto das inversas das matrizes elementares, $(E_{n-1} \cdots E_2E_1)^{-1}$, resulta em uma matriz $A$ triangular inferior com 1s na diagonal, onde os elementos da coluna $j$ de $A$ correspondem aos elementos (com sinal oposto) da matriz $E_j$ abaixo da diagonal principal.

*Prova:*
I. Sabemos que $(E_{n-1} \cdots E_2E_1)^{-1} = E_1^{-1}E_2^{-1}\cdots E_{n-1}^{-1}$.
II. Cada $E_k^{-1}$ é uma matriz triangular inferior com 1s na diagonal e um único elemento não nulo $h_{ik}h_{kk}^{-1}$ na coluna $k$ abaixo da diagonal.
III. O produto de matrizes triangulares inferiores com 1s na diagonal também é uma matriz triangular inferior com 1s na diagonal.
IV. Ao multiplicar as matrizes $E_1^{-1}E_2^{-1}\cdots E_{n-1}^{-1}$, o elemento na posição $(i,j)$ de $A$ resulta do elemento não nulo da matriz $E_j^{-1}$ na posição $(i,j)$.
V. Portanto, a matriz $A$ é uma matriz triangular inferior com 1s na diagonal, onde cada coluna $j$ corresponde aos elementos da matriz $E_j^{-1}$ abaixo da diagonal principal. $\blacksquare$

**Teorema 1** A fatoração triangular de uma matriz simétrica definida positiva $\Omega$ pode ser expressa como $\Omega = E^{-1}DE'^{-1}$, onde $E= E_{n-1} \cdots E_2E_1$ é o produto das matrizes elementares $E_k$, e $E^{-1}$ é uma matriz triangular inferior com 1s na diagonal.

*Prova:*
I. Pelo processo iterativo, temos $D = E_{n-1} \cdots E_2 E_1 \Omega E_1'E_2' \cdots E_{n-1}'$, que pode ser escrito como $D = E\Omega E'$, onde $E = E_{n-1} \cdots E_2 E_1$.
II. Multiplicando ambos os lados da equação $D = E\Omega E'$ por $E^{-1}$ à esquerda e $E'^{-1}$ à direita, obtemos: $E^{-1}DE'^{-1} = E^{-1} E\Omega E' E'^{-1}$.
III. Como $E^{-1}E = I$ e $E'E'^{-1} = I$, onde $I$ é a matriz identidade, a equação se simplifica para: $E^{-1}DE'^{-1} = \Omega$.
IV. Pelo Lema 1.1,  $E^{-1}$ é uma matriz triangular inferior com 1s na diagonal.
V. Portanto, provamos que a fatoração triangular de $\Omega$ pode ser escrita como $\Omega = E^{-1}DE'^{-1}$. $\blacksquare$

> 💡 **Exemplo Numérico (Verificação):** Para verificar a fatoração $\Omega = ADA'$, utilizando os resultados anteriores:
>
>$$
D = \begin{bmatrix}
4 & 0 & 0 \\
0 & 4 & 0 \\
0 & 0 & 4
\end{bmatrix}
$$
>
>$$
A = \begin{bmatrix}
1 & 0 & 0 \\
0.5 & 1 & 0 \\
0.5 & 0.5 & 1
\end{bmatrix}
$$
>
>$$
A' = \begin{bmatrix}
1 & 0.5 & 0.5 \\
0 & 1 & 0.5 \\
0 & 0 & 1
\end{bmatrix}
$$
>
>$$
ADA' = \begin{bmatrix}
1 & 0 & 0 \\
0.5 & 1 & 0 \\
0.5 & 0.5 & 1
\end{bmatrix} \begin{bmatrix}
4 & 0 & 0 \\
0 & 4 & 0 \\
0 & 0 & 4
\end{bmatrix} \begin{bmatrix}
1 & 0.5 & 0.5 \\
0 & 1 & 0.5 \\
0 & 0 & 1
\end{bmatrix} = \begin{bmatrix}
4 & 2 & 2 \\
2 & 5 & 3 \\
2 & 3 & 6
\end{bmatrix} = \Omega
$$
> A fatoração foi confirmada.

**Operações de Alto Desempenho**

As operações de multiplicação e transposição envolvendo matrizes triangulares são fundamentais para alcançar alto desempenho computacional. As matrizes triangulares possuem uma estrutura que permite otimizar cálculos, resultando em algoritmos mais rápidos e eficientes. Em particular, o produto $E\Omega E'$ onde $E$ é triangular inferior, possui um custo computacional menor do que o produto de matrizes genéricas.

**Redução do Custo Computacional:** A multiplicação de uma matriz triangular inferior por outra matriz pode ser efetuada sem a necessidade de calcular todas as multiplicações e somas necessárias em uma matriz genérica. Devido à estrutura triangular, é possível pular operações desnecessárias, o que resulta em uma redução significativa do tempo de processamento, especialmente para matrizes de grandes dimensões.

**Paralelização:** As operações de transformação da matriz $\Omega$ podem ser facilmente paralelizadas, o que é essencial para acelerar ainda mais os cálculos em sistemas computacionais com múltiplos processadores. A natureza independente das transformações de colunas permite uma fácil divisão da carga computacional, possibilitando que as operações sejam executadas simultaneamente.

**Aplicações em Otimização e Análise de Dados**

A eficiência computacional proporcionada pela fatoração triangular e suas operações associadas é fundamental em diversas aplicações práticas:

- **Otimização Numérica:** Na resolução de problemas de otimização, especialmente aqueles que envolvem funções quadráticas ou problemas de mínimos quadrados, a fatoração triangular é usada para resolver sistemas lineares e calcular a matriz inversa de forma eficiente, acelerando a convergência dos algoritmos.

- **Análise de Dados:** Em estatística e econometria, a fatoração triangular é amplamente utilizada para calcular a matriz de covariância de variáveis aleatórias, como vimos no contexto das projeções lineares. A eficiência computacional é crucial para lidar com grandes conjuntos de dados e modelos complexos.

- **Filtragem de Kalman:** No contexto da filtragem de Kalman, a fatoração triangular e de Cholesky é utilizada para atualizar a matriz de covariância dos estados, desempenhando um papel crucial na estimação e predição de séries temporais.

> 💡 **Exemplo Numérico:** Considere a matriz $\Omega$ e sua fatoração triangular já calculadas no capítulo anterior. O uso das matrizes de transformação $E$ e $E'$ e as suas inversas $E^{-1}$ e $E'^{-1}$, em vez de manipular diretamente a matriz $\Omega$, é mais eficiente computacionalmente para grandes matrizes. Por exemplo, o produto $E_1 \Omega E_1'$ para a matriz $\Omega$ 2x2 do exemplo anterior, pode ser computado utilizando operações escalares.

### Conclusão

A fatoração triangular de matrizes simétricas definidas positivas, ao se desdobrar em uma série de transformações representadas por matrizes elementares $E$, permite a aplicação de operações de alto desempenho. A natureza triangular dessas matrizes e a possibilidade de paralelização das operações resultam em algoritmos mais rápidos e eficientes, tornando a técnica essencial para aplicações que envolvem grande volume de dados e computação intensiva. A compreensão detalhada deste processo é crucial para a otimização de algoritmos em diversas áreas, incluindo estatística, econometria e otimização numérica. A fatoração triangular, por meio de transformações elementares, não só simplifica o processo, mas também o torna viável para problemas computacionais complexos.

### Referências
[^4]: *A referência geral ao capítulo 4 do livro é utilizada para contextualizar as informações apresentadas.*
[^4.4.3]: *Apresenta a matriz E₁ utilizada na primeira transformação de linhas.*
[^4.4.6]: *Apresenta a matriz E₂ utilizada na transformação de linhas subsequente.*
[^4.4.8]: *Apresenta a relação entre as matrizes E e a matriz A.*
<!-- END -->
