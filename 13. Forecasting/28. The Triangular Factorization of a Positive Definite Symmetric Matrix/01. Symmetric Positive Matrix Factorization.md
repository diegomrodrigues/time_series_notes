## A Fatoração Triangular de uma Matriz Simétrica Definida Positiva
### Introdução
Este capítulo do livro explora em detalhes o processo de fatoração triangular de uma matriz simétrica definida positiva, um conceito fundamental na análise de séries temporais e em diversas áreas da matemática e da estatística. A fatoração triangular, que expressa uma matriz $\Omega$ como o produto de uma matriz triangular inferior $A$, uma matriz diagonal $D$ e a transposta de $A$, $A'$, ou seja, $\Omega = ADA'$, é crucial para simplificar cálculos complexos envolvendo matrizes. Como veremos, essa decomposição possibilita a resolução eficiente de sistemas de equações lineares e facilita o cálculo de determinantes e inversas de matrizes, além de desempenhar um papel fundamental na compreensão das projeções lineares [^4].

### Conceitos Fundamentais
Uma matriz simétrica definida positiva $\Omega$ de dimensões $n \times n$ possui uma representação única na forma $\Omega = ADA'$ [^4.4.1], onde:
  - $A$ é uma matriz triangular inferior com elementos unitários ao longo da diagonal principal.
  - $D$ é uma matriz diagonal.

Essa representação, conhecida como fatoração triangular de $\Omega$, é essencial em muitos cálculos estatísticos e econométricos. A matriz A assume a seguinte forma:

$$
A = \begin{bmatrix}
1 & 0 & 0 & \cdots & 0 \\
a_{21} & 1 & 0 & \cdots & 0 \\
a_{31} & a_{32} & 1 & \cdots & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
a_{n1} & a_{n2} & a_{n3} & \cdots & 1
\end{bmatrix}
$$

E a matriz diagonal D é dada por:

$$
D = \begin{bmatrix}
d_{11} & 0 & 0 & \cdots & 0 \\
0 & d_{22} & 0 & \cdots & 0 \\
0 & 0 & d_{33} & \cdots & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
0 & 0 & 0 & \cdots & d_{nn}
\end{bmatrix}
$$
onde $d_{ii} > 0$ para todo $i$.

**Observação:** A positividade dos elementos diagonais de $D$, $d_{ii} > 0$, é uma consequência direta da propriedade de $\Omega$ ser definida positiva. Essa característica é fundamental para garantir a existência e unicidade da fatoração triangular e também para a existência da fatoração de Cholesky, como veremos mais adiante.

> 💡 **Exemplo Numérico:** Considere uma matriz simétrica definida positiva 2x2:
> $$\Omega = \begin{bmatrix} 4 & 2 \\ 2 & 5 \end{bmatrix}$$
>
> Aqui,  $\Omega_{11} = 4$, $\Omega_{12} = \Omega_{21} = 2$ e $\Omega_{22} = 5$. A fatoração triangular visa encontrar $A$ e $D$ tais que $\Omega = ADA'$.

**Procedimento para Obter a Fatoração Triangular**

O processo para calcular a fatoração triangular envolve transformar a matriz $\Omega$ em uma matriz com zeros abaixo da diagonal principal através de multiplicações e subtrações de linhas. Inicialmente, transforma-se $\Omega$ em uma matriz $H$ com zeros na primeira coluna abaixo da diagonal principal através de uma matriz $E_1$ [^4.4.3]:

$$
E_1 = \begin{bmatrix}
1 & 0 & 0 & \cdots & 0 \\
-\Omega_{21}\Omega_{11}^{-1} & 1 & 0 & \cdots & 0 \\
-\Omega_{31}\Omega_{11}^{-1} & 0 & 1 & \cdots & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
-\Omega_{n1}\Omega_{11}^{-1} & 0 & 0 & \cdots & 1
\end{bmatrix}
$$

A matriz $H$ é obtida através da seguinte operação: $H=E_1\Omega E_1'$ [^4.4.4], onde $E_1'$ é a transposta de $E_1$. Este processo é repetido para as colunas subsequentes da matriz, transformando-a em uma matriz diagonal $D$ utilizando matrizes $E_2, E_3, \ldots, E_{n-1}$ [^4.4.7].

> 💡 **Exemplo Numérico (Continuação):** Usando a matriz $\Omega$ do exemplo anterior, temos:
>
> $$E_1 = \begin{bmatrix} 1 & 0 \\ -\frac{2}{4} & 1 \end{bmatrix} = \begin{bmatrix} 1 & 0 \\ -0.5 & 1 \end{bmatrix}$$
>
> Calculamos $E_1'$, a transposta de $E_1$:
>
> $$E_1' = \begin{bmatrix} 1 & -0.5 \\ 0 & 1 \end{bmatrix}$$
>
> Agora, calculamos $H$:
>
> $$H = E_1 \Omega E_1' = \begin{bmatrix} 1 & 0 \\ -0.5 & 1 \end{bmatrix} \begin{bmatrix} 4 & 2 \\ 2 & 5 \end{bmatrix} \begin{bmatrix} 1 & -0.5 \\ 0 & 1 \end{bmatrix} = \begin{bmatrix} 4 & 0 \\ 0 & 4 \end{bmatrix}$$
>
> Observe que $H$ é agora uma matriz diagonal. Neste caso específico, $H$ é igual a $D$.
>

Por exemplo, a matriz $E_2$ é definida como:

$$
E_2 = \begin{bmatrix}
1 & 0 & 0 & \cdots & 0 \\
0 & 1 & 0 & \cdots & 0 \\
0 & -h_{32}h_{22}^{-1} & 1 & \cdots & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
0 & -h_{n2}h_{22}^{-1} & 0 & \cdots & 1
\end{bmatrix}
$$
onde $h_{ij}$ são os elementos da matriz $H$.

A matriz $A$ é obtida pela inversa das matrizes $E$:

$A = (E_{n-1} \cdots E_2E_1)^{-1}$  [^4.4.8]

A matriz $A$ pode ser obtida diretamente a partir da matriz $\Omega$, notando que a $j$-ésima coluna de $A$ corresponde à $j$-ésima coluna de $E_j^{-1}$ [^4.4.11], o que simplifica o processo.

**Lema 1**
A inversa de uma matriz elementar $E_k$ do tipo descrito é obtida simplesmente trocando o sinal dos elementos fora da diagonal principal. Ou seja, se
$E_k = I - v_k e_k^T$ onde $I$ é a matriz identidade, $e_k$ é o k-ésimo vetor canônico e $v_k$ é um vetor com zeros até a k-ésima posição, então $E_k^{-1} = I + v_k e_k^T$.

*Prova:* A prova é direta pela multiplicação de $E_k$ por $I+v_ke_k^T$.
I.  Definimos $E_k = I - v_k e_k^T$ e queremos mostrar que $E_k^{-1} = I + v_k e_k^T$.
II.  Vamos multiplicar $E_k$ por $I + v_k e_k^T$:
    $E_k (I + v_k e_k^T) = (I - v_k e_k^T)(I + v_k e_k^T) = I + v_k e_k^T - v_k e_k^T - v_k e_k^T v_k e_k^T$
III. Como $e_k^T v_k$ é um escalar que é igual a 0 (pois $v_k$ tem zeros nas primeiras $k-1$ posições e $e_k$ tem um 1 na k-ésima posição e zeros no resto), temos que $v_k e_k^T v_k e_k^T= v_k (e_k^T v_k) e_k^T = v_k(0) e_k^T=0$.
IV. Portanto, $E_k (I + v_k e_k^T) = I + v_k e_k^T - v_k e_k^T = I$.
V. De forma similar, $(I + v_k e_k^T)E_k = (I + v_k e_k^T)(I - v_k e_k^T) = I - v_k e_k^T + v_k e_k^T - v_k e_k^T v_k e_k^T = I $.
VI. Como $E_k (I + v_k e_k^T) = (I + v_k e_k^T)E_k = I$, concluímos que $E_k^{-1} = I + v_k e_k^T$. ■

> 💡 **Exemplo Numérico (Continuação):** Para a matriz $E_1$ do exemplo anterior, sua inversa $E_1^{-1}$ é obtida trocando o sinal do elemento fora da diagonal:
>
> $$E_1^{-1} = \begin{bmatrix} 1 & 0 \\ 0.5 & 1 \end{bmatrix}$$
>
> Neste caso, como só tivemos $E_1$, então $A = E_1^{-1}$:
> $$A = \begin{bmatrix} 1 & 0 \\ 0.5 & 1 \end{bmatrix}$$

**Lema 1.1**
O produto das matrizes elementares inversas  $E_1^{-1}E_2^{-1}\ldots E_{n-1}^{-1}$  resulta em uma matriz triangular inferior com uns na diagonal, onde as entradas abaixo da diagonal na j-ésima coluna correspondem a  $v_j$.

*Prova:* Este resultado segue diretamente do Lema 1. Cada matriz $E_k^{-1}$ adiciona uma coluna à matriz inferior com os elementos $v_k$. Ao multiplicar essas matrizes, as colunas são adicionadas sequencialmente, resultando na matriz $A$.

I. Do Lema 1, sabemos que $E_k^{-1} = I + v_k e_k^T$.
II. A matriz $E_1^{-1}$ é da forma:
$$
E_1^{-1} = \begin{bmatrix}
1 & 0 & 0 & \cdots & 0 \\
\Omega_{21}\Omega_{11}^{-1} & 1 & 0 & \cdots & 0 \\
\Omega_{31}\Omega_{11}^{-1} & 0 & 1 & \cdots & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
\Omega_{n1}\Omega_{11}^{-1} & 0 & 0 & \cdots & 1
\end{bmatrix}
$$
Onde $v_1$ é a primeira coluna abaixo da diagonal principal.
III. A matriz $E_2^{-1}$ é da forma:
$$
E_2^{-1} = \begin{bmatrix}
1 & 0 & 0 & \cdots & 0 \\
0 & 1 & 0 & \cdots & 0 \\
0 & h_{32}h_{22}^{-1} & 1 & \cdots & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
0 & h_{n2}h_{22}^{-1} & 0 & \cdots & 1
\end{bmatrix}
$$
Onde $v_2$ é a segunda coluna abaixo da diagonal principal.
IV. Note que as entradas da matriz $E_k^{-1}$ são os elementos $v_k$ na coluna $k$ e zeros em todas as outras entradas fora da diagonal principal.
V. Ao multiplicar $E_1^{-1}E_2^{-1}\ldots E_{n-1}^{-1}$, cada $E_k^{-1}$ adiciona sua coluna $v_k$ à matriz resultante, sem alterar as colunas anteriores.
VI. O produto resulta em uma matriz triangular inferior com 1's na diagonal, e as entradas abaixo da diagonal na j-ésima coluna correspondem a $v_j$. Logo, o produto $E_1^{-1}E_2^{-1}\ldots E_{n-1}^{-1}$ resulta na matriz $A$ onde a $j$-ésima coluna de $A$ corresponde à $j$-ésima coluna de $E_j^{-1}$. ■

> 💡 **Exemplo Numérico (Continuação):**  Neste exemplo, já obtivemos  $A$ e $D$:
> $$A = \begin{bmatrix} 1 & 0 \\ 0.5 & 1 \end{bmatrix}, \quad D = \begin{bmatrix} 4 & 0 \\ 0 & 4 \end{bmatrix}$$
> Vamos verificar se $\Omega = ADA'$:
> $$ADA' = \begin{bmatrix} 1 & 0 \\ 0.5 & 1 \end{bmatrix} \begin{bmatrix} 4 & 0 \\ 0 & 4 \end{bmatrix} \begin{bmatrix} 1 & 0.5 \\ 0 & 1 \end{bmatrix} = \begin{bmatrix} 4 & 0 \\ 2 & 4 \end{bmatrix} \begin{bmatrix} 1 & 0.5 \\ 0 & 1 \end{bmatrix} = \begin{bmatrix} 4 & 2 \\ 2 & 5 \end{bmatrix} = \Omega$$
> A fatoração triangular foi verificada.

**Unicidade da Fatoração Triangular**

A fatoração triangular de uma matriz simétrica definida positiva é única [^4.4.14]. Isto é, se $\Omega = A_1D_1A_1' = A_2D_2A_2'$, então $A_1=A_2$ e $D_1=D_2$. Esta propriedade garante que o processo descrito anteriormente sempre produzirá uma representação única para qualquer matriz $\Omega$.

**Fatoração de Cholesky**

Uma fatoração intimamente relacionada à fatoração triangular é a fatoração de Cholesky, que expressa uma matriz $\Omega$ como:

$\Omega=PP'$  [^4.4.16]

Onde $P = AD^{1/2}$ é a matriz de Cholesky, e $D^{1/2}$ é uma matriz diagonal cujos elementos são as raízes quadradas dos elementos correspondentes da matriz $D$. A fatoração de Cholesky fornece uma forma alternativa de decompor a matriz $\Omega$, com propriedades similares à fatoração triangular.

> 💡 **Exemplo Numérico (Continuação):** Usando as matrizes $A$ e $D$ do exemplo anterior, podemos calcular a matriz de Cholesky $P$. Primeiro, encontramos $D^{1/2}$:
>
> $$D^{1/2} = \begin{bmatrix} \sqrt{4} & 0 \\ 0 & \sqrt{4} \end{bmatrix} = \begin{bmatrix} 2 & 0 \\ 0 & 2 \end{bmatrix}$$
>
> Agora, calculamos $P = AD^{1/2}$:
>
> $$P = \begin{bmatrix} 1 & 0 \\ 0.5 & 1 \end{bmatrix} \begin{bmatrix} 2 & 0 \\ 0 & 2 \end{bmatrix} = \begin{bmatrix} 2 & 0 \\ 1 & 2 \end{bmatrix}$$
>
> Finalmente, verificamos se $\Omega = PP'$:
>
> $$PP' = \begin{bmatrix} 2 & 0 \\ 1 & 2 \end{bmatrix} \begin{bmatrix} 2 & 1 \\ 0 & 2 \end{bmatrix} = \begin{bmatrix} 4 & 2 \\ 2 & 5 \end{bmatrix} = \Omega$$

**Proposição 1:** A matriz de Cholesky $P$ é uma matriz triangular inferior com entradas positivas na diagonal.

*Prova:* Como $A$ é uma matriz triangular inferior com 1's na diagonal e $D^{1/2}$ é uma matriz diagonal com entradas positivas, o produto $P = AD^{1/2}$ resultará numa matriz triangular inferior com entradas positivas na diagonal. Os elementos diagonais de $P$ são $p_{ii} = 1\cdot \sqrt{d_{ii}} = \sqrt{d_{ii}} > 0$.
I. Seja $A$ uma matriz triangular inferior com 1's na diagonal.
II. Seja $D$ uma matriz diagonal com entradas positivas $d_{ii} > 0$.
III. Seja $D^{1/2}$ a matriz diagonal com entradas $\sqrt{d_{ii}} > 0$.
IV. Defina $P = AD^{1/2}$.
V. O produto de uma matriz triangular inferior ($A$) por uma matriz diagonal ($D^{1/2}$) resulta em uma matriz triangular inferior ($P$).
VI. Os elementos diagonais de $P$ são dados por $p_{ii} = a_{ii} \cdot \sqrt{d_{ii}} = 1 \cdot \sqrt{d_{ii}} = \sqrt{d_{ii}}$.
VII. Como $d_{ii} > 0$, segue que $\sqrt{d_{ii}} > 0$. Portanto, $p_{ii} > 0$.
VIII. Concluímos que $P$ é uma matriz triangular inferior com entradas positivas na diagonal. ■

**Corolário 1:** A fatoração de Cholesky também é única.

*Prova:* Se $\Omega = P_1P_1' = P_2P_2'$, então $P_1 = A_1 D_1^{1/2}$ e $P_2 = A_2 D_2^{1/2}$. Como a fatoração triangular é única, $A_1 = A_2$ e $D_1 = D_2$, o que implica que $P_1=P_2$.
I.  Assumimos que $\Omega$ tem duas fatorações de Cholesky: $\Omega = P_1P_1' = P_2P_2'$.
II.  Sabemos que $P_1 = A_1D_1^{1/2}$ e $P_2 = A_2D_2^{1/2}$, onde $A_1$ e $A_2$ são matrizes triangulares inferiores com uns na diagonal, e $D_1$ e $D_2$ são matrizes diagonais.
III. Substituindo na fatoração de Cholesky, temos:
    $A_1D_1^{1/2}(A_1D_1^{1/2})' = A_1D_1^{1/2}D_1^{1/2}A_1' = A_1D_1A_1'$ e
    $A_2D_2^{1/2}(A_2D_2^{1/2})' = A_2D_2^{1/2}D_2^{1/2}A_2' = A_2D_2A_2'$.
IV. Da unicidade da fatoração triangular, se $A_1D_1A_1'=A_2D_2A_2'$, então $A_1 = A_2$ e $D_1 = D_2$.
V. Se $A_1 = A_2$ e $D_1 = D_2$, então $D_1^{1/2} = D_2^{1/2}$.
VI. Assim, $P_1 = A_1D_1^{1/2} = A_2D_2^{1/2} = P_2$.
VII. Portanto, a fatoração de Cholesky é única. ■

### Conclusão
A fatoração triangular de uma matriz simétrica definida positiva $\Omega$, expressa como $\Omega = ADA'$, é uma ferramenta poderosa na análise de séries temporais e em diversos campos da matemática aplicada. Este processo, que envolve a decomposição da matriz $\Omega$ em três componentes distintos ($A$, $D$ e $A'$), permite simplificar cálculos complexos e possibilita uma melhor compreensão das relações entre variáveis. A unicidade da fatoração garante uma representação consistente para cada matriz $\Omega$, e a fatoração de Cholesky fornece uma alternativa igualmente válida. A compreensão destes conceitos é fundamental para a aplicação eficaz de métodos estatísticos e econométricos na modelagem de séries temporais e outros tipos de análise de dados.

### Referências
[^4]:  *A referência geral ao capítulo 4 do livro é utilizada para contextualizar as informações apresentadas.*
[^4.4.1]:  *Define a forma única da representação de uma matriz positiva definida simétrica.*
[^4.4.3]: *Apresenta a matriz E₁ utilizada na primeira transformação de linhas.*
[^4.4.4]: *Define a relação entre Ω, E₁ e H.*
[^4.4.7]: *Descreve o processo de transformação da matriz através de multiplicações por matrizes E, resultando em uma matriz diagonal D.*
[^4.4.8]: *Apresenta a relação entre as matrizes E e a matriz A.*
[^4.4.11]: *Explica como a matriz A pode ser obtida diretamente.*
[^4.4.14]: *Enfatiza a unicidade da fatoração triangular.*
[^4.4.16]: *Apresenta a fatoração de Cholesky, uma alternativa à fatoração triangular.*
<!-- END -->
