## A FatoraÃ§Ã£o de Cholesky e sua RelaÃ§Ã£o com a FatoraÃ§Ã£o Triangular

### IntroduÃ§Ã£o
Este capÃ­tulo aprofunda a discussÃ£o sobre a **fatoraÃ§Ã£o triangular**, com foco especÃ­fico na **fatoraÃ§Ã£o de Cholesky**, uma forma particular desta decomposiÃ§Ã£o matricial que desempenha um papel crucial em diversas aplicaÃ§Ãµes, especialmente em estatÃ­stica e computaÃ§Ã£o [^4.4.16]. Como jÃ¡ explorado, a fatoraÃ§Ã£o triangular decompÃµe uma matriz simÃ©trica positiva definida em trÃªs componentes: uma matriz triangular inferior com 1s na diagonal, uma matriz diagonal e a transposta da matriz triangular inferior. A fatoraÃ§Ã£o de Cholesky, por sua vez, leva esta decomposiÃ§Ã£o um passo adiante ao expressar a matriz diagonal como o produto de duas matrizes, cada uma sendo a raiz quadrada da matriz original, resultando em um produto de uma matriz triangular inferior e sua transposta.

Este tÃ³pico expande os conceitos apresentados anteriormente, construindo sobre a base da fatoraÃ§Ã£o triangular e introduzindo a fatoraÃ§Ã£o de Cholesky como uma ferramenta especÃ­fica para resolver problemas relacionados Ã  anÃ¡lise de dados, simulaÃ§Ãµes e otimizaÃ§Ãµes. O conhecimento prÃ©vio sobre **projeÃ§Ãµes lineares** e a **fatoraÃ§Ã£o triangular** Ã© essencial para uma compreensÃ£o completa dos temas abordados neste capÃ­tulo.

### Conceitos Fundamentais
Como vimos anteriormente, qualquer matriz simÃ©trica positiva definida $\Omega$ pode ser fatorada como:

$$ \Omega = ADA' $$,

onde **A** Ã© uma matriz triangular inferior com 1s na diagonal principal e **D** Ã© uma matriz diagonal com elementos estritamente positivos [^4.4.1]. A **fatoraÃ§Ã£o de Cholesky** surge como uma representaÃ§Ã£o alternativa, onde a matriz diagonal *D* Ã© expressa como o quadrado de outra matriz diagonal,  **DÂ¹/Â²**, tal que:

$$ \Omega = AD^{1/2}D^{1/2}A' = (AD^{1/2})(AD^{1/2})' $$.

Definindo **P = ADÂ¹/Â²**, temos a fatoraÃ§Ã£o de Cholesky:

$$ \Omega = PP' $$.

Aqui, **P** Ã© uma matriz triangular inferior, assim como *A*, mas com a diferenÃ§a que os elementos diagonais de P nÃ£o sÃ£o necessariamente iguais a 1, sendo, na verdade, a raiz quadrada dos elementos correspondentes de D. Essa forma de fatoraÃ§Ã£o Ã© particularmente Ãºtil em diversas aplicaÃ§Ãµes devido Ã  simplicidade da operaÃ§Ã£o e ao fato de que *P* Ã© uma matriz triangular inferior, como demonstrado no **Lema 2**.

> ðŸ’¡ **Exemplo NumÃ©rico:**
>
> Retomando o exemplo da fatoraÃ§Ã£o triangular da matriz $\Omega$, vamos calcular as matrizes DÂ¹/Â² e P:
>
> $$ \Omega = \begin{bmatrix} 4 & 2 & 2 \\ 2 & 5 & 3 \\ 2 & 3 & 6 \end{bmatrix} $$
>
>  ApÃ³s a aplicaÃ§Ã£o das operaÃ§Ãµes $E_k$  na seÃ§Ã£o anterior, obtivemos a matriz diagonal *D*:
>
> $$ D =  \begin{bmatrix} 4 & 0 & 0 \\ 0 & 4 & 0 \\ 0 & 0 & 4 \end{bmatrix} $$
>
>  A matriz  **DÂ¹/Â²**  Ã© entÃ£o:
>
> $$ D^{1/2} =  \begin{bmatrix} \sqrt{4} & 0 & 0 \\ 0 & \sqrt{4} & 0 \\ 0 & 0 & \sqrt{4} \end{bmatrix} =  \begin{bmatrix} 2 & 0 & 0 \\ 0 & 2 & 0 \\ 0 & 0 & 2 \end{bmatrix} $$
>
> E a matriz *A* obtida por meio do produto das inversas de $E_k$:
>
> $$ A =  \begin{bmatrix} 1 & 0 & 0 \\ 0.5 & 1 & 0 \\ 0.5 & 0.5 & 1 \end{bmatrix}$$
>
> Finalmente, a matriz **P** da fatoraÃ§Ã£o de Cholesky Ã© dada por:
>
> $$ P = AD^{1/2} =  \begin{bmatrix} 1 & 0 & 0 \\ 0.5 & 1 & 0 \\ 0.5 & 0.5 & 1 \end{bmatrix}  \begin{bmatrix} 2 & 0 & 0 \\ 0 & 2 & 0 \\ 0 & 0 & 2 \end{bmatrix} = \begin{bmatrix} 2 & 0 & 0 \\ 1 & 2 & 0 \\ 1 & 1 & 2 \end{bmatrix}$$
>
>
>
> ðŸ’¡ **Exemplo NumÃ©rico:**
>
> Vamos considerar outra matriz simÃ©trica positiva definida:
>
> $$ \Omega_2 = \begin{bmatrix} 9 & 3 & 6 \\ 3 & 5 & 4 \\ 6 & 4 & 21 \end{bmatrix} $$
>
> Para realizar a fatoraÃ§Ã£o de Cholesky $\Omega_2 = PP'$, podemos usar o seguinte algoritmo:
>
> 1.  Inicializar $P$ como uma matriz de zeros.
>
> 2.  Para cada $i$ de 1 atÃ© o tamanho da matriz:
>     *   Calcular $P_{ii} = \sqrt{\Omega_{ii} - \sum_{k=1}^{i-1} P_{ik}^2}$
>     *   Para cada $j$ de $i+1$ atÃ© o tamanho da matriz:
>         *   Calcular $P_{ji} = \frac{1}{P_{ii}} (\Omega_{ji} - \sum_{k=1}^{i-1} P_{jk}P_{ik})$
>
> Aplicando este algoritmo, obtemos:
>
> $$
> P = \begin{bmatrix}
> \sqrt{9} & 0 & 0 \\
> \frac{3}{\sqrt{9}} & \sqrt{5 - (\frac{3}{\sqrt{9}})^2} & 0 \\
> \frac{6}{\sqrt{9}} & \frac{4 - (\frac{3}{\sqrt{9}})(\frac{6}{\sqrt{9}})}{\sqrt{5 - (\frac{3}{\sqrt{9}})^2}}  & \sqrt{21 - (\frac{6}{\sqrt{9}})^2 - (\frac{4 - (\frac{3}{\sqrt{9}})(\frac{6}{\sqrt{9}})}{\sqrt{5 - (\frac{3}{\sqrt{9}})^2}})^2}
> \end{bmatrix}
> $$
>
> Simplificando:
>
> $$
> P = \begin{bmatrix}
> 3 & 0 & 0 \\
> 1 & 2 & 0 \\
> 2 & 1 & 4
> \end{bmatrix}
> $$
>
> Para verificar a fatoraÃ§Ã£o, multiplicamos $PP'$:
>
> $$ PP' = \begin{bmatrix} 3 & 0 & 0 \\ 1 & 2 & 0 \\ 2 & 1 & 4 \end{bmatrix} \begin{bmatrix} 3 & 1 & 2 \\ 0 & 2 & 1 \\ 0 & 0 & 4 \end{bmatrix} = \begin{bmatrix} 9 & 3 & 6 \\ 3 & 5 & 4 \\ 6 & 4 & 21 \end{bmatrix} = \Omega_2$$
>
>
>
> Este exemplo numÃ©rico demonstra o processo de cÃ¡lculo da matriz P, confirmando a fatoraÃ§Ã£o de Cholesky.

**Propriedades da FatoraÃ§Ã£o de Cholesky**
A matriz *P* na fatoraÃ§Ã£o de Cholesky possui algumas propriedades importantes:
1.  Ã‰ uma **matriz triangular inferior**: Todos os elementos acima da diagonal principal sÃ£o zero. Isso facilita a resoluÃ§Ã£o de sistemas lineares e o cÃ¡lculo de determinantes [Lema 2].
2.  Possui **elementos diagonais positivos**: Os elementos diagonais de *P* sÃ£o as raÃ­zes quadradas dos elementos diagonais da matriz *D*, que sÃ£o estritamente positivos [Lema 2].
3.  **Ã‰ Ãºnica**: Para uma matriz simÃ©trica positiva definida, a fatoraÃ§Ã£o de Cholesky Ã© Ãºnica. Ou seja, nÃ£o existem outras matrizes triangulares inferiores $P$ diferentes que satisfazem $\Omega = PP'$.

> ðŸ’¡ **Exemplo NumÃ©rico (VerificaÃ§Ã£o):**
> Para verificar a fatoraÃ§Ã£o de Cholesky da matriz $\Omega$, calculamos $PP'$:
>
> $$ PP' = \begin{bmatrix} 2 & 0 & 0 \\ 1 & 2 & 0 \\ 1 & 1 & 2 \end{bmatrix} \begin{bmatrix} 2 & 1 & 1 \\ 0 & 2 & 1 \\ 0 & 0 & 2 \end{bmatrix} = \begin{bmatrix} 4 & 2 & 2 \\ 2 & 5 & 3 \\ 2 & 3 & 6 \end{bmatrix} = \Omega$$
>
> Como resultado da multiplicaÃ§Ã£o de $P$ pela sua transposta, obtemos a matriz $\Omega$ original, confirmando a fatoraÃ§Ã£o de Cholesky.
>
> ðŸ’¡ **Exemplo NumÃ©rico (Unicidade):**
> Suponha que tivÃ©ssemos outra matriz triangular inferior $Q$ tal que $\Omega = QQ'$.  No entanto, devido Ã  unicidade da fatoraÃ§Ã£o de Cholesky, $Q$ deve ser igual a $P$. Para ilustrar, se tentarmos encontrar uma matriz $Q \neq P$ que satisfaÃ§a $QQ' = \Omega$, rapidamente perceberemos que tal matriz nÃ£o existe, dada a natureza das operaÃ§Ãµes de decomposiÃ§Ã£o. A unicidade garante que a matriz $P$ obtida atravÃ©s do processo de Cholesky Ã© a Ãºnica matriz triangular inferior que satisfaz a igualdade $\Omega = PP'$.
>

**AplicaÃ§Ãµes da FatoraÃ§Ã£o de Cholesky**
A fatoraÃ§Ã£o de Cholesky possui diversas aplicaÃ§Ãµes, incluindo:

1.  **SimulaÃ§Ã£o de dados:** Permite gerar nÃºmeros aleatÃ³rios com uma dada matriz de covariÃ¢ncia. Para gerar um vetor aleatÃ³rio com distribuiÃ§Ã£o normal multivariada, por exemplo, pode-se gerar um vetor de nÃºmeros aleatÃ³rios com distribuiÃ§Ã£o normal padrÃ£o e multiplicÃ¡-lo pela matriz *P*.
2.  **ResoluÃ§Ã£o de sistemas lineares:** Em sistemas lineares da forma $\Omega x = b$, onde $\Omega$ Ã© simÃ©trica positiva definida, a fatoraÃ§Ã£o de Cholesky pode ser usada para simplificar o cÃ¡lculo da soluÃ§Ã£o, dividindo o sistema em dois sistemas triangulares, que sÃ£o mais fÃ¡ceis de resolver.
3.  **OtimizaÃ§Ã£o:** A fatoraÃ§Ã£o de Cholesky pode ser utilizada para calcular mÃ­nimos quadrados de forma eficiente, pois simplifica a inversÃ£o de matrizes de covariÃ¢ncia.
4. **AtualizaÃ§Ã£o de ProjeÃ§Ãµes Lineares**: Como visto no capÃ­tulo anterior, as projeÃ§Ãµes lineares podem ser atualizadas recursivamente atravÃ©s do uso da fatoraÃ§Ã£o triangular [^4.5.12].

> ðŸ’¡ **Exemplo NumÃ©rico (SimulaÃ§Ã£o de Dados):**
>
> Suponha que queremos gerar um vetor aleatÃ³rio $Y$ de dimensÃ£o 3, com distribuiÃ§Ã£o normal multivariada, mÃ©dia zero e matriz de covariÃ¢ncia $\Omega = \begin{bmatrix} 4 & 2 & 2 \\ 2 & 5 & 3 \\ 2 & 3 & 6 \end{bmatrix}$.
>
> 1.  Calculamos a fatoraÃ§Ã£o de Cholesky de $\Omega$, obtendo $P = \begin{bmatrix} 2 & 0 & 0 \\ 1 & 2 & 0 \\ 1 & 1 & 2 \end{bmatrix}$.
> 2.  Geramos um vetor $Z$ de 3 variÃ¡veis aleatÃ³rias independentes, cada uma com distribuiÃ§Ã£o normal padrÃ£o. Por exemplo, usando Python:
>
> ```python
> import numpy as np
>
> Z = np.random.normal(0, 1, 3)
> print("Vetor Z:", Z)
> # Output (pode variar devido a aleatoriedade): [ 0.3  -1.2   0.8]
> ```
>
> 3.  Calculamos $Y = PZ$:
>
> ```python
> P = np.array([[2, 0, 0], [1, 2, 0], [1, 1, 2]])
> Y = np.dot(P, Z)
> print("Vetor Y:", Y)
> # Output (pode variar): [ 0.6  -2.1  -0.7]
> ```
>
> O vetor $Y$ gerado terÃ¡ a matriz de covariÃ¢ncia $\Omega$. Repetindo este processo vÃ¡rias vezes e calculando a matriz de covariÃ¢ncia amostral de $Y$, obterÃ­amos um resultado prÃ³ximo de $\Omega$.
>
> ðŸ’¡ **Exemplo NumÃ©rico (ResoluÃ§Ã£o de Sistema Linear):**
>
> Vamos resolver o sistema linear $\Omega x = b$, onde $\Omega = \begin{bmatrix} 4 & 2 & 2 \\ 2 & 5 & 3 \\ 2 & 3 & 6 \end{bmatrix}$ e $b = \begin{bmatrix} 10 \\ 15 \\ 20 \end{bmatrix}$.
>
> 1.  Calculamos a fatoraÃ§Ã£o de Cholesky de $\Omega$, obtendo $P = \begin{bmatrix} 2 & 0 & 0 \\ 1 & 2 & 0 \\ 1 & 1 & 2 \end{bmatrix}$.
>
> 2.  Resolvemos $Py = b$ por substituiÃ§Ã£o progressiva:
>
>   *  $2y_1 = 10 \Rightarrow y_1 = 5$
>   *  $1y_1 + 2y_2 = 15 \Rightarrow 5 + 2y_2 = 15 \Rightarrow y_2 = 5$
>   *  $1y_1 + 1y_2 + 2y_3 = 20 \Rightarrow 5 + 5 + 2y_3 = 20 \Rightarrow y_3 = 5$
>
>  Assim, $y = \begin{bmatrix} 5 \\ 5 \\ 5 \end{bmatrix}$.
>
> 3. Resolvemos $P^T x = y$ por substituiÃ§Ã£o retroativa:
>
>   * $2x_3 = 5 \Rightarrow x_3 = 2.5$
>   * $2x_2 + x_3 = 5 \Rightarrow 2x_2 + 2.5 = 5 \Rightarrow x_2 = 1.25$
>   * $2x_1 + x_2 + x_3 = 5 \Rightarrow 2x_1 + 1.25 + 2.5 = 5 \Rightarrow x_1 = 0.625$
>
>  Portanto, $x = \begin{bmatrix} 0.625 \\ 1.25 \\ 2.5 \end{bmatrix}$. Podemos verificar:
>
> $$\Omega x = \begin{bmatrix} 4 & 2 & 2 \\ 2 & 5 & 3 \\ 2 & 3 & 6 \end{bmatrix} \begin{bmatrix} 0.625 \\ 1.25 \\ 2.5 \end{bmatrix} = \begin{bmatrix} 10 \\ 15 \\ 20 \end{bmatrix} = b$$
>
> A soluÃ§Ã£o do sistema linear Ã© obtida de forma eficiente usando a fatoraÃ§Ã£o de Cholesky.

**Teorema 2**
A fatoraÃ§Ã£o de Cholesky de uma matriz de covariÃ¢ncia $\Omega$ pode ser utilizada para gerar um vetor aleatÃ³rio $Y$ com matriz de covariÃ¢ncia $\Omega$.

*Proof:*
Seja $Z$ um vetor de variÃ¡veis aleatÃ³rias independentes com distribuiÃ§Ã£o normal padrÃ£o. Para obter um vetor $Y$ com matriz de covariÃ¢ncia $\Omega$, podemos usar a fatoraÃ§Ã£o de Cholesky para obter uma matriz $P$ tal que $\Omega=PP^T$. EntÃ£o, definimos $Y=PZ$. A matriz de covariÃ¢ncia de $Y$ Ã© dada por:
$$Cov(Y) = Cov(PZ) = PCov(Z)P^T = PIP^T = PP^T = \Omega$$
Assim, o vetor aleatÃ³rio $Y$ tem matriz de covariÃ¢ncia $\Omega$.

I. Seja $Z$ um vetor de variÃ¡veis aleatÃ³rias independentes com distribuiÃ§Ã£o normal padrÃ£o, onde a matriz de covariÃ¢ncia Ã© a identidade, $Cov(Z) = I$.

II. Seja $\Omega$ uma matriz simÃ©trica positiva definida e $P$ a matriz triangular inferior da fatoraÃ§Ã£o de Cholesky de $\Omega$ de forma que $\Omega = PP^T$.

III. Definimos um novo vetor de variÃ¡veis aleatÃ³rias $Y = PZ$.

IV. A matriz de covariÃ¢ncia de $Y$ Ã© dada por:
  $$Cov(Y) = Cov(PZ) = E[(PZ)(PZ)^T] - E[PZ]E[PZ]^T = E[PZZ^TP^T]-E[PZ]E[PZ]^T = P E[ZZ^T]P^T- P E[Z] E[Z]^T P^T= PICov(Z)P^T$$

V.  Como $Cov(Z) = I$, a matriz de covariÃ¢ncia de Y Ã©:
 $$Cov(Y) = P I P^T = PP^T = \Omega$$
 VI. Portanto, $Y = PZ$ Ã© um vetor de variÃ¡veis aleatÃ³rias com matriz de covariÃ¢ncia igual a $\Omega$. $\blacksquare$

Este resultado mostra que a fatoraÃ§Ã£o de Cholesky pode ser usada para transformar um vetor de variÃ¡veis aleatÃ³rias independentes com variÃ¢ncia unitÃ¡ria em um vetor de variÃ¡veis aleatÃ³rias com uma matriz de covariÃ¢ncia desejada, $\Omega$.

**Teorema 2.1**
A fatoraÃ§Ã£o de Cholesky Ã© computacionalmente eficiente para resolver sistemas lineares da forma $\Omega x = b$, onde $\Omega$ Ã© uma matriz simÃ©trica positiva definida.

*Proof:*
Dado o sistema $\Omega x = b$, e a fatoraÃ§Ã£o de Cholesky $\Omega = PP^T$, podemos reescrever o sistema como $PP^T x = b$. Definindo $y = P^T x$, temos $Py = b$, que Ã© um sistema triangular inferior. Podemos resolver este sistema para $y$ por substituiÃ§Ã£o progressiva. Uma vez obtido $y$, resolvemos $P^T x = y$, que Ã© um sistema triangular superior, para obter $x$ por substituiÃ§Ã£o retroativa. Ambas as substituiÃ§Ãµes sÃ£o computacionalmente eficientes, necessitando de $O(n^2)$ operaÃ§Ãµes cada, enquanto a fatoraÃ§Ã£o de Cholesky tambÃ©m tem complexidade $O(n^3)$.  Portanto, a soluÃ§Ã£o do sistema linear por meio da fatoraÃ§Ã£o de Cholesky Ã© muito eficiente, evitando a inversÃ£o da matriz $\Omega$, que teria uma complexidade computacional muito maior. $\blacksquare$

AlÃ©m da aplicaÃ§Ã£o na resoluÃ§Ã£o de sistemas lineares, a fatoraÃ§Ã£o de Cholesky tambÃ©m Ã© Ãºtil para o cÃ¡lculo do determinante de uma matriz simÃ©trica positiva definida.

**Lema 3**
O determinante de uma matriz simÃ©trica positiva definida $\Omega$ Ã© igual ao quadrado do produto dos elementos diagonais da matriz P da fatoraÃ§Ã£o de Cholesky, $\Omega=PP^T$.

*Proof:*
Dado $\Omega = PP^T$, podemos usar a propriedade de que o determinante do produto de matrizes Ã© o produto dos determinantes, $\det(\Omega) = \det(PP^T) = \det(P)\det(P^T)$. AlÃ©m disso, como o determinante da transposta de uma matriz Ã© igual ao determinante da matriz original, $\det(P^T) = \det(P)$. Portanto, $\det(\Omega) = \det(P)^2$. Como $P$ Ã© uma matriz triangular inferior, seu determinante Ã© o produto de seus elementos diagonais. Denotando os elementos diagonais de $P$ por $p_{ii}$, temos $\det(P) = \prod_{i=1}^n p_{ii}$. Consequentemente, $\det(\Omega) = (\prod_{i=1}^n p_{ii})^2$. $\blacksquare$
> ðŸ’¡ **Exemplo NumÃ©rico (Determinante):**
>
> Para a matriz $\Omega = \begin{bmatrix} 4 & 2 & 2 \\ 2 & 5 & 3 \\ 2 & 3 & 6 \end{bmatrix}$, obtivemos a matriz de Cholesky $P = \begin{bmatrix} 2 & 0 & 0 \\ 1 & 2 & 0 \\ 1 & 1 & 2 \end{bmatrix}$.
>
> Os elementos diagonais de $P$ sÃ£o $p_{11} = 2$, $p_{22} = 2$ e $p_{33} = 2$.
>
> O determinante de $P$ Ã© o produto desses elementos: $\det(P) = 2 \times 2 \times 2 = 8$.
>
> Portanto, o determinante de $\Omega$ Ã© $\det(\Omega) = \det(P)^2 = 8^2 = 64$.
>
> Podemos verificar esse resultado usando o mÃ©todo tradicional de cÃ¡lculo de determinantes (que Ã© mais custoso computacionalmente):
>
> $\det(\Omega) = 4(5\times6 - 3\times3) - 2(2\times6 - 2\times3) + 2(2\times3 - 2\times5) = 4(30-9) - 2(12-6) + 2(6-10) = 4(21) - 2(6) + 2(-4) = 84 - 12 - 8 = 64$
>
> A fatoraÃ§Ã£o de Cholesky fornece uma forma eficiente de calcular o determinante da matriz simÃ©trica positiva definida.

Este resultado permite o cÃ¡lculo do determinante de $\Omega$ sem a necessidade de um cÃ¡lculo direto da definiÃ§Ã£o, o que pode ser muito mais eficiente computacionalmente.

### ConclusÃ£o
A **fatoraÃ§Ã£o de Cholesky** surge como uma forma especial da **fatoraÃ§Ã£o triangular**, onde a matriz diagonal Ã© decomposta em uma matriz e sua transposta. Essa fatoraÃ§Ã£o oferece uma ferramenta poderosa para simplificar cÃ¡lculos e implementar algoritmos em estatÃ­stica e computaÃ§Ã£o.  As aplicaÃ§Ãµes em simulaÃ§Ãµes, resoluÃ§Ã£o de sistemas lineares e otimizaÃ§Ã£o ressaltam a importÃ¢ncia da fatoraÃ§Ã£o de Cholesky e a sua relaÃ§Ã£o com as projeÃ§Ãµes lineares e a fatoraÃ§Ã£o triangular, ambos temas discutidos anteriormente [^4.5.13]. O entendimento desses conceitos permite a construÃ§Ã£o de modelos mais eficientes e uma anÃ¡lise mais profunda dos processos estocÃ¡sticos.

### ReferÃªncias
[^4.4.1]: Qualquer matriz simÃ©trica positiva definida $\Omega$ pode ser expressa como $\Omega = ADA'$, onde A Ã© uma matriz triangular inferior com 1s na diagonal principal, e D Ã© uma matriz diagonal com elementos positivos.
[^4.4.16]: ExpressÃ£o [4.4.16] Ã© conhecida como a fatoraÃ§Ã£o de Cholesky de $\Omega$...
[^4.5.12]: ...o Ã³timo forecast de Y3 condicional em Y2 e Y1 pode ser lido da Ãºltima linha em bloco de A: $\hat{P}(Y_3|Y_2,Y_1) = \Omega_{31} \Omega_{11}^{-1} Y_1 + H_{32}H_{22}^{-1} (Y_2 - \Omega_{21}\Omega_{11}^{-1} Y_1) = P(Y_3|Y_1) + H_{32}H_{22}^{-1} [Y_2-P(Y_2|Y_1)]$
[^4.5.13]: O MSE da projeÃ§Ã£o linear Ã© a variÃ¢ncia de $Y_3$, que de [4.5.5] Ã© dada por $d_{33}$: $E[Y_3 - P(Y_3|Y_2,Y_1)]^2 = h_{33} - h_{32}h_{22}^{-1}h_{23}$
<!-- END -->
