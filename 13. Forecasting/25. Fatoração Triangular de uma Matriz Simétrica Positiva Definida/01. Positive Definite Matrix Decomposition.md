## Fatora√ß√£o Triangular de uma Matriz Sim√©trica Positiva Definida
### Introdu√ß√£o
Este cap√≠tulo explora em detalhes a fatora√ß√£o triangular de uma matriz sim√©trica positiva definida, um conceito essencial em diversas √°reas da matem√°tica, estat√≠stica e, particularmente, na an√°lise de s√©ries temporais. A representa√ß√£o de uma matriz como o produto de uma matriz triangular inferior, uma matriz diagonal e a transposta da matriz triangular inferior, oferece uma poderosa ferramenta para simplificar c√°lculos e an√°lises [^4.4.1]. Este t√≥pico constr√≥i sobre a discuss√£o anterior de proje√ß√µes lineares e estima√ß√£o de m√≠nimos quadrados ordin√°rios (OLS), fornecendo uma base para entender m√©todos computacionais e te√≥ricos mais avan√ßados.

### Conceitos Fundamentais
A fatora√ß√£o triangular, tamb√©m conhecida como fatora√ß√£o de Cholesky quando a matriz diagonal √© expressa como o quadrado de uma outra matriz diagonal, √© um m√©todo para decompor uma matriz sim√©trica positiva definida em um produto de tr√™s matrizes de uma forma espec√≠fica [^4.4.1]. Formalmente, dada uma matriz **sim√©trica positiva definida** $\Omega$ de dimens√£o *n x n*, podemos express√°-la como:

$$ \Omega = ADA' $$,

onde:

1.  **A** √© uma **matriz triangular inferior** de dimens√£o *n x n* com todos os elementos da diagonal principal iguais a 1. Isso significa que todos os elementos acima da diagonal principal s√£o zero.
2.  **D** √© uma **matriz diagonal** de dimens√£o *n x n* com todos os elementos da diagonal principal estritamente positivos, ou seja, $d_{ii} > 0$ para todo *i*. Todos os elementos fora da diagonal s√£o zero.
3.  **A'** √© a **transposta** da matriz A.

A import√¢ncia desta fatora√ß√£o reside na sua unicidade e na sua utilidade em simplificar c√°lculos envolvendo matrizes sim√©tricas positivas definidas.

> üí° **Exemplo Num√©rico:**
> Vamos considerar uma matriz sim√©trica positiva definida $\Omega$ de dimens√£o 3x3:
>
>  $$ \Omega = \begin{bmatrix} 4 & 2 & 2 \\ 2 & 5 & 3 \\ 2 & 3 & 6 \end{bmatrix} $$
>
>  O objetivo √© encontrar matrizes A e D tal que $\Omega = ADA'$. Este processo ser√° detalhado nos pr√≥ximos passos, e demonstrar√° como a fatora√ß√£o triangular funciona na pr√°tica.

**Constru√ß√£o da Fatora√ß√£o Triangular**
A fatora√ß√£o triangular pode ser constru√≠da de forma iterativa. Come√ßamos transformando $\Omega$ numa matriz com zeros na primeira coluna, abaixo da diagonal principal [^4.4.2]. Isso √© feito atrav√©s da pr√©-multiplica√ß√£o de $\Omega$ por uma matriz **E‚ÇÅ**:

$$
E_1 = \begin{bmatrix}
1 & 0 & 0 & \ldots & 0 \\
-\frac{\Omega_{21}}{\Omega_{11}} & 1 & 0 & \ldots & 0 \\
-\frac{\Omega_{31}}{\Omega_{11}} & 0 & 1 & \ldots & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
-\frac{\Omega_{n1}}{\Omega_{11}} & 0 & 0 & \ldots & 1
\end{bmatrix}
$$
Onde $E_1$ √© uma matriz com 1s na diagonal principal, e elementos da forma $-\frac{\Omega_{i1}}{\Omega_{11}}$ abaixo da diagonal principal na primeira coluna [^4.4.3].
A pr√©-multiplica√ß√£o por *$E‚ÇÅ$* e a p√≥s-multiplica√ß√£o pela transposta *$E‚ÇÅ'$* resulta em uma matriz *H*:

$$
H = E_1\Omega E_1'
$$

onde *H* tem zeros na primeira coluna, abaixo da diagonal principal [^4.4.4]. O processo √© ent√£o repetido para as colunas seguintes.
Em cada etapa, pr√©-multiplicamos e p√≥s-multiplicamos com uma matriz $E_k$ constru√≠da de forma an√°loga, resultando em:

$$
E_{n-1} \ldots E_2 E_1 \Omega E_1' E_2' \ldots E_{n-1}' = D
$$

Onde *D* √© uma matriz diagonal. A matriz *A* √© ent√£o obtida pela invers√£o e multiplica√ß√£o das matrizes *E* [^4.4.8].

> üí° **Exemplo Num√©rico (continua√ß√£o):**
>
> Para a matriz $\Omega$ do exemplo anterior, vamos calcular $E_1$:
>
> $$ E_1 = \begin{bmatrix} 1 & 0 & 0 \\ -\frac{2}{4} & 1 & 0 \\ -\frac{2}{4} & 0 & 1 \end{bmatrix} = \begin{bmatrix} 1 & 0 & 0 \\ -0.5 & 1 & 0 \\ -0.5 & 0 & 1 \end{bmatrix} $$
>
> Agora, calculamos $H = E_1 \Omega E_1'$
>
> $$ H = \begin{bmatrix} 1 & 0 & 0 \\ -0.5 & 1 & 0 \\ -0.5 & 0 & 1 \end{bmatrix} \begin{bmatrix} 4 & 2 & 2 \\ 2 & 5 & 3 \\ 2 & 3 & 6 \end{bmatrix} \begin{bmatrix} 1 & -0.5 & -0.5 \\ 0 & 1 & 0 \\ 0 & 0 & 1 \end{bmatrix} = \begin{bmatrix} 4 & 0 & 0 \\ 0 & 4 & 2 \\ 0 & 2 & 5 \end{bmatrix} $$
>
> Observe que a primeira coluna de $H$, abaixo da diagonal principal, agora possui zeros.

**Observa√ß√£o:** Note que cada matriz $E_k$ √© uma matriz triangular inferior com 1s na diagonal e com elementos abaixo da diagonal na coluna *k* que s√£o utilizados para zerar os elementos abaixo da diagonal na matriz resultante da opera√ß√£o $E_{k-1} \ldots E_1 \Omega E_1' \ldots E_{k-1}' $. Portanto, a matriz $E_k^{-1}$ √© id√™ntica a $E_k$ exceto pelo sinal dos elementos fora da diagonal. Isso facilita o c√°lculo de $A$ como o produto das inversas das matrizes $E_k$.

**Lema 1**
A inversa de uma matriz $E_k$ como definida acima √© obtida trocando o sinal dos elementos abaixo da diagonal principal.

*Proof*:
Seja $E_k$ uma matriz da forma:
$$
E_k = I - v_k e_k'
$$
onde $I$ √© a matriz identidade, $e_k$ √© o vetor coluna com 1 na posi√ß√£o *k* e 0 em outras posi√ß√µes, e $v_k$ √© o vetor com elementos $-\frac{\Omega_{ik}}{\Omega_{kk}}$ para $i > k$ e 0 caso contr√°rio. Ent√£o, a inversa de $E_k$ √© dada por:
$$
E_k^{-1} = I + v_k e_k'
$$
Esta rela√ß√£o pode ser verificada multiplicando $E_k$ por $E_k^{-1}$ e observando que o resultado √© a matriz identidade.

I. Seja $E_k = I - v_k e_k'$ e $E_k^{-1} = I + v_k e_k'$.

II. Multiplicando $E_k$ por $E_k^{-1}$:
$$ E_k E_k^{-1} = (I - v_k e_k')(I + v_k e_k') $$

III. Expandindo o produto:
$$ E_k E_k^{-1} = I + v_k e_k' - v_k e_k' - v_k e_k' v_k e_k' $$

IV. Observe que $e_k' v_k$ √© um escalar (produto interno de dois vetores).  Como $e_k$ √© um vetor com 1 na posi√ß√£o $k$ e 0 em outras posi√ß√µes, e os elementos de $v_k$ s√£o da forma $-\frac{\Omega_{ik}}{\Omega_{kk}}$ para $i>k$ e zero caso contr√°rio, $e_k' v_k = 0$.
$$ E_k E_k^{-1} = I + v_k e_k' - v_k e_k' - v_k (0) e_k' = I $$

V. Portanto, $E_k E_k^{-1} = I$, confirmando que $E_k^{-1} = I + v_k e_k'$ √© a inversa de $E_k$. ‚ñ†

Essa demonstra√ß√£o mostra que a inversa da matriz $E_k$ √© facilmente obtida, confirmando a observa√ß√£o anterior sobre a facilidade de obter a matriz A.

> üí° **Exemplo Num√©rico (continua√ß√£o):**
>
>   A inversa de $E_1$ √© obtida simplesmente trocando o sinal dos elementos abaixo da diagonal:
>
> $$ E_1^{-1} = \begin{bmatrix} 1 & 0 & 0 \\ 0.5 & 1 & 0 \\ 0.5 & 0 & 1 \end{bmatrix} $$
>
>   Este resultado √© √∫til para obter a matriz $A$.

**Unicidade da Fatora√ß√£o**
A fatora√ß√£o triangular √© √∫nica. Para demonstrar isso, suponha que existam duas fatora√ß√µes triangulares para a matriz $\Omega$:

$$ \Omega = A_1 D_1 A_1' = A_2 D_2 A_2' $$.

Multiplicando √† esquerda por *$A‚ÇÇ‚Åª¬π$* e √† direita por *(A‚ÇÅ')‚Åª¬π*, temos [^4.4.15]:

$$ A_2^{-1} A_1 D_1  = D_2 A_2' (A_1')^{-1} $$.

O lado esquerdo desta equa√ß√£o √© uma matriz triangular superior, enquanto o lado direito √© uma matriz triangular inferior. A √∫nica maneira de isso ser verdade √© se ambas as matrizes forem iguais √† matriz identidade. Isso implica que A‚ÇÅ = A‚ÇÇ e D‚ÇÅ = D‚ÇÇ [^4.4.15]. Portanto, a fatora√ß√£o triangular √© √∫nica.

*Proof*:
I.  Assuma que existem duas fatora√ß√µes triangulares para $\Omega$:
    $$\Omega = A_1 D_1 A_1' = A_2 D_2 A_2'$$

II. Multiplicando √† esquerda por $A_2^{-1}$:
    $$A_2^{-1} \Omega = A_2^{-1} A_1 D_1 A_1' = D_2 A_2'$$

III. Multiplicando √† direita por $(A_1')^{-1}$:
    $$A_2^{-1} A_1 D_1 = D_2 A_2' (A_1')^{-1}$$

IV. O lado esquerdo, $A_2^{-1} A_1 D_1$, √© o produto de tr√™s matrizes. $A_1$ e $A_2$ s√£o triangulares inferiores com 1's na diagonal, e $D_1$ √© diagonal, tornando o produto triangular inferior. A inversa de uma matriz triangular inferior tamb√©m √© triangular inferior, o que faz com que $A_2^{-1} A_1$ seja triangular inferior.
    O produto de uma matriz triangular inferior por uma diagonal continua sendo triangular inferior.

V. O lado direito, $D_2 A_2' (A_1')^{-1}$, √© o produto de tr√™s matrizes. $A_2'$ e $(A_1')^{-1}$ s√£o triangulares superiores, e $D_2$ √© diagonal. Portanto, o lado direito √© triangular superior.

VI. Uma matriz triangular inferior √© igual a uma matriz triangular superior se e somente se ambas forem diagonais. Portanto, $A_2^{-1} A_1 D_1$ e $D_2 A_2' (A_1')^{-1}$ s√£o ambas diagonais. Como $A_1$ e $A_2$ s√£o triangulares inferiores com 1's na diagonal, $A_2^{-1} A_1$ deve ser igual a $I$.

VII. Se $A_2^{-1}A_1=I$, ent√£o $A_1 = A_2$, e consequentemente $D_1 = D_2$.

VIII. Portanto, a fatora√ß√£o triangular √© √∫nica. ‚ñ†

**Fatora√ß√£o de Cholesky**
A **fatora√ß√£o de Cholesky** √© uma forma particular da fatora√ß√£o triangular em que a matriz diagonal *D* √© expressa como o quadrado de outra matriz diagonal, **D¬π/¬≤** [^4.4.16]:

$$ \Omega = AD^{1/2} (AD^{1/2})' = PP' $$,

onde
*   P = AD¬π/¬≤
e D¬π/¬≤ √© uma matriz diagonal cujos elementos diagonais s√£o as ra√≠zes quadradas dos elementos diagonais da matriz D. A matriz P tamb√©m √© uma matriz triangular inferior. Esta representa√ß√£o √© √∫til em certas aplica√ß√µes, especialmente para simula√ß√µes e gera√ß√£o de n√∫meros aleat√≥rios com uma dada matriz de covari√¢ncia.

> üí° **Exemplo Num√©rico (continua√ß√£o):**
> Continuando o exemplo, vamos encontrar a matriz diagonal $D$ e depois $D^{1/2}$ e finalmente a matriz $P$.
>
> Ap√≥s aplicar a sequ√™ncia de opera√ß√µes $E_k$ at√© obter uma matriz diagonal, ter√≠amos:
>
> $$ D =  \begin{bmatrix} 4 & 0 & 0 \\ 0 & 4 & 0 \\ 0 & 0 & 4 \end{bmatrix} $$
>
> $$ D^{1/2} =  \begin{bmatrix} 2 & 0 & 0 \\ 0 & 2 & 0 \\ 0 & 0 & 2 \end{bmatrix} $$
>
> E a matriz A seria o produto das inversas das matrizes $E_k$:
>
> $$ A = E_1^{-1} E_2^{-1} = \begin{bmatrix} 1 & 0 & 0 \\ 0.5 & 1 & 0 \\ 0.5 & 0.5 & 1 \end{bmatrix}$$
>
> Finalmente, a matriz P na fatora√ß√£o de Cholesky √© dada por:
>
> $$ P = AD^{1/2} =  \begin{bmatrix} 1 & 0 & 0 \\ 0.5 & 1 & 0 \\ 0.5 & 0.5 & 1 \end{bmatrix}  \begin{bmatrix} 2 & 0 & 0 \\ 0 & 2 & 0 \\ 0 & 0 & 2 \end{bmatrix} = \begin{bmatrix} 2 & 0 & 0 \\ 1 & 2 & 0 \\ 1 & 1 & 2 \end{bmatrix}$$
>
> Note que $P$ √© uma matriz triangular inferior.
>
>  Podemos verificar que $PP^T = \Omega$:
> $$ PP' = \begin{bmatrix} 2 & 0 & 0 \\ 1 & 2 & 0 \\ 1 & 1 & 2 \end{bmatrix} \begin{bmatrix} 2 & 1 & 1 \\ 0 & 2 & 1 \\ 0 & 0 & 2 \end{bmatrix} = \begin{bmatrix} 4 & 2 & 2 \\ 2 & 5 & 3 \\ 2 & 3 & 6 \end{bmatrix} = \Omega $$

**Lema 2**
A matriz P na fatora√ß√£o de Cholesky de uma matriz sim√©trica positiva definida $\Omega$ √© uma matriz triangular inferior com elementos diagonais positivos.

*Proof*:
A matriz $P$ √© dada por $P = AD^{1/2}$, onde $A$ √© uma matriz triangular inferior com 1s na diagonal principal e $D^{1/2}$ √© uma matriz diagonal com elementos positivos na diagonal. O produto de uma matriz triangular inferior com uma matriz diagonal resulta em uma matriz triangular inferior. Adicionalmente, os elementos da diagonal de $P$ s√£o o produto dos elementos diagonais correspondentes de $A$ e $D^{1/2}$, que s√£o $1$ e $\sqrt{d_{ii}}$, respectivamente. Portanto, os elementos diagonais de $P$ s√£o todos positivos.

I. Seja $P = AD^{1/2}$.

II. $A$ √© uma matriz triangular inferior com 1s na diagonal principal, e $D^{1/2}$ √© uma matriz diagonal com elementos diagonais positivos, $d_{ii}^{1/2} > 0$.

III. O produto de uma matriz triangular inferior ($A$) com uma matriz diagonal ($D^{1/2}$) √© uma matriz triangular inferior.

IV. Os elementos diagonais de $P$ s√£o dados pelo produto dos elementos diagonais correspondentes de $A$ e $D^{1/2}$. Como os elementos diagonais de $A$ s√£o todos iguais a 1 e os elementos diagonais de $D^{1/2}$ s√£o $\sqrt{d_{ii}}$, ent√£o os elementos diagonais de $P$ s√£o $\sqrt{d_{ii}}$, que s√£o todos positivos.

V. Portanto, $P$ √© uma matriz triangular inferior com elementos diagonais positivos.‚ñ†

**Aplica√ß√£o em Proje√ß√µes Lineares**
Como vimos na se√ß√£o anterior, a fatora√ß√£o triangular √© muito √∫til na atualiza√ß√£o de proje√ß√µes lineares, fornecendo um m√©todo eficiente para calcular os coeficientes e os erros de proje√ß√µes lineares de forma recursiva [^4.5.2]. Al√©m disso, a fatoriza√ß√£o √© uma ferramenta muito poderosa na constru√ß√£o de proje√ß√µes lineares [^4.5.6].

**Teorema 1**
A fatora√ß√£o de Cholesky pode ser usada para determinar a proje√ß√£o linear de uma vari√°vel aleat√≥ria $Y_i$ sobre um conjunto de vari√°veis aleat√≥rias $Y_1, \ldots, Y_{i-1}$.

*Proof:*
Seja $\Omega$ a matriz de covari√¢ncia das vari√°veis aleat√≥rias $Y = [Y_1, Y_2, \ldots, Y_n]^T$, com $\Omega = E[YY^T]$. Usando a fatora√ß√£o de Cholesky, podemos escrever $\Omega = PP^T$. Considere a proje√ß√£o de $Y_i$ sobre $Y_1, \ldots, Y_{i-1}$, denotada por $\hat{Y_i}$. As vari√°veis transformadas $Z = P^{-1}Y$ t√™m matriz de covari√¢ncia igual √† identidade. Assim, a proje√ß√£o de $Z_i$ em $Z_1, \ldots, Z_{i-1}$ √© simplesmente $\hat{Z_i} = [Z_1, \ldots, Z_{i-1}]^T[Z_1, \ldots, Z_{i-1}] = [Z_1, \ldots, Z_{i-1}]$, onde os coeficientes da proje√ß√£o s√£o obtidos por meio da matriz triangular inferior $P$. Os elementos de $P$ permitem obter os coeficientes da proje√ß√£o de $Y_i$ sobre os elementos de $Y_1, \ldots, Y_{i-1}$ e, consequentemente, a proje√ß√£o linear de $Y_i$.

I. Seja $Y = [Y_1, Y_2, \ldots, Y_n]^T$ um vetor de vari√°veis aleat√≥rias com matriz de covari√¢ncia $\Omega = E[YY^T]$.

II. Usando a fatora√ß√£o de Cholesky, podemos escrever $\Omega = PP^T$, onde $P$ √© uma matriz triangular inferior com elementos diagonais positivos.

III. Defina $Z = P^{-1}Y$. Ent√£o, a matriz de covari√¢ncia de $Z$ √©:
    $$Cov(Z) = Cov(P^{-1}Y) = P^{-1} Cov(Y) (P^{-1})^T = P^{-1} \Omega (P^{-1})^T = P^{-1}PP^T (P^{-1})^T = I$$

IV. A proje√ß√£o de $Z_i$ sobre $Z_1, \ldots, Z_{i-1}$ √© dada por:
   $$\hat{Z_i} = \sum_{j=1}^{i-1} \beta_j Z_j $$
   Como $Cov(Z) = I$, as vari√°veis $Z_1, \ldots, Z_{i-1}$ s√£o ortogonais e os coeficientes da proje√ß√£o s√£o nulos. A proje√ß√£o de $Z_i$ sobre $Z_1, \ldots, Z_{i-1}$ √© um vetor com os primeiros $i-1$ elementos iguais aos pr√≥prios elementos $Z_1, \ldots, Z_{i-1}$ e os restantes elementos s√£o zero, ou seja, $\hat{Z_i}$ √© o vetor formado pela proje√ß√£o de $Z_i$ sobre o subespa√ßo gerado por $Z_1,\ldots,Z_{i-1}$.
   
V.  Como $Z = P^{-1}Y$, temos $Y = PZ$. Logo, podemos expressar $Y_i$ como uma combina√ß√£o linear das vari√°veis $Z_1, \ldots, Z_i$ dadas pelos elementos da $i$-√©sima linha da matriz $P$. Os coeficientes desta combina√ß√£o linear s√£o os elementos da matriz $P$.

VI. Ao usar a matriz triangular inferior P, calculamos os coeficientes da proje√ß√£o de $Y_i$ sobre $Y_1, \ldots, Y_{i-1}$. Como $P$ √© triangular inferior, $Y_i$ √© uma combina√ß√£o linear de $Z_1, \ldots, Z_i$. Consequentemente, os coeficientes da proje√ß√£o de $Y_i$ sobre $Y_1, \ldots, Y_{i-1}$ podem ser encontrados atrav√©s da matriz $P$.

VII. Portanto, a fatora√ß√£o de Cholesky pode ser usada para determinar a proje√ß√£o linear de $Y_i$ sobre $Y_1, \ldots, Y_{i-1}$. ‚ñ†

> üí° **Exemplo Num√©rico (continua√ß√£o):**
>
> Vamos supor que $Y$ √© um vetor de vari√°veis aleat√≥rias com a matriz de covari√¢ncia $\Omega$ que usamos nos exemplos anteriores. Assim, temos:
>
> $$ \Omega = \begin{bmatrix} 4 & 2 & 2 \\ 2 & 5 & 3 \\ 2 & 3 & 6 \end{bmatrix} $$
> e a matriz P da fatora√ß√£o de Cholesky:
>
>  $$ P = \begin{bmatrix} 2 & 0 & 0 \\ 1 & 2 & 0 \\ 1 & 1 & 2 \end{bmatrix} $$
>
> Se $Z=P^{-1}Y$, ent√£o $Y=PZ$. A primeira linha de $P$ diz que $Y_1=2Z_1$. A segunda linha de $P$ diz que $Y_2 = Z_1 + 2Z_2$. E a terceira linha de $P$ diz que $Y_3 = Z_1 + Z_2 + 2Z_3$. Desta forma, √© poss√≠vel obter os coeficientes da proje√ß√£o de cada vari√°vel sobre as anteriores.
>
>Por exemplo, para projetar $Y_3$ em $Y_1$ e $Y_2$, observamos que:
>
>$$ Y_3 = Z_1 + Z_2 + 2Z_3 $$
>
> Da rela√ß√£o $Y=PZ$, temos $Z=P^{-1}Y$. Calculando $P^{-1}$:
>
>$$ P^{-1} = \begin{bmatrix} 1/2 & 0 & 0 \\ -1/4 & 1/2 & 0 \\ 0 & -1/4 & 1/2 \end{bmatrix}$$
>
> Ent√£o:
>
> $$ Z_1 = \frac{1}{2}Y_1 $$
> $$ Z_2 = -\frac{1}{4}Y_1 + \frac{1}{2}Y_2 $$
> $$ Z_3 = -\frac{1}{4}Y_2 + \frac{1}{2}Y_3 $$
>
> Substituindo, ter√≠amos:
>
>$$ Y_3 = \frac{1}{2}Y_1 + (-\frac{1}{4}Y_1 + \frac{1}{2}Y_2) + 2(-\frac{1}{4}Y_2 + \frac{1}{2}Y_3) $$
>$$ Y_3 = \frac{1}{2}Y_1 -\frac{1}{4}Y_1 + \frac{1}{2}Y_2 - \frac{1}{2}Y_2 + Y_3 $$
>$$ 0 = \frac{1}{4}Y_1  $$
>
> Isto demonstra como a matriz P da fatora√ß√£o de Cholesky ajuda a obter as rela√ß√µes de proje√ß√£o entre as vari√°veis aleat√≥rias.

### Conclus√£o
A fatora√ß√£o triangular, incluindo a fatora√ß√£o de Cholesky, √© uma ferramenta poderosa e fundamental na matem√°tica e estat√≠stica, com aplica√ß√µes em diversas √°reas. A capacidade de decompor matrizes sim√©tricas positivas definidas desta forma fornece uma abordagem eficiente para simplificar c√°lculos, entender propriedades de modelos estat√≠sticos e implementar algoritmos computacionais, como o filtro de Kalman. O uso dessa fatora√ß√£o, como discutido neste cap√≠tulo, complementa a teoria das proje√ß√µes lineares, conectando a teoria com aplica√ß√µes pr√°ticas [^4.5.13].

### Refer√™ncias
[^4.4.1]: Qualquer matriz sim√©trica positiva definida $\Omega$ pode ser expressa como $\Omega = ADA'$, onde A √© uma matriz triangular inferior com 1s na diagonal principal, e D √© uma matriz diagonal com elementos positivos.
[^4.4.2]: Para ver como a fatoriza√ß√£o triangular pode ser calculada, considere...
[^4.4.3]: Esta matriz sempre existe, desde que $\Omega_{11} \neq 0$. Isso √© garantido no caso atual, porque $\Omega_{11}$ √© igual a $e_1\Omega e_1$, onde $e_1 = [1 \, 0 \, 0 \, \ldots \, 0]$. Como $\Omega$ √© positiva definida, $e_1\Omega e_1$ deve ser maior que zero.
[^4.4.4]: Quando $\Omega$ √© pr√©-multiplicado por $E_1$ e p√≥s-multiplicado por $E_1'$, o resultado √©...
[^4.4.8]: Assim, existe uma matriz A...
[^4.4.15]: Multiplicando √† esquerda [4.4.14] por $D_1^{-1}A_1^{-1}$ e multiplicando √† direita por $[A_2']^{-1}$ se obt√©m...
[^4.4.16]: Express√£o [4.4.16] √© conhecida como a fatora√ß√£o de Cholesky de $\Omega$...
[^4.5.1]: Seja $Y = (Y_1, Y_2, \ldots, Y_n)'$ um vetor (n x 1) de vari√°veis aleat√≥rias cuja matriz de segundo momento √© dada por $\Omega = E(YY')$.
[^4.5.2]: Seja $\Omega = ADA'$ a fatora√ß√£o triangular de $\Omega$, e defina $\tilde{Y} = A^{-1}Y$.
[^4.5.6]: Para ver a implica√ß√£o disso, pr√©-multiplique [4.5.2] por A: $A\tilde{Y} = Y$.
[^4.5.13]: O MSE da proje√ß√£o linear √© a vari√¢ncia de $Y_3$, que de [4.5.5] √© dada por $d_{33}$: $E[Y_3 - P(Y_3|Y_2,Y_1)]^2 = h_{33} - h_{32}h_{22}^{-1}h_{23}$
<!-- END -->
