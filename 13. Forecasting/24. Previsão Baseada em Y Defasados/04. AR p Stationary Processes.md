## Previs√£o em Processos AR(p) Estacion√°rios: Decomposi√ß√£o e Converg√™ncia

### Introdu√ß√£o
Este cap√≠tulo aprofunda a an√°lise da previs√£o em processos AR(p) estacion√°rios, com foco na representa√ß√£o da vari√°vel em termos de suas defasagens e erros futuros, explorando a forma da solu√ß√£o de uma equa√ß√£o de diferen√ßas de ordem *p* para calcular a previs√£o √≥tima. Em continuidade aos t√≥picos anteriores [^SECTION_PLACEHOLDER] e [^PREV_TOPIC], que abordaram a lei das proje√ß√µes iteradas e o decaimento geom√©trico em processos AR(1), ser√° demonstrado como um processo AR(p) pode ser decomposto em termos de seus valores passados e futuros erros, e como essa decomposi√ß√£o permite uma melhor compreens√£o da estrutura das previs√µes e da converg√™ncia para a m√©dia de um processo estacion√°rio.

### Conceitos Fundamentais
Conforme estabelecido em [^PREV_TOPIC], a previs√£o √≥tima de um processo AR(p) √© calculada de forma iterativa, utilizando a lei das proje√ß√µes iteradas.  Em resumo, um processo AR(p) estacion√°rio √© definido como:
$$(Y_t - \mu) = \phi_1(Y_{t-1} - \mu) + \phi_2(Y_{t-2} - \mu) + \ldots + \phi_p(Y_{t-p} - \mu) + \epsilon_t$$
Onde $\mu$ √© a m√©dia do processo, $\phi_1, \phi_2, ..., \phi_p$ s√£o os coeficientes autorregressivos, e $\epsilon_t$ √© um erro de ru√≠do branco com m√©dia zero e vari√¢ncia constante $\sigma^2$. A previs√£o de *s* per√≠odos √† frente, $\hat{Y}_{t+s|t}$, baseada nas informa√ß√µes dispon√≠veis no instante *t*, √© dada pela itera√ß√£o da equa√ß√£o acima.
A principal dificuldade surge quando se tenta expressar $Y_{t+s}$ em termos de $Y_t$, $Y_{t-1}$, ... e dos $\epsilon$ futuros ($\epsilon_{t+1}$, $\epsilon_{t+2}$, ...).  Uma abordagem √© basear a previs√£o na solu√ß√£o da equa√ß√£o de diferen√ßas de ordem *p* associada ao modelo AR(p), que, conforme a equa√ß√£o [^4.2.20], se expressa como:
$$Y_{t+s} - \mu = f_1^s(Y_t - \mu) + f_2^s(Y_{t-1} - \mu) + \ldots + f_p^s(Y_{t-p+1} - \mu) + \epsilon_{t+s} + \psi_1 \epsilon_{t+s-1} + \psi_2 \epsilon_{t+s-2} + \ldots + \psi_{s-1} \epsilon_{t+1}$$
onde os termos $f_i^s$ s√£o fun√ß√µes dos coeficientes $\phi_i$ e do horizonte de previs√£o *s*. Esta equa√ß√£o revela a estrutura da previs√£o de *s* per√≠odos √† frente, mostrando como ela se decomp√µe em fun√ß√£o dos valores passados de $Y$ e dos erros futuros.

A previs√£o √≥tima $\hat{Y}_{t+s|t}$  √© obtida ao tomar a esperan√ßa condicional da equa√ß√£o anterior em rela√ß√£o as informa√ß√µes em *t*:
$$ \hat{Y}_{t+s|t} - \mu = f_1^s(Y_t - \mu) + f_2^s(Y_{t-1} - \mu) + \ldots + f_p^s(Y_{t-p+1} - \mu) $$
Note que os erros futuros, por serem independentes do presente e do passado, desaparecem da equa√ß√£o da previs√£o. Assim, a previs√£o √© expressa em termos de valores passados de $Y$ atrav√©s da fun√ß√£o $f_i^s$. Para encontrar os valores das fun√ß√µes $f_i^s$ √© necess√°rio encontrar a solu√ß√£o geral da equa√ß√£o de diferen√ßas, e usar as condi√ß√µes iniciais para determinar os coeficientes espec√≠ficos.

> üí° **Exemplo Num√©rico:** Considere um processo AR(2) com $\mu = 10$, $\phi_1 = 0.7$, e $\phi_2 = 0.2$. A equa√ß√£o do processo √©
>
> $$ (Y_t - 10) = 0.7(Y_{t-1} - 10) + 0.2(Y_{t-2} - 10) + \epsilon_t $$
>
>  ou
>
> $$ Y_t = 10 + 0.7(Y_{t-1} - 10) + 0.2(Y_{t-2} - 10) + \epsilon_t $$
> $$ Y_t = 0.7Y_{t-1} + 0.2Y_{t-2} + 10 - 7 - 2 + \epsilon_t $$
> $$ Y_t = 0.7Y_{t-1} + 0.2Y_{t-2} + 1 + \epsilon_t $$
>
>  Para encontrar a previs√£o de 2 per√≠odos √† frente a partir de valores em *t*, precisamos expressar $Y_{t+2}$ em termos de valores em *t* e dos erros futuros. Primeiro, podemos escrever:
>
>  $$ Y_{t+1} = 0.7Y_t + 0.2Y_{t-1} + 1 + \epsilon_{t+1} $$
>  $$ Y_{t+2} = 0.7Y_{t+1} + 0.2Y_t + 1 + \epsilon_{t+2} $$
>  Substituindo a primeira equa√ß√£o na segunda:
>
>  $$ Y_{t+2} = 0.7 (0.7Y_t + 0.2Y_{t-1} + 1 + \epsilon_{t+1}) + 0.2Y_t + 1 + \epsilon_{t+2} $$
>  $$ Y_{t+2} = (0.7^2 + 0.2)Y_t + (0.7 \times 0.2)Y_{t-1} + 0.7 + 1 + 0.7\epsilon_{t+1} + \epsilon_{t+2} $$
>  $$ Y_{t+2} = 0.69Y_t + 0.14Y_{t-1} + 1.7 + 0.7\epsilon_{t+1} + \epsilon_{t+2} $$
>
>  Assim, a previs√£o de 2 per√≠odos √† frente √©:
>
>  $$\hat{Y}_{t+2|t} = 0.69Y_t + 0.14Y_{t-1} + 1.7$$
>  ou, usando a forma centrada:
>  $$\hat{Y}_{t+2|t} - 10 = 0.69(Y_t-10) + 0.14(Y_{t-1}-10)$$
>  Observe que os coeficientes de $Y_t$ e $Y_{t-1}$ s√£o obtidos a partir da forma da solu√ß√£o da equa√ß√£o de diferen√ßas. Em geral, os coeficientes $f_i^s$ s√£o encontrados atrav√©s da solu√ß√£o da equa√ß√£o de diferen√ßas de ordem *p* associada ao processo AR(p). Esta solu√ß√£o depende dos par√¢metros do modelo AR(p) ($\phi_1, \phi_2, ..., \phi_p$) e do horizonte de previs√£o *s*.

**Observa√ß√£o 1:** A solu√ß√£o da equa√ß√£o de diferen√ßas para um processo AR(p) pode ser obtida atrav√©s da an√°lise das ra√≠zes do polin√¥mio caracter√≠stico associado, como explorado em [^4.2.20]. A estacionariedade do processo AR(p) garante que estas ra√≠zes estejam fora do c√≠rculo unit√°rio, o que, por sua vez, assegura o decaimento dos coeficientes $f_i^s$ √† medida que o horizonte de previs√£o *s* aumenta. Essa an√°lise das ra√≠zes √© crucial para entender a din√¢mica de longo prazo e a converg√™ncia das previs√µes para a m√©dia.

**Lema 4:** A previs√£o √≥tima $\hat{Y}_{t+s|t}$ para um processo AR(p) estacion√°rio converge para a m√©dia incondicional $\mu$ √† medida que o horizonte de previs√£o *s* tende ao infinito.

*Proof:*

I. A previs√£o de *s* per√≠odos √† frente para um processo AR(p) √© dada por:
$$\hat{Y}_{t+s|t} - \mu = f_1^s(Y_t - \mu) + f_2^s(Y_{t-1} - \mu) + \ldots + f_p^s(Y_{t-p+1} - \mu)$$
onde $f_i^s$ s√£o fun√ß√µes que dependem dos par√¢metros do modelo AR(p) e de *s*.

II. Como o processo AR(p) √© estacion√°rio, as ra√≠zes do polin√¥mio caracter√≠stico associado ($1 - \phi_1z - \phi_2z^2 - \ldots - \phi_pz^p = 0$) est√£o fora do c√≠rculo unit√°rio no plano complexo.

III. A estacionariedade implica que o impacto de observa√ß√µes passadas sobre as previs√µes futuras decresce exponencialmente com o aumento do horizonte de tempo *s*.  Isso garante que os coeficientes $f_i^s$ tendam a zero quando *s* tende ao infinito.

IV. Portanto:
$$\lim_{s \to \infty} f_i^s = 0$$

V. Como os termos $(Y_{t-i+1} - \mu)$ s√£o finitos, temos:
$$\lim_{s \to \infty} (\hat{Y}_{t+s|t} - \mu) = 0$$
VI. Portanto, a previs√£o converge para a m√©dia incondicional:
$$\lim_{s \to \infty} \hat{Y}_{t+s|t} = \mu$$
‚ñ†

**Lema 4.1:** Para um processo AR(p) estacion√°rio, os coeficientes $\psi_j$ na representa√ß√£o de $Y_{t+s}$ em fun√ß√£o dos erros futuros, ou seja,
$$Y_{t+s} - \mu = f_1^s(Y_t - \mu) + f_2^s(Y_{t-1} - \mu) + \ldots + f_p^s(Y_{t-p+1} - \mu) + \epsilon_{t+s} + \psi_1 \epsilon_{t+s-1} + \psi_2 \epsilon_{t+s-2} + \ldots + \psi_{s-1} \epsilon_{t+1}$$
tamb√©m decrescem √† medida que o √≠ndice *j* aumenta.

*Proof:*  A representa√ß√£o de $Y_{t+s}$ em termos de erros futuros √© obtida pela itera√ß√£o da equa√ß√£o do processo AR(p), como demonstrado no exemplo num√©rico para o caso AR(2). Como o processo √© estacion√°rio, os coeficientes $\psi_j$ s√£o determinados pela estrutura do modelo AR(p), e refletem o impacto decrescente de um choque no processo em diferentes per√≠odos no futuro.  A estacionariedade garante que o efeito de choques passados decres√ßa no tempo, logo o impacto dos erros futuros decresce √† medida que o √≠ndice *j* aumenta.
‚ñ†

**Corol√°rio 4:** A converg√™ncia para a m√©dia incondicional $\mu$ para um processo AR(p) estacion√°rio √© garantida pela estacionariedade do processo, que implica um decaimento da influ√™ncia de valores passados e dos erros futuros sobre a previs√£o, fazendo com que previs√µes de longo prazo se aproximem da m√©dia do processo.

*Proof:*  Segue diretamente do Lema 4 e da defini√ß√£o de um processo estacion√°rio. A condi√ß√£o de estacionariedade restringe os par√¢metros do modelo (os $\phi_i$), e essas restri√ß√µes garantem que o impacto de condi√ß√µes iniciais na previs√£o se tornem cada vez menos relevantes √† medida que o horizonte de previs√£o aumenta.
‚ñ†

> üí° **Exemplo Num√©rico:**  Utilizando o mesmo processo AR(2) do exemplo anterior, com $\mu = 10$, $\phi_1 = 0.7$, e $\phi_2 = 0.2$, podemos analisar a converg√™ncia para a m√©dia.
>
>   - $\hat{Y}_{t+1|t} = 0.7 Y_t + 0.2 Y_{t-1} + 1$ (j√° calculado no exemplo anterior, usando itera√ß√£o do modelo)
>   - $\hat{Y}_{t+2|t} = 0.69 Y_t + 0.14 Y_{t-1} + 1.7$ (j√° calculado no exemplo anterior, usando a forma da solu√ß√£o da equa√ß√£o de diferen√ßas)
>
>  Para encontrar $\hat{Y}_{t+3|t}$ e observar a tend√™ncia, precisamos expressar $Y_{t+3}$ em termos de $Y_t$, $Y_{t-1}$,...
>
> $$Y_{t+3} = 0.7Y_{t+2} + 0.2Y_{t+1} + 1 + \epsilon_{t+3}$$
>
>  Substituindo:
>
> $$Y_{t+3} = 0.7(0.69Y_t + 0.14Y_{t-1} + 1.7 + 0.7\epsilon_{t+1} + \epsilon_{t+2}) + 0.2(0.7Y_t + 0.2Y_{t-1} + 1 + \epsilon_{t+1}) + 1 + \epsilon_{t+3}$$
>
> $$Y_{t+3} = (0.7 \times 0.69 + 0.2 \times 0.7)Y_t + (0.7 \times 0.14 + 0.2 \times 0.2)Y_{t-1}  + 0.7 \times 1.7 + 0.2 \times 1 + 1 + 0.7^2\epsilon_{t+1} + 0.2\epsilon_{t+1} + 0.7\epsilon_{t+2}+ \epsilon_{t+3}$$
>
> $$Y_{t+3} = 0.623Y_t + 0.138Y_{t-1}  + 3.39 + 0.69\epsilon_{t+1} + 0.7\epsilon_{t+2}+ \epsilon_{t+3}$$
>
>  E portanto:
>
>  $$\hat{Y}_{t+3|t} =  0.623Y_t + 0.138Y_{t-1} + 3.39$$
>  ou, na forma centrada:
>  $$\hat{Y}_{t+3|t} - 10 = 0.623(Y_t-10) + 0.138(Y_{t-1}-10)$$
>
>  Note como os coeficientes dos valores de $Y$ defasados est√£o ficando cada vez menores, ilustrando a converg√™ncia para a m√©dia (10) com o aumento de *s*. Os valores dos coeficientes podem ser obtidos da solu√ß√£o da equa√ß√£o de diferen√ßas correspondente.
>
>  Suponha que  $Y_t = 15$ e $Y_{t-1} = 12$:
>
>  - $\hat{Y}_{t+1|t} = 0.7 \times 15 + 0.2 \times 12 + 1= 13.9$
>  - $\hat{Y}_{t+2|t} = 0.69 \times 15 + 0.14 \times 12 + 1.7 = 13.53$
>  - $\hat{Y}_{t+3|t} = 0.623 \times 15 + 0.138 \times 12 + 3.39 = 13.369$
>
>  Como podemos ver, o impacto das observa√ß√µes passadas vai diminuindo em cada passo a frente e as previs√µes se aproximam da m√©dia de 10.
>
>   | Passo √† Frente (s) | Coeficiente de $Y_t$ | Coeficiente de $Y_{t-1}$ | Termo Constante | Previs√£o $\hat{Y}_{t+s|t}$ |
>   |-------------------|------------------------|---------------------------|----------------|---------------------------|
>   | 1                 | 0.7                    | 0.2                      | 1              | 13.9                    |
>   | 2                 | 0.69                   | 0.14                      | 1.7            | 13.53                    |
>   | 3                 | 0.623                 | 0.138                       | 3.39             | 13.369                      |
>   | ...                 | ... | ... | ...            | ...|
>
>  Este exemplo demonstra que, para um processo AR(2) estacion√°rio, a previs√£o √≥tima converge para a m√©dia incondicional $\mu = 10$ √† medida que o horizonte de previs√£o *s* aumenta. Observe como a magnitude dos coeficientes $f_i^s$ de $Y_t$ e $Y_{t-1}$ diminui com o aumento de *s*, refletindo a perda de informa√ß√£o e a converg√™ncia para a m√©dia.

A forma geral da previs√£o de *s* per√≠odos √† frente pode ser expressa como uma combina√ß√£o linear das observa√ß√µes passadas, com pesos que dependem do horizonte de previs√£o e dos par√¢metros do modelo AR(p).
**Proposi√ß√£o 2.1:** A representa√ß√£o de um processo AR(p) em termos de seus valores passados e erros futuros pode ser obtida de forma iterativa, seguindo o processo de substitui√ß√£o usado no exemplo num√©rico para o caso AR(2), e a solu√ß√£o da equa√ß√£o de diferen√ßas fornece uma forma geral e expl√≠cita para expressar essa representa√ß√£o.
*Proof:*
I. A equa√ß√£o de um processo AR(p) √© definida como:
$$Y_t - \mu = \phi_1(Y_{t-1} - \mu) + \phi_2(Y_{t-2} - \mu) + \ldots + \phi_p(Y_{t-p} - \mu) + \epsilon_t$$
II. Para expressar $Y_{t+s}$ em fun√ß√£o dos valores passados e dos erros futuros, pode-se realizar substitui√ß√µes sucessivas, de forma similar ao exemplo num√©rico para o caso AR(2).
III. Cada substitui√ß√£o de $Y_{t+k}$  em termos de seus valores defasados adiciona um termo $\epsilon_{t+k}$  e modifica os coeficientes dos valores passados de $Y$.
IV. Esse processo iterativo gera uma express√£o para $Y_{t+s}$ como uma combina√ß√£o linear dos valores passados $Y_t, Y_{t-1}, \ldots$ e dos erros futuros $\epsilon_{t+1}, \epsilon_{t+2}, \ldots, \epsilon_{t+s}$, cujos coeficientes dependem da estrutura do modelo AR(p) e do horizonte de previs√£o *s*.
V. A solu√ß√£o da equa√ß√£o de diferen√ßas correspondente ao processo AR(p) fornece uma forma geral para essa representa√ß√£o, permitindo obter os coeficientes $f_i^s$ e $\psi_j$ em fun√ß√£o dos par√¢metros do modelo AR(p) e do horizonte de previs√£o *s*.
‚ñ†

**Proposi√ß√£o 2:** A solu√ß√£o geral da equa√ß√£o de diferen√ßas para um processo AR(p), expressa como a representa√ß√£o da vari√°vel em termos de suas defasagens e erros futuros, permite calcular a previs√£o √≥tima de *s* per√≠odos √† frente como uma combina√ß√£o linear dos valores defasados e dos par√¢metros do modelo, que converge para a m√©dia do processo quando *s* tende para o infinito.

*Proof:*
I.  A solu√ß√£o geral da equa√ß√£o de diferen√ßas associada ao modelo AR(p) expressa $Y_{t+s}$ como uma fun√ß√£o dos valores defasados $Y_t, Y_{t-1}, ...$ e dos erros futuros $\epsilon_{t+1}, \epsilon_{t+2},...$:
$$Y_{t+s} - \mu = f_1^s(Y_t - \mu) + f_2^s(Y_{t-1} - \mu) + \ldots + f_p^s(Y_{t-p+1} - \mu) + \epsilon_{t+s} + \psi_1 \epsilon_{t+s-1} + \psi_2 \epsilon_{t+s-2} + \ldots + \psi_{s-1} \epsilon_{t+1}$$
II. A previs√£o √≥tima $\hat{Y}_{t+s|t}$ √© obtida tomando a esperan√ßa condicional de $Y_{t+s}$ no tempo $t$, o que elimina os termos com erros futuros, pois $E[\epsilon_{t+k}|Y_t, Y_{t-1}, ...] = 0$ para $k > 0$:
$$\hat{Y}_{t+s|t} - \mu = E[Y_{t+s} - \mu|Y_t, Y_{t-1}, ...] = f_1^s(Y_t - \mu) + f_2^s(Y_{t-1} - \mu) + \ldots + f_p^s(Y_{t-p+1} - \mu)$$
III. De acordo com o Lema 4, quando o processo √© estacion√°rio, os coeficientes $f_i^s$ tendem a zero √† medida que *s* tende ao infinito, ou seja:
$$ \lim_{s \to \infty} f_i^s = 0 $$
IV. Portanto, a previs√£o √≥tima converge para a m√©dia $\mu$ quando *s* tende ao infinito:
$$ \lim_{s \to \infty} \hat{Y}_{t+s|t} = \mu $$
V. Conclu√≠mos que a solu√ß√£o geral da equa√ß√£o de diferen√ßas permite obter uma representa√ß√£o da vari√°vel em termos de suas defasagens e erros futuros, e esse m√©todo possibilita calcular a previs√£o √≥tima e verificar sua converg√™ncia para a m√©dia.
‚ñ†

### Conclus√£o
Este cap√≠tulo explorou a previs√£o em processos AR(p) estacion√°rios, com foco na representa√ß√£o da vari√°vel em termos de suas defasagens e erros futuros, utilizando a solu√ß√£o da equa√ß√£o de diferen√ßas associada ao modelo AR(p). A an√°lise demonstrou como a previs√£o √≥tima para m√∫ltiplos per√≠odos √† frente √© obtida iterativamente e como o decaimento da influ√™ncia das observa√ß√µes passadas e erros futuros leva a uma converg√™ncia para a m√©dia do processo quando o horizonte de previs√£o tende ao infinito. Os resultados apresentados s√£o fundamentais para a compreens√£o da estrutura das previs√µes em modelos AR(p) e para o desenvolvimento de ferramentas de an√°lise de s√©ries temporais. A solu√ß√£o da equa√ß√£o de diferen√ßas fornece uma maneira geral de calcular a previs√£o, e de explicitar como as informa√ß√µes passadas influenciam a previs√£o futura.

### Refer√™ncias
[^SECTION_PLACEHOLDER]: *T√≥pico anterior do texto base*
[^PREV_TOPIC]: *T√≥pico anterior do texto base*
[^4.2.20]:  *Se√ß√£o 4.2 do texto base*
<!-- END -->
