## Previs√£o √ìtima em Processos ARMA(1,1): M√©dia Ponderada e Decaimento da Influ√™ncia do Presente

### Introdu√ß√£o

Este cap√≠tulo tem como objetivo aprofundar a an√°lise da previs√£o em processos ARMA(1,1), focando na deriva√ß√£o da previs√£o √≥tima de m√∫ltiplos per√≠odos √† frente e na demonstra√ß√£o de que esta pode ser expressa como uma m√©dia ponderada entre o valor corrente do processo e sua m√©dia incondicional. Em continuidade aos cap√≠tulos anteriores, que abordaram as previs√µes em modelos AR(p) e MA(1), ser√° analisado o comportamento da previs√£o em modelos ARMA(1,1) e demonstrado como o peso associado ao valor corrente do processo decai com o horizonte de previs√£o, revelando uma converg√™ncia para a m√©dia incondicional do processo, resultado crucial na modelagem de s√©ries temporais.

### Conceitos Fundamentais

Um processo ARMA(1,1) √© definido como [^4.2.37]:

$$(Y_t - \mu) = \phi(Y_{t-1} - \mu) + \epsilon_t + \theta \epsilon_{t-1}$$

onde $\mu$ √© a m√©dia do processo, $\phi$ √© o coeficiente autoregressivo, $\theta$ √© o coeficiente da m√©dia m√≥vel e $\epsilon_t$ √© um ru√≠do branco com m√©dia zero e vari√¢ncia $\sigma^2$.  A previs√£o de um per√≠odo √† frente para um processo ARMA(1,1) √© dada por [^4.2.39]:

$$\hat{Y}_{t+1|t} = \mu + \frac{\phi + \theta}{1 + \theta L} (Y_t - \mu)$$
ou
$$\hat{Y}_{t+1|t} = \mu +  \frac{\phi + \theta}{1 + \theta} (Y_t - \mu)$$
A previs√£o de um per√≠odo √† frente utiliza tanto o valor corrente do processo ($Y_t$) quanto a m√©dia n√£o condicionada $\mu$.

Para previs√µes de m√∫ltiplos per√≠odos √† frente (s>1), a lei das proje√ß√µes iteradas nos permite expressar a previs√£o √≥tima como [^4.2.39]:
$$\hat{Y}_{t+s|t} = \mu + \frac{\phi^s + \theta \phi^{s-1}}{1 + \theta L} (Y_t - \mu)$$
ou
$$\hat{Y}_{t+s|t} = \mu + \frac{\phi + \theta}{1 + \theta L}\phi^{s-1} (Y_t - \mu)$$
Usando a representa√ß√£o do modelo em termos de defasagens [^4.2.16] e considerando o resultado em [^4.2.39] para previs√µes maiores que um per√≠odo √† frente, podemos escrever:

$$\hat{Y}_{t+s|t} = \mu + \frac{\phi^s + \theta\phi^{s-1}}{1 + \theta} (Y_t - \mu)$$
$$\hat{Y}_{t+s|t} = \mu + \frac{\phi(\phi^{s-1} + \theta\phi^{s-2})}{1 + \theta} (Y_t - \mu)$$
ou
$$\hat{Y}_{t+s|t} = \mu + \phi^{s-1} \frac{(\phi + \theta)}{1 + \theta}(Y_t - \mu)$$

que √© uma m√©dia ponderada entre o valor corrente do processo, $Y_t$, e a m√©dia n√£o condicionada, $\mu$, com um peso $\phi^{s-1} \frac{(\phi + \theta)}{1 + \theta}$, que decai geometricamente com o horizonte de previs√£o, *s*.
Este resultado √© central para entender o comportamento da previs√£o em processos ARMA(1,1), demonstrando como a influ√™ncia do valor corrente do processo diminui √† medida que o horizonte de previs√£o se alonga. A taxa de decaimento √© determinada pelo coeficiente autoregressivo $\phi$, e √© influenciada pelo coeficiente da m√©dia m√≥vel $\theta$.

> üí° **Exemplo Num√©rico:** Considere um processo ARMA(1,1) com m√©dia $\mu = 20$, $\phi = 0.7$ e $\theta = 0.4$. No instante *t*, observamos $Y_t = 25$.
>
>  **Previs√£o de um per√≠odo √† frente (s=1):**
>
> $$ \hat{Y}_{t+1|t} = 20 + \frac{0.7 + 0.4}{1+ 0.4} (25 - 20) = 20 + \frac{1.1}{1.4} \times 5 = 20 + 3.928 \approx 23.93$$
>
>  **Previs√£o de dois per√≠odos √† frente (s=2):**
>
> $$\hat{Y}_{t+2|t} = 20 + \frac{0.7(0.7 + 0.4)}{1 + 0.4} (25 - 20) = 20 + 0.7 \times \frac{1.1}{1.4} \times 5 =  20 + 0.7 \times 3.928 \approx  22.75$$
>
>  **Previs√£o de tr√™s per√≠odos √† frente (s=3):**
>
>   $$\hat{Y}_{t+3|t} = 20 + 0.7^2 \times \frac{0.7+0.4}{1+0.4} (25 - 20) = 20 + 0.49 \times \frac{1.1}{1.4} \times 5 \approx 21.93$$
>
>  Este exemplo ilustra como a previs√£o se aproxima da m√©dia do processo, que neste caso √© 20, √† medida que o horizonte de previs√£o (*s*) aumenta, e como o peso dado para o valor observado $Y_t$ decai com o aumento de *s*, com uma taxa de decaimento controlada pelo par√¢metro $\phi$. A influ√™ncia de *t* diminui a cada passo, levando √† converg√™ncia.

**Lema 6:** Para um processo ARMA(1,1) estacion√°rio e invert√≠vel, a previs√£o √≥tima de *s* per√≠odos √† frente, $\hat{Y}_{t+s|t}$, converge para a m√©dia incondicional $\mu$ √† medida que *s* tende ao infinito.

*Proof:*
I.  A previs√£o de *s* per√≠odos √† frente para um processo ARMA(1,1) √© dada por
$$\hat{Y}_{t+s|t} = \mu + \phi^{s-1} \frac{\phi + \theta}{1 + \theta}(Y_t - \mu)$$

II. Para que o processo ARMA(1,1) seja estacion√°rio, o coeficiente autoregressivo deve satisfazer a condi√ß√£o $|\phi| < 1$.

III. √Ä medida que *s* tende ao infinito:
$$ \lim_{s \to \infty} \phi^{s-1} = 0$$
IV. Aplicando este limite na equa√ß√£o de previs√£o, obtemos:
$$ \lim_{s \to \infty} (\hat{Y}_{t+s|t} - \mu) = \lim_{s \to \infty} \phi^{s-1}\frac{\phi + \theta}{1 + \theta} (Y_t - \mu) = 0 \times \frac{\phi + \theta}{1 + \theta}(Y_t - \mu) = 0$$

V.  Portanto,
$$\lim_{s \to \infty} \hat{Y}_{t+s|t} = \mu$$
‚ñ†

**Lema 6.1:** A vari√¢ncia do erro de previs√£o para um horizonte *s* per√≠odos √† frente, $e_{t+s|t} = Y_{t+s} - \hat{Y}_{t+s|t}$ para um processo ARMA(1,1), aumenta com o aumento de *s* e converge para a vari√¢ncia incondicional do processo.

*Proof:* A demonstra√ß√£o desse resultado requer a an√°lise da representa√ß√£o do processo em termos de choques passados e futuros, juntamente com a forma da previs√£o recursiva. A vari√¢ncia do erro de previs√£o √© dada por $Var(e_{t+s|t}) = E[(Y_{t+s} - \hat{Y}_{t+s|t})^2]$. Para um processo ARMA(1,1) estacion√°rio, essa vari√¢ncia converge para a vari√¢ncia incondicional do processo √† medida que *s* aumenta, o que √© uma consequ√™ncia da estacionariedade e invertibilidade do processo.
I. Sabemos que $Y_{t+s} - \mu$ pode ser escrito como uma combina√ß√£o linear dos valores passados de $Y_t$ e de choques futuros $\epsilon$:
   $$ Y_{t+s} - \mu = \alpha_s (Y_t - \mu) + \sum_{i=0}^{s-1} \beta_i \epsilon_{t+s-i} $$
   onde os coeficientes $\alpha_s$ e $\beta_i$ dependem dos par√¢metros do modelo ARMA(1,1) e do horizonte *s*.

II. A previs√£o √≥tima √©:
   $$ \hat{Y}_{t+s|t} - \mu = \alpha_s (Y_t - \mu) $$

III. Portanto, o erro de previs√£o √©:
   $$ e_{t+s|t} = Y_{t+s} - \hat{Y}_{t+s|t} = \sum_{i=0}^{s-1} \beta_i \epsilon_{t+s-i}$$

IV. A vari√¢ncia do erro de previs√£o √©:
   $$ Var(e_{t+s|t}) = E[(e_{t+s|t})^2] = E[(\sum_{i=0}^{s-1} \beta_i \epsilon_{t+s-i})^2] = \sum_{i=0}^{s-1} \beta_i^2 \sigma^2 $$
V.  Quando s tende ao infinito, a soma converge para a vari√¢ncia incondicional do processo ARMA(1,1):
    $$\lim_{s \to \infty} Var(e_{t+s|t}) = \gamma_0 $$
Onde $\gamma_0 = \frac{1 + 2\theta\phi + \theta^2}{1-\phi^2}\sigma^2$ √© a vari√¢ncia incondicional do processo ARMA(1,1).
‚ñ†

> üí° **Exemplo Num√©rico (Vari√¢ncia do Erro):** Continuando com o mesmo processo ARMA(1,1) do exemplo anterior, com  $\mu = 20$, $\phi = 0.7$ e $\theta = 0.4$ e, adicionalmente, assumindo  $\sigma^2 = 1$. Podemos analisar o comportamento da vari√¢ncia do erro de previs√£o.
>
> A vari√¢ncia do erro de previs√£o para 1 passo √† frente √©:
>
> $$ Var(e_{t+1|t}) =  \sigma^2 = 1 $$
>
>  A vari√¢ncia do erro de previs√£o para 2 passos √† frente √© dada por:
> $$ Var(e_{t+2|t}) = \sigma^2 (1 + \theta^2 + \phi^2) =  1 (1 + 0.4^2 + 0.7^2) = 1.65 $$
>
>  E para 3 passos √† frente √©:
> $$ Var(e_{t+3|t}) = \sigma^2 (1 + \theta^2 + \theta^2\phi^2 + \phi^2 + \phi^4 ) $$
>
> Ao calcular para diferentes valores de s, pode-se observar que a vari√¢ncia tende para a vari√¢ncia incondicional do processo, que √© dada por
>
>  $$\gamma_0 = \frac{1 + 2\theta\phi + \theta^2}{1-\phi^2}\sigma^2 = \frac{1 + 2 \times 0.4 \times 0.7 + 0.4^2}{1 - 0.7^2} \times 1 = \frac{1 + 0.56 + 0.16}{0.51} = 3.3725$$
>
>   | Passo √† Frente (s) | Vari√¢ncia do Erro de Previs√£o $Var(e_{t+s|t})$ |
>   |-------------------|--------------------------------------------|
>   | 1                 | 1                                         |
>   | 2                 | 1.65                                       |
>   | 3                 | 1.9385                                     |
>   | 4                 | 2.1029                                     |
>   | 5                 | 2.2131                                     |
>   | 10                | 2.5789                                     |
>   | $\infty$          | 3.3725                                    |
>
>  Este exemplo num√©rico ilustra que a vari√¢ncia do erro de previs√£o aumenta com o aumento do horizonte de previs√£o, tendendo para a vari√¢ncia incondicional do processo, e demonstra que quanto maior o horizonte de previs√£o, menor a precis√£o da previs√£o.

**Proposi√ß√£o 3:** A previs√£o √≥tima de *s* per√≠odos √† frente para um processo ARMA(1,1) estacion√°rio e invert√≠vel, $\hat{Y}_{t+s|t}$, pode ser expressa como uma m√©dia ponderada entre o valor corrente do processo ($Y_t$) e sua m√©dia incondicional ($\mu$), com o peso associado a $(Y_t - \mu)$ decaindo geometricamente com o horizonte de previs√£o *s*.

*Proof:* Este resultado segue da equa√ß√£o da previs√£o √≥tima, $\hat{Y}_{t+s|t} = \mu + \phi^{s-1} \frac{\phi + \theta}{1 + \theta}(Y_t - \mu)$, onde o termo $\phi^{s-1} \frac{\phi + \theta}{1 + \theta}$ √© o peso associado a $(Y_t - \mu)$. Como o processo √© estacion√°rio, $|\phi| < 1$, e portanto o termo $\phi^{s-1}$ tende a zero √† medida que *s* tende ao infinito. A velocidade com que este peso decai √© determinada pelo valor absoluto do coeficiente autorregressivo, $\phi$.
‚ñ†

> **Observa√ß√£o:** Em modelos ARMA(1,1) a velocidade com que o peso de $Y_t$ decresce √© dada pelo par√¢metro autoregressivo, $\phi$, da mesma forma que em processos AR(1).
>
>  A presen√ßa do par√¢metro da m√©dia m√≥vel, $\theta$, afeta apenas o valor inicial do peso, para previs√µes de um per√≠odo √† frente, mas n√£o o seu comportamento assint√≥tico, que √© determinado por $\phi$.
**Proposi√ß√£o 3.1:**  A previs√£o √≥tima de *s* per√≠odos √† frente para um processo ARMA(1,1) estacion√°rio e invert√≠vel, $\hat{Y}_{t+s|t}$, pode ser reescrita em fun√ß√£o da previs√£o de um per√≠odo √† frente e a m√©dia incondicional,  destacando a natureza iterativa do processo de previs√£o.

*Proof:*
I.  Sabemos que a previs√£o de *s* per√≠odos √† frente para um processo ARMA(1,1) √© dada por:
$$ \hat{Y}_{t+s|t} = \mu + \phi^{s-1} \frac{\phi + \theta}{1 + \theta}(Y_t - \mu) $$
II. A previs√£o de um per√≠odo √† frente √© dada por:
$$ \hat{Y}_{t+1|t} = \mu + \frac{\phi + \theta}{1 + \theta}(Y_t - \mu) $$
III. Podemos reescrever $\hat{Y}_{t+s|t}$ como:
$$ \hat{Y}_{t+s|t} = \mu + \phi^{s-1}(\hat{Y}_{t+1|t} - \mu) $$
Esta forma expressa a previs√£o de *s* per√≠odos √† frente como uma m√©dia ponderada entre a previs√£o de um per√≠odo √† frente e a m√©dia incondicional do processo, onde o peso da previs√£o de um per√≠odo √† frente decai geometricamente com o horizonte de previs√£o *s*.
‚ñ†

> **Observa√ß√£o:** A Proposi√ß√£o 3.1 revela uma rela√ß√£o iterativa para a constru√ß√£o de previs√µes em processos ARMA(1,1). A previs√£o de *s* per√≠odos √† frente pode ser expressa em fun√ß√£o da previs√£o de um per√≠odo √† frente, que por sua vez utiliza o valor corrente do processo. Essa caracter√≠stica iterativa √© fundamental para a implementa√ß√£o de algoritmos de previs√£o.

**Teorema 1:** A previs√£o √≥tima para um processo ARMA(1,1) pode ser expressa como uma combina√ß√£o linear entre o valor corrente do processo e as previs√µes √≥timas dos per√≠odos anteriores.

*Proof:*
I. Partindo da representa√ß√£o da previs√£o de *s* per√≠odos √† frente:
  $$ \hat{Y}_{t+s|t} = \mu + \phi^{s-1} \frac{(\phi + \theta)}{1 + \theta}(Y_t - \mu) $$

II. Para *s* = 1:
   $$ \hat{Y}_{t+1|t} = \mu + \frac{(\phi + \theta)}{1 + \theta}(Y_t - \mu) $$

III. Para *s* = 2:
   $$ \hat{Y}_{t+2|t} = \mu + \phi \frac{(\phi + \theta)}{1 + \theta}(Y_t - \mu) $$
   
IV. Reorganizando a express√£o para $\hat{Y}_{t+2|t}$ em fun√ß√£o de $\hat{Y}_{t+1|t}$ :
   $$ \hat{Y}_{t+2|t} = \mu + \phi (\hat{Y}_{t+1|t} - \mu) $$
V. Generalizando para qualquer *s* > 1:
$$ \hat{Y}_{t+s|t} = \mu + \phi (\hat{Y}_{t+s-1|t} - \mu) $$
Esta express√£o demonstra que a previs√£o de *s* per√≠odos √† frente pode ser expressa em fun√ß√£o da previs√£o de *s-1* per√≠odos √† frente e da m√©dia do processo, revelando a natureza recursiva do processo de previs√£o.
‚ñ†

> **Observa√ß√£o:** O Teorema 1 estabelece uma rela√ß√£o recursiva entre previs√µes de diferentes horizontes, mostrando que cada previs√£o pode ser obtida a partir da previs√£o do per√≠odo anterior, ajustada pela m√©dia do processo. Essa caracter√≠stica simplifica a implementa√ß√£o de algoritmos de previs√£o e destaca a import√¢ncia da proje√ß√£o iterada na an√°lise de processos ARMA. A converg√™ncia para a m√©dia incondicional garante que para grandes horizontes, a previs√£o converge para esse valor.

> üí° **Exemplo Num√©rico (Previs√£o Recursiva):** Vamos retomar o exemplo do processo ARMA(1,1) com $\mu = 20$, $\phi = 0.7$, $\theta = 0.4$ e $Y_t = 25$. J√° calculamos:
>
> $$ \hat{Y}_{t+1|t} \approx 23.93$$
>
>  Agora, vamos calcular $\hat{Y}_{t+2|t}$ usando a rela√ß√£o recursiva do Teorema 1:
>
> $$ \hat{Y}_{t+2|t} = \mu + \phi (\hat{Y}_{t+1|t} - \mu) = 20 + 0.7 \times (23.93 - 20) = 20 + 0.7 \times 3.93 = 20 + 2.751 \approx 22.75$$
>
> E para $\hat{Y}_{t+3|t}$:
>
> $$ \hat{Y}_{t+3|t} = \mu + \phi (\hat{Y}_{t+2|t} - \mu) = 20 + 0.7 \times (22.75 - 20) = 20 + 0.7 \times 2.75 = 20 + 1.925 \approx 21.93$$
>
>  Esses resultados coincidem com os obtidos anteriormente, demonstrando a validade da abordagem recursiva. Este exemplo tamb√©m destaca a praticidade da abordagem recursiva, que permite calcular previs√µes futuras usando as previs√µes anteriores e os par√¢metros do modelo.

### Conclus√£o

Este cap√≠tulo demonstrou como a previs√£o √≥tima de m√∫ltiplos per√≠odos √† frente em processos ARMA(1,1) pode ser interpretada como uma m√©dia ponderada entre o valor corrente do processo e a m√©dia incondicional, e como o peso associado ao valor corrente decai com o aumento do horizonte de previs√£o, revelando uma converg√™ncia da previs√£o para a m√©dia do processo. A an√°lise tamb√©m mostrou como a vari√¢ncia do erro de previs√£o aumenta com o aumento do horizonte de tempo e que, no limite, tende para a vari√¢ncia incondicional do processo. Estes resultados s√£o fundamentais para a compreens√£o do comportamento de previs√µes de longo prazo em modelos ARMA(1,1),  e mostram a import√¢ncia de levar em conta tanto a m√©dia incondicional quanto a din√¢mica do processo para obter previs√µes precisas. A previs√£o √© uma combina√ß√£o linear entre o valor corrente e a m√©dia do processo, e a influ√™ncia do valor corrente decai com o tempo.

### Refer√™ncias
[^SECTION_PLACEHOLDER]: *T√≥pico anterior do texto base*
[^PREV_TOPIC]: *T√≥pico anterior do texto base*
[^4.2.37]:  *Se√ß√£o 4.2 do texto base*
[^4.2.39]:  *Se√ß√£o 4.2 do texto base*
[^4.2.16]:  *Se√ß√£o 4.2 do texto base*
<!-- END -->
