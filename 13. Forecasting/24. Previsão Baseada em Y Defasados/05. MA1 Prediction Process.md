## Previs√µes em Processos MA(1) Invert√≠veis: Erro Recursivo e Horizontes de Longo Prazo
### Introdu√ß√£o
Em continuidade aos t√≥picos anteriores [^SECTION_PLACEHOLDER] e [^PREV_TOPIC], que discutiram previs√µes em processos AR(p), este cap√≠tulo focar√° especificamente na previs√£o em processos MA(1) invert√≠veis. Examinaremos como a previs√£o de um per√≠odo √† frente utiliza um erro de previs√£o obtido recursivamente, e como as previs√µes de m√∫ltiplos per√≠odos √† frente se comportam. Analisaremos tamb√©m o porqu√™ dos erros de previs√£o se tornarem zero para horizontes maiores que um per√≠odo no futuro, quando os erros futuros n√£o s√£o observ√°veis.

### Conceitos Fundamentais
Como vimos anteriormente [^4.2.28], um processo MA(1) invert√≠vel √© definido como:
$$Y_t - \mu = \epsilon_t + \theta \epsilon_{t-1}$$
onde $\mu$ √© a m√©dia do processo, $\theta$ √© o coeficiente do processo MA(1) e $\epsilon_t$ √© um ru√≠do branco com m√©dia zero e vari√¢ncia $\sigma^2$. A invertibilidade do processo MA(1) ( $|\theta| < 1 $) nos permite expressar o erro $\epsilon_t$ em termos de valores passados de $Y_t$ [^4.2.31]:
$$ \epsilon_t = (Y_t - \mu) - \theta(Y_{t-1} - \mu) + \theta^2(Y_{t-2} - \mu) - \ldots $$
que pode ser expressa recursivamente como
$$\epsilon_t = (Y_t - \mu) - \theta \epsilon_{t-1}$$
Esta representa√ß√£o recursiva do erro permite expressar $\epsilon_t$ e, consequentemente, prever $Y_{t+1}$ utilizando informa√ß√µes passadas.

#### Previs√£o de Um Per√≠odo √† Frente
A previs√£o √≥tima de um per√≠odo √† frente, $\hat{Y}_{t+1|t}$, para um processo MA(1) √© dada por:
$$\hat{Y}_{t+1|t} = \mu + \theta \hat{\epsilon}_t$$ [^4.2.32]
onde $\hat{\epsilon}_t$ √© uma estimativa recursiva do erro no tempo t, baseada na equa√ß√£o anterior, que √© iniciada com  $\hat{\epsilon}_0 = 0$.
Essa equa√ß√£o mostra que a previs√£o de um per√≠odo √† frente se baseia na m√©dia do processo, $\mu$, ajustada pelo erro estimado $\hat{\epsilon}_t$, que depende das realiza√ß√µes passadas da s√©rie e de $\theta$.
A previs√£o para um per√≠odo √† frente,  $\hat{Y}_{t+1|t}$, usa a informa√ß√£o mais recente, que √© o erro do per√≠odo anterior, obtido recursivamente atrav√©s da equa√ß√£o do processo MA(1). Essa natureza recursiva do c√°lculo de $\hat{\epsilon}_t$ √© fundamental para a previs√£o de um per√≠odo √† frente em processos MA(1) invert√≠veis.

> üí° **Exemplo Num√©rico:** Suponha um processo MA(1) com $\mu = 5$ e $\theta = 0.6$. No instante $t=2$, temos $Y_1 = 7$, e $Y_2=8$. Inicializamos o processo assumindo que $\hat{\epsilon}_0 = 0$. Ent√£o, podemos usar:
>
> - $\hat{\epsilon}_1 = (Y_1 - \mu) - \theta \hat{\epsilon}_0 = (7 - 5) - 0.6(0) = 2$.
> - $\hat{\epsilon}_2 = (Y_2 - \mu) - \theta \hat{\epsilon}_1 = (8 - 5) - 0.6(2) = 3 - 1.2 = 1.8$
>
> Agora, a previs√£o de um per√≠odo √† frente √©:
>
> $$\hat{Y}_{3|2} = \mu + \theta \hat{\epsilon}_2 = 5 + 0.6(1.8) = 5 + 1.08 = 6.08$$
>
> Este exemplo demonstra como a previs√£o de um per√≠odo √† frente √© ajustada com base no erro estimado do per√≠odo anterior. O valor de $\hat{\epsilon}_2$ (1.8) representa o desvio do valor observado $Y_2$ em rela√ß√£o √† m√©dia, considerando a influ√™ncia do erro anterior. Este desvio, ponderado por $\theta$, √© adicionado √† m√©dia para obter a previs√£o de $Y_3$.

#### Previs√µes de M√∫ltiplos Per√≠odos √† Frente
Para previs√µes de m√∫ltiplos per√≠odos √† frente (s>1), a equa√ß√£o do processo MA(1) √© dada por:
$$Y_{t+s} = \mu + \epsilon_{t+s} + \theta \epsilon_{t+s-1}$$
Ao tomarmos a esperan√ßa condicional de $Y_{t+s}$ com base nas informa√ß√µes dispon√≠veis no tempo *t*, obtemos:
$$\hat{Y}_{t+s|t} = E[Y_{t+s}|Y_t, Y_{t-1}, \ldots] = \mu + E[\epsilon_{t+s}|Y_t, Y_{t-1}, \ldots] + \theta E[\epsilon_{t+s-1}|Y_t, Y_{t-1}, \ldots]$$
Como o ru√≠do branco $\epsilon$ √© independente de informa√ß√µes passadas, temos que
$$ E[\epsilon_{t+s}|Y_t, Y_{t-1}, \ldots] = 0 $$
para $s > 0$. Similarmente, $E[\epsilon_{t+s-1}|Y_t, Y_{t-1}, \ldots] = 0$, para $s > 1$. Desta forma, para qualquer $s>1$:
$$\hat{Y}_{t+s|t} = \mu $$
Este resultado revela uma propriedade importante da previs√£o em modelos MA(1): a previs√£o √≥tima para horizontes maiores que um per√≠odo √† frente √© simplesmente a m√©dia incondicional do processo, $\mu$. Isto ocorre porque os erros futuros, como $\epsilon_{t+1}, \epsilon_{t+2}, ...$ s√£o independentes de qualquer informa√ß√£o no tempo *t* e portanto, n√£o contribuem para a previs√£o.

> üí° **Exemplo Num√©rico (M√∫ltiplos Per√≠odos):** Usando o mesmo processo MA(1) do exemplo anterior, com $\mu = 5$ e $\theta = 0.6$, e assumindo que $\hat{\epsilon}_2 = 1.8$, ent√£o a previs√£o para um per√≠odo √† frente √© $\hat{Y}_{3|2} = 6.08$. J√° a previs√£o para dois per√≠odos √† frente √©:
>
> $$\hat{Y}_{4|2} = 5$$
>
> E a previs√£o para tr√™s per√≠odos √† frente √©:
>
> $$\hat{Y}_{5|2} = 5$$
>
> Observe como as previs√µes para m√∫ltiplos per√≠odos √† frente ($s>1$) se igualam √† m√©dia incondicional do processo, $\mu = 5$. Isso ocorre porque as informa√ß√µes dispon√≠veis no per√≠odo *t* n√£o oferecem insights sobre a evolu√ß√£o dos erros nos per√≠odos futuros. O processo MA(1) s√≥ utiliza o erro do per√≠odo anterior para ajustar a previs√£o; erros futuros s√£o considerados ru√≠do n√£o correlacionado com o passado, e, portanto, sua expectativa condicional √© zero.

**Lema 5:** Para um processo MA(1) invert√≠vel, a previs√£o √≥tima de *s* per√≠odos √† frente, $\hat{Y}_{t+s|t}$, √© igual √† m√©dia incondicional $\mu$ para $s > 1$.

*Proof:*
I.   A previs√£o de *s* per√≠odos √† frente √© dada por:
   $$\hat{Y}_{t+s|t} = E[Y_{t+s} | Y_t, Y_{t-1}, \ldots] $$
   Onde, para o processo MA(1) invert√≠vel:
   $$ Y_{t+s} = \mu + \epsilon_{t+s} + \theta \epsilon_{t+s-1} $$
II. Aplicando a esperan√ßa condicional:
   $$\hat{Y}_{t+s|t} = E[\mu | Y_t, Y_{t-1}, \ldots] + E[\epsilon_{t+s}|Y_t, Y_{t-1}, \ldots] + \theta E[\epsilon_{t+s-1}|Y_t, Y_{t-1}, \ldots]$$
III.  Como o erro $\epsilon_t$ √© um ru√≠do branco e independente do passado, para $s > 1$, temos:
   $$ E[\epsilon_{t+s}|Y_t, Y_{t-1}, \ldots] = 0 $$
   $$ E[\epsilon_{t+s-1}|Y_t, Y_{t-1}, \ldots] = 0 $$
IV. Portanto, para $s > 1$:
   $$\hat{Y}_{t+s|t} = \mu$$
   confirmando que a previs√£o de *s* per√≠odos √† frente √© igual √† m√©dia incondicional $\mu$ para $s > 1$.
   ‚ñ†

**Lema 5.1:** Para um processo MA(1) invert√≠vel, o erro de previs√£o de um per√≠odo √† frente, $e_{t+1|t} = Y_{t+1} - \hat{Y}_{t+1|t}$, √© igual a $\epsilon_{t+1}$, e para $s>1$, o erro de previs√£o $e_{t+s|t} = Y_{t+s} - \hat{Y}_{t+s|t}$ √© dado por
$$ e_{t+s|t} =  \epsilon_{t+s} + \theta \epsilon_{t+s-1} $$

*Proof:*
I. Sabemos que $Y_{t+s} = \mu + \epsilon_{t+s} + \theta \epsilon_{t+s-1}$.
II. Pela defini√ß√£o do erro de previs√£o, temos: $e_{t+s|t} = Y_{t+s} - \hat{Y}_{t+s|t}$.
III. Para $s=1$, $\hat{Y}_{t+1|t} = \mu + \theta \hat{\epsilon}_t$, e portanto
   $$ e_{t+1|t} = Y_{t+1} - \hat{Y}_{t+1|t} = (\mu + \epsilon_{t+1} + \theta \epsilon_t) - (\mu + \theta \hat{\epsilon}_t) = \epsilon_{t+1} + \theta (\epsilon_t - \hat{\epsilon}_t) $$
    No entanto, a estima√ß√£o recursiva de $\epsilon_t$ utiliza todos os valores passados para obter a melhor estimativa de $\epsilon_t$, e portanto, quando $t \rightarrow \infty$, $\epsilon_t = \hat{\epsilon}_t$. Assim, para *t* grande, o erro de previs√£o para $s=1$ √© dado por $e_{t+1|t} = \epsilon_{t+1}$.
IV. Para $s > 1$, $\hat{Y}_{t+s|t} = \mu$. Ent√£o:
$$e_{t+s|t} = Y_{t+s} - \hat{Y}_{t+s|t} = \mu + \epsilon_{t+s} + \theta \epsilon_{t+s-1} - \mu = \epsilon_{t+s} + \theta \epsilon_{t+s-1}$$
Portanto, para $s>1$, o erro de previs√£o √© igual √† soma do erro do per√≠odo e do erro do per√≠odo anterior multiplicado por $\theta$.
‚ñ†

**Corol√°rio 5:** Para um processo MA(1) invert√≠vel, a vari√¢ncia do erro de previs√£o de um per√≠odo √† frente √© $\sigma^2$ e a vari√¢ncia do erro de previs√£o para s>1 per√≠odos √† frente √© $(1+\theta^2)\sigma^2$.

*Proof:*
I. Pelo Lema 5.1, o erro de previs√£o de um per√≠odo √† frente √© $e_{t+1|t}=\epsilon_{t+1}$.
II. Portanto, a vari√¢ncia do erro de previs√£o de um per√≠odo √† frente √©
$$ Var(e_{t+1|t}) = Var(\epsilon_{t+1}) = \sigma^2 $$
III. Para $s>1$, o erro de previs√£o √©  $e_{t+s|t} =  \epsilon_{t+s} + \theta \epsilon_{t+s-1}$,  e portanto, a vari√¢ncia do erro de previs√£o √©
$$Var(e_{t+s|t}) = Var(\epsilon_{t+s} + \theta \epsilon_{t+s-1}) = Var(\epsilon_{t+s}) + \theta^2 Var(\epsilon_{t+s-1}) = \sigma^2 + \theta^2 \sigma^2 = (1+\theta^2)\sigma^2$$
‚ñ†

**Corol√°rio 5.1:** Para um processo MA(1) invert√≠vel, a covari√¢ncia entre os erros de previs√£o de um per√≠odo √† frente e dois per√≠odos √† frente, $Cov(e_{t+1|t}, e_{t+2|t})$, √© igual a $\theta \sigma^2$.

*Proof:*
I. Do Lema 5.1, temos que $e_{t+1|t} = \epsilon_{t+1}$ e $e_{t+2|t} = \epsilon_{t+2} + \theta \epsilon_{t+1}$.
II. A covari√¢ncia entre $e_{t+1|t}$ e $e_{t+2|t}$ √© definida como:
    $$ Cov(e_{t+1|t}, e_{t+2|t}) = Cov(\epsilon_{t+1}, \epsilon_{t+2} + \theta \epsilon_{t+1}) $$
III. Usando a propriedade da covari√¢ncia, temos:
    $$ Cov(\epsilon_{t+1}, \epsilon_{t+2} + \theta \epsilon_{t+1}) = Cov(\epsilon_{t+1}, \epsilon_{t+2}) + \theta Cov(\epsilon_{t+1}, \epsilon_{t+1}) $$
IV. Como os erros $\epsilon_t$ s√£o ru√≠do branco, $Cov(\epsilon_{t+1}, \epsilon_{t+2}) = 0$, e $Cov(\epsilon_{t+1}, \epsilon_{t+1}) = Var(\epsilon_{t+1}) = \sigma^2$.
V. Portanto:
    $$ Cov(e_{t+1|t}, e_{t+2|t}) = 0 + \theta \sigma^2 = \theta \sigma^2 $$
    ‚ñ†

> üí° **Exemplo Num√©rico (Erro de Previs√£o):** Continuando com o exemplo anterior do processo MA(1) com $\mu = 5$ e $\theta = 0.6$, e assumindo $\sigma^2 = 0.25$.
>
>  - A vari√¢ncia do erro de previs√£o de um per√≠odo √† frente √©:
>  $$ Var(e_{t+1|t}) = \sigma^2 = 0.25 $$
>
>  - A vari√¢ncia do erro de previs√£o para dois per√≠odos √† frente √©:
>   $$ Var(e_{t+2|t}) = (1+\theta^2)\sigma^2 = (1 + 0.6^2)0.25 = 1.36 \times 0.25 = 0.34 $$
>  - A covari√¢ncia entre o erro de previs√£o de um per√≠odo √† frente e dois per√≠odos √† frente √©:
>   $$ Cov(e_{t+1|t}, e_{t+2|t}) = \theta \sigma^2 = 0.6 \times 0.25 = 0.15$$
>
>   Este resultado demonstra que a vari√¢ncia do erro aumenta com o aumento do horizonte de previs√£o para um processo MA(1) , mas que essa vari√¢ncia se torna constante para horizontes maiores que um per√≠odo √† frente. Adicionalmente, demonstra que os erros de previs√µes em diferentes horizontes em processos MA(1) s√£o correlacionados. A vari√¢ncia do erro para previs√µes de dois per√≠odos √† frente √© maior do que para um per√≠odo √† frente devido √† propaga√ß√£o da incerteza do erro no processo. A covari√¢ncia positiva sugere que se um erro de previs√£o em um per√≠odo for positivo, √© mais prov√°vel que o erro no per√≠odo seguinte tamb√©m o seja, devido √† influ√™ncia de $\theta$.

Os resultados apresentados mostram que, embora o processo MA(1) seja influenciado pelos erros passados, a previsibilidade diminui com o aumento do horizonte de previs√£o, fazendo com que previs√µes de longo prazo sejam iguais √† m√©dia do processo, e com erros maiores do que previs√µes de um per√≠odo a frente.

**Observa√ß√£o 1:** √â importante notar que a propriedade de a previs√£o convergir para a m√©dia incondicional do processo para horizontes de longo prazo √© uma caracter√≠stica dos modelos MA(q). Em geral, para um processo MA(q), a previs√£o √≥tima para horizontes $s > q$ se igualar√° √† m√©dia incondicional do processo.

### Conclus√£o
Este cap√≠tulo explorou as previs√µes em processos MA(1) invert√≠veis, destacando a import√¢ncia da estimativa recursiva dos erros para previs√µes de um per√≠odo √† frente e a converg√™ncia para a m√©dia incondicional para previs√µes de m√∫ltiplos per√≠odos √† frente.  A an√°lise demonstrou que, em um processo MA(1) invert√≠vel, a previs√£o √≥tima de um per√≠odo √† frente depende da estimativa recursiva dos erros passados, enquanto que para previs√µes com horizontes maiores que um per√≠odo √† frente, a previs√£o √≥tima √© igual √† m√©dia do processo, $\mu$.  Esta caracter√≠stica √© uma consequ√™ncia da independ√™ncia entre os choques futuros e as informa√ß√µes dispon√≠veis no instante *t*. A natureza recursiva do c√°lculo do erro de previs√£o e a perda de informa√ß√£o para horizontes de tempo maiores do que um per√≠odo foram analisadas em detalhe.

### Refer√™ncias
[^SECTION_PLACEHOLDER]: *T√≥pico anterior do texto base*
[^PREV_TOPIC]:  *T√≥pico anterior do texto base*
[^4.2.28]:  *Se√ß√£o 4.2 do texto base*
[^4.2.31]:  *Se√ß√£o 4.2 do texto base*
[^4.2.32]:  *Se√ß√£o 4.2 do texto base*
<!-- END -->
