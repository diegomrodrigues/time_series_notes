## Previs√£o de um Processo AR(1)
### Introdu√ß√£o
Este cap√≠tulo aborda a previs√£o de s√©ries temporais, com foco espec√≠fico em processos AR(1) (Autorregressivos de primeira ordem). Como vimos anteriormente, a previs√£o √© uma componente crucial da an√°lise de s√©ries temporais, permitindo antecipar valores futuros com base em dados hist√≥ricos. Nos cap√≠tulos anteriores, estabelecemos a base para modelos de proje√ß√£o linear e o uso da esperan√ßa condicional para previs√µes √≥timas. Este cap√≠tulo se aprofunda no c√°lculo pr√°tico de previs√µes para um processo AR(1), utilizando o operador de retardo para derivar uma f√≥rmula recursiva.  [^1] [^2] [^3]

### Conceitos Fundamentais
Um processo AR(1) estacion√°rio √© definido pela equa√ß√£o:
$$
(1 - \phi L)(Y_t - \mu) = \epsilon_t,
$$
onde $Y_t$ √© o valor da s√©rie temporal no instante $t$, $\mu$ √© a m√©dia do processo, $\phi$ √© o coeficiente autorregressivo, $L$ √© o operador de retardo (onde $LY_t = Y_{t-1}$), e $\epsilon_t$ √© um ru√≠do branco com m√©dia zero.  O objetivo √© calcular a previs√£o √≥tima para $Y_{t+s}$ dado o conjunto de informa√ß√µes no tempo $t$, denotado como $\hat{Y}_{t+s|t}$.

> üí° **Exemplo Num√©rico:**
> Vamos considerar um processo AR(1) com m√©dia $\mu = 10$, coeficiente autorregressivo $\phi = 0.7$ e ru√≠do branco $\epsilon_t$ com desvio padr√£o de 2. O valor atual da s√©rie temporal √© $Y_t = 15$. Queremos prever o valor para um passo √† frente, $Y_{t+1}$.
>
>  Usando a equa√ß√£o  $(1 - \phi L)(Y_t - \mu) = \epsilon_t$, se expande para $Y_t - \phi Y_{t-1} - \mu(1-\phi) = \epsilon_t$. E, reorganizando temos: $Y_t = \mu(1-\phi) + \phi Y_{t-1} + \epsilon_t$.
>
> A m√©dia $\mu$ representa o valor em torno do qual a s√©rie temporal flutua, enquanto $\phi$ controla qu√£o dependente o valor atual √© do valor anterior. Um $\phi$ positivo indica que valores acima da m√©dia tendem a ser seguidos por valores tamb√©m acima da m√©dia, enquanto $\phi$ negativo indica o oposto.
>

Para um processo AR(1) estacion√°rio, a representa√ß√£o MA(‚àû) (m√©dia m√≥vel de ordem infinita) √© dada por [^4]:
$$
\psi(L) = \frac{1}{1 - \phi L} = 1 + \phi L + \phi^2 L^2 + \phi^3 L^3 + \dots
$$
Assim, podemos expressar $Y_t$ como uma combina√ß√£o linear de ru√≠dos brancos passados:
$$
Y_t - \mu = \sum_{j=0}^{\infty} \phi^j \epsilon_{t-j}
$$

Para calcular a previs√£o de *s* per√≠odos √† frente, usamos a f√≥rmula de previs√£o Wiener-Kolmogorov [^5]:
$$
\hat{Y}_{t+s|t} = \mu + \left[\frac{\psi(L)}{L^s}\right]_+  (Y_t - \mu),
$$
onde $\left[\frac{\psi(L)}{L^s}\right]_+$ representa a parte do polin√¥mio do operador de retardo com pot√™ncias n√£o negativas. No caso espec√≠fico do processo AR(1),
$$
\left[\frac{\psi(L)}{L^s}\right]_+ = \phi^s + \phi^{s+1}L + \phi^{s+2}L^2 + \dots = \frac{\phi^s}{1 - \phi L}.
$$

Substituindo na equa√ß√£o da previs√£o √≥tima, temos:

$$
\hat{Y}_{t+s|t} = \mu + \frac{\phi^s}{1 - \phi L} (Y_t - \mu).
$$

Para uma previs√£o de um passo √† frente ($s=1$),  [^6]
$$
\left[ \frac{\psi(L)}{L} \right]_+ = \frac{\phi}{1 - \phi L}
$$
e a previs√£o √≥tima simplifica-se para [^7]:
$$
\hat{Y}_{t+1|t} = \mu + \frac{\phi}{1 - \phi L}(Y_t - \mu)
$$
que tamb√©m pode ser expressa de forma recursiva,
$$
\hat{Y}_{t+1|t} = \mu + \phi (Y_t - \mu).
$$
Esta express√£o mostra que a previs√£o de um passo √† frente √© uma m√©dia ponderada da m√©dia do processo ($\mu$) e do desvio do valor atual em rela√ß√£o √† m√©dia ($Y_t - \mu$). A pondera√ß√£o √© dada pelo par√¢metro autorregressivo $\phi$.

> üí° **Exemplo Num√©rico (continua√ß√£o):**
> Usando a f√≥rmula recursiva para um passo √† frente:
>
> $\hat{Y}_{t+1|t} = \mu + \phi (Y_t - \mu)$
>
> Substituindo os valores $\mu = 10$, $\phi = 0.7$ e $Y_t = 15$:
>
> $\hat{Y}_{t+1|t} = 10 + 0.7 (15 - 10) = 10 + 0.7 \times 5 = 10 + 3.5 = 13.5$
>
> Portanto, a previs√£o para o pr√≥ximo per√≠odo √© 13.5. Este valor est√° entre a m√©dia do processo (10) e o valor atual (15), ponderado por $\phi = 0.7$. O valor de 0.7 indica que o valor futuro ser√° influenciado de forma positiva pelo valor corrente.
>

Essa rela√ß√£o recursiva significa que a previs√£o de *s* passos √† frente para um processo AR(1) pode ser calculada iterativamente, como vemos adiante.
Expandindo a formula para previs√£o de *s* passos √† frente, obtemos:
$$
\hat{Y}_{t+s|t} = \mu + \phi^s (Y_t - \mu),
$$
que mostra como a previs√£o decai geometricamente para a m√©dia $\mu$ √† medida que o horizonte da previs√£o *s* aumenta. Isso ocorre porque, com o aumento de *s*, o impacto das observa√ß√µes passadas diminui, dada a natureza autoregressiva do modelo.

> üí° **Exemplo Num√©rico (previs√£o com s>1):**
> Usando o mesmo exemplo, vamos calcular a previs√£o para dois passos √† frente ($s=2$):
>
> $\hat{Y}_{t+2|t} = \mu + \phi^2 (Y_t - \mu)$
>
> Substituindo os valores:
>
> $\hat{Y}_{t+2|t} = 10 + (0.7)^2 (15 - 10) = 10 + 0.49 \times 5 = 10 + 2.45 = 12.45$
>
> Para tr√™s passos √† frente ($s=3$):
>
> $\hat{Y}_{t+3|t} = 10 + (0.7)^3 (15 - 10) = 10 + 0.343 \times 5 = 10 + 1.715 = 11.715$
>
> Podemos observar que, conforme *s* aumenta, a previs√£o se aproxima da m√©dia do processo ($\mu = 10$).
>
> ```mermaid
>   graph LR
>      A[Y_t=15] -->|s=1| B[Y_t+1=13.5]
>      B -->|s=2| C[Y_t+2=12.45]
>      C -->|s=3| D[Y_t+3=11.715]
>      D --> ... --> E[Œº=10]
> ```
> A previs√£o decai em dire√ß√£o √† m√©dia do processo $\mu = 10$.

#### Lema
A previs√£o para *s* passos √† frente pode ser obtida recursivamente atrav√©s de:
$\hat{Y}_{t+s|t} = \mu + \phi(\hat{Y}_{t+s-1|t} - \mu)$

##### Demonstra√ß√£o
Provaremos que a previs√£o para *s* passos √† frente, $\hat{Y}_{t+s|t}$, pode ser calculada recursivamente usando a previs√£o de um passo anterior, $\hat{Y}_{t+s-1|t}$.

I. Come√ßamos com a express√£o para a previs√£o de *s* passos √† frente:
$$
\hat{Y}_{t+s|t} = \mu + \phi^s(Y_t - \mu)
$$

II. Podemos reescrever $\phi^s$ como $\phi \cdot \phi^{s-1}$:
$$
\hat{Y}_{t+s|t} = \mu + \phi \cdot \phi^{s-1}(Y_t - \mu)
$$

III. Adicionamos e subtra√≠mos $\mu \phi$ do lado direito da equa√ß√£o:
$$
\hat{Y}_{t+s|t} = \mu + \phi \cdot \phi^{s-1}(Y_t - \mu) + \mu\phi - \mu\phi
$$

IV. Reorganizamos a express√£o:
$$
\hat{Y}_{t+s|t} = \mu + \phi (\mu + \phi^{s-1}(Y_t-\mu)-\mu)
$$
V. Reconhecendo que $\hat{Y}_{t+s-1|t} = \mu + \phi^{s-1}(Y_t-\mu)$, substitu√≠mos na equa√ß√£o:
$$
\hat{Y}_{t+s|t} = \mu + \phi(\hat{Y}_{t+s-1|t}-\mu)
$$
Assim, demonstramos que a previs√£o para *s* passos √† frente pode ser calculada recursivamente.
$\blacksquare$

**Lema 1**
A vari√¢ncia do erro de previs√£o para *s* passos √† frente, denotada por $Var(Y_{t+s} - \hat{Y}_{t+s|t})$, √© dada por:
$$
Var(Y_{t+s} - \hat{Y}_{t+s|t}) = \sigma^2 \sum_{j=0}^{s-1} \phi^{2j}
$$
onde $\sigma^2$ √© a vari√¢ncia do ru√≠do branco $\epsilon_t$.

> üí° **Exemplo Num√©rico (Vari√¢ncia do Erro):**
> Usando o exemplo anterior ($\phi = 0.7$ e $\sigma^2 = 2^2 = 4$). Vamos calcular a vari√¢ncia do erro de previs√£o para 1, 2 e 3 passos √† frente:
>
> Para $s = 1$:
> $Var(Y_{t+1} - \hat{Y}_{t+1|t}) = 4 \sum_{j=0}^{0} (0.7)^{2j} = 4 \times (0.7)^0 = 4 \times 1 = 4$
>
> Para $s = 2$:
> $Var(Y_{t+2} - \hat{Y}_{t+2|t}) = 4 \sum_{j=0}^{1} (0.7)^{2j} = 4 \times [(0.7)^0 + (0.7)^2] = 4 \times (1 + 0.49) = 4 \times 1.49 = 5.96$
>
> Para $s = 3$:
> $Var(Y_{t+3} - \hat{Y}_{t+3|t}) = 4 \sum_{j=0}^{2} (0.7)^{2j} = 4 \times [(0.7)^0 + (0.7)^2 + (0.7)^4] = 4 \times (1 + 0.49 + 0.2401) = 4 \times 1.7301 = 6.9204$
>
> A vari√¢ncia do erro de previs√£o aumenta com o horizonte *s*, o que √© consistente com a intui√ß√£o de que previs√µes mais distantes no futuro s√£o mais incertas.
>

##### Demonstra√ß√£o
Aqui, derivaremos a vari√¢ncia do erro de previs√£o para *s* passos √† frente.

I. Come√ßamos com a representa√ß√£o MA(‚àû) de $Y_{t+s}$:
$$
Y_{t+s} - \mu = \sum_{j=0}^{\infty} \phi^j \epsilon_{t+s-j}
$$
II. Expandimos a soma para separar os termos que s√£o conhecidos no tempo *t* dos que n√£o s√£o:
$$
Y_{t+s} - \mu = \sum_{j=0}^{s-1} \phi^j \epsilon_{t+s-j} + \sum_{j=s}^{\infty} \phi^j \epsilon_{t+s-j}
$$
III. A previs√£o de *s* passos √† frente √© dada por:
$$
\hat{Y}_{t+s|t} = \mu + \sum_{j=s}^{\infty} \phi^j \epsilon_{t+s-j}
$$
IV. O erro de previs√£o √© a diferen√ßa entre o valor real e o valor previsto:
$$
Y_{t+s} - \hat{Y}_{t+s|t} = \sum_{j=0}^{s-1} \phi^j \epsilon_{t+s-j}
$$
V. Calculamos a vari√¢ncia do erro de previs√£o:
$$
Var(Y_{t+s} - \hat{Y}_{t+s|t}) = Var\left(\sum_{j=0}^{s-1} \phi^j \epsilon_{t+s-j}\right)
$$
VI. Como os ru√≠dos brancos s√£o independentes e t√™m vari√¢ncia $\sigma^2$, a vari√¢ncia da soma √© a soma das vari√¢ncias:
$$
Var(Y_{t+s} - \hat{Y}_{t+s|t}) = \sum_{j=0}^{s-1} \phi^{2j} Var(\epsilon_{t+s-j})
$$
VII. Substitu√≠mos a vari√¢ncia do ru√≠do branco, $Var(\epsilon_{t+s-j}) = \sigma^2$, na equa√ß√£o:
$$
Var(Y_{t+s} - \hat{Y}_{t+s|t}) = \sigma^2 \sum_{j=0}^{s-1} \phi^{2j}
$$
Assim, demonstramos a f√≥rmula para a vari√¢ncia do erro de previs√£o.
$\blacksquare$

**Teorema 1**
Quando $s \to \infty$, a previs√£o $\hat{Y}_{t+s|t}$ converge para a m√©dia do processo $\mu$. Adicionalmente, a vari√¢ncia do erro de previs√£o, $Var(Y_{t+s} - \hat{Y}_{t+s|t})$, converge para a vari√¢ncia incondicional do processo, dado que $|\phi|<1$.

> üí° **Exemplo Num√©rico (Converg√™ncia):**
> No nosso exemplo ($\phi = 0.7$, $\sigma^2 = 4$), quando $s \to \infty$:
>
> $\lim_{s \to \infty} \hat{Y}_{t+s|t} = \mu = 10$
>
> $\lim_{s \to \infty} Var(Y_{t+s} - \hat{Y}_{t+s|t}) = \frac{\sigma^2}{1-\phi^2} = \frac{4}{1 - (0.7)^2} = \frac{4}{1 - 0.49} = \frac{4}{0.51} \approx 7.84$
>
> Isso indica que, conforme o horizonte da previs√£o aumenta, a previs√£o converge para a m√©dia do processo (10), e a vari√¢ncia do erro de previs√£o converge para aproximadamente 7.84, que √© a vari√¢ncia incondicional do processo AR(1).
>

##### Demonstra√ß√£o
Vamos provar a converg√™ncia da previs√£o e da vari√¢ncia do erro de previs√£o √† medida que o horizonte de previs√£o se aproxima do infinito.

I. Come√ßamos com a f√≥rmula para a previs√£o de *s* passos √† frente:
$$
\hat{Y}_{t+s|t} = \mu + \phi^s (Y_t - \mu)
$$

II. Tomamos o limite quando $s$ tende a infinito:
$$
\lim_{s \to \infty} \hat{Y}_{t+s|t} = \lim_{s \to \infty} \left[ \mu + \phi^s (Y_t - \mu) \right]
$$

III. Dado que $|\phi| < 1$, ent√£o $\lim_{s \to \infty} \phi^s = 0$.  Assim:
$$
\lim_{s \to \infty} \hat{Y}_{t+s|t} = \mu + 0 \cdot (Y_t - \mu) = \mu
$$
Isso mostra que, conforme o horizonte da previs√£o se aproxima do infinito, a previs√£o converge para a m√©dia do processo, $\mu$.

IV. Agora, analisamos a vari√¢ncia do erro de previs√£o:
$$
Var(Y_{t+s} - \hat{Y}_{t+s|t}) = \sigma^2 \sum_{j=0}^{s-1} \phi^{2j}
$$
V. Tomamos o limite quando $s$ tende a infinito:
$$
\lim_{s \to \infty} Var(Y_{t+s} - \hat{Y}_{t+s|t}) = \lim_{s \to \infty} \left[ \sigma^2 \sum_{j=0}^{s-1} \phi^{2j} \right]
$$
VI. Como $|\phi| < 1$, a soma √© uma s√©rie geom√©trica que converge para $\frac{1}{1 - \phi^2}$:
$$
\lim_{s \to \infty} Var(Y_{t+s} - \hat{Y}_{t+s|t}) = \sigma^2 \sum_{j=0}^{\infty} \phi^{2j} = \sigma^2 \frac{1}{1-\phi^2}
$$
VII. O resultado $\frac{\sigma^2}{1-\phi^2}$ √© a vari√¢ncia incondicional do processo AR(1).
Assim, demonstramos que a vari√¢ncia do erro de previs√£o converge para a vari√¢ncia incondicional do processo conforme o horizonte da previs√£o se aproxima do infinito.
$\blacksquare$

### Conclus√£o
Este cap√≠tulo demonstrou como a previs√£o de um processo AR(1) pode ser calculada utilizando o operador de retardo e simplificada para uma forma recursiva. A f√≥rmula de previs√£o Wiener-Kolmogorov nos fornece uma base te√≥rica para previs√µes √≥timas, enquanto a representa√ß√£o do operador de retardo permite uma deriva√ß√£o pr√°tica de f√≥rmulas de previs√£o. A rela√ß√£o recursiva √© particularmente √∫til para calcular previs√µes de m√∫ltiplos passos, onde a previs√£o converge gradualmente para a m√©dia do processo √† medida que o horizonte da previs√£o aumenta. A capacidade de decompor o processo em termos de operadores de retardo √© uma ferramenta essencial na an√°lise de s√©ries temporais, facilitando a previs√£o e a compreens√£o do comportamento dos processos temporais. Al√©m disso, derivamos a express√£o da vari√¢ncia do erro de previs√£o e demonstramos que a previs√£o converge para a m√©dia do processo e a vari√¢ncia do erro de previs√£o para a vari√¢ncia incondicional do processo conforme o horizonte da previs√£o aumenta.
### Refer√™ncias
[^1]: Express√£o [4.1.1], p√°g 73
[^2]: Express√£o [4.1.2], p√°g 73
[^3]: Express√£o [4.1.9], p√°g 74
[^4]: Express√£o [4.2.17], p√°g 80
[^5]: Express√£o [4.2.16], p√°g 80
[^6]: Express√£o [4.2.18], p√°g 80
[^7]: Express√£o [4.2.19], p√°g 80
<!-- END -->
