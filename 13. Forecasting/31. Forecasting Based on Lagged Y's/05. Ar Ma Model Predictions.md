## A Construção de Erros e a Expressão de Previsões em Modelos AR e MA

### Introdução
Em continuidade à exploração da modelagem de séries temporais, este capítulo aprofunda a discussão sobre como os **erros** são construídos a partir dos dados observados e como essa construção permite expressar as previsões em termos de valores passados da série temporal, particularmente em modelos **Autorregressivos (AR)** e de **Médias Móveis (MA)**. Conforme visto anteriormente, a representação de séries temporais utilizando modelos AR e MA envolve expressar a série como uma função linear de seus valores passados e/ou ruídos brancos, $\epsilon_t$. No entanto, em aplicações práticas, os ruídos brancos não são diretamente observáveis e precisam ser estimados a partir dos dados da série. O texto explora como operadores de defasagem e recursões permitem construir os ruídos (ou erros) e expressar as previsões dos modelos AR e MA em função de valores passados da série temporal.

### Construção de Erros a partir de Dados Observados
A construção de erros em modelos AR e MA envolve a manipulação das equações desses modelos para isolar o termo de erro, $\epsilon_t$, em função dos valores passados da série $Y_t$ e dos parâmetros do modelo. Esta abordagem permite expressar o termo de erro como uma função dos valores observados da série temporal e, assim, estimá-lo recursivamente a partir dos dados disponíveis. Para modelos **AR(p)**, expressos como $\phi(L)(Y_t - \mu) = \epsilon_t$, onde $\phi(L) = 1 - \phi_1L - \phi_2L^2 - \ldots - \phi_pL^p$, o termo de erro é dado por
$$ \epsilon_t = (Y_t - \mu) - \phi_1(Y_{t-1} - \mu) - \ldots - \phi_p(Y_{t-p} - \mu) $$
Esta equação expressa o erro $\epsilon_t$ como o resíduo da regressão de $Y_t$ sobre seus valores defasados e demonstra como este erro pode ser calculado utilizando os parâmetros do modelo e os valores observados de $Y$.

**Observação 1**: A construção do erro em um modelo AR(p) envolve a utilização dos parâmetros do modelo e valores passados da série. A precisão desta construção depende da estimativa precisa dos parâmetros.

> 💡 **Exemplo Numérico:** Considere um modelo AR(1) dado por $Y_t = 0.7Y_{t-1} + \epsilon_t$. O termo de erro é $\epsilon_t = Y_t - 0.7Y_{t-1}$. Se $Y_t=10$ e $Y_{t-1}=12$, então $\epsilon_t = 10 - 0.7*12 = 10 - 8.4 = 1.6$. Isso demonstra como o erro é construído utilizando os valores passados e o parâmetro do modelo.
>
> Vamos adicionar mais um exemplo com valores diferentes para ilustrar: Se $Y_t=15$ e $Y_{t-1}=10$, então $\epsilon_t = 15 - 0.7*10 = 15 - 7 = 8$. Isso mostra que o erro é sensível à mudança nos valores da série temporal.

Para modelos **MA(q)**, expressos como $Y_t - \mu = (1 + \theta_1L + \theta_2L^2 + \ldots + \theta_qL^q)\epsilon_t = \theta(L)\epsilon_t$, a obtenção dos ruídos brancos exige um procedimento recursivo devido à natureza invertida do modelo. Usando o operador de defasagem, podemos escrever:
$$ \epsilon_t = \frac{Y_t - \mu}{1 + \theta_1L + \theta_2L^2 + \ldots + \theta_qL^q} = \theta(L)^{-1}(Y_t-\mu) $$
e expressar $\epsilon_t$ como uma combinação linear dos valores passados de $Y_t$. A implementação prática requer a retro-substituição iterativa, que fornece uma forma recursiva de aproximar o valor do erro no tempo $t$, utilizando os valores defasados da série temporal e do próprio erro. Para um modelo MA(1) na forma invertível, o processo é dado por:
$$ \epsilon_t = (Y_t - \mu) - \theta\epsilon_{t-1} $$
Onde o valor atual de $\epsilon_t$ é função do valor atual de $Y_t$, da média $\mu$ e do valor defasado de $\epsilon$ multiplicado pelo parâmetro $\theta$.

**Lema 1:** A condição de invertibilidade para um modelo MA(q) é essencial para expressar o ruído branco $\epsilon_t$ em função dos valores passados da série $Y_t$, permitindo o uso da retro-substituição iterativa.
*Proof:*
I. Um modelo MA(q) é definido como $Y_t - \mu = (1 + \theta_1 L + \ldots + \theta_q L^q)\epsilon_t$.
II. Para expressar $\epsilon_t$ em função dos valores de $Y_t$, precisamos obter o inverso do operador de médias móveis: $\epsilon_t = \frac{1}{1 + \theta_1 L + \ldots + \theta_q L^q} (Y_t - \mu) = \theta(L)^{-1}(Y_t-\mu)$.
III. A condição de invertibilidade garante que o operador $\theta(L)^{-1}$ possa ser expresso como uma série de potências em $L$ que converge, o que é essencial para a implementação da retro-substituição iterativa e para expressar o termo de erro em função dos valores passados da série. ■

> 💡 **Exemplo Numérico:** Considere um modelo MA(1) dado por $Y_t = \epsilon_t + 0.5\epsilon_{t-1}$. Para obter os valores de $\epsilon_t$, reescrevemos a equação como $\epsilon_t = Y_t - 0.5\epsilon_{t-1}$. Assumindo que $\epsilon_0=0$ e com observações $Y_1=12, Y_2 = 11.5, ...$ temos $\epsilon_1 = Y_1 - 0.5 * 0 = 12$, $\epsilon_2 = Y_2 - 0.5 * \epsilon_1 = 11.5 - 0.5 * 12 = 5.5$ e assim por diante.
>
> Vamos adicionar mais algumas iterações e valores para a série para entender melhor a retro-substituição: Seja $Y_3=10$, então $\epsilon_3 = Y_3 - 0.5\epsilon_2 = 10 - 0.5*5.5 = 7.25$. E, se $Y_4=13$ e $Y_5=14$, então $\epsilon_4 = Y_4 - 0.5\epsilon_3 = 13 - 0.5 * 7.25 = 9.375$ e $\epsilon_5 = Y_5 - 0.5\epsilon_4 = 14 - 0.5*9.375 = 9.3125$. O processo recursivo mostra como os erros vão sendo atualizados a cada passo.

Para modelos **ARMA(p,q)**, a construção dos erros combina as abordagens dos modelos AR(p) e MA(q). O modelo ARMA é definido por $\phi(L)(Y_t - \mu) = \theta(L)\epsilon_t$, que pode ser reescrita para expressar o ruído branco como
$$\epsilon_t = \frac{\phi(L)}{\theta(L)}(Y_t - \mu)$$
Para calcular os valores de $\epsilon_t$, também é preciso um procedimento iterativo, usando as observações da série e o ruído estimado no período anterior, resultando em
$$\hat{\epsilon}_t = (Y_t - \mu) - \phi_1(Y_{t-1} - \mu) - \ldots - \phi_p(Y_{t-p} - \mu) - \theta_1\hat{\epsilon}_{t-1} - \ldots - \theta_q\hat{\epsilon}_{t-q}$$

**Lema 1.1**: A retro-substituição iterativa, quando aplicada a um modelo ARMA(p, q) causal e invertível, permite aproximar os ruídos brancos subjacentes à série temporal, por meio de um processo recursivo que utiliza os dados observados e as estimativas anteriores dos ruídos.
*Proof:*
I. Em modelos ARMA(p, q) causais e invertíveis, a série $Y_t$ pode ser expressa tanto em função de ruídos brancos (MA(∞)) como também os ruídos brancos podem ser expressos em função dos valores passados de $Y_t$ (AR(∞)).
II. A retro-substituição iterativa aproxima o processo de inversão do operador de médias móveis e, assim, obtém uma estimativa do ruído branco em função dos valores passados da série.
III. Para um modelo causal e invertível, a série de potências do inverso do operador converge, garantindo que o erro de aproximação diminua à medida que mais iterações são realizadas. ■

> 💡 **Exemplo Numérico:** Considere um modelo ARMA(1,1) dado por $Y_t = 0.8Y_{t-1} + \epsilon_t + 0.5\epsilon_{t-1}$. A equação para o cálculo dos ruídos é dada por $\epsilon_t = Y_t - 0.8Y_{t-1} - 0.5\epsilon_{t-1}$. Assumindo que $\epsilon_0 = 0$, podemos calcular os ruídos recursivamente, com as observações $Y_1 = 10, Y_2 = 12, ...$, $\epsilon_1 = 10 - 0.8*0 - 0.5*0 = 10$, $\epsilon_2 = 12 - 0.8 * 10 - 0.5 * 10 = 12 - 8 - 5 = -1$, e assim por diante. Este processo mostra como os ruídos podem ser obtidos usando tanto os valores observados de Y como as estimativas anteriores dos ruídos.
>
> Vamos adicionar mais algumas iterações e valores para ilustrar: Se $Y_3 = 11$, então $\epsilon_3 = 11 - 0.8 * 12 - 0.5 * (-1) = 11 - 9.6 + 0.5 = 1.9$. E, se $Y_4 = 13$ e $Y_5 = 15$, então $\epsilon_4 = 13 - 0.8 * 11 - 0.5 * 1.9 = 13 - 8.8 - 0.95 = 3.25$ e $\epsilon_5 = 15 - 0.8 * 13 - 0.5 * 3.25 = 15 - 10.4 - 1.625 = 2.975$. É crucial entender como o erro depende dos erros anteriores e dos valores passados da série.

**Proposição 1.2:**  A inicialização do processo iterativo de retro-substituição para modelos MA e ARMA com valores zero para os ruídos iniciais ($\epsilon_0 = 0$ e possivelmente $\epsilon_{-1}=\epsilon_{-2}=\ldots=0$) é uma prática comum, mas outras inicializações podem ser consideradas dependendo do contexto. A escolha da inicialização afeta as estimativas dos ruídos para os primeiros períodos, mas seu efeito tende a diminuir à medida que a série temporal progride.
*Proof:*
I. A retro-substituição iterativa, por sua natureza recursiva, requer a definição de valores iniciais para os ruídos.
II. A inicialização com valores zero é uma escolha simples que geralmente funciona bem em muitas aplicações, pois com o aumento da quantidade de dados, o efeito da inicialização se torna cada vez menor.
III. Inicializações alternativas podem envolver o uso de médias amostrais ou valores estimados por outros métodos, dependendo do conhecimento prévio sobre a série temporal e dos objetivos da modelagem.
IV. O impacto da inicialização sobre as estimativas dos ruídos é maior nos primeiros períodos da série, enquanto que, com o aumento do número de iterações, o processo converge para valores estáveis, independentemente da escolha da inicialização, quando o modelo é causal e invertível. ■

### Expressão de Previsões em Termos de Valores Passados
Uma vez que os erros são construídos usando os dados observados e os parâmetros dos modelos, é possível expressar as previsões em função dos valores passados da série temporal, $Y_t$, utilizando operadores de defasagem e recursões. Para um modelo AR(p), a previsão para um passo à frente, $\hat{Y}_{t+1}$, pode ser expressa como:
$$ \hat{Y}_{t+1} = \mu + \phi_1(Y_t - \mu) + \ldots + \phi_p(Y_{t-p+1} - \mu) $$
Este resultado expressa a previsão como uma combinação linear dos valores passados da série temporal e da média do processo.

> 💡 **Exemplo Numérico:** Usando o modelo AR(1) com $\mu = 0$ e $\phi_1 = 0.7$ como antes, a previsão um passo à frente é $\hat{Y}_{t+1} = 0.7Y_t$. Se $Y_t = 15$, então a previsão para $Y_{t+1}$ é $\hat{Y}_{t+1} = 0.7*15 = 10.5$. Isso mostra como a previsão utiliza o valor atual da série. Vamos agora considerar o caso com $\mu=2$. Se $Y_t=10$ então a previsão é dada por $\hat{Y}_{t+1} = 2 + 0.7*(10-2) = 2+5.6=7.6$.

Para modelos MA(q), a previsão pode ser escrita como
$$\hat{Y}_{t+1} = \mu + \theta_1\hat{\epsilon}_t + \theta_2\hat{\epsilon}_{t-1} + \ldots + \theta_q\hat{\epsilon}_{t-q+1}$$
onde $\hat{\epsilon}$ representa os ruídos estimados pelo processo de retro-substituição iterativa. Substituindo recursivamente os valores de $\hat{\epsilon}$, a previsão de $Y_{t+1}$ pode ser expressa, por aproximação, como uma função linear dos valores passados da série e dos parâmetros do modelo.

> 💡 **Exemplo Numérico:** Usando o modelo MA(1) com $\mu=0$ e $\theta=0.5$, a previsão um passo à frente é $\hat{Y}_{t+1} = 0.5\hat{\epsilon}_t$. Se o último erro estimado foi $\hat{\epsilon}_t = 5.5$, como visto no exemplo numérico anterior, então a previsão para $Y_{t+1}$ é $\hat{Y}_{t+1} = 0.5 * 5.5 = 2.75$. Isso demonstra como a previsão é baseada nas estimativas de erros.
>
> Se $\mu = 2$ e $\hat{\epsilon}_t = 5.5$ então $\hat{Y}_{t+1} = 2 + 0.5 * 5.5 = 4.75$.

**Teorema 2:** As previsões de um modelo ARMA(p, q) podem ser expressas como uma função dos valores passados da série temporal e de um resíduo estimado recursivamente, utilizando a retro-substituição iterativa.

*Proof:*
I. A equação do modelo ARMA(p, q) é $\phi(L)(Y_t - \mu) = \theta(L)\epsilon_t$.
II. Para um passo à frente, podemos expressar $Y_{t+1}$ como $Y_{t+1} = \mu + \sum_{i=1}^p \phi_i (Y_{t+1-i} - \mu) + \sum_{j=1}^q \theta_j\epsilon_{t+1-j}$.
III. Substituindo as estimativas dos ruídos brancos obtidas pela retro-substituição iterativa em lugar dos $\epsilon_{t+1-j}$, podemos expressar a previsão de um passo à frente como uma combinação linear dos valores passados da série e de ruídos estimados, que também são obtidos a partir dos valores passados da série.
IV.  As estimativas dos ruídos brancos são dadas por $\hat{\epsilon}_t = (Y_t - \mu) - \sum_{i=1}^p \phi_i(Y_{t-i} - \mu) - \sum_{j=1}^q \theta_j\hat{\epsilon}_{t-j}$, onde as iterações são iniciadas com uma estimativa de $\hat{\epsilon}_0$ que geralmente é 0.
V. Portanto, a previsão de um modelo ARMA pode ser escrita em termos dos valores passados da série temporal e um erro estimado recursivamente através da retro-substituição. ■

> 💡 **Exemplo Numérico:** Considere o modelo ARMA(1,1) dado por $Y_t = 0.7Y_{t-1} + \epsilon_t + 0.4\epsilon_{t-1}$. A previsão de um passo à frente é dada por $\hat{Y}_{t+1} = 0.7Y_t + \hat{\epsilon}_{t+1} + 0.4\hat{\epsilon}_t$, e como não conhecemos $\epsilon_{t+1}$, a previsão se torna $\hat{Y}_{t+1} = 0.7Y_t + 0.4\hat{\epsilon}_t$. Assumindo que calculamos $\hat{\epsilon}_t$ utilizando a retro-substituição iterativa, como ilustrado no exemplo anterior, a previsão pode ser expressa em função dos valores de $Y_t$, $Y_{t-1}$, etc. e da sequência de ruídos brancos estimados.
>
> Usando os exemplos numéricos anteriores, se $Y_t=15$ e $\hat{\epsilon}_t=2.975$, então a previsão para um passo à frente é $\hat{Y}_{t+1} = 0.7 * 15 + 0.4 * 2.975 = 10.5 + 1.19 = 11.69$. Vamos adicionar um caso com $\mu = 2$. Então a previsão fica $\hat{Y}_{t+1} = 2 + 0.7 * (15-2) + 0.4 * 2.975 = 2 + 9.1 + 1.19 = 12.29$. Isto mostra como os parâmetros, valores passados e ruídos estimados influenciam a previsão.

**Teorema 2.1:** A previsão de *h* passos à frente em um modelo ARMA(p, q) pode ser obtida recursivamente, utilizando as previsões dos valores da série e dos ruídos, com a previsão do ruído sendo igual a zero para horizontes de previsão maiores que *q*.
*Proof:*
I. A previsão de um passo à frente é dada por $\hat{Y}_{t+1} = \mu + \sum_{i=1}^p \phi_i (Y_{t+1-i} - \mu) + \sum_{j=1}^q \theta_j\hat{\epsilon}_{t+1-j}$.
II. Para prever *h* passos à frente, substituímos os valores observados $Y_{t+1-i}$ que não são conhecidos pelas suas previsões. Assim, obtemos $\hat{Y}_{t+h|t} = \mu + \sum_{i=1}^p \phi_i (\hat{Y}_{t+h-i|t} - \mu) + \sum_{j=1}^q \theta_j\hat{\epsilon}_{t+h-j|t}$, onde $\hat{Y}_{t+h-i|t}$ é a previsão de $Y_{t+h-i}$ dado as informações até o tempo *t*, e $\hat{\epsilon}_{t+h-j|t}$ é a previsão do ruído $\epsilon_{t+h-j}$.
III. Para horizontes de previsão *h* > *q*, a previsão do ruído é zero, uma vez que o modelo não considera nenhum novo componente de ruído além do horizonte *q*. Desta forma, para *h* > *q*, $\hat{\epsilon}_{t+h-j|t} = 0$.
IV. Portanto, a previsão de *h* passos à frente pode ser obtida recursivamente utilizando os resultados das previsões anteriores e o fato de que as previsões dos ruídos tendem a zero para horizontes de previsão maiores que a ordem *q* do modelo. ■

> 💡 **Exemplo Numérico:**  Considerando o modelo ARMA(1,1) anterior, se quisermos prever dois passos à frente $(h=2)$, teremos que usar a previsão de um passo à frente: $\hat{Y}_{t+2|t} = 0.7\hat{Y}_{t+1|t} + 0.4\hat{\epsilon}_{t+1|t}$. Como a previsão do ruído para $h>q$ é zero, $\hat{\epsilon}_{t+1|t} = 0$, então $\hat{Y}_{t+2|t} = 0.7\hat{Y}_{t+1|t}$. Se $\hat{Y}_{t+1|t} = 11.69$ então $\hat{Y}_{t+2|t} = 0.7 * 11.69 = 8.183$. Se usarmos o modelo com $\mu=2$, então $\hat{Y}_{t+2|t} = 2 + 0.7 * (\hat{Y}_{t+1|t} - 2) = 2 + 0.7*(12.29-2) = 2+7.203=9.203$. Isso ilustra como as previsões de longo prazo são obtidas recursivamente.

### Conclusão
Este capítulo explorou a importância da construção de erros a partir dos dados observados em modelos AR e MA, mostrando como operadores de defasagem e recursões permitem expressar as previsões em termos de valores passados da série temporal. A retro-substituição iterativa oferece uma ferramenta essencial para extrair ruídos brancos em modelos MA e ARMA, tornando possível expressar as previsões de forma recursiva e utilizando apenas os dados observados. A capacidade de expressar as previsões como funções dos valores passados torna os modelos AR, MA e ARMA ferramentas úteis para a análise e previsão de séries temporais em diversas áreas, como economia, finanças, engenharia, entre outras. A modelagem de séries temporais usando modelos AR e MA é uma poderosa ferramenta para previsão, e este capítulo explorou alguns dos mecanismos essenciais para realizar tais previsões.

### Referências
[^1]: [4.2. Forecasts Based on an Infinite Number of Observations, páginas 77-79]
[^2]: [4.3. Forecasts Based on a Finite Number of Observations, página 85]
[^3]: [4.5. Updating a Linear Projection, página 93]
<!-- END -->
