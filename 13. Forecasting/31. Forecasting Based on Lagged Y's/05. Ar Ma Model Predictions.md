## A Constru√ß√£o de Erros e a Express√£o de Previs√µes em Modelos AR e MA

### Introdu√ß√£o
Em continuidade √† explora√ß√£o da modelagem de s√©ries temporais, este cap√≠tulo aprofunda a discuss√£o sobre como os **erros** s√£o constru√≠dos a partir dos dados observados e como essa constru√ß√£o permite expressar as previs√µes em termos de valores passados da s√©rie temporal, particularmente em modelos **Autorregressivos (AR)** e de **M√©dias M√≥veis (MA)**. Conforme visto anteriormente, a representa√ß√£o de s√©ries temporais utilizando modelos AR e MA envolve expressar a s√©rie como uma fun√ß√£o linear de seus valores passados e/ou ru√≠dos brancos, $\epsilon_t$. No entanto, em aplica√ß√µes pr√°ticas, os ru√≠dos brancos n√£o s√£o diretamente observ√°veis e precisam ser estimados a partir dos dados da s√©rie. O texto explora como operadores de defasagem e recurs√µes permitem construir os ru√≠dos (ou erros) e expressar as previs√µes dos modelos AR e MA em fun√ß√£o de valores passados da s√©rie temporal.

### Constru√ß√£o de Erros a partir de Dados Observados
A constru√ß√£o de erros em modelos AR e MA envolve a manipula√ß√£o das equa√ß√µes desses modelos para isolar o termo de erro, $\epsilon_t$, em fun√ß√£o dos valores passados da s√©rie $Y_t$ e dos par√¢metros do modelo. Esta abordagem permite expressar o termo de erro como uma fun√ß√£o dos valores observados da s√©rie temporal e, assim, estim√°-lo recursivamente a partir dos dados dispon√≠veis. Para modelos **AR(p)**, expressos como $\phi(L)(Y_t - \mu) = \epsilon_t$, onde $\phi(L) = 1 - \phi_1L - \phi_2L^2 - \ldots - \phi_pL^p$, o termo de erro √© dado por
$$ \epsilon_t = (Y_t - \mu) - \phi_1(Y_{t-1} - \mu) - \ldots - \phi_p(Y_{t-p} - \mu) $$
Esta equa√ß√£o expressa o erro $\epsilon_t$ como o res√≠duo da regress√£o de $Y_t$ sobre seus valores defasados e demonstra como este erro pode ser calculado utilizando os par√¢metros do modelo e os valores observados de $Y$.

**Observa√ß√£o 1**: A constru√ß√£o do erro em um modelo AR(p) envolve a utiliza√ß√£o dos par√¢metros do modelo e valores passados da s√©rie. A precis√£o desta constru√ß√£o depende da estimativa precisa dos par√¢metros.

> üí° **Exemplo Num√©rico:** Considere um modelo AR(1) dado por $Y_t = 0.7Y_{t-1} + \epsilon_t$. O termo de erro √© $\epsilon_t = Y_t - 0.7Y_{t-1}$. Se $Y_t=10$ e $Y_{t-1}=12$, ent√£o $\epsilon_t = 10 - 0.7*12 = 10 - 8.4 = 1.6$. Isso demonstra como o erro √© constru√≠do utilizando os valores passados e o par√¢metro do modelo.
>
> Vamos adicionar mais um exemplo com valores diferentes para ilustrar: Se $Y_t=15$ e $Y_{t-1}=10$, ent√£o $\epsilon_t = 15 - 0.7*10 = 15 - 7 = 8$. Isso mostra que o erro √© sens√≠vel √† mudan√ßa nos valores da s√©rie temporal.

Para modelos **MA(q)**, expressos como $Y_t - \mu = (1 + \theta_1L + \theta_2L^2 + \ldots + \theta_qL^q)\epsilon_t = \theta(L)\epsilon_t$, a obten√ß√£o dos ru√≠dos brancos exige um procedimento recursivo devido √† natureza invertida do modelo. Usando o operador de defasagem, podemos escrever:
$$ \epsilon_t = \frac{Y_t - \mu}{1 + \theta_1L + \theta_2L^2 + \ldots + \theta_qL^q} = \theta(L)^{-1}(Y_t-\mu) $$
e expressar $\epsilon_t$ como uma combina√ß√£o linear dos valores passados de $Y_t$. A implementa√ß√£o pr√°tica requer a retro-substitui√ß√£o iterativa, que fornece uma forma recursiva de aproximar o valor do erro no tempo $t$, utilizando os valores defasados da s√©rie temporal e do pr√≥prio erro. Para um modelo MA(1) na forma invert√≠vel, o processo √© dado por:
$$ \epsilon_t = (Y_t - \mu) - \theta\epsilon_{t-1} $$
Onde o valor atual de $\epsilon_t$ √© fun√ß√£o do valor atual de $Y_t$, da m√©dia $\mu$ e do valor defasado de $\epsilon$ multiplicado pelo par√¢metro $\theta$.

**Lema 1:** A condi√ß√£o de invertibilidade para um modelo MA(q) √© essencial para expressar o ru√≠do branco $\epsilon_t$ em fun√ß√£o dos valores passados da s√©rie $Y_t$, permitindo o uso da retro-substitui√ß√£o iterativa.
*Proof:*
I. Um modelo MA(q) √© definido como $Y_t - \mu = (1 + \theta_1 L + \ldots + \theta_q L^q)\epsilon_t$.
II. Para expressar $\epsilon_t$ em fun√ß√£o dos valores de $Y_t$, precisamos obter o inverso do operador de m√©dias m√≥veis: $\epsilon_t = \frac{1}{1 + \theta_1 L + \ldots + \theta_q L^q} (Y_t - \mu) = \theta(L)^{-1}(Y_t-\mu)$.
III. A condi√ß√£o de invertibilidade garante que o operador $\theta(L)^{-1}$ possa ser expresso como uma s√©rie de pot√™ncias em $L$ que converge, o que √© essencial para a implementa√ß√£o da retro-substitui√ß√£o iterativa e para expressar o termo de erro em fun√ß√£o dos valores passados da s√©rie. ‚ñ†

> üí° **Exemplo Num√©rico:** Considere um modelo MA(1) dado por $Y_t = \epsilon_t + 0.5\epsilon_{t-1}$. Para obter os valores de $\epsilon_t$, reescrevemos a equa√ß√£o como $\epsilon_t = Y_t - 0.5\epsilon_{t-1}$. Assumindo que $\epsilon_0=0$ e com observa√ß√µes $Y_1=12, Y_2 = 11.5, ...$ temos $\epsilon_1 = Y_1 - 0.5 * 0 = 12$, $\epsilon_2 = Y_2 - 0.5 * \epsilon_1 = 11.5 - 0.5 * 12 = 5.5$ e assim por diante.
>
> Vamos adicionar mais algumas itera√ß√µes e valores para a s√©rie para entender melhor a retro-substitui√ß√£o: Seja $Y_3=10$, ent√£o $\epsilon_3 = Y_3 - 0.5\epsilon_2 = 10 - 0.5*5.5 = 7.25$. E, se $Y_4=13$ e $Y_5=14$, ent√£o $\epsilon_4 = Y_4 - 0.5\epsilon_3 = 13 - 0.5 * 7.25 = 9.375$ e $\epsilon_5 = Y_5 - 0.5\epsilon_4 = 14 - 0.5*9.375 = 9.3125$. O processo recursivo mostra como os erros v√£o sendo atualizados a cada passo.

Para modelos **ARMA(p,q)**, a constru√ß√£o dos erros combina as abordagens dos modelos AR(p) e MA(q). O modelo ARMA √© definido por $\phi(L)(Y_t - \mu) = \theta(L)\epsilon_t$, que pode ser reescrita para expressar o ru√≠do branco como
$$\epsilon_t = \frac{\phi(L)}{\theta(L)}(Y_t - \mu)$$
Para calcular os valores de $\epsilon_t$, tamb√©m √© preciso um procedimento iterativo, usando as observa√ß√µes da s√©rie e o ru√≠do estimado no per√≠odo anterior, resultando em
$$\hat{\epsilon}_t = (Y_t - \mu) - \phi_1(Y_{t-1} - \mu) - \ldots - \phi_p(Y_{t-p} - \mu) - \theta_1\hat{\epsilon}_{t-1} - \ldots - \theta_q\hat{\epsilon}_{t-q}$$

**Lema 1.1**: A retro-substitui√ß√£o iterativa, quando aplicada a um modelo ARMA(p, q) causal e invert√≠vel, permite aproximar os ru√≠dos brancos subjacentes √† s√©rie temporal, por meio de um processo recursivo que utiliza os dados observados e as estimativas anteriores dos ru√≠dos.
*Proof:*
I. Em modelos ARMA(p, q) causais e invert√≠veis, a s√©rie $Y_t$ pode ser expressa tanto em fun√ß√£o de ru√≠dos brancos (MA(‚àû)) como tamb√©m os ru√≠dos brancos podem ser expressos em fun√ß√£o dos valores passados de $Y_t$ (AR(‚àû)).
II. A retro-substitui√ß√£o iterativa aproxima o processo de invers√£o do operador de m√©dias m√≥veis e, assim, obt√©m uma estimativa do ru√≠do branco em fun√ß√£o dos valores passados da s√©rie.
III. Para um modelo causal e invert√≠vel, a s√©rie de pot√™ncias do inverso do operador converge, garantindo que o erro de aproxima√ß√£o diminua √† medida que mais itera√ß√µes s√£o realizadas. ‚ñ†

> üí° **Exemplo Num√©rico:** Considere um modelo ARMA(1,1) dado por $Y_t = 0.8Y_{t-1} + \epsilon_t + 0.5\epsilon_{t-1}$. A equa√ß√£o para o c√°lculo dos ru√≠dos √© dada por $\epsilon_t = Y_t - 0.8Y_{t-1} - 0.5\epsilon_{t-1}$. Assumindo que $\epsilon_0 = 0$, podemos calcular os ru√≠dos recursivamente, com as observa√ß√µes $Y_1 = 10, Y_2 = 12, ...$, $\epsilon_1 = 10 - 0.8*0 - 0.5*0 = 10$, $\epsilon_2 = 12 - 0.8 * 10 - 0.5 * 10 = 12 - 8 - 5 = -1$, e assim por diante. Este processo mostra como os ru√≠dos podem ser obtidos usando tanto os valores observados de Y como as estimativas anteriores dos ru√≠dos.
>
> Vamos adicionar mais algumas itera√ß√µes e valores para ilustrar: Se $Y_3 = 11$, ent√£o $\epsilon_3 = 11 - 0.8 * 12 - 0.5 * (-1) = 11 - 9.6 + 0.5 = 1.9$. E, se $Y_4 = 13$ e $Y_5 = 15$, ent√£o $\epsilon_4 = 13 - 0.8 * 11 - 0.5 * 1.9 = 13 - 8.8 - 0.95 = 3.25$ e $\epsilon_5 = 15 - 0.8 * 13 - 0.5 * 3.25 = 15 - 10.4 - 1.625 = 2.975$. √â crucial entender como o erro depende dos erros anteriores e dos valores passados da s√©rie.

**Proposi√ß√£o 1.2:**  A inicializa√ß√£o do processo iterativo de retro-substitui√ß√£o para modelos MA e ARMA com valores zero para os ru√≠dos iniciais ($\epsilon_0 = 0$ e possivelmente $\epsilon_{-1}=\epsilon_{-2}=\ldots=0$) √© uma pr√°tica comum, mas outras inicializa√ß√µes podem ser consideradas dependendo do contexto. A escolha da inicializa√ß√£o afeta as estimativas dos ru√≠dos para os primeiros per√≠odos, mas seu efeito tende a diminuir √† medida que a s√©rie temporal progride.
*Proof:*
I. A retro-substitui√ß√£o iterativa, por sua natureza recursiva, requer a defini√ß√£o de valores iniciais para os ru√≠dos.
II. A inicializa√ß√£o com valores zero √© uma escolha simples que geralmente funciona bem em muitas aplica√ß√µes, pois com o aumento da quantidade de dados, o efeito da inicializa√ß√£o se torna cada vez menor.
III. Inicializa√ß√µes alternativas podem envolver o uso de m√©dias amostrais ou valores estimados por outros m√©todos, dependendo do conhecimento pr√©vio sobre a s√©rie temporal e dos objetivos da modelagem.
IV. O impacto da inicializa√ß√£o sobre as estimativas dos ru√≠dos √© maior nos primeiros per√≠odos da s√©rie, enquanto que, com o aumento do n√∫mero de itera√ß√µes, o processo converge para valores est√°veis, independentemente da escolha da inicializa√ß√£o, quando o modelo √© causal e invert√≠vel. ‚ñ†

### Express√£o de Previs√µes em Termos de Valores Passados
Uma vez que os erros s√£o constru√≠dos usando os dados observados e os par√¢metros dos modelos, √© poss√≠vel expressar as previs√µes em fun√ß√£o dos valores passados da s√©rie temporal, $Y_t$, utilizando operadores de defasagem e recurs√µes. Para um modelo AR(p), a previs√£o para um passo √† frente, $\hat{Y}_{t+1}$, pode ser expressa como:
$$ \hat{Y}_{t+1} = \mu + \phi_1(Y_t - \mu) + \ldots + \phi_p(Y_{t-p+1} - \mu) $$
Este resultado expressa a previs√£o como uma combina√ß√£o linear dos valores passados da s√©rie temporal e da m√©dia do processo.

> üí° **Exemplo Num√©rico:** Usando o modelo AR(1) com $\mu = 0$ e $\phi_1 = 0.7$ como antes, a previs√£o um passo √† frente √© $\hat{Y}_{t+1} = 0.7Y_t$. Se $Y_t = 15$, ent√£o a previs√£o para $Y_{t+1}$ √© $\hat{Y}_{t+1} = 0.7*15 = 10.5$. Isso mostra como a previs√£o utiliza o valor atual da s√©rie. Vamos agora considerar o caso com $\mu=2$. Se $Y_t=10$ ent√£o a previs√£o √© dada por $\hat{Y}_{t+1} = 2 + 0.7*(10-2) = 2+5.6=7.6$.

Para modelos MA(q), a previs√£o pode ser escrita como
$$\hat{Y}_{t+1} = \mu + \theta_1\hat{\epsilon}_t + \theta_2\hat{\epsilon}_{t-1} + \ldots + \theta_q\hat{\epsilon}_{t-q+1}$$
onde $\hat{\epsilon}$ representa os ru√≠dos estimados pelo processo de retro-substitui√ß√£o iterativa. Substituindo recursivamente os valores de $\hat{\epsilon}$, a previs√£o de $Y_{t+1}$ pode ser expressa, por aproxima√ß√£o, como uma fun√ß√£o linear dos valores passados da s√©rie e dos par√¢metros do modelo.

> üí° **Exemplo Num√©rico:** Usando o modelo MA(1) com $\mu=0$ e $\theta=0.5$, a previs√£o um passo √† frente √© $\hat{Y}_{t+1} = 0.5\hat{\epsilon}_t$. Se o √∫ltimo erro estimado foi $\hat{\epsilon}_t = 5.5$, como visto no exemplo num√©rico anterior, ent√£o a previs√£o para $Y_{t+1}$ √© $\hat{Y}_{t+1} = 0.5 * 5.5 = 2.75$. Isso demonstra como a previs√£o √© baseada nas estimativas de erros.
>
> Se $\mu = 2$ e $\hat{\epsilon}_t = 5.5$ ent√£o $\hat{Y}_{t+1} = 2 + 0.5 * 5.5 = 4.75$.

**Teorema 2:** As previs√µes de um modelo ARMA(p, q) podem ser expressas como uma fun√ß√£o dos valores passados da s√©rie temporal e de um res√≠duo estimado recursivamente, utilizando a retro-substitui√ß√£o iterativa.

*Proof:*
I. A equa√ß√£o do modelo ARMA(p, q) √© $\phi(L)(Y_t - \mu) = \theta(L)\epsilon_t$.
II. Para um passo √† frente, podemos expressar $Y_{t+1}$ como $Y_{t+1} = \mu + \sum_{i=1}^p \phi_i (Y_{t+1-i} - \mu) + \sum_{j=1}^q \theta_j\epsilon_{t+1-j}$.
III. Substituindo as estimativas dos ru√≠dos brancos obtidas pela retro-substitui√ß√£o iterativa em lugar dos $\epsilon_{t+1-j}$, podemos expressar a previs√£o de um passo √† frente como uma combina√ß√£o linear dos valores passados da s√©rie e de ru√≠dos estimados, que tamb√©m s√£o obtidos a partir dos valores passados da s√©rie.
IV.  As estimativas dos ru√≠dos brancos s√£o dadas por $\hat{\epsilon}_t = (Y_t - \mu) - \sum_{i=1}^p \phi_i(Y_{t-i} - \mu) - \sum_{j=1}^q \theta_j\hat{\epsilon}_{t-j}$, onde as itera√ß√µes s√£o iniciadas com uma estimativa de $\hat{\epsilon}_0$ que geralmente √© 0.
V. Portanto, a previs√£o de um modelo ARMA pode ser escrita em termos dos valores passados da s√©rie temporal e um erro estimado recursivamente atrav√©s da retro-substitui√ß√£o. ‚ñ†

> üí° **Exemplo Num√©rico:** Considere o modelo ARMA(1,1) dado por $Y_t = 0.7Y_{t-1} + \epsilon_t + 0.4\epsilon_{t-1}$. A previs√£o de um passo √† frente √© dada por $\hat{Y}_{t+1} = 0.7Y_t + \hat{\epsilon}_{t+1} + 0.4\hat{\epsilon}_t$, e como n√£o conhecemos $\epsilon_{t+1}$, a previs√£o se torna $\hat{Y}_{t+1} = 0.7Y_t + 0.4\hat{\epsilon}_t$. Assumindo que calculamos $\hat{\epsilon}_t$ utilizando a retro-substitui√ß√£o iterativa, como ilustrado no exemplo anterior, a previs√£o pode ser expressa em fun√ß√£o dos valores de $Y_t$, $Y_{t-1}$, etc. e da sequ√™ncia de ru√≠dos brancos estimados.
>
> Usando os exemplos num√©ricos anteriores, se $Y_t=15$ e $\hat{\epsilon}_t=2.975$, ent√£o a previs√£o para um passo √† frente √© $\hat{Y}_{t+1} = 0.7 * 15 + 0.4 * 2.975 = 10.5 + 1.19 = 11.69$. Vamos adicionar um caso com $\mu = 2$. Ent√£o a previs√£o fica $\hat{Y}_{t+1} = 2 + 0.7 * (15-2) + 0.4 * 2.975 = 2 + 9.1 + 1.19 = 12.29$. Isto mostra como os par√¢metros, valores passados e ru√≠dos estimados influenciam a previs√£o.

**Teorema 2.1:** A previs√£o de *h* passos √† frente em um modelo ARMA(p, q) pode ser obtida recursivamente, utilizando as previs√µes dos valores da s√©rie e dos ru√≠dos, com a previs√£o do ru√≠do sendo igual a zero para horizontes de previs√£o maiores que *q*.
*Proof:*
I. A previs√£o de um passo √† frente √© dada por $\hat{Y}_{t+1} = \mu + \sum_{i=1}^p \phi_i (Y_{t+1-i} - \mu) + \sum_{j=1}^q \theta_j\hat{\epsilon}_{t+1-j}$.
II. Para prever *h* passos √† frente, substitu√≠mos os valores observados $Y_{t+1-i}$ que n√£o s√£o conhecidos pelas suas previs√µes. Assim, obtemos $\hat{Y}_{t+h|t} = \mu + \sum_{i=1}^p \phi_i (\hat{Y}_{t+h-i|t} - \mu) + \sum_{j=1}^q \theta_j\hat{\epsilon}_{t+h-j|t}$, onde $\hat{Y}_{t+h-i|t}$ √© a previs√£o de $Y_{t+h-i}$ dado as informa√ß√µes at√© o tempo *t*, e $\hat{\epsilon}_{t+h-j|t}$ √© a previs√£o do ru√≠do $\epsilon_{t+h-j}$.
III. Para horizontes de previs√£o *h* > *q*, a previs√£o do ru√≠do √© zero, uma vez que o modelo n√£o considera nenhum novo componente de ru√≠do al√©m do horizonte *q*. Desta forma, para *h* > *q*, $\hat{\epsilon}_{t+h-j|t} = 0$.
IV. Portanto, a previs√£o de *h* passos √† frente pode ser obtida recursivamente utilizando os resultados das previs√µes anteriores e o fato de que as previs√µes dos ru√≠dos tendem a zero para horizontes de previs√£o maiores que a ordem *q* do modelo. ‚ñ†

> üí° **Exemplo Num√©rico:**  Considerando o modelo ARMA(1,1) anterior, se quisermos prever dois passos √† frente $(h=2)$, teremos que usar a previs√£o de um passo √† frente: $\hat{Y}_{t+2|t} = 0.7\hat{Y}_{t+1|t} + 0.4\hat{\epsilon}_{t+1|t}$. Como a previs√£o do ru√≠do para $h>q$ √© zero, $\hat{\epsilon}_{t+1|t} = 0$, ent√£o $\hat{Y}_{t+2|t} = 0.7\hat{Y}_{t+1|t}$. Se $\hat{Y}_{t+1|t} = 11.69$ ent√£o $\hat{Y}_{t+2|t} = 0.7 * 11.69 = 8.183$. Se usarmos o modelo com $\mu=2$, ent√£o $\hat{Y}_{t+2|t} = 2 + 0.7 * (\hat{Y}_{t+1|t} - 2) = 2 + 0.7*(12.29-2) = 2+7.203=9.203$. Isso ilustra como as previs√µes de longo prazo s√£o obtidas recursivamente.

### Conclus√£o
Este cap√≠tulo explorou a import√¢ncia da constru√ß√£o de erros a partir dos dados observados em modelos AR e MA, mostrando como operadores de defasagem e recurs√µes permitem expressar as previs√µes em termos de valores passados da s√©rie temporal. A retro-substitui√ß√£o iterativa oferece uma ferramenta essencial para extrair ru√≠dos brancos em modelos MA e ARMA, tornando poss√≠vel expressar as previs√µes de forma recursiva e utilizando apenas os dados observados. A capacidade de expressar as previs√µes como fun√ß√µes dos valores passados torna os modelos AR, MA e ARMA ferramentas √∫teis para a an√°lise e previs√£o de s√©ries temporais em diversas √°reas, como economia, finan√ßas, engenharia, entre outras. A modelagem de s√©ries temporais usando modelos AR e MA √© uma poderosa ferramenta para previs√£o, e este cap√≠tulo explorou alguns dos mecanismos essenciais para realizar tais previs√µes.

### Refer√™ncias
[^1]: [4.2. Forecasts Based on an Infinite Number of Observations, p√°ginas 77-79]
[^2]: [4.3. Forecasts Based on a Finite Number of Observations, p√°gina 85]
[^3]: [4.5. Updating a Linear Projection, p√°gina 93]
<!-- END -->
