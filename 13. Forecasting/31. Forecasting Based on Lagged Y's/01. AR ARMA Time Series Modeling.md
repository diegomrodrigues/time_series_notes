## Previs√£o Baseada em Valores Defasados de Y: Representa√ß√µes AR e ARMA
### Introdu√ß√£o
Em continuidade √† discuss√£o sobre a previs√£o de s√©ries temporais, este cap√≠tulo foca em como modelar previs√µes usando valores passados da pr√≥pria s√©rie, ao inv√©s de assumir observa√ß√µes diretas sobre os ru√≠dos do processo [^1]. As representa√ß√µes **Autorregressivas (AR)** e **Autorregressivas de M√©dias M√≥veis (ARMA)** oferecem uma estrutura poderosa para expressar previs√µes como fun√ß√µes dos dados hist√≥ricos, facilitando a implementa√ß√£o de algoritmos computacionais eficientes. A abordagem anterior considerou que o termo de erro, $\epsilon_t$, era observado diretamente [^1]. No entanto, em situa√ß√µes pr√°ticas de previs√£o, usualmente dispomos de observa√ß√µes sobre valores defasados de Y, e n√£o de $\epsilon_t$ [^1]. Este cen√°rio motiva o desenvolvimento de modelos que expressam a previs√£o em fun√ß√£o dos pr√≥prios valores passados de Y, o que √© fundamental para a aplica√ß√£o em grande escala e para a an√°lise pr√°tica de s√©ries temporais.

### Conceitos Fundamentais
A modelagem com representa√ß√µes AR e ARMA permite construir previs√µes de forma recursiva, o que √© extremamente √∫til quando se lida com grandes volumes de dados e com a necessidade de c√°lculos r√°pidos [^1]. O texto introduz a representa√ß√£o **AR(‚àû)** para uma s√©rie temporal, expressa como $\eta(L)(Y_t - \mu) = \epsilon_t$ [^1], onde $\eta(L)$ √© um polin√¥mio em operadores de defasagem, $L$, com $\eta_0 = 1$ e $\sum_{j=0}^\infty |\eta_j| < \infty$. Essa representa√ß√£o pressup√µe que a s√©rie temporal pode ser expressa como uma fun√ß√£o linear de seus pr√≥prios valores passados mais um ru√≠do branco [^1]. Em seguida, o texto estabelece a conex√£o entre o polin√¥mio AR, $\eta(L)$, e o polin√¥mio de m√©dias m√≥veis, $\psi(L)$, por meio da rela√ß√£o $\eta(L) = [\psi(L)]^{-1}$ [^1].

**Lema 1** A condi√ß√£o $\sum_{j=0}^\infty |\eta_j| < \infty$ para o operador $\eta(L)$ garante a converg√™ncia da representa√ß√£o AR(‚àû).
*Proof:* Esta condi√ß√£o de converg√™ncia absoluta √© uma condi√ß√£o suficiente para garantir que a s√©rie infinita de coeficientes, quando aplicada aos valores defasados de $Y_t$, resulte em um valor finito e bem definido.

> üí° **Exemplo Num√©rico:** Considere um operador $\eta(L) = 1 + 0.5L + 0.25L^2 + 0.125L^3 + \ldots$. Aqui, $\eta_j = (0.5)^j$. A soma dos valores absolutos dos coeficientes √© $\sum_{j=0}^\infty |(0.5)^j| = \frac{1}{1-0.5} = 2 < \infty$. Isso satisfaz a condi√ß√£o de converg√™ncia, indicando que o modelo AR(‚àû) com esses coeficientes √© bem definido. Se tiv√©ssemos um operador onde a soma dos coeficientes fosse infinita, como $\eta(L) = 1 + L + L^2 + L^3 + \ldots$, a condi√ß√£o n√£o seria satisfeita.

Em particular, o texto foca no modelo **Autorregressivo (AR(p))** que √© descrito por $(1 - \phi_1 L - \phi_2 L^2 - \ldots - \phi_p L^p)(Y_t - \mu) = \epsilon_t$ [^1], ou, de forma mais compacta, $\phi(L)(Y_t - \mu) = \epsilon_t$ [^1]. Aqui, $\phi(L)$ representa o operador autorregressivo que satisfaz as condi√ß√µes de estacionariedade. Este modelo, por sua estrutura, √© mais adequado quando a s√©rie apresenta uma depend√™ncia forte com seus valores passados. Adicionalmente, o texto aborda o modelo **M√©dias M√≥veis (MA(q))**, que √© descrito como $Y_t - \mu = (1 + \theta_1 L + \theta_2 L^2 + \ldots + \theta_q L^q)\epsilon_t$ [^1], ou $Y_t - \mu = \theta(L)\epsilon_t$ [^1], em que o operador de m√©dias m√≥veis $\theta(L)$ e o ru√≠do branco $\epsilon_t$ representam uma combina√ß√£o linear de choques aleat√≥rios. O texto enfatiza a import√¢ncia da representa√ß√£o invert√≠vel para o modelo MA, que √© essencial para estabelecer a rela√ß√£o entre o modelo MA e sua representa√ß√£o AR equivalente [^1].

**Observa√ß√£o 1**: A condi√ß√£o de invertibilidade para o modelo MA(q) √© an√°loga √† condi√ß√£o de estacionaridade para o modelo AR(p). Ambas s√£o cruciais para garantir que os modelos sejam bem comportados e possam ser utilizados para previs√£o. Especificamente, para o MA(q), isso implica que as ra√≠zes do polin√¥mio $\theta(z) = 1 + \theta_1 z + \ldots + \theta_q z^q$ devem estar fora do c√≠rculo unit√°rio.

> üí° **Exemplo Num√©rico:** Considere um modelo MA(1) dado por $Y_t = 0.8\epsilon_{t-1} + \epsilon_t$. O polin√¥mio $\theta(z) = 1 + 0.8z$. A raiz deste polin√¥mio √© $z = -\frac{1}{0.8} = -1.25$. Como $|-1.25| > 1$, a condi√ß√£o de invertibilidade √© satisfeita. Se, por outro lado, tiv√©ssemos um modelo MA(1) com $\theta(z) = 1 + 1.5z$, a raiz seria $z = -\frac{1}{1.5} \approx -0.67$. Como $|-0.67| < 1$, este modelo MA(1) n√£o seria invert√≠vel.

A representa√ß√£o AR(‚àû), $\eta(L)(Y_t - \mu) = \epsilon_t$, √© utilizada para derivar a previs√£o √≥tima de $Y_{t+s}$ como fun√ß√£o de valores passados de Y. De acordo com a express√£o  $\hat{E}[Y_{t+s}|Y_t, Y_{t-1},\ldots] = \mu + [\frac{\psi(L)}{L^s}]_+\eta(L)(Y_t-\mu)$ [^1], o termo $[\frac{\psi(L)}{L^s}]_+$ √© um operador de aniquila√ß√£o, que elimina termos com expoentes negativos do operador de defasagem, $L$ [^1]. Assim, √© poss√≠vel obter um algoritmo recursivo para construir as previs√µes, usando os pr√≥prios valores passados de $Y$.

**Proposi√ß√£o 2**: A opera√ß√£o $[\frac{\psi(L)}{L^s}]_+$ corresponde √† parte causal do operador $\frac{\psi(L)}{L^s}$.
*Proof:* 
I. Seja $\psi(L) = \sum_{j=0}^\infty \psi_j L^j$ o operador de m√©dias m√≥veis.
II. O operador $\frac{\psi(L)}{L^s}$ pode ser escrito como $\frac{1}{L^s}\sum_{j=0}^\infty \psi_j L^j = \sum_{j=0}^\infty \psi_j L^{j-s}$.
III. Ao expandir a s√©rie, temos: $\frac{\psi(L)}{L^s} = \psi_0 L^{-s} + \psi_1 L^{1-s} + \ldots + \psi_{s-1} L^{-1} + \psi_s L^0 + \psi_{s+1} L^1 + \ldots$.
IV. A parte causal, $[\frac{\psi(L)}{L^s}]_+$, √© definida como a soma de todos os termos com pot√™ncias n√£o-negativas de $L$.
V. Portanto, $[\frac{\psi(L)}{L^s}]_+ = \sum_{j=s}^\infty \psi_j L^{j-s} = \psi_s L^0 + \psi_{s+1} L^1 + \psi_{s+2} L^2 + \ldots$ que corresponde √† parte causal do operador $\frac{\psi(L)}{L^s}$. ‚ñ†

> üí° **Exemplo Num√©rico:** Suponha que $\psi(L) = 1 + 0.5L + 0.2L^2$ e queremos calcular $[\frac{\psi(L)}{L^2}]_+$.
>  
>   $\frac{\psi(L)}{L^2} = \frac{1}{L^2} + \frac{0.5L}{L^2} + \frac{0.2L^2}{L^2} = L^{-2} + 0.5L^{-1} + 0.2$.
>   
>  Aplicando $[\cdot]_+$, removemos os termos com expoentes negativos:
>  
>  $[\frac{\psi(L)}{L^2}]_+ = 0.2$.
>  
>  Este exemplo ilustra como o operador de aniquila√ß√£o funciona, isolando a parte causal do operador.

**Teorema 3:** Dado um modelo AR(p) com operador $\phi(L)$ e um modelo MA(q) com operador $\theta(L)$,  a representa√ß√£o ARMA(p, q) combina ambas as estruturas, de forma que $\phi(L)(Y_t - \mu) = \theta(L)\epsilon_t$. Este modelo combina as caracter√≠sticas de modelos AR e MA, oferecendo maior flexibilidade na modelagem de s√©ries temporais.

> üí° **Exemplo Num√©rico:** Considere um modelo ARMA(1,1) dado por $(1 - 0.7L)(Y_t - 5) = (1 + 0.4L)\epsilon_t$. Aqui, $\phi(L) = 1 - 0.7L$ e $\theta(L) = 1 + 0.4L$, e $\mu = 5$. Expandindo a equa√ß√£o, temos:
>  
>  $Y_t - 5 - 0.7(Y_{t-1} - 5) = \epsilon_t + 0.4\epsilon_{t-1}$.
>  
>  Rearranjando, temos:
>  
>  $Y_t = 5 + 0.7Y_{t-1} - 0.7*5 + \epsilon_t + 0.4\epsilon_{t-1}$
>  
>  $Y_t = 1.5 + 0.7Y_{t-1} + \epsilon_t + 0.4\epsilon_{t-1}$.
>  
>  Este exemplo mostra como um modelo ARMA combina termos autorregressivos e de m√©dias m√≥veis para modelar a s√©rie temporal.

**Corol√°rio 3.1:** A representa√ß√£o ARMA(p, q) pode ser expressa como uma representa√ß√£o AR(‚àû) ou MA(‚àû), sob certas condi√ß√µes de estacionariedade e invertibilidade dos operadores $\phi(L)$ e $\theta(L)$.
*Proof:*
I. A representa√ß√£o ARMA(p,q) √© dada por $\phi(L)(Y_t - \mu) = \theta(L)\epsilon_t$.
II. Se $\phi(L)$ √© estacion√°rio, ent√£o $[\phi(L)]^{-1}$ existe e pode ser representado por uma s√©rie de pot√™ncias em $L$, ou seja, $\eta(L) = [\phi(L)]^{-1} = \sum_{j=0}^\infty \eta_j L^j$, com $\sum_{j=0}^\infty |\eta_j| < \infty$.
III.  Multiplicando ambos os lados por $[\phi(L)]^{-1}$, temos $(Y_t - \mu) = [\phi(L)]^{-1}\theta(L)\epsilon_t = \eta(L)\theta(L)\epsilon_t$. Definindo $\psi(L) = \eta(L)\theta(L)$, obtemos uma representa√ß√£o MA(‚àû), ou seja, $Y_t - \mu = \psi(L)\epsilon_t$.
IV. Analogamente, se $\theta(L)$ √© invert√≠vel, ent√£o $[\theta(L)]^{-1}$ existe e pode ser representado por uma s√©rie de pot√™ncias em $L$, ou seja, $\omega(L) = [\theta(L)]^{-1} = \sum_{j=0}^\infty \omega_j L^j$, com $\sum_{j=0}^\infty |\omega_j| < \infty$.
V.  Multiplicando ambos os lados de $\phi(L)(Y_t - \mu) = \theta(L)\epsilon_t$ por $[\theta(L)]^{-1}$, temos $[\theta(L)]^{-1}\phi(L)(Y_t - \mu) = \epsilon_t$. Definindo $\kappa(L) = [\theta(L)]^{-1}\phi(L)$, temos $\kappa(L)(Y_t - \mu) = \epsilon_t$, que √© uma representa√ß√£o AR(‚àû).
VI. Portanto, sob as condi√ß√µes de estacionariedade para $\phi(L)$ e invertibilidade para $\theta(L)$, a representa√ß√£o ARMA(p,q) pode ser expressa como uma representa√ß√£o AR(‚àû) ou MA(‚àû). ‚ñ†

> üí° **Exemplo Num√©rico:** Considere o modelo ARMA(1,1) do exemplo anterior: $(1 - 0.7L)(Y_t - 5) = (1 + 0.4L)\epsilon_t$. Para express√°-lo como um MA(‚àû), precisamos encontrar o inverso de $\phi(L) = 1 - 0.7L$. Sabemos que para $|0.7| < 1$, o inverso √© dado por:
>
>  $[\phi(L)]^{-1} = \frac{1}{1-0.7L} = 1 + 0.7L + (0.7L)^2 + (0.7L)^3 + \ldots = \sum_{j=0}^\infty (0.7)^jL^j$.
>
>  Substituindo na equa√ß√£o original:
>
> $Y_t - 5 = (1 + 0.7L + (0.7)^2L^2 + \ldots)(1 + 0.4L)\epsilon_t$.
>
>  Multiplicando os operadores, obtemos:
>
>  $Y_t - 5 = (1 + (0.7 + 0.4)L + (0.7*0.4 + 0.7^2)L^2 + \ldots) \epsilon_t$
>
>  $Y_t - 5 = (1 + 1.1L + 0.77L^2 + \ldots) \epsilon_t$.
>
>  Esta √© a representa√ß√£o MA(‚àû) do modelo ARMA(1,1). Similarmente, podemos tentar express√°-lo como um AR(‚àû) encontrando o inverso de $\theta(L)$, mas isso pode ser mais complexo. Este exemplo demonstra que um modelo ARMA pode ser expresso de forma equivalente como um modelo MA(‚àû).

### Conclus√£o
Este cap√≠tulo demonstra a import√¢ncia das representa√ß√µes AR e ARMA para a modelagem de s√©ries temporais, destacando como essas representa√ß√µes permitem expressar as previs√µes em fun√ß√£o dos dados passados [^1]. A capacidade de gerar previs√µes de forma recursiva, utilizando valores defasados da pr√≥pria s√©rie, torna esses modelos ferramentas poderosas para a an√°lise e previs√£o de s√©ries temporais em diversas aplica√ß√µes pr√°ticas [^1]. A discuss√£o sobre a representa√ß√£o AR(‚àû) e sua liga√ß√£o com os operadores de defasagem prepara o terreno para a an√°lise de modelos mais complexos, como os modelos ARMA, que combinam as caracter√≠sticas dos modelos AR e MA para capturar diferentes padr√µes de depend√™ncia temporal. A formula√ß√£o apresentada enfatiza o uso de uma estrutura matem√°tica que pode ser implementada eficientemente, o que √© crucial para aplica√ß√µes de larga escala [^1].

### Refer√™ncias
[^1]:  [4.2. Forecasts Based on an Infinite Number of Observations, p√°ginas 77-79]
<!-- END -->
