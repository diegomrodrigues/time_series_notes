## A Representa√ß√£o AR(\infty) e Aproxima√ß√µes na Modelagem de S√©ries Temporais

### Introdu√ß√£o
Em continuidade √† explora√ß√£o da previs√£o de s√©ries temporais utilizando valores passados da s√©rie, este cap√≠tulo se aprofunda nas implica√ß√µes pr√°ticas da representa√ß√£o **Autorregressiva de ordem infinita (AR(\infty))** [^1]. Como vimos anteriormente, a representa√ß√£o AR(\infty) modela uma s√©rie temporal como uma fun√ß√£o linear de todos os seus valores passados mais um termo de erro, ou seja,  $\eta(L)(Y_t - \mu) = \epsilon_t$, onde $\eta(L)$ √© um polin√¥mio de grau infinito em operadores de defasagem $L$ [^1]. No entanto, a aplica√ß√£o direta dessa formula√ß√£o em situa√ß√µes reais enfrenta desafios, especialmente devido √† necessidade de lidar com infinitos par√¢metros e dados hist√≥ricos. Para lidar com essa dificuldade, este cap√≠tulo explora como a necessidade de truncar a representa√ß√£o AR(\infty) introduz aproxima√ß√µes na modelagem, analisando as consequ√™ncias dessas aproxima√ß√µes para a previs√£o de s√©ries temporais.

### Truncamento da Representa√ß√£o AR(\infty) e suas Implica√ß√µes
A representa√ß√£o AR(\infty) √© expressa como $\eta(L)(Y_t - \mu) = \epsilon_t$ [^1], onde $\eta(L) = \sum_{j=0}^\infty \eta_j L^j$. Na pr√°tica, contudo, √© imposs√≠vel trabalhar com um n√∫mero infinito de termos [^1]. Para implementar esta representa√ß√£o, √© necess√°rio truncar o polin√¥mio $\eta(L)$ em um n√∫mero finito de termos. Isso leva √† aproxima√ß√£o da representa√ß√£o AR(\infty) por modelos de ordem finita, como os modelos AR(p). O truncamento da representa√ß√£o AR(\infty) √© uma etapa necess√°ria para a aplica√ß√£o pr√°tica, mas tamb√©m introduz uma fonte de erro no processo de modelagem.

**Observa√ß√£o 1:** O truncamento da representa√ß√£o AR(\infty) para um n√∫mero finito de termos, por exemplo, p, transforma o modelo em um AR(p), que pode ser expresso como $(1 - \phi_1 L - \phi_2 L^2 - \ldots - \phi_p L^p)(Y_t - \mu) = \epsilon_t$ [^1]. Esta aproxima√ß√£o implica que a influ√™ncia de valores defasados de Y, al√©m da ordem p, √© desprezada.

> üí° **Exemplo Num√©rico:** Suponha que a representa√ß√£o AR(\infty) verdadeira seja dada por $\eta(L) = 1 + 0.5L + 0.25L^2 + 0.125L^3 + \ldots$. Ao truncar esta representa√ß√£o em um modelo AR(2), teremos: $\eta(L) \approx 1 + 0.5L + 0.25L^2$. Esta aproxima√ß√£o ignora a influ√™ncia dos termos $0.125L^3 + \ldots$. Para ilustrar o erro introduzido, considere que $Y_t = 0.5Y_{t-1} + 0.25Y_{t-2} + 0.125Y_{t-3} + \epsilon_t$. Se estimarmos um modelo AR(2) da forma $Y_t = \phi_1Y_{t-1} + \phi_2Y_{t-2} + \epsilon_t$, os valores de $\phi_1$ e $\phi_2$ estimados ser√£o pr√≥ximos de 0.5 e 0.25 respectivamente, mas a parte $0.125Y_{t-3}$ √© ignorada pelo modelo, o que implica em perda de informa√ß√£o. Se $Y_{t-3}$ fosse significativamente correlacionado com $Y_t$, essa omiss√£o levaria a erros na modelagem e previs√£o.

O texto tamb√©m apresenta a rela√ß√£o entre os polin√¥mios AR e MA atrav√©s da express√£o $\eta(L) = [\psi(L)]^{-1}$ [^1]. Isso implica que a modelagem de uma s√©rie temporal pode ser abordada tanto na forma AR quanto na forma MA, sendo a escolha entre essas representa√ß√µes muitas vezes motivada pela conveni√™ncia e interpreta√ß√£o dos par√¢metros do modelo. A representa√ß√£o MA(q), que √© expressa como $Y_t - \mu = (1 + \theta_1 L + \theta_2 L^2 + \ldots + \theta_q L^q)\epsilon_t$ [^1], oferece uma maneira alternativa de modelar a depend√™ncia temporal de uma s√©rie.

**Lema 1** A representa√ß√£o MA(q) √© mais adequada quando a s√©rie temporal apresenta depend√™ncia com os ru√≠dos brancos anteriores, enquanto a representa√ß√£o AR(p) √© mais adequada quando a s√©rie apresenta depend√™ncia com seus valores passados.
*Proof:*
I. A representa√ß√£o MA(q) expressa a s√©rie $Y_t$ como uma combina√ß√£o linear dos ru√≠dos brancos anteriores $\epsilon_t$, ou seja, $Y_t - \mu = \epsilon_t + \theta_1 \epsilon_{t-1} + \ldots + \theta_q \epsilon_{t-q}$. 
II. Isso implica que o valor atual $Y_t$ √© afetado diretamente pelos choques passados.
III. Por outro lado, a representa√ß√£o AR(p) expressa a s√©rie $Y_t$ como uma combina√ß√£o linear de seus pr√≥prios valores passados, ou seja, $Y_t - \mu = \phi_1 (Y_{t-1} - \mu) + \ldots + \phi_p (Y_{t-p} - \mu) + \epsilon_t$.
IV. Desta forma, o valor atual $Y_t$ √© influenciado diretamente pelos valores anteriores da pr√≥pria s√©rie. ‚ñ†

> üí° **Exemplo Num√©rico:** Suponha que a s√©rie temporal $Y_t$ seja gerada por $Y_t = \epsilon_t + 0.7\epsilon_{t-1}$. Aqui, $Y_t$ depende diretamente do choque atual ($\epsilon_t$) e do choque imediatamente anterior ($\epsilon_{t-1}$). Neste caso, um modelo MA(1) √© mais adequado do que um modelo AR(p) para modelar $Y_t$.  Se tent√°ssemos modelar com AR(p), precisar√≠amos de uma ordem $p$ muito alta para capturar essa depend√™ncia corretamente, o que levaria a uma representa√ß√£o mais complexa. No entanto, se $Y_t$ fosse gerada por $Y_t = 0.8Y_{t-1} + \epsilon_t$, ent√£o um modelo AR(1) seria a melhor escolha.

**Lema 1.1** Se um processo √© invert√≠vel, ent√£o sua fun√ß√£o de autocovari√¢ncia decai exponencialmente.
*Proof:*
I. Um processo invert√≠vel MA(q) pode ser expresso como um processo AR(\infty) convergente.
II. A fun√ß√£o de autocovari√¢ncia de um processo AR(\infty) √© dada por uma combina√ß√£o linear de termos exponenciais.
III. Se o processo AR(\infty) converge, os termos exponenciais decaem para zero √† medida que o lag aumenta.
IV. Portanto, se o processo MA(q) √© invert√≠vel, a sua fun√ß√£o de autocovari√¢ncia decai exponencialmente. ‚ñ†

O texto destaca a import√¢ncia da **invertibilidade** para a representa√ß√£o MA(q) [^1]. Esta condi√ß√£o garante que a s√©rie temporal possa ser expressa como uma fun√ß√£o linear de seus pr√≥prios valores passados, permitindo estabelecer a rela√ß√£o entre o modelo MA e sua representa√ß√£o AR equivalente [^1]. Esta condi√ß√£o √© an√°loga √† condi√ß√£o de estacionariedade para o modelo AR(p) e √© fundamental para garantir que os modelos sejam bem comportados e possam ser utilizados para previs√£o.

**Observa√ß√£o 2**: A condi√ß√£o de invertibilidade para o modelo MA(q) implica que as ra√≠zes do polin√¥mio $\theta(z) = 1 + \theta_1 z + \ldots + \theta_q z^q$ devem estar fora do c√≠rculo unit√°rio, ou seja, $|z_i| > 1$ para todas as ra√≠zes $z_i$. Isso garante a converg√™ncia da representa√ß√£o AR equivalente ao modelo MA(q).

> üí° **Exemplo Num√©rico:** Considere um modelo MA(1) dado por $Y_t - \mu = \epsilon_t + 0.8\epsilon_{t-1}$. O polin√¥mio $\theta(z) = 1 + 0.8z$, e sua raiz √© $z = -1/0.8 = -1.25$. Como $|-1.25| > 1$, este modelo MA(1) √© invert√≠vel. Agora, considere um modelo MA(1) n√£o invert√≠vel, por exemplo, $Y_t - \mu = \epsilon_t + 1.5\epsilon_{t-1}$. O polin√¥mio √© $\theta(z) = 1 + 1.5z$ e a raiz √© $z = -1/1.5 = -0.666...$, com $|z|<1$. Este modelo n√£o √© invert√≠vel e n√£o possui uma representa√ß√£o AR equivalente convergente.

A previs√£o √≥tima de $Y_{t+s}$, dada por $\hat{E}[Y_{t+s}|Y_t, Y_{t-1},\ldots] = \mu + [\frac{\psi(L)}{L^s}]_+\eta(L)(Y_t-\mu)$ [^1], utiliza o operador de aniquila√ß√£o $[\cdot]_+$ para manter apenas os termos com pot√™ncias n√£o-negativas de $L$ [^1]. Este processo √© fundamental para expressar a previs√£o em termos dos valores passados observados de $Y_t$ [^1]. A representa√ß√£o ARMA(p,q), dada por $\phi(L)(Y_t - \mu) = \theta(L)\epsilon_t$ [^1], combina as estruturas de modelos AR e MA, oferecendo flexibilidade adicional na modelagem de s√©ries temporais [^1]. A escolha entre modelos AR, MA ou ARMA depender√° da natureza dos dados e da forma como a depend√™ncia temporal se manifesta na s√©rie.

**Teorema 2** Dado um modelo ARMA(p, q), a representa√ß√£o da previs√£o √≥tima √© a combina√ß√£o da previs√£o baseada em valores passados de Y e o operador de aniquila√ß√£o.
*Proof:*
I. A representa√ß√£o ARMA(p,q) √© dada por $\phi(L)(Y_t - \mu) = \theta(L)\epsilon_t$ [^1].
II. Dividindo por $\phi(L)$ temos $Y_t - \mu = [\phi(L)]^{-1} \theta(L)\epsilon_t$.
III. Definindo $\psi(L) = [\phi(L)]^{-1}\theta(L)$ e usando o operador de aniquila√ß√£o, a previs√£o √≥tima √© dada por $\hat{E}[Y_{t+s}|Y_t, Y_{t-1},\ldots] = \mu + [\frac{\psi(L)}{L^s}]_+\eta(L)(Y_t-\mu)$, onde $\eta(L) = [\phi(L)]^{-1}$ [^1].
IV. O operador de aniquila√ß√£o, $[\cdot]_+$, mant√©m apenas os termos com pot√™ncias n√£o negativas de $L$, garantindo que a previs√£o seja expressa em termos de valores passados de $Y$.
V. A parte $[\frac{\psi(L)}{L^s}]_+$ corresponde √† parte causal do operador $\frac{\psi(L)}{L^s}$. ‚ñ†

> üí° **Exemplo Num√©rico:** Considere o modelo ARMA(1,1) dado por $(1 - 0.7L)(Y_t - 5) = (1 + 0.4L)\epsilon_t$. Para calcular a previs√£o de $Y_{t+1}$, temos $\psi(L) = \frac{1+0.4L}{1-0.7L}$. Expandindo $\psi(L)$ em pot√™ncias de $L$: $\psi(L) = (1+0.4L)(1 + 0.7L + 0.7^2L^2 + 0.7^3L^3 + ...) = 1 + 1.1L + 1.17L^2 + 1.177L^3 + \ldots$. Ent√£o, $\frac{\psi(L)}{L} = \frac{1}{L} + 1.1 + 1.17L + 1.177L^2 + \ldots$ e $[\frac{\psi(L)}{L}]_+ = 1.1 + 1.17L + 1.177L^2 + \ldots$ e $\eta(L) = (1-0.7L)^{-1} = 1 + 0.7L + (0.7)^2L^2 + \ldots$. A previs√£o para um passo √† frente seria dada por: $\hat{E}[Y_{t+1}|Y_t, Y_{t-1},...] = 5 + (1.1 + 1.17L + \ldots)(1 - 0.7L)(Y_t-5)$. Aproximando com os dois primeiros termos do operador aniquila√ß√£o: $\hat{E}[Y_{t+1}|Y_t, Y_{t-1},...] \approx 5 + 1.1(Y_t - 5) + 1.17(Y_{t-1}-5)$. Note que a influ√™ncia de $Y_{t-1}$ √© considerada na previs√£o. Se estivessemos calculando a previs√£o de dois passos √† frente, o operador seria $[\frac{\psi(L)}{L^2}]_+$, e os termos mantidos na expans√£o de $\psi(L)$ seriam os multiplicados por $L^0, L^1, L^2 \ldots$ e a previs√£o dependeria de $Y_t, Y_{t-1}, Y_{t-2}\ldots$

**Corol√°rio 2.1** Se o processo ARMA √© causal e invert√≠vel, ent√£o a previs√£o √≥tima converge para a m√©dia do processo √† medida que o horizonte de previs√£o aumenta.
*Proof:*
I. Se um processo ARMA √© causal, ent√£o seus coeficientes AR decaem para zero √† medida que a defasagem aumenta.
II. Se o processo ARMA √© invert√≠vel, ent√£o seus coeficientes MA tamb√©m decaem para zero √† medida que a defasagem aumenta.
III. A previs√£o √≥tima √© uma combina√ß√£o linear dos valores passados da s√©rie, e se os coeficientes decaem para zero, a contribui√ß√£o dos valores passados torna-se insignificante √† medida que o horizonte de previs√£o aumenta.
IV. Portanto, a previs√£o converge para a m√©dia do processo, que √© a constante que sobra na equa√ß√£o ARMA quando todos os termos passados se tornam zero no longo prazo. ‚ñ†

> üí° **Exemplo Num√©rico:**  Considere novamente o modelo ARMA(1,1) dado por $(1 - 0.7L)(Y_t - 5) = (1 + 0.4L)\epsilon_t$. √Ä medida que o horizonte de previs√£o aumenta (por exemplo, previs√£o para $Y_{t+10}, Y_{t+20}$ etc.), a influ√™ncia dos valores passados de $Y_t$ diminui devido √† causalidade e invertibilidade. Eventualmente, a previs√£o se aproxima da m√©dia do processo, que neste caso √© 5. Isso significa que a incerteza no longo prazo aumenta, e a melhor previs√£o que podemos fazer √© a m√©dia da s√©rie, indicando que a s√©rie tem uma tend√™ncia a retornar para a m√©dia.

**Proposi√ß√£o 3** A fun√ß√£o de autocovari√¢ncia de um processo AR(p) estacion√°rio √© uma soma de exponenciais amortecidas.
*Proof:*
I. A fun√ß√£o de autocovari√¢ncia de um processo AR(p) estacion√°rio satisfaz a equa√ß√£o de Yule-Walker.
II. As solu√ß√µes dessa equa√ß√£o s√£o da forma $\gamma(h) = \sum_{i=1}^p A_i z_i^{|h|}$, onde $z_i$ s√£o as ra√≠zes do polin√¥mio caracter√≠stico do modelo AR(p) e $A_i$ s√£o constantes.
III. Se o processo for estacion√°rio, todas as ra√≠zes $z_i$ est√£o dentro do c√≠rculo unit√°rio ($|z_i| < 1$).
IV. Portanto, a fun√ß√£o de autocovari√¢ncia √© uma soma de exponenciais amortecidas, pois $|z_i|^{|h|}$ decai para zero √† medida que $|h|$ aumenta. ‚ñ†

> üí° **Exemplo Num√©rico:** Considere um modelo AR(2) definido por $Y_t = 1.2 Y_{t-1} - 0.4 Y_{t-2} + \epsilon_t$. O polin√¥mio caracter√≠stico √© $1 - 1.2z + 0.4z^2 = 0$, cujas ra√≠zes s√£o $z_1 = 1.5$ e $z_2 = 1$. Como $z_1$ est√° fora do c√≠rculo unit√°rio, o modelo n√£o √© estacion√°rio. As solu√ß√µes da equa√ß√£o de Yule-Walker para um modelo AR(2) estacion√°rio teriam ra√≠zes dentro do c√≠rculo unit√°rio e seriam da forma $\gamma(h) = A_1z_1^{|h|} + A_2z_2^{|h|}$. Quando $|z_1|<1$ e $|z_2|<1$, a fun√ß√£o de autocovari√¢ncia decai exponencialmente.  Por exemplo, se tivessemos $z_1=0.8$ e $z_2 = 0.5$, $\gamma(h)$ seria uma soma de termos que decaem como $0.8^{|h|}$ e $0.5^{|h|}$, que s√£o exponenciais amortecidas.

### Conclus√£o
Este cap√≠tulo explorou como a representa√ß√£o AR(\infty) √© truncada para ser aplicada na pr√°tica, e como essa aproxima√ß√£o introduz um erro que √© mitigado pela escolha apropriada de modelos de ordem finita. A discuss√£o destacou como a representa√ß√£o AR(\infty) oferece uma forma te√≥rica de modelar s√©ries temporais, mas a implementa√ß√£o pr√°tica requer aproxima√ß√µes que, em √∫ltima an√°lise, leva ao uso de modelos AR, MA ou ARMA. As condi√ß√µes de estacionariedade e invertibilidade, juntamente com o uso do operador de aniquila√ß√£o, s√£o cruciais para garantir que os modelos sejam bem comportados e possam ser utilizados para previs√µes confi√°veis.

### Refer√™ncias
[^1]: [4.2. Forecasts Based on an Infinite Number of Observations, p√°ginas 77-79]
<!-- END -->
