## Influ√™ncia do Erro Amostral nas Autocorrela√ß√µes Amostrais
### Introdu√ß√£o
Expandindo a discuss√£o sobre autocorrela√ß√µes amostrais como estimativas de autocorrela√ß√µes populacionais, este cap√≠tulo aborda a influ√™ncia do erro amostral e como ele pode levar a interpreta√ß√µes equivocadas dos padr√µes observados em s√©ries temporais. Como vimos anteriormente, as autocorrela√ß√µes amostrais ($ \hat{p}_j$) s√£o ferramentas cruciais na identifica√ß√£o de propriedades de s√©ries temporais, especialmente na distin√ß√£o entre processos *Moving Average* (MA) e *Autoregressive* (AR) [^1]. No entanto, √© fundamental reconhecer que elas s√£o estimativas baseadas em uma amostra finita de dados, e, portanto, sujeitas a erros amostrais. Esses erros podem gerar padr√µes nas autocorrela√ß√µes amostrais que n√£o refletem as verdadeiras depend√™ncias temporais na s√©rie. Este cap√≠tulo explora esse fen√¥meno em detalhes, demonstrando como o erro amostral pode influenciar a interpreta√ß√£o de gr√°ficos de autocorrela√ß√£o e sugerindo cautelas na an√°lise.

### O Efeito do Erro Amostral nas Autocorrela√ß√µes Amostrais

A autocorrela√ß√£o amostral $\hat{p}_j$ no lag $j$ √© uma estimativa da autocorrela√ß√£o populacional $\rho_j$ que, como vimos anteriormente, √© dada por [^4]:

$$
\hat{p}_j = \frac{\hat{\gamma}_j}{\hat{\gamma}_0}
$$

onde $\hat{\gamma}_j$ representa a *covari√¢ncia amostral* no lag $j$ [^4]. Em um cen√°rio ideal, onde temos acesso a todo o hist√≥rico de dados, $\hat{p}_j$ convergir√° para $\rho_j$ √† medida que o tamanho da amostra aumenta. No entanto, na pr√°tica, trabalhamos com amostras finitas, o que introduz o erro amostral. O erro amostral pode se manifestar de v√°rias formas, incluindo varia√ß√µes aleat√≥rias nas estimativas das autocorrela√ß√µes, mesmo quando o processo subjacente √© bem comportado.

√â importante notar que as estimativas $\hat{p}_j$ para diferentes lags n√£o s√£o estatisticamente independentes. Especificamente, se houver autocorrela√ß√£o na s√©rie temporal que gerou os dados, ent√£o $\hat{p}_i$ ser√° correlacionado com $\hat{p}_j$ para $i \neq j$ [^4]. Isto √©, o erro amostral em um lag influencia o erro amostral em outros lags. Isso implica que os padr√µes observados em um gr√°fico de autocorrela√ß√£o amostral podem n√£o representar um padr√£o real da autocorrela√ß√£o populacional $\rho_j$ [^4], mas sim um artefato do erro amostral.

Para quantificar a incerteza associada √†s autocorrela√ß√µes amostrais, podemos utilizar o conceito de intervalos de confian√ßa. Se supormos que a s√©rie temporal √© um ru√≠do branco gaussiano, ent√£o, para um lag $j \neq 0$, a vari√¢ncia da autocorrela√ß√£o amostral $\hat{p}_j$ pode ser aproximada por $\frac{1}{T}$, onde $T$ √© o tamanho da amostra [^4]. Em outras palavras:
$$Var(\hat{p}_j) \approx \frac{1}{T}$$

Consequentemente, um intervalo de confian√ßa aproximado de 95% para $\hat{p}_j$ seria dado por $\pm 2/\sqrt{T}$. Este intervalo √© o utilizado como guia nas figuras de autocorrela√ß√£o amostral [^4]. Se o valor estimado da autocorrela√ß√£o amostral  $\hat{p}_j$ estiver fora desse intervalo, temos evid√™ncia para rejeitar a hip√≥tese nula de que a autocorrela√ß√£o populacional √© zero. No entanto, √© importante lembrar que a varia√ß√£o em $\hat{p}_j$ para diferentes lags n√£o √© independente e que esses testes devem ser interpretados com cautela.

> üí° **Exemplo Num√©rico:** Vamos supor que temos uma s√©rie temporal com $T=400$ observa√ß√µes e queremos analisar a autocorrela√ß√£o amostral $\hat{p}_j$. Se assumirmos que a s√©rie √© um ru√≠do branco, o desvio padr√£o aproximado de $\hat{p}_j$ √© dado por $\sqrt{\frac{1}{400}} = 0.05$. Assim, o intervalo de confian√ßa de 95% seria $\pm 2 \times 0.05 = \pm 0.1$.  Isso significa que, para um ru√≠do branco, esperamos que 95% das autocorrela√ß√µes amostrais $\hat{p}_j$ para $j \neq 0$ estejam entre -0.1 e 0.1. Se observarmos autocorrela√ß√µes amostrais significativamente fora desse intervalo, podemos suspeitar que a s√©rie n√£o √© um ru√≠do branco. No entanto, devemos estar cientes que, devido a depend√™ncia entre as estimativas $\hat{p}_j$, esses valores podem apresentar um padr√£o devido a erros amostrais, ao inv√©s de refletir um padr√£o na autocorrela√ß√£o populacional.

> üí° **Exemplo Num√©rico:** Considere uma s√©rie temporal gerada por um processo de ru√≠do branco com m√©dia zero e desvio padr√£o unit√°rio. Simulamos uma amostra de $T=100$ observa√ß√µes usando Python:
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
> from statsmodels.graphics.tsaplots import plot_acf
>
> # Generate white noise
> np.random.seed(42) # for reproducibility
> T = 100
> white_noise = np.random.normal(0, 1, T)
>
> # Plotting the ACF
> plot_acf(white_noise, lags=20, title='ACF of White Noise (T=100)')
> plt.xlabel('Lag')
> plt.ylabel('Autocorrelation')
> plt.show()
> ```
> Ao gerar o gr√°fico de autocorrela√ß√£o (ACF) para esta s√©rie de ru√≠do branco, podemos observar que, embora a autocorrela√ß√£o populacional seja zero para todos os lags diferentes de zero, as autocorrela√ß√µes amostrais apresentam valores que se situam tanto dentro quanto fora do intervalo de confian√ßa de 95% (aproximadamente $\pm 2/\sqrt{100} = \pm 0.2$). Isso demonstra claramente como o erro amostral pode levar a falsos positivos na identifica√ß√£o de autocorrela√ß√µes significativas em s√©ries temporais. O gr√°fico gerado mostra uma varia√ß√£o em torno de zero, mas algumas barras ultrapassam os limites do intervalo de confian√ßa. Isto √© esperado, j√° que essas autocorrela√ß√µes s√£o amostrais. Se aumentarmos o tamanho amostral, as autocorrela√ß√µes amostrais se aproximar√£o de zero, demonstrando o efeito da converg√™ncia dos estimadores amostrais aos seus valores populacionais.

### Implica√ß√µes Pr√°ticas e Cautelas

O erro amostral imp√µe limita√ß√µes √† nossa capacidade de inferir a verdadeira autocorrela√ß√£o populacional a partir de um conjunto de dados finito.  Como demonstrado em [^Proposi√ß√£o 1], as autocovari√¢ncias e autocorrela√ß√µes amostrais s√£o estimativas enviesadas das autocovari√¢ncias e autocorrela√ß√µes populacionais. Embora existam formas de se estimar de forma n√£o enviesada as autocovari√¢ncias (como em [^Proposi√ß√£o 1.1]), o seu uso n√£o √© o padr√£o na pr√°tica.  Em resumo, o uso de autocorrela√ß√µes amostrais, e suas interpreta√ß√µes, devem ser feitas com cautela, uma vez que elas podem ser influenciadas pelo erro amostral.

1.  **Interpreta√ß√£o de Padr√µes:** Os gr√°ficos de autocorrela√ß√£o amostral devem ser analisados com cautela, pois podem apresentar padr√µes que n√£o refletem o processo gerador dos dados. Por exemplo, um padr√£o de decaimento exponencial em um gr√°fico de autocorrela√ß√£o amostral pode n√£o ser evid√™ncia conclusiva de um processo AR(p), j√° que o erro amostral pode introduzir esse comportamento em um ru√≠do branco.
2.  **Tamanho da Amostra:** Amostras maiores geralmente levam a estimativas mais precisas das autocorrela√ß√µes populacionais. Para amostras menores, o erro amostral pode ser mais expressivo e dificultar a distin√ß√£o entre um padr√£o "real" e ru√≠do nas autocorrela√ß√µes amostrais.
3.  **Autocorrela√ß√µes Parciais:** Como explorado em cap√≠tulos anteriores, as autocorrela√ß√µes parciais podem complementar a an√°lise das autocorrela√ß√µes amostrais. A autocorrela√ß√£o parcial √© definida como o √∫ltimo coeficiente em uma proje√ß√£o linear de uma vari√°vel em seus valores defasados. Enquanto as autocorrela√ß√µes amostrais medem a correla√ß√£o entre uma vari√°vel e seus lags, sem remover a influ√™ncia dos lags intermedi√°rios, a autocorrela√ß√£o parcial remove a influ√™ncia dos lags intermedi√°rios, permitindo uma an√°lise mais precisa da depend√™ncia direta de uma vari√°vel nos seus lags.
4.  **Testes de Hip√≥teses:** A aplica√ß√£o de testes de hip√≥teses formais pode ser √∫til para verificar se as autocorrela√ß√µes amostrais s√£o significativamente diferentes de zero. Esses testes devem ser feitos com cautela devido √† depend√™ncia entre as autocorrela√ß√µes amostrais.
5.  **Parsim√¥nia:** √â importante adotar uma abordagem parcimoniosa na modelagem, evitando modelos complexos que se ajustem bem √† amostra, mas que sejam suscet√≠veis ao erro de amostragem e que tenham uma fraca capacidade de generaliza√ß√£o para fora da amostra. Em outras palavras, modelos mais simples podem ser mais robustos para previs√£o fora da amostra.

**Lema 1:** *Para um processo de ru√≠do branco, as autocorrela√ß√µes amostrais $\hat{p}_j$ s√£o assintoticamente n√£o correlacionadas.*
*Proof:* Sob a hip√≥tese de ru√≠do branco, as autocorrela√ß√µes populacionais $\rho_j$ s√£o zero para $j \neq 0$.  Embora as estimativas amostrais $\hat{p}_j$ sejam correlacionadas em amostras finitas, essa correla√ß√£o desaparece quando o tamanho da amostra $T$ tende ao infinito. A demonstra√ß√£o formal deste resultado envolve a an√°lise das propriedades assint√≥ticas das autocorrela√ß√µes amostrais e est√° al√©m do escopo desta introdu√ß√£o, mas a ideia intuitiva √© que para grandes $T$, a lei dos grandes n√∫meros garante que as estimativas convergem para seus valores esperados.  Esta propriedade √© fundamental para a validade de muitos testes estat√≠sticos que assumem a n√£o correla√ß√£o entre as amostras.

**Proposi√ß√£o 2:** *Sob condi√ß√µes de regularidade, as autocorrela√ß√µes amostrais $\hat{p}_j$ s√£o assintoticamente normalmente distribu√≠das para processos estacion√°rios*.
*Proof:* Este resultado segue do Teorema do Limite Central aplicado √†s autocovari√¢ncias amostrais, que formam a base do c√°lculo das autocorrela√ß√µes amostrais. A demonstra√ß√£o formal √© um pouco t√©cnica, envolvendo expans√µes de Taylor e an√°lise de converg√™ncia de momentos. Contudo, a ideia essencial √© que, quando o tamanho da amostra $T$ √© grande, a distribui√ß√£o de $\hat{p}_j$ se aproxima de uma distribui√ß√£o normal, com m√©dia pr√≥xima de $\rho_j$ e vari√¢ncia que pode ser estimada usando a f√≥rmula apresentada anteriormente. Este resultado √© fundamental para a constru√ß√£o de intervalos de confian√ßa e testes de hip√≥teses.

**Proposi√ß√£o 2.1** *Para um processo de ru√≠do branco, e sob condi√ß√µes de regularidade, as autocorrela√ß√µes amostrais $\hat{p}_j$ s√£o assintoticamente normalmente distribu√≠das com m√©dia zero e vari√¢ncia $\frac{1}{T}$*.
*Proof:*
I.  Da Proposi√ß√£o 2, sabemos que as autocorrela√ß√µes amostrais $\hat{p}_j$ s√£o assintoticamente normalmente distribu√≠das para processos estacion√°rios.
II. Para um processo de ru√≠do branco, a autocorrela√ß√£o populacional $\rho_j = 0$ para $j \ne 0$.
III. A vari√¢ncia da autocorrela√ß√£o amostral para um ru√≠do branco √© dada aproximadamente por $Var(\hat{p}_j) \approx \frac{1}{T}$.
IV.  Portanto, combinando os resultados de I, II e III, conclu√≠mos que as autocorrela√ß√µes amostrais $\hat{p}_j$ s√£o assintoticamente normalmente distribu√≠das com m√©dia zero e vari√¢ncia $\frac{1}{T}$. ‚ñ†

### Conclus√£o
A an√°lise de autocorrela√ß√µes amostrais √© um passo crucial na modelagem de s√©ries temporais, mas √© essencial ter em mente que elas s√£o estimativas sujeitas a erro amostral. O erro amostral pode levar a conclus√µes err√¥neas sobre as propriedades temporais da s√©rie e a escolha inadequada de modelos, e a interpreta√ß√£o deve ser feita com cautela. Ao considerar o erro amostral, a depend√™ncia entre estimativas, utilizar autocorrela√ß√µes parciais, e testar hip√≥teses formais, √© poss√≠vel construir modelos mais confi√°veis para previs√µes e an√°lises de s√©ries temporais. O pr√≥ximo passo √© explorar o uso desses conceitos dentro de metodologias mais estruturadas como a de Box-Jenkins.
### Refer√™ncias
[^1]: Express√£o [4.1.1] √© conhecida como o erro quadr√°tico m√©dio associado √† previs√£o.
[^4]: Express√£o [4.8.6]
[^Proposi√ß√£o 1]: Proposi√ß√£o 1 no cap√≠tulo anterior
[^Proposi√ß√£o 1.1]: Proposi√ß√£o 1.1 no cap√≠tulo anterior
### 5.2. Likelihood Function for an AR(1)
Come√ßamos com o caso mais simples de um processo **AR(1)** para derivar a fun√ß√£o de verossimilhan√ßa. O modelo √© dado por:
$$Y_t = c + \phi Y_{t-1} + \epsilon_t$$
onde $\epsilon_t \sim i.i.d. N(0, \sigma^2)$ [^5.1.5]. Para calcular a fun√ß√£o de verossimilhan√ßa, √© necess√°rio obter a densidade conjunta de $Y_1, Y_2, \dots, Y_T$ dado $\theta = (c, \phi, \sigma^2)$. Em vez de obter a densidade conjunta diretamente, podemos obter a densidade condicional de $Y_t$ dado $Y_{t-1}, Y_{t-2}, \dots, Y_1$, e ent√£o obter a densidade conjunta usando a regra da cadeia para densidades.

A distribui√ß√£o condicional de $Y_t$ dado $Y_{t-1}$ √© dada por
$$Y_t | Y_{t-1} \sim N(c + \phi Y_{t-1}, \sigma^2)$$
Ent√£o, a densidade condicional de $Y_t$ dado $Y_{t-1}$ √©
$$f(y_t | y_{t-1}; \theta) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(y_t - c - \phi y_{t-1})^2}{2\sigma^2}\right)$$
Assumindo que as observa√ß√µes de Y s√£o independentes condicional √†s observa√ß√µes passadas, a fun√ß√£o de verossimilhan√ßa para a amostra $(y_1, y_2, \dots, y_T)$ √© dada por
$$L(\theta; y_1, y_2, \dots, y_T) = f(y_1; \theta) \prod_{t=2}^T f(y_t | y_{t-1}; \theta)$$
O primeiro termo $f(y_1; \theta)$ representa a distribui√ß√£o marginal da primeira observa√ß√£o, a qual √©, em geral, diferente da distribui√ß√£o condicional. Se a primeira observa√ß√£o √© tratada como fixa (i.e. condicionada), podemos ignorar o termo $f(y_1; \theta)$. Isso se torna um problema com amostras pequenas, mas com amostras grandes, a diferen√ßa entre o caso condicional e o marginal √© m√≠nima.

Podemos obter a fun√ß√£o de log-verossimilhan√ßa a partir da express√£o acima. Para o caso condicional, podemos ignorar o termo $f(y_1; \theta)$ e o log da fun√ß√£o de verossimilhan√ßa torna-se
$$\mathcal{L}(\theta; y_1, y_2, \dots, y_T) = \sum_{t=2}^T \log\left(\frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(y_t - c - \phi y_{t-1})^2}{2\sigma^2}\right)\right)$$
$$= \sum_{t=2}^T \left(-\frac{1}{2}\log(2\pi\sigma^2) - \frac{(y_t - c - \phi y_{t-1})^2}{2\sigma^2}\right)$$
$$= -\frac{T-1}{2}\log(2\pi\sigma^2) - \frac{1}{2\sigma^2}\sum_{t=2}^T (y_t - c - \phi y_{t-1})^2$$

> üí° **Exemplo Num√©rico:** Vamos considerar um modelo AR(1) com $c = 0.5$, $\phi = 0.7$ e $\sigma^2 = 1$. Suponha que temos uma s√©rie temporal de tamanho $T=100$, e os primeiros dois valores da s√©rie s√£o $y_1 = 1.2$ e $y_2 = 1.5$. Vamos calcular a contribui√ß√£o para a fun√ß√£o de log-verossimilhan√ßa para a segunda observa√ß√£o ($t=2$).
>
> A densidade condicional de $y_2$ dado $y_1$ √©:
> $$f(y_2 | y_1; \theta) = \frac{1}{\sqrt{2\pi(1)}} \exp\left(-\frac{(1.5 - 0.5 - 0.7(1.2))^2}{2(1)}\right)$$
> $$f(y_2 | y_1; \theta) = \frac{1}{\sqrt{2\pi}} \exp\left(-\frac{(1.5 - 0.5 - 0.84)^2}{2}\right)$$
> $$f(y_2 | y_1; \theta) = \frac{1}{\sqrt{2\pi}} \exp\left(-\frac{(0.16)^2}{2}\right)$$
> $$f(y_2 | y_1; \theta) \approx \frac{1}{2.5066} \exp(-0.0128) \approx 0.3989 \times 0.9873 \approx 0.3938$$
>
> O log da fun√ß√£o de verossimilhan√ßa para essa observa√ß√£o √©:
> $$\log(f(y_2 | y_1; \theta)) = -\frac{1}{2}\log(2\pi) - \frac{1}{2}\log(1) - \frac{(1.5 - 0.5 - 0.7(1.2))^2}{2(1)}$$
> $$\log(f(y_2 | y_1; \theta)) =  -\frac{1}{2}\log(2\pi) - \frac{(0.16)^2}{2} \approx -0.9189 - 0.0128 \approx -0.9317$$
> Para o caso condicional, a fun√ß√£o de log-verossimilhan√ßa para todo o conjunto de dados $y_1, y_2, \dots, y_T$ √© obtida somando as contribui√ß√µes de cada observa√ß√£o a partir de $t=2$:
> $$\mathcal{L}(\theta; y_1, y_2, \dots, y_T) =  -\frac{99}{2}\log(2\pi) - \frac{1}{2}\sum_{t=2}^{100} (y_t - 0.5 - 0.7 y_{t-1})^2$$
> Este exemplo ilustra como cada observa√ß√£o contribui para a fun√ß√£o de log-verossimilhan√ßa, e como a otimiza√ß√£o desta fun√ß√£o leva √†s estimativas dos par√¢metros do modelo.

### 5.3. Likelihood Function for an AR(p)
O processo para o modelo **AR(p)** √© dado por:
$$Y_t = c + \phi_1 Y_{t-1} + \phi_2 Y_{t-2} + \dots + \phi_p Y_{t-p} + \epsilon_t$$
onde $\epsilon_t \sim i.i.d. N(0, \sigma^2)$. Similarmente ao caso AR(1), a distribui√ß√£o condicional de $Y_t$ dado $Y_{t-1}, Y_{t-2}, \dots, Y_{t-p}$ √©
$$Y_t | Y_{t-1}, Y_{t-2}, \dots, Y_{t-p} \sim N(c + \phi_1 Y_{t-1} + \phi_2 Y_{t-2} + \dots + \phi_p Y_{t-p}, \sigma^2)$$
Ent√£o, a densidade condicional de $Y_t$ dado $Y_{t-1}, Y_{t-2}, \dots, Y_{t-p}$ √©
$$f(y_t | y_{t-1}, y_{t-2}, \dots, y_{t-p}; \theta) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(y_t - c - \phi_1 y_{t-1} - \phi_2 y_{t-2} - \dots - \phi_p y_{t-p})^2}{2\sigma^2}\right)$$
A fun√ß√£o de log-verossimilhan√ßa condicional para uma amostra $(y_1, y_2, \dots, y_T)$ torna-se
$$\mathcal{L}(\theta; y_1, y_2, \dots, y_T) = \sum_{t=p+1}^T \log\left(\frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(y_t - c - \phi_1 y_{t-1} - \phi_2 y_{t-2} - \dots - \phi_p y_{t-p})^2}{2\sigma^2}\right)\right)$$
$$= -\frac{T-p}{2}\log(2\pi\sigma^2) - \frac{1}{2\sigma^2}\sum_{t=p+1}^T (y_t - c - \phi_1 y_{t-1} - \phi_2 y_{t-2} - \dots - \phi_p y_{t-p})^2$$
### 5.4. Likelihood Function for an MA(1)
O modelo **MA(1)** √© dado por:
$$Y_t = \mu + \epsilon_t + \theta \epsilon_{t-1}$$
onde $\epsilon_t \sim i.i.d. N(0, \sigma^2)$. Aqui, a distribui√ß√£o condicional de $Y_t$ dado $Y_{t-1}$ n√£o tem uma forma direta, pois o valor de $\epsilon_{t-1}$ n√£o √© observ√°vel. Nesse cen√°rio, vamos derivar a fun√ß√£o de log-verossimilhan√ßa conjunta utilizando a abordagem recursiva.
Primeiro, notamos que
$$\epsilon_t = Y_t - \mu - \theta \epsilon_{t-1}$$
Como $\epsilon_t \sim N(0, \sigma^2)$,  $Y_t | \epsilon_{t-1} \sim N(\mu + \theta \epsilon_{t-1}, \sigma^2)$. O problema aqui √© que $\epsilon_{t-1}$ n√£o √© observado. Para construir a verossimilhan√ßa, vamos come√ßar tratando $\epsilon_0$ como um par√¢metro desconhecido. Ent√£o, podemos escrever $\epsilon_1 = Y_1 - \mu - \theta \epsilon_0$, $\epsilon_2 = Y_2 - \mu - \theta \epsilon_1$, e assim por diante. Assim, para um dado conjunto de par√¢metros $(\mu, \theta, \sigma^2)$, uma amostra observada $(y_1, y_2, \dots, y_T)$ produz uma sequ√™ncia de ru√≠dos $\epsilon_1, \epsilon_2, \dots, \epsilon_T$. Assim, a distribui√ß√£o conjunta de $\epsilon_1, \epsilon_2, \dots, \epsilon_T$ dado $\theta$, $\epsilon_0$ √©
$$f(\epsilon_1, \epsilon_2, \dots, \epsilon_T; \theta, \epsilon_0) = \prod_{t=1}^T \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{\epsilon_t^2}{2\sigma^2}\right)$$
A fun√ß√£o de log-verossimilhan√ßa condicional √©
$$\mathcal{L}(\theta, \epsilon_0; y_1, y_2, \dots, y_T) = -\frac{T}{2}\log(2\pi\sigma^2) - \frac{1}{2\sigma^2}\sum_{t=1}^T \epsilon_t^2$$
onde $\epsilon_t$ s√£o dados por $\epsilon_t = y_t - \mu - \theta \epsilon_{t-1}$, e $\epsilon_0$ √© um par√¢metro adicional. Para remover a depend√™ncia de $\epsilon_0$, em vez de trat√°-lo como um par√¢metro adicional, podemos tratar $\epsilon_0 = 0$. Isso corresponde a iniciar a recurs√£o com o valor esperado de $\epsilon_0$.
Para uma aproxima√ß√£o, podemos tratar $\epsilon_0 = 0$.
A fun√ß√£o de log-verossimilhan√ßa condicional se torna
$$\mathcal{L}(\theta; y_1, y_2, \dots, y_T) = -\frac{T}{2}\log(2\pi\sigma^2) - \frac{1}{2\sigma^2}\sum_{t=1}^T \epsilon_t^2$$
onde $\epsilon_t = y_t - \mu - \theta \epsilon_{t-1}$, e $\epsilon_0 = 0$.

> üí° **Exemplo Num√©rico:** Vamos considerar um modelo MA(1) com $\mu = 2$, $\theta = 0.6$, e $\sigma^2 = 0.5$. Suponha que temos as observa√ß√µes $y_1 = 2.3$ e $y_2 = 2.8$. Inicializando $\epsilon_0 = 0$, podemos calcular os erros $\epsilon_t$ recursivamente.
>
> Para $t=1$:
> $$\epsilon_1 = y_1 - \mu - \theta \epsilon_0 = 2.3 - 2 - 0.6 \times 0 = 0.3$$
> Para $t=2$:
> $$\epsilon_2 = y_2 - \mu - \theta \epsilon_1 = 2.8 - 2 - 0.6 \times 0.3 = 0.8 - 0.18 = 0.62$$
>
> As contribui√ß√µes para a fun√ß√£o de log-verossimilhan√ßa s√£o dadas por:
>
> $$ \mathcal{L}(\theta; y_1,y_2) = -\frac{2}{2}\log(2\pi \times 0.5) - \frac{1}{2 \times 0.5}(0.3^2 + 0.62^2) $$
> $$ \mathcal{L}(\theta; y_1,y_2) = -\log(\sqrt{\pi}) - 0.5\log(2) - (0.09 + 0.3844)  $$
> $$ \mathcal{L}(\theta; y_1,y_2) = -0.5724 - 0.3466 - 0.4744 = -1.3934 $$
>
> Isso demonstra o c√°lculo recursivo dos erros para cada observa√ß√£o, e como eles contribuem para a fun√ß√£o de log-verossimilhan√ßa. A fun√ß√£o completa de log-verossimilhan√ßa seria a soma das contribui√ß√µes de todas as observa√ß√µes, baseada no c√°lculo recursivo de $\epsilon_t$.

### 5.5. Likelihood Function for an MA(q)
A extens√£o para o modelo **MA(q)** √© direta:
$$Y_t = \mu + \epsilon_t + \theta_1 \epsilon_{t-1} + \theta_2 \epsilon_{t-2} + \dots + \theta_q \epsilon_{t-q}$$
onde $\epsilon_t \sim i.i.d. N(0, \sigma^2)$. Podemos obter as fun√ß√µes $\epsilon_t$ recursivamente como:
$$\epsilon_t = Y_t - \mu - \theta_1 \epsilon_{t-1} - \theta_2 \epsilon_{t-2} - \dots - \theta_q \epsilon_{t-q}$$
e tratar $\epsilon_0 = \epsilon_{-1} = \dots = \epsilon_{1-q} = 0$. A fun√ß√£o de log-verossimilhan√ßa condicional √©
$$\mathcal{L}(\theta; y_1, y_2, \dots, y_T) = -\frac{T}{2}\log(2\pi\sigma^2) - \frac{1}{2\sigma^2}\sum_{t=1}^T \epsilon_t^2$$
onde $\epsilon_t$ s√£o dados pela recurs√£o anterior.

### 5.6. Likelihood Function for an ARMA(p, q)
Para o caso geral do modelo **ARMA(p, q)**, a fun√ß√£o √© similar √†s fun√ß√µes para os modelos MA e AR, e a fun√ß√£o de log-verossimilhan√ßa condicional ser√° dada por:
$$Y_t = c + \phi_1 Y_{t-1} + \phi_2 Y_{t-2} + \dots + \phi_p Y_{t-p} + \epsilon_t + \theta_1 \epsilon_{t-1} + \theta_2 \epsilon_{t-2} + \dots + \theta_q \epsilon_{t-q}$$
onde $\epsilon_t \sim i.i.d. N(0, \sigma^2)$. As fun√ß√µes de $\epsilon_t$ s√£o obtidas recursivamente da express√£o acima:
$$\epsilon_t = Y_t - c - \phi_1 Y_{t-1} - \phi_2 Y_{t-2} - \dots - \phi_p Y_{t-p} - \theta_1 \epsilon_{t-1} - \theta_2 \epsilon_{t-2} - \dots - \theta_q \epsilon_{t-q}$$
Iniciamos a recurs√£o com $\epsilon_0 = \epsilon_{-1} = \dots = \epsilon_{1-q} = 0$ e $Y_0 = Y_{-1} = \dots = Y_{1-p} = 0$.

A fun√ß√£o de log-verossimilhan√ßa condicional se torna:
$$\mathcal{L}(\theta; y_1, y_2, \dots, y_T) = -\frac{T}{2}\log(2\pi\sigma^2) - \frac{1}{2\sigma^2}\sum_{t=1}^T \epsilon_t^2$$
onde $\theta = (c, \phi_1, \dots, \phi_p, \theta_1, \dots, \theta_q, \sigma^2)$, e $\epsilon_t$ s√£o obtidos recursivamente a partir da equa√ß√£o anterior.
<!-- END -->
