## Previs√£o de um Passo √† Frente para um Processo MA(1)
### Introdu√ß√£o
Neste cap√≠tulo, continuamos a explorar a previs√£o de s√©ries temporais, focando agora no c√°lculo da previs√£o de um passo √† frente para um processo de m√©dias m√≥veis de primeira ordem, conhecido como MA(1). Como vimos anteriormente, a representa√ß√£o de um processo MA(1) invert√≠vel nos permite expressar as previs√µes como uma fun√ß√£o dos valores passados da s√©rie temporal [^4]. Esta se√ß√£o detalha o processo de c√°lculo da previs√£o de um passo √† frente, sublinhando sua simplicidade e efici√™ncia computacional. Adicionalmente, vamos demonstrar como esta representa√ß√£o recursiva nos permite fazer previs√µes de forma eficiente.

### Conceitos Fundamentais
Um processo MA(1) √© definido como
$$Y_t = \mu + \varepsilon_t + \theta\varepsilon_{t-1},$$ [^4]
onde $\mu$ √© a m√©dia do processo, $\varepsilon_t$ √© ru√≠do branco com m√©dia zero e vari√¢ncia $\sigma^2$, e $\theta$ √© o par√¢metro que define a correla√ß√£o entre os choques $\varepsilon_t$ e $\varepsilon_{t-1}$.

Como estabelecido anteriormente, para um processo MA(1) invert√≠vel (ou seja, $|\theta|<1$), podemos expressar $\varepsilon_t$ em fun√ß√£o dos valores passados da s√©rie temporal $Y_t$, utilizando uma representa√ß√£o autorregressiva de ordem infinita:
$$\varepsilon_t = (Y_t - \mu) - \theta(Y_{t-1} - \mu) + \theta^2(Y_{t-2} - \mu) - \theta^3(Y_{t-3} - \mu) + \ldots$$[^4]
**Proposi√ß√£o 1**
Uma representa√ß√£o alternativa para $\varepsilon_t$ pode ser dada atrav√©s da formula√ß√£o recursiva
$$\varepsilon_t = (Y_t - \mu) - \theta \varepsilon_{t-1}$$
*Proof:*
 Partindo da defini√ß√£o do processo MA(1) temos que $\varepsilon_{t-1} = Y_{t-1} - \mu - \theta\varepsilon_{t-2}$, assim
$$Y_{t-1} - \mu = \varepsilon_{t-1} + \theta\varepsilon_{t-2}$$
Substituindo na express√£o da representa√ß√£o autorregressiva de ordem infinita de $\varepsilon_t$ temos que:
$$\varepsilon_t = (Y_t - \mu) - \theta(Y_{t-1} - \mu) + \theta^2(Y_{t-2} - \mu) - \theta^3(Y_{t-3} - \mu) + \ldots$$
$$\varepsilon_t = (Y_t - \mu) - \theta(\varepsilon_{t-1} + \theta\varepsilon_{t-2}) + \theta^2(Y_{t-2} - \mu) - \theta^3(Y_{t-3} - \mu) + \ldots$$
$$\varepsilon_t = (Y_t - \mu) - \theta\varepsilon_{t-1} - \theta^2\varepsilon_{t-2} + \theta^2(Y_{t-2} - \mu) - \theta^3(Y_{t-3} - \mu) + \ldots$$
$$\varepsilon_t = (Y_t - \mu) - \theta\varepsilon_{t-1} - \theta^2(\varepsilon_{t-2} - (Y_{t-2} - \mu)) - \theta^3(Y_{t-3} - \mu) + \ldots$$
Observando a express√£o entre par√™nteses concluimos que:
$$\varepsilon_{t-1} = (Y_{t-1} - \mu) - \theta(Y_{t-2} - \mu) + \theta^2(Y_{t-3} - \mu) - \theta^3(Y_{t-4} - \mu) + \ldots$$
Portanto,  $\varepsilon_{t-1} - (Y_{t-1} - \mu)$ √© igual a $-\theta\varepsilon_{t-2}$
Assim,
$$\varepsilon_t = (Y_t - \mu) - \theta\varepsilon_{t-1} - \theta^2(-\theta\varepsilon_{t-3}) - \theta^3(Y_{t-3} - \mu) + \ldots$$
$$\varepsilon_t = (Y_t - \mu) - \theta\varepsilon_{t-1} + \theta^3\varepsilon_{t-3} - \theta^3(Y_{t-3} - \mu) + \ldots$$
Usando o mesmo racioc√≠nio para todos os termos concluimos que a representa√ß√£o autorregressiva de ordem infinita pode ser escrita da seguinte forma:
$$\varepsilon_t = (Y_t - \mu) - \theta\varepsilon_{t-1}$$
Essa formula√ß√£o recursiva nos permite encontrar o valor de $\varepsilon_t$ usando o valor de $Y_t$ e $\varepsilon_{t-1}$ que j√° foi calculado no passo anterior.

A previs√£o de um passo √† frente para um processo MA(1) √© dada por
$$\hat{Y}_{t+1|t} = \mu + \theta\varepsilon_t,$$ [^4]
onde $\varepsilon_t$ √© o choque n√£o observado no per√≠odo $t$. Usando a representa√ß√£o recursiva do Lema 1 [^4], podemos expressar esta previs√£o da seguinte forma:
$$\hat{Y}_{t+1|t} = \mu + \theta (Y_t - \hat{Y}_{t|t-1}).$$ [^4]
Essa express√£o recursiva, como demonstrado anteriormente [^4], permite calcular a previs√£o de um per√≠odo √† frente usando apenas o valor atual da s√©rie temporal $Y_t$ e a previs√£o do per√≠odo anterior $\hat{Y}_{t|t-1}$.

> üí° **Observa√ß√£o Importante:**
>
> A previs√£o de um passo √† frente, expressa como $\hat{Y}_{t+1|t} = \mu + \theta\varepsilon_t$, pode parecer depender de $\varepsilon_t$, que √© uma vari√°vel n√£o observada. No entanto, ao utilizar a representa√ß√£o recursiva $\hat{Y}_{t+1|t} = \mu + \theta (Y_t - \hat{Y}_{t|t-1})$, substitu√≠mos a depend√™ncia em $\varepsilon_t$ pela depend√™ncia em valores observados de $Y_t$ e nas previs√µes anteriores $\hat{Y}_{t|t-1}$, o que torna a previs√£o comput√°vel em tempo real.

### O C√°lculo da Previs√£o
O c√°lculo da previs√£o de um passo √† frente para um processo MA(1) usando a representa√ß√£o recursiva, $\hat{Y}_{t+1|t} = \mu + \theta (Y_t - \hat{Y}_{t|t-1})$, envolve os seguintes passos:

1.  **Inicializa√ß√£o:** Iniciamos o processo definindo uma previs√£o inicial para o primeiro per√≠odo, usualmente a m√©dia do processo: $\hat{Y}_{1|0} = \mu$.

2.  **Itera√ß√£o:** Para cada per√≠odo $t$, com $t \geq 1$, calculamos a previs√£o para o per√≠odo seguinte utilizando o valor observado de $Y_t$ e a previs√£o do per√≠odo anterior $\hat{Y}_{t|t-1}$:
    $$\hat{Y}_{t+1|t} = \mu + \theta (Y_t - \hat{Y}_{t|t-1}).$$
    Este passo √© repetido para cada nova observa√ß√£o.
    
    > üí° **Exemplo Num√©rico:**
>
> Suponhamos um processo MA(1) com $\mu = 10$, $\theta = 0.6$. Vamos simular algumas observa√ß√µes e calcular as previs√µes passo a passo. Considere os seguintes valores simulados para a s√©rie temporal: $Y_1 = 11.2$, $Y_2 = 9.8$, $Y_3 = 10.5$, $Y_4 = 10.1$, $Y_5= 10.9$. Os c√°lculos das previs√µes seriam:
>
> *   Inicializa√ß√£o: $\hat{Y}_{1|0} = 10$.
> *   $t=1$: $\hat{Y}_{2|1} = 10 + 0.6(11.2 - 10) = 10 + 0.6(1.2) = 10.72$.
> *   $t=2$: $\hat{Y}_{3|2} = 10 + 0.6(9.8 - 10.72) = 10 + 0.6(-0.92) = 9.448$.
> *   $t=3$: $\hat{Y}_{4|3} = 10 + 0.6(10.5 - 9.448) = 10 + 0.6(1.052) = 10.6312$.
> *   $t=4$: $\hat{Y}_{5|4} = 10 + 0.6(10.1 - 10.6312) = 10 + 0.6(-0.5312) = 9.6813$.
> *   $t=5$: $\hat{Y}_{6|5} = 10 + 0.6(10.9 - 9.6813) = 10 + 0.6(1.2187) = 10.7312$.
>
> Vamos usar um exemplo com c√≥digo Python para simular os erros e ver como as previs√µes se comportam:
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
>
> # Par√¢metros do processo MA(1)
> mu = 10
> theta = 0.6
> sigma = 1  # Desvio padr√£o do ru√≠do branco
>
> # N√∫mero de observa√ß√µes
> n = 100
>
> # Simula√ß√£o do ru√≠do branco
> errors = np.random.normal(0, sigma, n)
>
> # Simula√ß√£o da s√©rie temporal MA(1)
> Y = np.zeros(n)
> Y[0] = mu + errors[0]
> for t in range(1, n):
>    Y[t] = mu + errors[t] + theta * errors[t-1]
>
> # C√°lculo das previs√µes de um passo √† frente
> Y_hat = np.zeros(n)
> Y_hat[0] = mu # Inicializa√ß√£o
> for t in range(1, n):
>    Y_hat[t] = mu + theta * (Y[t-1] - Y_hat[t-1])
>
> # Visualiza√ß√£o dos resultados
> plt.figure(figsize=(12, 6))
> plt.plot(Y, label='S√©rie Temporal MA(1)')
> plt.plot(Y_hat, label='Previs√£o de 1 Passo √† Frente', linestyle='--')
> plt.xlabel('Tempo')
> plt.ylabel('Valor')
> plt.title('S√©rie Temporal MA(1) e Previs√£o de 1 Passo √† Frente')
> plt.legend()
> plt.grid(True)
> plt.show()
>
> # Calculando os erros de previs√£o (res√≠duos)
> residuals = Y[1:] - Y_hat[1:]
>
> # An√°lise dos res√≠duos
> plt.figure(figsize=(12, 6))
> plt.plot(residuals, marker='o', linestyle='-', label='Res√≠duos')
> plt.axhline(y=0, color='r', linestyle='--', label='Zero Line')
> plt.xlabel('Tempo')
> plt.ylabel('Res√≠duos')
> plt.title('An√°lise de Res√≠duos')
> plt.legend()
> plt.grid(True)
> plt.show()
>
> print(f"Erro quadr√°tico m√©dio: {np.mean(residuals**2)}")
> print(f"M√©dia dos res√≠duos: {np.mean(residuals)}")
> print(f"Desvio padr√£o dos res√≠duos: {np.std(residuals)}")
>
> ```
>
>Este c√≥digo gera um gr√°fico da s√©rie temporal simulada e das previs√µes, bem como um gr√°fico da an√°lise dos res√≠duos. O output tamb√©m apresenta algumas estat√≠sticas da an√°lise dos res√≠duos. A an√°lise dos res√≠duos √© importante para verificar a qualidade da previs√£o. Ideally, they should be random and have mean close to zero.
>
> Este exemplo demonstra como a previs√£o de um passo √† frente √© calculada de forma recursiva e pode ser facilmente implementada em c√≥digo.

  √â importante notar que, para $s>1$ a previs√£o √© simplesmente $\mu$, como vimos anteriormente.

**Lema 1.1**
A previs√£o $s$ passos √† frente para um processo MA(1), com $s>1$, √© igual √† m√©dia do processo, ou seja, $\hat{Y}_{t+s|t} = \mu$.

*Proof:*
 Provaremos que se $s>1$, ent√£o $\hat{Y}_{t+s|t} = \mu$.
 I. A defini√ß√£o de um processo MA(1) √© dada por $Y_t = \mu + \varepsilon_t + \theta\varepsilon_{t-1}$.
 II. A previs√£o $s$ passos √† frente √© definida como o valor esperado condicional de $Y_{t+s}$ dado o conjunto de informa√ß√µes dispon√≠veis at√© o tempo $t$, ou seja:
    $$\hat{Y}_{t+s|t} = E[Y_{t+s}|Y_t, Y_{t-1}, \ldots]$$
 III. Para $s>1$, temos que $Y_{t+s} = \mu + \varepsilon_{t+s} + \theta\varepsilon_{t+s-1}$.
 IV. Dado que os erros $\varepsilon_i$ para $i>t$ s√£o desconhecidos no tempo $t$ e t√™m m√©dia zero, temos:
 $$E[\varepsilon_{t+s}|Y_t, Y_{t-1}, \ldots] = 0$$
  e
 $$E[\varepsilon_{t+s-1}|Y_t, Y_{t-1}, \ldots] = 0$$
 V. Portanto,
 $$\hat{Y}_{t+s|t} = E[\mu + \varepsilon_{t+s} + \theta\varepsilon_{t+s-1}|Y_t, Y_{t-1}, \ldots] = \mu + 0 + 0 = \mu$$
 Isso confirma que a previs√£o para um processo MA(1) para $s>1$ √© simplesmente a m√©dia do processo, $\mu$. ‚ñ†

### Efici√™ncia Computacional
Uma das grandes vantagens da representa√ß√£o recursiva para o c√°lculo da previs√£o de um passo √† frente √© sua efici√™ncia computacional. A express√£o $\hat{Y}_{t+1|t} = \mu + \theta (Y_t - \hat{Y}_{t|t-1})$ envolve apenas uma subtra√ß√£o, uma multiplica√ß√£o e uma adi√ß√£o, o que a torna adequada para aplica√ß√µes em tempo real. A representa√ß√£o autorregressiva de ordem infinita, que poderia ser utilizada alternativamente, exigiria uma soma infinita de termos, o que na pr√°tica, exigiria truncar a s√©rie. A forma recursiva elimina a necessidade de truncar a s√©rie e, portanto, permite um c√°lculo mais preciso e eficiente.

### Conclus√£o
Nesta se√ß√£o, detalhamos o c√°lculo da previs√£o de um passo √† frente para um processo MA(1), utilizando a representa√ß√£o recursiva que deriva da representa√ß√£o autorregressiva infinita. Demonstramos a simplicidade e efici√™ncia computacional desta abordagem, sublinhando como a previs√£o √© expressa em termos dos valores observados da s√©rie temporal e das previs√µes anteriores. A formula√ß√£o recursiva, conforme demonstrado pelo Lema 1 [^4] e Corol√°rio 1.1 [^4], torna o c√°lculo da previs√£o de um passo √† frente f√°cil e r√°pido, ideal para aplica√ß√µes em tempo real.

### Refer√™ncias
[^4]: Se√ß√£o 4.2, [4.2.10], [4.2.28], [4.2.29], [4.2.30], [4.2.16], Lema 1, Corol√°rio 1.1
<!-- END -->
