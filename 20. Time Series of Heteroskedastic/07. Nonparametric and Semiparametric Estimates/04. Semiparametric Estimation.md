## Estimativas Semiparam√©tricas da Heteroskedasticidade Condicional

### Introdu√ß√£o

Em continuidade aos cap√≠tulos anteriores, que abordaram estimativas n√£o param√©tricas e param√©tricas para a heteroskedasticidade condicional, este cap√≠tulo introduz as **estimativas semiparam√©tricas**. Essas abordagens combinam elementos de ambos os mundos, buscando um equil√≠brio entre a flexibilidade das estimativas n√£o param√©tricas e a efici√™ncia e interpretabilidade das estimativas param√©tricas. Especificamente, exploraremos como as estimativas semiparam√©tricas podem combinar uma especifica√ß√£o param√©trica para a vari√¢ncia condicional $h_t$ com uma estimativa n√£o param√©trica para a densidade da inova√ß√£o $\nu_t$.

### Combina√ß√£o de Componentes Param√©tricos e N√£o Param√©tricos

As **estimativas semiparam√©tricas** da heteroskedasticidade condicional buscam aproveitar as vantagens das abordagens param√©tricas e n√£o param√©tricas, mitigando suas desvantagens. Em geral, essas estimativas consistem em especificar parametricamente a forma funcional da vari√¢ncia condicional $h_t$ (como em modelos ARCH ou GARCH) e, simultaneamente, estimar n√£o parametricamente a densidade da inova√ß√£o $\nu_t$ [^1]. A inova√ß√£o $\nu_t$ √© definida como $u_t = \sqrt{h_t}\nu_t$, onde $u_t$ √© o res√≠duo e $h_t$ √© a vari√¢ncia condicional.

A **motiva√ß√£o** para essa abordagem √© que, embora a forma funcional da vari√¢ncia condicional possa ser razoavelmente bem aproximada por um modelo param√©trico, a distribui√ß√£o das inova√ß√µes pode ser mais complexa e dif√≠cil de modelar parametricamente. Muitas s√©ries temporais financeiras exibem caudas mais pesadas do que as distribui√ß√µes normais, o que pode levar a infer√™ncias incorretas se a distribui√ß√£o da inova√ß√£o for modelada incorretamente.

> üí° **Exemplo Num√©rico:** Imagine que estamos modelando a volatilidade di√°ria de uma a√ß√£o. Especificamos um modelo GARCH(1,1) para modelar a vari√¢ncia condicional $h_t$. No entanto, em vez de assumir que as inova√ß√µes $\nu_t$ seguem uma distribui√ß√£o normal, estimamos sua densidade n√£o parametricamente usando uma estimativa de kernel. Isso nos permite capturar a forma real da distribui√ß√£o das inova√ß√µes, mesmo que ela seja diferente da normal.

A **implementa√ß√£o** de uma estimativa semiparam√©trica envolve os seguintes passos:

1.  **Especificar um modelo param√©trico para a vari√¢ncia condicional $h_t$**: Isso pode ser um modelo ARCH, GARCH ou qualquer outra especifica√ß√£o apropriada.
2.  **Estimar os par√¢metros do modelo param√©trico**: Os par√¢metros do modelo param√©trico s√£o estimados usando m√©todos de m√°xima verossimilhan√ßa ou outros m√©todos de estima√ß√£o.
3.  **Calcular os res√≠duos normalizados**: Os res√≠duos normalizados s√£o calculados como $\hat{\nu}_t = u_t / \sqrt{\hat{h}_t}$, onde $\hat{h}_t$ √© a estimativa da vari√¢ncia condicional obtida do modelo param√©trico e $u_t$ s√£o os res√≠duos do modelo de s√©ries temporais original.
4.  **Estimar a densidade das inova√ß√µes n√£o parametricamente**: A densidade das inova√ß√µes $\hat{\nu}_t$ √© estimada usando um m√©todo n√£o param√©trico, como uma estimativa de kernel.
5. **Construir a fun√ß√£o de verossimilhan√ßa:** A fun√ß√£o de verossimilhan√ßa √© constru√≠da usando a especifica√ß√£o param√©trica da vari√¢ncia condicional e a estimativa n√£o param√©trica da densidade das inova√ß√µes.
6. **Maximizar a fun√ß√£o de verossimilhan√ßa:** A fun√ß√£o de verossimilhan√ßa √© maximizada para obter as estimativas dos par√¢metros do modelo. Este passo pode envolver otimiza√ß√£o num√©rica.

> üí° **Exemplo Num√©rico:** Suponha que especificamos um modelo GARCH(1,1) para a vari√¢ncia condicional, onde $h_t = \alpha_0 + \alpha_1 u_{t-1}^2 + \beta_1 h_{t-1}$. Ap√≥s estimar os par√¢metros $\alpha_0, \alpha_1,$ e $\beta_1$ por m√°xima verossimilhan√ßa, obtemos $\hat{\alpha}_0 = 0.01$, $\hat{\alpha}_1 = 0.1$, e $\hat{\beta}_1 = 0.8$. Os res√≠duos normalizados s√£o ent√£o calculados usando esses par√¢metros estimados e a s√©rie de retornos original.

A **vantagem** dessa abordagem √© que ela permite capturar a heteroskedasticidade condicional e a forma n√£o normal da distribui√ß√£o da inova√ß√£o de forma flex√≠vel. A especifica√ß√£o param√©trica da vari√¢ncia condicional fornece uma estrutura para modelar a depend√™ncia temporal da volatilidade, enquanto a estimativa n√£o param√©trica da densidade da inova√ß√£o permite modelar a forma real da distribui√ß√£o, mesmo que ela seja complexa.

> üí° **Exemplo Num√©rico:** Suponha que ap√≥s estimar um modelo GARCH(1,1) para os retornos di√°rios de uma a√ß√£o, calculamos os res√≠duos normalizados $\hat{\nu}_t$. Observamos que a distribui√ß√£o dos res√≠duos normalizados tem caudas mais pesadas do que uma distribui√ß√£o normal. Estimamos a densidade dos res√≠duos normalizados n√£o parametricamente usando uma estimativa de kernel. Ao usar essa estimativa n√£o param√©trica da densidade na fun√ß√£o de verossimilhan√ßa, podemos obter estimativas mais precisas dos par√¢metros do modelo GARCH(1,1) e, consequentemente, melhores previs√µes da volatilidade.

No contexto da modelagem semiparam√©trica da vari√¢ncia condicional, a **fun√ß√£o de verossimilhan√ßa** (likelihood function) desempenha um papel fundamental. Ela permite combinar a parte param√©trica (vari√¢ncia condicional) com a parte n√£o param√©trica (densidade da inova√ß√£o). A verossimilhan√ßa √© ent√£o maximizada para estimar os par√¢metros do modelo.

Vamos supor que temos um modelo param√©trico para a vari√¢ncia condicional $h_t(\theta)$, onde $\theta$ √© o vetor de par√¢metros. Tamb√©m temos uma estimativa n√£o param√©trica da fun√ß√£o de densidade de probabilidade (PDF) das inova√ß√µes $\nu_t$, denotada por $\hat{f}(\nu_t)$.

A **fun√ß√£o de verossimilhan√ßa condicional** para uma amostra de $T$ observa√ß√µes √© dada por:

$$
L(\theta) = \prod_{t=1}^{T} \frac{1}{\sqrt{h_t(\theta)}} \hat{f}\left(\frac{u_t}{\sqrt{h_t(\theta)}}\right)
$$

Onde:

*   $u_t$ s√£o os res√≠duos observados da s√©rie temporal.
*   $h_t(\theta)$ √© a vari√¢ncia condicional modelada parametricamente, dependendo do vetor de par√¢metros $\theta$.
*   $\hat{f}(\nu_t)$ √© a estimativa n√£o param√©trica da densidade da inova√ß√£o $\nu_t = \frac{u_t}{\sqrt{h_t(\theta)}}$.

A **log-verossimilhan√ßa** √© ent√£o:

$$
\log L(\theta) = \sum_{t=1}^{T} \left[-\frac{1}{2} \log(h_t(\theta)) + \log\left(\hat{f}\left(\frac{u_t}{\sqrt{h_t(\theta)}}\right)\right)\right]
$$

O objetivo √© **maximizar esta log-verossimilhan√ßa em rela√ß√£o a $\theta$**, ou seja:

$$
\hat{\theta} = \arg\max_{\theta} \log L(\theta)
$$

Onde $\hat{\theta}$ s√£o as estimativas de m√°xima verossimilhan√ßa dos par√¢metros do modelo.

> üí° **Exemplo Num√©rico:** Considere um modelo GARCH(1,1) com $\theta = (\alpha_0, \alpha_1, \beta_1)$. Suponha que ap√≥s a estima√ß√£o n√£o param√©trica da densidade das inova√ß√µes, descobrimos que a densidade estimada $\hat{f}(\nu_t)$ atribui maior probabilidade a valores extremos do que uma distribui√ß√£o normal. Ao maximizar a fun√ß√£o de log-verossimilhan√ßa usando essa densidade estimada, obtemos estimativas para $\theta$ que levam em conta a presen√ßa de caudas pesadas, resultando em previs√µes de volatilidade mais precisas, especialmente em per√≠odos de alta volatilidade.

**Teorema 1** [Consist√™ncia e Normalidade Assint√≥tica]
Sob condi√ß√µes de regularidade apropriadas, as estimativas semiparam√©tricas convergem em probabilidade para os verdadeiros valores dos par√¢metros e possuem uma distribui√ß√£o normal assint√≥tica.

*Proof strategy:* A prova envolve a demonstra√ß√£o de que o estimador de m√°xima verossimilhan√ßa semiparam√©trico √© consistente e assintoticamente normal. Isso requer impor condi√ß√µes sobre a identifica√ß√£o dos par√¢metros, a suavidade da fun√ß√£o de verossimilhan√ßa e a taxa de converg√™ncia da estimativa n√£o param√©trica da densidade.

**Prova do Teorema 1**

Para provar a consist√™ncia e a normalidade assint√≥tica das estimativas semiparam√©tricas, precisamos seguir v√°rios passos que garantem que o estimador de m√°xima verossimilhan√ßa (MLE) semiparam√©trico se comporte de maneira previs√≠vel √† medida que o tamanho da amostra aumenta.

I. **Consist√™ncia:**

Para provar a consist√™ncia, precisamos mostrar que $\hat{\theta}$ converge em probabilidade para o verdadeiro valor $\theta_0$, ou seja, para qualquer $\epsilon > 0$:

$$
\lim_{T \to \infty} P(|\hat{\theta} - \theta_0| > \epsilon) = 0
$$

A. **Identifica√ß√£o:** Devemos garantir que o modelo seja identificado, ou seja, que diferentes valores dos par√¢metros $\theta$ levem a diferentes distribui√ß√µes observ√°veis dos dados. Isso significa que:

$$
P_{\theta_1} \neq P_{\theta_2} \text{ para } \theta_1 \neq \theta_2
$$

B. **Continuidade e Domina√ß√£o:** Asseguramos que a log-verossimilhan√ßa seja cont√≠nua em $\theta$ e que exista uma fun√ß√£o dominadora $M(u_t)$ tal que:

$$
|log L(\theta)| \leq M(u_t)
$$

e $E[M(u_t)] < \infty$.

C. **Converg√™ncia Uniforme:** Mostramos que a log-verossimilhan√ßa amostral converge uniformemente em probabilidade para a log-verossimilhan√ßa esperada:

$$
\sup_{\theta} \left| \frac{1}{T} \sum_{t=1}^{T} log L_t(\theta) - E[log L_t(\theta)] \right| \xrightarrow{p} 0
$$

D. **Conclus√£o da Consist√™ncia:** Com essas condi√ß√µes, podemos aplicar o teorema de consist√™ncia do MLE, que garante que $\hat{\theta}$ converge em probabilidade para $\theta_0$.

II. **Normalidade Assint√≥tica:**

Para provar a normalidade assint√≥tica, precisamos mostrar que $\sqrt{T}(\hat{\theta} - \theta_0)$ converge em distribui√ß√£o para uma distribui√ß√£o normal com m√©dia zero e matriz de covari√¢ncia $\Sigma$, ou seja:

$$
\sqrt{T}(\hat{\theta} - \theta_0) \xrightarrow{d} N(0, \Sigma)
$$

A. **Expans√£o de Taylor:** Expandimos a fun√ß√£o escore (primeira derivada da log-verossimilhan√ßa) em torno do verdadeiro valor $\theta_0$:

$$
S(\hat{\theta}) = S(\theta_0) + H(\theta_0)(\hat{\theta} - \theta_0) + O_p(\|\hat{\theta} - \theta_0\|^2)
$$

onde $S(\theta)$ √© a fun√ß√£o escore e $H(\theta)$ √© a matriz Hessiana (segunda derivada da log-verossimilhan√ßa).

B. **Condi√ß√µes de Regularidade:** Assumimos as seguintes condi√ß√µes de regularidade:

   * A fun√ß√£o escore tem m√©dia zero e vari√¢ncia finita.
   * A matriz Hessiana satisfaz a lei dos grandes n√∫meros, convergindo para uma matriz definida negativa $\mathcal{I}(\theta_0)$ (a matriz de informa√ß√£o de Fisher):

$$
-\frac{1}{T}H(\theta_0) \xrightarrow{p} \mathcal{I}(\theta_0)
$$

   * A estimativa n√£o param√©trica da densidade $\hat{f}(\nu_t)$ converge para a verdadeira densidade $f(\nu_t)$ a uma taxa apropriada.

C. **Teorema do Limite Central:** Aplicamos o teorema do limite central para a fun√ß√£o escore:

$$
\frac{1}{\sqrt{T}}S(\theta_0) \xrightarrow{d} N(0, \mathcal{I}(\theta_0))
$$

D. **Deriva√ß√£o da Distribui√ß√£o Assint√≥tica:** Usando a expans√£o de Taylor e as condi√ß√µes de regularidade, obtemos:

$$
\sqrt{T}(\hat{\theta} - \theta_0) \approx -\mathcal{I}(\theta_0)^{-1} \frac{1}{\sqrt{T}}S(\theta_0)
$$

Aplicando o teorema do limite central, conclu√≠mos que:

$$
\sqrt{T}(\hat{\theta} - \theta_0) \xrightarrow{d} N(0, \mathcal{I}(\theta_0)^{-1})
$$

Portanto, a matriz de covari√¢ncia assint√≥tica √© $\Sigma = \mathcal{I}(\theta_0)^{-1}$.

Em resumo, sob as condi√ß√µes de regularidade apropriadas, as estimativas semiparam√©tricas $\hat{\theta}$ s√£o consistentes e assintoticamente normais. A consist√™ncia √© garantida pela identifica√ß√£o do modelo e pela converg√™ncia uniforme da log-verossimilhan√ßa, enquanto a normalidade assint√≥tica segue do teorema do limite central aplicado √† fun√ß√£o escore. ‚ñ†

> üí° **Exemplo Num√©rico:** Suponha que estamos usando um modelo semiparam√©trico para estimar a volatilidade de uma a√ß√£o. Ap√≥s estimar os par√¢metros do modelo, obtemos um intervalo de confian√ßa para um dos par√¢metros, digamos, $\alpha$, que representa a persist√™ncia da volatilidade. Se o intervalo de confian√ßa for [0.8, 0.9], podemos concluir que a volatilidade da a√ß√£o √© altamente persistente.

### Desafios e Considera√ß√µes

Embora as estimativas semiparam√©tricas ofere√ßam vantagens significativas, elas tamb√©m apresentam desafios e considera√ß√µes importantes:

1.  **Escolha do Modelo Param√©trico:** A escolha do modelo param√©trico para a vari√¢ncia condicional pode afetar o desempenho da estimativa semiparam√©trica. √â importante escolher um modelo que capture as caracter√≠sticas essenciais da depend√™ncia temporal da volatilidade.
2.  **Estimativa N√£o Param√©trica da Densidade:** A estimativa n√£o param√©trica da densidade pode ser sens√≠vel √† escolha do m√©todo de estima√ß√£o e dos par√¢metros de suaviza√ß√£o. √â importante escolher um m√©todo de estima√ß√£o apropriado e otimizar os par√¢metros de suaviza√ß√£o usando t√©cnicas como valida√ß√£o cruzada.
3.  **C√°lculo da Fun√ß√£o de Verossimilhan√ßa:** O c√°lculo da fun√ß√£o de verossimilhan√ßa pode ser computacionalmente intensivo, especialmente para grandes conjuntos de dados. √â importante usar algoritmos de otimiza√ß√£o eficientes para maximizar a fun√ß√£o de verossimilhan√ßa.
4.  **Condi√ß√µes de Regularidade:** A consist√™ncia e a normalidade assint√≥tica das estimativas semiparam√©tricas dependem do cumprimento de certas condi√ß√µes de regularidade. √â importante verificar se essas condi√ß√µes s√£o satisfeitas nos dados em an√°lise.

Para lidar com o desafio da escolha da especifica√ß√£o param√©trica para $h_t$, podemos utilizar testes de especifica√ß√£o para modelos de heteroskedasticidade condicional, como o teste de Box-Pierce aplicado aos quadrados dos res√≠duos normalizados. Esses testes podem ajudar a identificar se a especifica√ß√£o param√©trica captura adequadamente a depend√™ncia temporal da volatilidade.

> üí° **Exemplo Num√©rico:** Suponha que, ap√≥s ajustar um modelo GARCH(1,1), aplicamos o teste de Box-Pierce aos quadrados dos res√≠duos normalizados e obtemos um valor-p de 0.03. Isso indica que h√° evid√™ncias de autocorrela√ß√£o nos quadrados dos res√≠duos normalizados, sugerindo que a especifica√ß√£o GARCH(1,1) pode n√£o capturar completamente a din√¢mica da volatilidade e que uma especifica√ß√£o mais complexa ou uma abordagem semiparam√©trica pode ser mais apropriada.

**Lema 1** [Adapta√ß√£o Assint√≥tica]
Sob certas condi√ß√µes, as estimativas semiparam√©tricas adaptam-se assintoticamente √† verdadeira distribui√ß√£o das inova√ß√µes, no sentido de que o estimador de m√°xima verossimilhan√ßa semiparam√©trico atinge a mesma efici√™ncia assint√≥tica que o estimador de m√°xima verossimilhan√ßa param√©trico, se a verdadeira distribui√ß√£o das inova√ß√µes fosse conhecida.

*Proof strategy:* A prova envolve mostrar que a perda de efici√™ncia devido √† estimativa n√£o param√©trica da densidade converge para zero √† medida que o tamanho da amostra aumenta. Isso requer impor condi√ß√µes sobre a taxa de converg√™ncia da estimativa n√£o param√©trica e a suavidade da fun√ß√£o de verossimilhan√ßa.

**Prova do Lema 1**

Para demonstrar a adapta√ß√£o assint√≥tica das estimativas semiparam√©tricas, precisamos mostrar que a perda de efici√™ncia devido √† estimativa n√£o param√©trica da densidade converge para zero √† medida que o tamanho da amostra aumenta.

I. **Defini√ß√£o de Efici√™ncia Assint√≥tica:** A efici√™ncia assint√≥tica de um estimador √© medida pela sua vari√¢ncia assint√≥tica. Um estimador √© assintoticamente eficiente se sua vari√¢ncia assint√≥tica atinge o limite inferior de Cram√©r-Rao.

II. **Estimador de M√°xima Verossimilhan√ßa Param√©trico:** Seja $\theta_{MLE}$ o estimador de m√°xima verossimilhan√ßa param√©trico, assumindo que a verdadeira distribui√ß√£o das inova√ß√µes √© conhecida. Sua vari√¢ncia assint√≥tica √© dada pelo limite inferior de Cram√©r-Rao:

   $$
   Var(\sqrt{T}(\theta_{MLE} - \theta_0)) \to \mathcal{I}^{-1}(\theta_0)
   $$

   onde $\mathcal{I}(\theta_0)$ √© a matriz de informa√ß√£o de Fisher avaliada no verdadeiro valor dos par√¢metros $\theta_0$.

III. **Estimador de M√°xima Verossimilhan√ßa Semiparam√©trico:** Seja $\hat{\theta}$ o estimador de m√°xima verossimilhan√ßa semiparam√©trico. Sua vari√¢ncia assint√≥tica √© dada por:

   $$
   Var(\sqrt{T}(\hat{\theta} - \theta_0)) \to \Sigma
   $$

   onde $\Sigma$ √© a matriz de covari√¢ncia assint√≥tica do estimador semiparam√©trico.

IV. **Perda de Efici√™ncia:** A perda de efici√™ncia devido √† estimativa n√£o param√©trica da densidade √© medida pela diferen√ßa entre as vari√¢ncias assint√≥ticas dos estimadores param√©trico e semiparam√©trico:

   $$
   Perda = Var(\sqrt{T}(\hat{\theta} - \theta_0)) - Var(\sqrt{T}(\theta_{MLE} - \theta_0)) = \Sigma - \mathcal{I}^{-1}(\theta_0)
   $$

V. **Condi√ß√µes para Adapta√ß√£o Assint√≥tica:** Para que a estimativa semiparam√©trica se adapte assintoticamente √† verdadeira distribui√ß√£o das inova√ß√µes, a perda de efici√™ncia deve convergir para zero √† medida que o tamanho da amostra aumenta. Isso requer as seguintes condi√ß√µes:

   A. **Taxa de Converg√™ncia:** A estimativa n√£o param√©trica da densidade $\hat{f}(\nu_t)$ deve convergir para a verdadeira densidade $f(\nu_t)$ a uma taxa suficientemente r√°pida:

      $$
      \sup_{\nu} |\hat{f}(\nu) - f(\nu)| = O_p(T^{-a})
      $$

      onde $a > 1/4$.

   B. **Suavidade da Fun√ß√£o de Verossimilhan√ßa:** A fun√ß√£o de verossimilhan√ßa deve ser suficientemente suave em rela√ß√£o √† densidade da inova√ß√£o.

VI. **Conclus√£o:** Sob essas condi√ß√µes, a perda de efici√™ncia converge para zero √† medida que o tamanho da amostra aumenta, o que implica que o estimador de m√°xima verossimilhan√ßa semiparam√©trico atinge a mesma efici√™ncia assint√≥tica que o estimador de m√°xima verossimilhan√ßa param√©trico, se a verdadeira distribui√ß√£o das inova√ß√µes fosse conhecida. ‚ñ†

> üí° **Exemplo Num√©rico:** Imagine que comparamos o desempenho de um modelo GARCH(1,1) padr√£o (param√©trico) com um modelo semiparam√©trico que utiliza uma estimativa de kernel para a densidade das inova√ß√µes. Ap√≥s analisar um longo per√≠odo de dados, descobrimos que o modelo semiparam√©trico tem um erro quadr√°tico m√©dio (MSE) ligeiramente menor e um intervalo de confian√ßa mais estreito para os par√¢metros do modelo. Isso sugere que o modelo semiparam√©trico se adapta melhor aos dados e fornece estimativas mais precisas.

**Teorema 1.1** [Robustez √† m√° especifica√ß√£o da densidade]
Sob condi√ß√µes de regularidade, o estimador semiparam√©trico √© mais robusto √† m√° especifica√ß√£o da densidade da inova√ß√£o do que o estimador param√©trico padr√£o.

*Proof strategy:* A prova envolve comparar a sensibilidade dos dois estimadores a desvios da verdadeira densidade da inova√ß√£o. O estimador semiparam√©trico, ao estimar a densidade n√£o parametricamente, √© menos sens√≠vel a erros na especifica√ß√£o da forma funcional da densidade.

**Prova do Teorema 1.1**
Para demonstrar a robustez do estimador semiparam√©trico √† m√° especifica√ß√£o da densidade da inova√ß√£o em compara√ß√£o com o estimador param√©trico padr√£o, precisamos analisar como ambos os estimadores se comportam quando a distribui√ß√£o verdadeira das inova√ß√µes difere da distribui√ß√£o assumida pelo modelo.

I. **Estimador Param√©trico:**
   - Assume-se uma forma funcional espec√≠fica para a densidade da inova√ß√£o, $f(\nu_t; \eta)$, onde $\eta$ √© o vetor de par√¢metros da distribui√ß√£o.
   - A fun√ß√£o de verossimilhan√ßa √© constru√≠da com base nessa densidade:

   $$
   L(\theta, \eta) = \prod_{t=1}^{T} \frac{1}{\sqrt{h_t(\theta)}} f\left(\frac{u_t}{\sqrt{h_t(\theta)}}; \eta\right)
   $$

   - O estimador param√©trico $(\hat{\theta}_{P}, \hat{\eta}_{P})$ √© obtido maximizando esta fun√ß√£o de verossimilhan√ßa.

II. **Estimador Semiparam√©trico:**
   - A forma funcional da densidade da inova√ß√£o √© estimada n√£o parametricamente, $\hat{f}(\nu_t)$.
   - A fun√ß√£o de verossimilhan√ßa √© constru√≠da usando esta estimativa n√£o param√©trica:

   $$
   L(\theta) = \prod_{t=1}^{T} \frac{1}{\sqrt{h_t(\theta)}} \hat{f}\left(\frac{u_t}{\sqrt{h_t(\theta)}}\right)
   $$

   - O estimador semiparam√©trico $\hat{\theta}_{SP}$ √© obtido maximizando esta fun√ß√£o de verossimilhan√ßa.

III. **An√°lise da Robustez:**
   - Suponha que a verdadeira densidade da inova√ß√£o seja $f^{*}(\nu_t)$, que difere da densidade assumida $f(\nu_t; \eta)$ no modelo param√©trico.
   - A robustez de um estimador pode ser avaliada pela sua sensibilidade a esta diferen√ßa. Uma medida comum √© o vi√©s assint√≥tico do estimador sob m√° especifica√ß√£o.

IV. **Vi√©s Assint√≥tico:**
   - O vi√©s assint√≥tico do estimador param√©trico √© dado por:

   $$
   Bias(\hat{\theta}_{P}) = \lim_{T \to \infty} E[\hat{\theta}_{P} - \theta_0]
   $$

   sob a verdadeira densidade $f^{*}(\nu_t)$. Este vi√©s pode ser significativo se a diferen√ßa entre $f(\nu_t; \eta)$ e $f^{*}(\nu_t)$ for grande.
   - O vi√©s assint√≥tico do estimador semiparam√©trico √© dado por:

   $$
   Bias(\hat{\theta}_{SP}) = \lim_{T \to \infty} E[\hat{\theta}_{SP} - \theta_0]
   $$

   sob a verdadeira densidade $f^{*}(\nu_t)$. Como $\hat{f}(\nu_t)$ √© uma estimativa n√£o param√©trica que se aproxima de $f^{*}(\nu_t)$ √† medida que o tamanho da amostra aumenta, o vi√©s do estimador semiparam√©trico tende a ser menor.

V. **Condi√ß√µes de Regularidade:**
   - Para garantir que o estimador semiparam√©trico seja mais robusto, as seguintes condi√ß√µes devem ser satisfeitas:
      1. A estimativa n√£o param√©trica $\hat{f}(\nu_t)$ deve convergir para $f^{*}(\nu_t)$ a uma taxa apropriada.
      2. A fun√ß√£o de verossimilhan√ßa deve ser suficientemente suave em rela√ß√£o √† densidade da inova√ß√£o.
      3. A especifica√ß√£o param√©trica da vari√¢ncia condicional $h_t(\theta)$ deve ser razoavelmente precisa.

VI. **Conclus√£o:**
   - Sob as condi√ß√µes de regularidade apropriadas, o estimador semiparam√©trico √© mais robusto √† m√° especifica√ß√£o da densidade da inova√ß√£o do que o estimador param√©trico padr√£o. Isso ocorre porque a estimativa n√£o param√©trica da densidade permite que o modelo se adapte √† verdadeira distribui√ß√£o das inova√ß√µes, reduzindo o vi√©s assint√≥tico.

Em resumo, o estimador semiparam√©trico oferece uma prote√ß√£o contra a m√° especifica√ß√£o da densidade da inova√ß√£o, o que o torna uma escolha mais robusta em situa√ß√µes onde a verdadeira distribui√ß√£o √© desconhecida ou dif√≠cil de modelar parametricamente. ‚ñ†

> üí° **Exemplo Num√©rico:** Suponha que estamos modelando a volatilidade de retornos de a√ß√µes e a verdadeira distribui√ß√£o dos erros tem caudas mais pesadas que a distribui√ß√£o normal assumida por um modelo GARCH padr√£o. Um modelo GARCH padr√£o subestimar√° a probabilidade de grandes choques, levando a previs√µes de volatilidade imprecisas. Um modelo semiparam√©trico, que estima a distribui√ß√£o dos erros n√£o parametricamente, se ajustar√° melhor √† verdadeira distribui√ß√£o, resultando em previs√µes de volatilidade mais precisas e robustas.

### Conclus√£o

As estimativas semiparam√©tricas da heteroskedasticidade condicional oferecem uma abordagem flex√≠vel e eficiente para modelar a volatilidade de s√©ries temporais financeiras. Ao combinar uma especifica√ß√£o param√©trica para a vari√¢ncia condicional com uma estimativa n√£o param√©trica para a densidade da inova√ß√£o, esses m√©todos podem capturar padr√µes complexos que os modelos param√©tricos podem n√£o conseguir identificar. Embora a implementa√ß√£o de estimativas semiparam√©tricas apresente desafios computacionais e te√≥ricos, as vantagens em termos de precis√£o e robustez tornam essa abordagem uma ferramenta valiosa para a an√°lise de s√©ries temporais financeiras.

### Refer√™ncias

[^1]: Cap√≠tulo 21, "Time Series Models of Heteroskedasticity".
<!-- END -->