## Modelos AR(p) e Previs√£o Linear √ìtima em S√©ries Temporais Heterosced√°sticas

### Introdu√ß√£o

Este cap√≠tulo explora em profundidade os **modelos autoregressivos de ordem *p* (AR(*p*))** no contexto de s√©ries temporais heterosced√°sticas. Em particular, focamos na defini√ß√£o formal de um processo AR(*p*) [^1], suas propriedades estat√≠sticas, e como estes modelos s√£o utilizados para a previs√£o linear √≥tima. Exploraremos a import√¢ncia de garantir a estacionariedade do processo, a forma da previs√£o linear √≥tima e como a heteroscedasticidade condicional se manifesta nesse contexto.

### Conceitos Fundamentais

Um processo autoregressivo de ordem *p*, denotado AR(*p*) [^1], √© um modelo estat√≠stico utilizado para descrever s√©ries temporais em que o valor atual da s√©rie, $y_t$, depende linearmente de seus *p* valores passados, juntamente com um termo de erro (ou inova√ß√£o) $u_t$. Formalmente, o modelo √© definido como:

$$ y_t = c + \phi_1 y_{t-1} + \phi_2 y_{t-2} + \dots + \phi_p y_{t-p} + u_t $$

onde:
*   $y_t$ √© o valor da s√©rie temporal no instante *t*.
*   $c$ √© uma constante (intercepto).
*   $\phi_1, \phi_2, \dots, \phi_p$ s√£o os coeficientes autoregressivos que quantificam a influ√™ncia dos valores passados da s√©rie.
*   $y_{t-1}, y_{t-2}, \dots, y_{t-p}$ s√£o os *p* valores passados da s√©rie temporal.
*   $u_t$ √© o termo de erro ou ru√≠do branco no instante *t*.

> üí° **Exemplo Num√©rico:** Considere um modelo AR(1) com $c = 5$, $\phi_1 = 0.7$ e $u_t \sim N(0, 2)$.  Se $y_{t-1} = 10$, ent√£o $y_t = 5 + 0.7 * 10 + u_t = 12 + u_t$.  Em um cen√°rio espec√≠fico, se $u_t = -1$, ent√£o $y_t = 11$. Este exemplo ilustra como o valor atual √© uma combina√ß√£o linear do valor anterior e um choque aleat√≥rio.

O termo de erro $u_t$ √© caracterizado como **ru√≠do branco** [^1], o que implica que ele satisfaz as seguintes condi√ß√µes:

1.  **M√©dia zero:** $E(u_t) = 0$ [^1].
2.  **Vari√¢ncia constante:** $E(u_t u_\tau) = \sigma^2$ para $t = \tau$ e $E(u_t u_\tau) = 0$ caso contr√°rio [^1]. Isso significa que a vari√¢ncia de $u_t$ √© constante ao longo do tempo e n√£o h√° autocorrela√ß√£o entre os erros em diferentes instantes.

> üí° **Exemplo Num√©rico:** Suponha que $u_t$ tenha uma vari√¢ncia de $\sigma^2 = 4$. Isso significa que o desvio padr√£o de $u_t$ √© $\sqrt{4} = 2$. Em simula√ß√µes, esperar√≠amos que aproximadamente 68% dos valores de $u_t$ estejam entre -2 e 2, e aproximadamente 95% entre -4 e 4.

Para que o processo AR(*p*) seja **estacion√°rio** (em covari√¢ncia), as ra√≠zes do polin√¥mio caracter√≠stico associado devem estar fora do c√≠rculo unit√°rio [^1]. O polin√¥mio caracter√≠stico √© dado por:

$$ 1 - \phi_1 z - \phi_2 z^2 - \dots - \phi_p z^p = 0 $$

onde *z* √© uma vari√°vel complexa. Se todas as ra√≠zes deste polin√¥mio tiverem m√≥dulo maior que 1, o processo AR(*p*) √© estacion√°rio. A estacionariedade √© crucial para que o modelo AR(*p*) seja √∫til para previs√£o e an√°lise, pois garante que as propriedades estat√≠sticas da s√©rie temporal n√£o mudem ao longo do tempo.

> üí° **Exemplo Num√©rico:** Considere um processo AR(1) com $\phi_1 = 0.5$. O polin√¥mio caracter√≠stico √© $1 - 0.5z = 0$. A raiz √© $z = 2$, que tem um m√≥dulo maior que 1, ent√£o o processo √© estacion√°rio.  Agora, se $\phi_1 = 1.2$, a raiz √© $z = 1/1.2 \approx 0.83$, que tem um m√≥dulo menor que 1, indicando que o processo n√£o √© estacion√°rio.

**Teorema 1** (Condi√ß√£o de Estacionariedade Alternativa): Um processo AR(p) √© estacion√°rio se e somente se todos os valores de *z* que satisfazem a equa√ß√£o $z^p - \phi_1 z^{p-1} - \phi_2 z^{p-2} - \dots - \phi_p = 0$ possuem m√≥dulo menor que 1.
*Proof:* Esta √© uma representa√ß√£o alternativa da condi√ß√£o de estacionariedade, obtida manipulando o polin√¥mio caracter√≠stico original. A equival√™ncia decorre da rela√ß√£o entre as ra√≠zes de um polin√¥mio e os seus coeficientes.

A estacionariedade implica que a fun√ß√£o de autocorrela√ß√£o (ACF) do processo AR(*p*) decai para zero √† medida que a defasagem aumenta. Al√©m disso, processos AR(*p*) estacion√°rios possuem representa√ß√£o como um processo de m√©dias m√≥veis de ordem infinita (MA($\infty$)).

A **previs√£o linear √≥tima** do n√≠vel de $y_t$ para um processo AR(*p*) estacion√°rio [^1] √© dada pela proje√ß√£o linear de $y_t$ sobre os seus passados, ou seja:

$$ \hat{E}(y_t | y_{t-1}, y_{t-2}, \dots) = c + \phi_1 y_{t-1} + \phi_2 y_{t-2} + \dots + \phi_p y_{t-p} $$

onde $\hat{E}(y_t | y_{t-1}, y_{t-2}, \dots)$ denota a proje√ß√£o linear de $y_t$ sobre uma constante e $(y_{t-1}, y_{t-2}, \dots)$. Enquanto a m√©dia condicional de $y_t$ muda ao longo do tempo de acordo com [21.1.4], se o processo for estacion√°rio, a m√©dia incondicional de $y_t$ √© constante e dada por:

$$ E(y_t) = \frac{c}{1 - \phi_1 - \phi_2 - \dots - \phi_p} $$

> üí° **Exemplo Num√©rico:**  Considere um AR(2) com $c=10$, $\phi_1 = 0.4$ e $\phi_2 = 0.3$.  A m√©dia incondicional √© $E(y_t) = \frac{10}{1 - 0.4 - 0.3} = \frac{10}{0.3} \approx 33.33$. Isto significa que, a longo prazo, a s√©rie temporal ir√° flutuar em torno deste valor.

**Prova:**
Para provar que a m√©dia incondicional de $y_t$ √© dada por $ E(y_t) = \frac{c}{1 - \phi_1 - \phi_2 - \dots - \phi_p} $, sob a condi√ß√£o de estacionariedade, procedemos da seguinte forma:

I. Assumimos que o processo √© estacion√°rio, o que implica que a m√©dia $E(y_t)$ √© constante ao longo do tempo, ou seja, $E(y_t) = E(y_{t-1}) = E(y_{t-2}) = \dots = \mu$.

II. Tomamos a esperan√ßa da equa√ß√£o do modelo AR(p):
    $$E(y_t) = E(c + \phi_1 y_{t-1} + \phi_2 y_{t-2} + \dots + \phi_p y_{t-p} + u_t)$$

III. Usamos a propriedade da linearidade da esperan√ßa:
     $$E(y_t) = E(c) + \phi_1 E(y_{t-1}) + \phi_2 E(y_{t-2}) + \dots + \phi_p E(y_{t-p}) + E(u_t)$$

IV. Como $E(y_t) = \mu$ para todo *t* e $E(u_t) = 0$, substitu√≠mos na equa√ß√£o:
    $$\mu = c + \phi_1 \mu + \phi_2 \mu + \dots + \phi_p \mu + 0$$

V. Fatoramos $\mu$ do lado direito da equa√ß√£o:
   $$\mu = c + \mu(\phi_1 + \phi_2 + \dots + \phi_p)$$

VI. Isolamos $\mu$:
    $$\mu - \mu(\phi_1 + \phi_2 + \dots + \phi_p) = c$$
    $$\mu(1 - \phi_1 - \phi_2 - \dots - \phi_p) = c$$

VII. Finalmente, dividimos ambos os lados por $(1 - \phi_1 - \phi_2 - \dots - \phi_p)$ para obter a m√©dia incondicional:
     $$\mu = \frac{c}{1 - \phi_1 - \phi_2 - \dots - \phi_p}$$

Portanto, demonstramos que $E(y_t) = \frac{c}{1 - \phi_1 - \phi_2 - \dots - \phi_p}$ ‚ñ†

√â importante notar que a vari√¢ncia da previs√£o tamb√©m pode ser calculada.

**Teorema 2** (Vari√¢ncia do Erro de Previs√£o): A vari√¢ncia do erro de previs√£o para um passo √† frente, $e_t = y_t - \hat{E}(y_t | y_{t-1}, y_{t-2}, \dots)$, √© dada por $Var(e_t) = E(u_t^2) = \sigma^2$.

*Proof:* Como $\hat{E}(y_t | y_{t-1}, y_{t-2}, \dots)$ √© a proje√ß√£o linear √≥tima, o erro de previs√£o √© ortogonal aos regressores. Assim, $e_t = u_t$, e a vari√¢ncia do erro de previs√£o √© simplesmente a vari√¢ncia do termo de erro.

**Prova:**
Para provar que a vari√¢ncia do erro de previs√£o para um passo √† frente √© $Var(e_t) = E(u_t^2) = \sigma^2$, seguimos os seguintes passos:

I. Definimos o erro de previs√£o para um passo √† frente como a diferen√ßa entre o valor real $y_t$ e a previs√£o linear √≥tima $\hat{E}(y_t | y_{t-1}, y_{t-2}, \dots)$:
   $$e_t = y_t - \hat{E}(y_t | y_{t-1}, y_{t-2}, \dots)$$

II. Substitu√≠mos $y_t$ pela sua express√£o no modelo AR(p):
    $$e_t = (c + \phi_1 y_{t-1} + \phi_2 y_{t-2} + \dots + \phi_p y_{t-p} + u_t) - \hat{E}(y_t | y_{t-1}, y_{t-2}, \dots)$$

III. Substitu√≠mos a previs√£o linear √≥tima:
     $$e_t = (c + \phi_1 y_{t-1} + \phi_2 y_{t-2} + \dots + \phi_p y_{t-p} + u_t) - (c + \phi_1 y_{t-1} + \phi_2 y_{t-2} + \dots + \phi_p y_{t-p})$$

IV. Simplificamos a express√£o:
    $$e_t = u_t$$

V. Calculamos a vari√¢ncia do erro de previs√£o:
   $$Var(e_t) = Var(u_t)$$

VI. Como $u_t$ √© ru√≠do branco com vari√¢ncia $\sigma^2$, temos:
    $$Var(u_t) = E(u_t^2) = \sigma^2$$

VII. Portanto, conclu√≠mos que a vari√¢ncia do erro de previs√£o √©:
     $$Var(e_t) = E(u_t^2) = \sigma^2$$ ‚ñ†

**Corol√°rio 2.1**: A vari√¢ncia do erro de previs√£o *k*-passos √† frente geralmente aumenta com *k*.

> üí° **Exemplo Num√©rico:** No AR(1) do exemplo anterior ($c = 5$, $\phi_1 = 0.7$, $u_t \sim N(0, 2)$), para prever $y_{t+1}$ dado $y_t = 11$, temos $\hat{y}_{t+1} = 5 + 0.7 * 11 = 12.7$. O erro de previs√£o tem vari√¢ncia $\sigma^2 = 2$. Para prever $y_{t+2}$, temos $\hat{y}_{t+2} = 5 + 0.7 * \hat{y}_{t+1} = 5 + 0.7 * 12.7 = 13.89$. A vari√¢ncia do erro de previs√£o para 2 passos √† frente ser√° maior que 2, pois acumula a incerteza da previs√£o de $y_{t+1}$.

A demonstra√ß√£o do corol√°rio 2.1 requer a an√°lise recursiva da previs√£o *k*-passos √† frente e a propaga√ß√£o dos erros.

Al√©m disso, a fun√ß√£o de autocorrela√ß√£o parcial (PACF) √© uma ferramenta √∫til para identificar a ordem *p* de um processo AR(*p*). A PACF mede a correla√ß√£o entre $y_t$ e $y_{t-k}$ ap√≥s remover o efeito das defasagens intermedi√°rias $y_{t-1}, y_{t-2}, \dots, y_{t-k+1}$. Para um processo AR(*p*), a PACF ter√° um corte abrupto ap√≥s a defasagem *p*.

> üí° **Exemplo Num√©rico:** Imagine que voc√™ calcula a PACF de uma s√©rie temporal e observa os seguintes valores: PACF(1) = 0.6, PACF(2) = 0.2, PACF(3) = -0.05. Como a PACF se torna essencialmente zero ap√≥s a defasagem 1, isso sugere que um modelo AR(1) pode ser apropriado para essa s√©rie temporal.

### Conclus√£o

Neste cap√≠tulo, estabelecemos a base para entender os modelos AR(*p*) no contexto de s√©ries temporais heterosced√°sticas. Definimos formalmente o modelo AR(*p*), discutimos as condi√ß√µes para estacionariedade, apresentamos a forma da previs√£o linear √≥tima e derivamos a m√©dia incondicional. Estes conceitos s√£o fundamentais para a an√°lise e modelagem de s√©ries temporais, e ser√£o expandidos em cap√≠tulos subsequentes para abordar modelos mais complexos e suas aplica√ß√µes em finan√ßas e economia.

### Refer√™ncias
[^1]: P√°gina 657.
<!-- END -->