## A MÃ©dia Incondicional em Modelos AR(p) EstacionÃ¡rios

### IntroduÃ§Ã£o

Este capÃ­tulo aprofunda a anÃ¡lise da **mÃ©dia incondicional** em **modelos Autoregressivos de ordem *p* (AR(*p*)) estacionÃ¡rios**, expandindo os conceitos apresentados nos capÃ­tulos anteriores [^1]. A mÃ©dia incondicional, denotada por $E(y_t)$, representa o valor central em torno do qual a sÃ©rie temporal flutua a longo prazo. Neste capÃ­tulo, exploraremos em detalhe a derivaÃ§Ã£o, interpretaÃ§Ã£o e significÃ¢ncia da mÃ©dia incondicional, bem como a sua relaÃ§Ã£o com a estacionariedade em covariÃ¢ncia.

### DerivaÃ§Ã£o Formal da MÃ©dia Incondicional

Como mencionado anteriormente, a mÃ©dia incondicional de um processo AR(*p*) estacionÃ¡rio Ã© dada por [^1]:

$$ E(y_t) = \frac{c}{1 - \phi_1 - \phi_2 - \dots - \phi_p} $$

Essa expressÃ£o Ã© vÃ¡lida apenas se o processo AR(*p*) for estacionÃ¡rio em covariÃ¢ncia. Para derivar formalmente essa expressÃ£o, partimos da definiÃ§Ã£o do modelo AR(*p*):

$$ y_t = c + \phi_1 y_{t-1} + \phi_2 y_{t-2} + \dots + \phi_p y_{t-p} + u_t $$

Tomamos a esperanÃ§a matemÃ¡tica de ambos os lados da equaÃ§Ã£o:

$$ E(y_t) = E(c + \phi_1 y_{t-1} + \phi_2 y_{t-2} + \dots + \phi_p y_{t-p} + u_t) $$

Usando a propriedade da linearidade da esperanÃ§a, temos:

$$ E(y_t) = E(c) + \phi_1 E(y_{t-1}) + \phi_2 E(y_{t-2}) + \dots + \phi_p E(y_{t-p}) + E(u_t) $$

Como o processo Ã© estacionÃ¡rio em covariÃ¢ncia, a mÃ©dia $E(y_t)$ Ã© constante ao longo do tempo, ou seja, $E(y_t) = E(y_{t-1}) = E(y_{t-2}) = \dots = \mu$. AlÃ©m disso, o termo de erro $u_t$ tem mÃ©dia zero, ou seja, $E(u_t) = 0$. Substituindo essas informaÃ§Ãµes na equaÃ§Ã£o, obtemos:

$$ \mu = c + \phi_1 \mu + \phi_2 \mu + \dots + \phi_p \mu + 0 $$

Rearranjando a equaÃ§Ã£o, temos:

$$ \mu = c + \mu (\phi_1 + \phi_2 + \dots + \phi_p) $$

Isolando $\mu$, obtemos:

$$ \mu - \mu (\phi_1 + \phi_2 + \dots + \phi_p) = c $$

$$ \mu (1 - \phi_1 - \phi_2 - \dots + \phi_p) = c $$

Finalmente, dividindo ambos os lados por $(1 - \phi_1 - \phi_2 - \dots - \phi_p)$, obtemos a expressÃ£o para a mÃ©dia incondicional:

$$ \mu = E(y_t) = \frac{c}{1 - \phi_1 - \phi_2 - \dots - \phi_p} $$

Essa derivaÃ§Ã£o demonstra formalmente como a mÃ©dia incondicional Ã© expressa em termos da constante *c* e dos coeficientes autoregressivos $\phi_i$.

**Teorema 8**: A mÃ©dia incondicional $E(y_t)$ de um processo AR(p) estacionÃ¡rio Ã© finita se e somente se $1 - \phi_1 - \phi_2 - ... - \phi_p \neq 0$.

*Proof:* Da derivaÃ§Ã£o acima, temos $E(y_t) = \frac{c}{1 - \phi_1 - \phi_2 - ... - \phi_p}$. Para que a mÃ©dia incondicional seja finita, o denominador deve ser diferente de zero. Se $1 - \phi_1 - \phi_2 - ... - \phi_p = 0$, entÃ£o $E(y_t)$ seria indefinido (ou infinito), o que contradiz a estacionariedade do processo. $\blacksquare$

**CorolÃ¡rio 8.1**: Se $1 - \phi_1 - \phi_2 - ... - \phi_p = 0$, o processo AR(p) nÃ£o Ã© estacionÃ¡rio e a mÃ©dia incondicional nÃ£o estÃ¡ definida.

Para complementar a anÃ¡lise da condiÃ§Ã£o de estacionariedade e a existÃªncia da mÃ©dia incondicional, podemos apresentar um resultado relacionado Ã s raÃ­zes do polinÃ´mio caracterÃ­stico do processo AR(p).

**Teorema 8.2**: Um processo AR(p) Ã© estacionÃ¡rio se e somente se todas as raÃ­zes do polinÃ´mio caracterÃ­stico $1 - \phi_1 z - \phi_2 z^2 - \dots - \phi_p z^p = 0$ estÃ£o fora do cÃ­rculo unitÃ¡rio no plano complexo (i.e., tÃªm mÃ³dulo maior que 1).

*Proof:* (EsboÃ§o) A estacionariedade de um processo AR(p) estÃ¡ relacionada Ã  sua capacidade de retornar ao seu valor mÃ©dio apÃ³s um choque.  Isto, por sua vez, estÃ¡ intimamente ligado Ã s raÃ­zes do polinÃ´mio caracterÃ­stico. Se as raÃ­zes estiverem dentro do cÃ­rculo unitÃ¡rio, os choques terÃ£o efeitos explosivos, levando Ã  nÃ£o-estacionariedade. Se as raÃ­zes estiverem fora do cÃ­rculo unitÃ¡rio, os efeitos dos choques diminuirÃ£o ao longo do tempo, garantindo a estacionariedade. A demonstraÃ§Ã£o formal envolve a anÃ¡lise da funÃ§Ã£o de autocovariÃ¢ncia do processo e sua relaÃ§Ã£o com as raÃ­zes do polinÃ´mio caracterÃ­stico. $\blacksquare$

Para uma prova mais detalhada do Teorema 8.2, considere a seguinte:

*Proof:*

I.  **DefiniÃ§Ã£o do PolinÃ´mio CaracterÃ­stico:**
    O polinÃ´mio caracterÃ­stico de um processo AR(p) Ã© definido como:
    $$
    \phi(z) = 1 - \phi_1 z - \phi_2 z^2 - \dots - \phi_p z^p
    $$
    onde $z$ Ã© uma variÃ¡vel complexa.

II. **RelaÃ§Ã£o entre Estacionariedade e RaÃ­zes:**
    Um processo AR(p) Ã© estacionÃ¡rio se e somente se todas as raÃ­zes de $\phi(z) = 0$ estÃ£o fora do cÃ­rculo unitÃ¡rio no plano complexo. Ou seja, se $z_1, z_2, \dots, z_p$ sÃ£o as raÃ­zes de $\phi(z) = 0$, entÃ£o $|z_i| > 1$ para todo $i = 1, 2, \dots, p$.

III. **InversÃ£o das RaÃ­zes:**
     Seja $w_i = \frac{1}{z_i}$. EntÃ£o $|w_i| < 1$ para todo $i$ se e somente se $|z_i| > 1$ para todo $i$. Considere o polinÃ´mio cujas raÃ­zes sÃ£o $w_i$:
     $$
     \psi(w) = w^p \phi\left(\frac{1}{w}\right) = w^p - \phi_1 w^{p-1} - \phi_2 w^{p-2} - \dots - \phi_p
     $$

IV. **FunÃ§Ã£o de AutocovariÃ¢ncia:**
    A funÃ§Ã£o de autocovariÃ¢ncia $\gamma(k)$ de um processo AR(p) pode ser expressa em termos das raÃ­zes do polinÃ´mio caracterÃ­stico. Para um processo estacionÃ¡rio, a funÃ§Ã£o de autocovariÃ¢ncia deve decair para zero Ã  medida que $k$ aumenta.  Isto ocorre se e somente se todas as raÃ­zes do polinÃ´mio $\psi(w)$ estiverem dentro do cÃ­rculo unitÃ¡rio.

V.  **CondiÃ§Ã£o de Decaimento:**
    A condiÃ§Ã£o para que $\gamma(k)$ decaia Ã© equivalente Ã  condiÃ§Ã£o de que a representaÃ§Ã£o do processo AR(p) como uma soma ponderada de choques passados (sua representaÃ§Ã£o de mÃ©dia mÃ³vel infinita) seja convergente. Essa convergÃªncia Ã© garantida se e somente se as raÃ­zes do polinÃ´mio caracterÃ­stico estiverem fora do cÃ­rculo unitÃ¡rio.

VI. **ConclusÃ£o:**
    Portanto, um processo AR(p) Ã© estacionÃ¡rio se e somente se todas as raÃ­zes do polinÃ´mio caracterÃ­stico $\phi(z) = 1 - \phi_1 z - \phi_2 z^2 - \dots - \phi_p z^p = 0$ estiverem fora do cÃ­rculo unitÃ¡rio no plano complexo. $\blacksquare$

> ğŸ’¡ **Exemplo NumÃ©rico:**
>
> 1. **Caso EstacionÃ¡rio:** Considere um processo AR(1) com $c = 5$ e $\phi_1 = 0.7$. A mÃ©dia incondicional Ã© $E(y_t) = \frac{5}{1 - 0.7} = \frac{5}{0.3} \approx 16.67$. Isso significa que, a longo prazo, a sÃ©rie temporal flutua em torno de 16.67.
>
> 2. **Caso NÃ£o EstacionÃ¡rio:** Considere um processo AR(1) com $c = 5$ e $\phi_1 = 1.0$. Neste caso, $1 - \phi_1 = 1 - 1 = 0$. A mÃ©dia incondicional seria $E(y_t) = \frac{5}{0}$, que Ã© indefinida. Este processo nÃ£o Ã© estacionÃ¡rio.
>
> 3. **Caso AR(2) EstacionÃ¡rio:** Considere um processo AR(2) com $c=10$, $\phi_1=0.4$ e $\phi_2=0.3$. A mÃ©dia incondicional Ã© $E(y_t)=\frac{10}{1-0.4-0.3} = \frac{10}{0.3} \approx 33.33$
>
> 4. **Caso AR(2) NÃ£o EstacionÃ¡rio:** Considere um processo AR(2) com $c=10$, $\phi_1=0.7$ e $\phi_2=0.3$. Neste caso, $1 - \phi_1 - \phi_2 = 1 - 0.7 - 0.3 = 0$. A mÃ©dia incondicional Ã© indefinida, e o processo nÃ£o Ã© estacionÃ¡rio.
>
> 5. **RaÃ­zes do PolinÃ´mio CaracterÃ­stico - AR(1):**
>
>    *   Seja um processo AR(1): $y_t = 0.5y_{t-1} + u_t$. O polinÃ´mio caracterÃ­stico Ã© $1 - 0.5z = 0$.
>    *   A raiz Ã© $z = \frac{1}{0.5} = 2$. Como $|2| > 1$, o processo Ã© estacionÃ¡rio.
>
> 6. **RaÃ­zes do PolinÃ´mio CaracterÃ­stico - AR(2):**
>
>    *   Seja um processo AR(2): $y_t = 0.5y_{t-1} - 0.6y_{t-2} + u_t$. O polinÃ´mio caracterÃ­stico Ã© $1 - 0.5z + 0.6z^2 = 0$.
>    *   As raÃ­zes sÃ£o $z = \frac{0.5 \pm \sqrt{(-0.5)^2 - 4(0.6)(1)}}{2(0.6)} = \frac{0.5 \pm \sqrt{-2.15}}{1.2}$.
>    *   As raÃ­zes sÃ£o complexas: $z \approx 0.4167 \pm 1.336i$.
>    *   O mÃ³dulo das raÃ­zes Ã© $|z| = \sqrt{0.4167^2 + 1.336^2} \approx 1.40$. Como $|z| > 1$, o processo Ã© estacionÃ¡rio.
>
> 7. **Python code for roots of AR(2) process:**
> ```python
> import numpy as np
>
> # AR coefficients
> phi1 = 0.5
> phi2 = -0.6
>
> # Polynomial coefficients (1 - phi1*z - phi2*z^2 = 0) => (phi2*z^2 + phi1*z - 1 = 0)
> a = phi2
> b = phi1
> c = -1
>
> # Calculate roots
> delta = (b**2) - 4*(a*c)
>
> # Find roots
> if delta > 0:
>     x1 = (-b - np.sqrt(delta)) / (2*a)
>     x2 = (-b + np.sqrt(delta)) / (2*a)
>     print('Real and distinct roots')
>     print(f'Root 1: {x1}')
>     print(f'Root 2: {x2}')
> elif delta == 0:
>     x = (-b - np.sqrt(delta)) / (2 * a)
>     print('Real and equal root')
>     print(f'Root: {x}')
> else:
>     real_part = -b / (2*a)
>     imaginary_part = np.sqrt(abs(delta)) / (2*a)
>     x1 = complex(real_part, imaginary_part)
>     x2 = complex(real_part, -imaginary_part)
>     print('Complex roots')
>     print(f'Root 1: {x1}')
>     print(f'Root 2: {x2}')
>
> #Check that roots are outside the unit circle
> print(f'Absolute Value of Root 1: {np.abs(x1)}')
> print(f'Absolute Value of Root 2: {np.abs(x2)}')
>
> ```

### InterpretaÃ§Ã£o e Significado da MÃ©dia Incondicional

A mÃ©dia incondicional $E(y_t)$ representa o valor mÃ©dio da sÃ©rie temporal a longo prazo, assumindo que o processo Ã© estacionÃ¡rio. Ela fornece um ponto de referÃªncia para entender o comportamento geral da sÃ©rie temporal.

1.  **Valor Central:** A sÃ©rie temporal flutua em torno da mÃ©dia incondicional. Em um processo estacionÃ¡rio, os desvios da mÃ©dia sÃ£o temporÃ¡rios e a sÃ©rie tende a retornar a esse valor a longo prazo.

2.  **Ponto de Ancoragem:** A mÃ©dia incondicional serve como um ponto de ancoragem para a previsÃ£o a longo prazo. Ã€ medida que o horizonte de previsÃ£o aumenta, a previsÃ£o linear Ã³tima converge para a mÃ©dia incondicional.

3.  **ComparaÃ§Ã£o entre SÃ©ries:** A mÃ©dia incondicional permite comparar o nÃ­vel mÃ©dio de diferentes sÃ©ries temporais. Se duas sÃ©ries temporais tÃªm diferentes mÃ©dias incondicionais, isso indica que elas flutuam em torno de valores centrais diferentes.

> ğŸ’¡ **Exemplo NumÃ©rico:** Considere duas sÃ©ries temporais: uma representando os retornos de uma aÃ§Ã£o e outra representando os retornos de um tÃ­tulo do governo. Se a mÃ©dia incondicional dos retornos da aÃ§Ã£o for 0.1 (10\%) e a mÃ©dia incondicional dos retornos do tÃ­tulo for 0.03 (3\%), isso indica que, a longo prazo, espera-se que a aÃ§Ã£o forneÃ§a um retorno mÃ©dio maior do que o tÃ­tulo do governo.
>
> Para criar este exemplo usando Python, podemos usar cÃ³digo similar aos exemplos anteriores, apenas simulando duas sÃ©ries com diferentes parÃ¢metros para as suas mÃ©dias incondicionais, e entÃ£o estimar essas mÃ©dias a partir dos dados gerados.
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
>
> # Parameters
> mean_stock_return = 0.1
> mean_bond_return = 0.03
> std_stock = 0.2
> std_bond = 0.05
> n = 100
>
> # Simulate returns
> np.random.seed(42)
> stock_returns = np.random.normal(mean_stock_return, std_stock, n)
> bond_returns = np.random.normal(mean_bond_return, std_bond, n)
>
> # Calculate sample means
> sample_mean_stock = np.mean(stock_returns)
> sample_mean_bond = np.mean(bond_returns)
>
> print(f"Sample Mean Stock Return: {sample_mean_stock:.4f}")
> print(f"Sample Mean Bond Return: {sample_mean_bond:.4f}")
>
> # Plotting
> plt.figure(figsize=(10, 6))
> plt.plot(stock_returns, label='Stock Returns')
> plt.plot(bond_returns, label='Bond Returns')
> plt.axhline(y=mean_stock_return, color='red', linestyle='--', label=f'Long-term Stock Mean ({mean_stock_return:.2f})')
> plt.axhline(y=mean_bond_return, color='green', linestyle='--', label=f'Long-term Bond Mean ({mean_bond_return:.2f})')
> plt.xlabel("Time")
> plt.ylabel("Returns")
> plt.title("Simulated Stock and Bond Returns")
> plt.legend()
> plt.grid(True)
> plt.show()
> ```

### MÃ©dia Incondicional e Estacionariedade em CovariÃ¢ncia

A estacionariedade em covariÃ¢ncia Ã© uma condiÃ§Ã£o necessÃ¡ria para que a mÃ©dia incondicional seja bem definida e interpretÃ¡vel. Se o processo nÃ£o for estacionÃ¡rio, a mÃ©dia nÃ£o serÃ¡ constante ao longo do tempo e a expressÃ£o $E(y_t) = \frac{c}{1 - \phi_1 - \phi_2 - \dots - \phi_p}$ nÃ£o serÃ¡ vÃ¡lida.

Em um processo nÃ£o estacionÃ¡rio, a mÃ©dia pode variar ao longo do tempo, tornando a interpretaÃ§Ã£o do "valor central" da sÃ©rie temporal mais complexa. Processos nÃ£o estacionÃ¡rios podem apresentar tendÃªncias (crescentes ou decrescentes) ou outros padrÃµes que fazem com que a mÃ©dia varie significativamente ao longo do tempo.

Para ilustrar como a mÃ©dia incondicional pode ser enganosa em processos nÃ£o estacionÃ¡rios, podemos introduzir o conceito de passeio aleatÃ³rio (random walk).

**Exemplo**: Considere um processo de passeio aleatÃ³rio definido como $y_t = y_{t-1} + u_t$, onde $u_t$ Ã© um ruÃ­do branco com mÃ©dia zero. Neste caso, $\phi_1 = 1$ e $c = 0$. Formalmente, a mÃ©dia incondicional seria indefinida (divisÃ£o por zero). Intuitivamente, o processo nÃ£o possui uma mÃ©dia para a qual ele retorna, pois ele "passeia" indefinidamente.

> ğŸ’¡ **Exemplo NumÃ©rico:** Considere uma sÃ©rie temporal representando o Produto Interno Bruto (PIB) de um paÃ­s. Se o PIB estiver crescendo ao longo do tempo, a sÃ©rie temporal nÃ£o serÃ¡ estacionÃ¡ria. Calcular uma "mÃ©dia incondicional" para toda a sÃ©rie nÃ£o capturarÃ¡ a tendÃªncia de crescimento. Ã‰ melhor modelar a tendÃªncia separadamente e analisar os desvios da tendÃªncia (que podem ser estacionÃ¡rios).
>
> ```python
> import numpy as np
> import pandas as pd
> import matplotlib.pyplot as plt
>
> # Generate Sample GDP Data (with an increasing trend)
> np.random.seed(42)
> n = 100
> time = np.arange(n)
> trend = 2 * time
> noise = np.random.randn(n) * 10
> gdp = trend + noise
>
> # Calculate the mean GDP
> mean_gdp = np.mean(gdp)
>
> print("Mean GDP:", mean_gdp)
>
> # Plot the data
> plt.figure(figsize=(10, 6))
> plt.plot(gdp, label='GDP')
> plt.hlines(mean_gdp, xmin=0, xmax=n-1, color='red', label='Mean GDP')
> plt.xlabel("Time")
> plt.ylabel("GDP")
> plt.title("GDP Time Series with Increasing Trend")
> plt.legend()
> plt.grid(True)
> plt.show()
> ```
>
> Neste exemplo, podemos ver visualmente que a linha da mÃ©dia (em vermelho) nÃ£o representa bem o comportamento da sÃ©rie, devido Ã  tendÃªncia crescente.

**ProposiÃ§Ã£o 9**: Se um processo AR(p) nÃ£o Ã© estacionÃ¡rio, a expressÃ£o $E(y_t) = \frac{c}{1 - \phi_1 - \phi_2 - ... - \phi_p}$ nÃ£o Ã© vÃ¡lida e a mÃ©dia incondicional nÃ£o pode ser interpretada como o valor central em torno do qual a sÃ©rie flutua.

*Proof:* A derivaÃ§Ã£o da expressÃ£o para a mÃ©dia incondicional depende crucialmente da suposiÃ§Ã£o de estacionariedade. Sem estacionariedade, $E(y_t) \neq E(y_{t-1})$ e a derivaÃ§Ã£o nÃ£o se sustenta. A falta de estacionariedade invalida a interpretaÃ§Ã£o da mÃ©dia como um valor central constante. $\blacksquare$

**ProposiÃ§Ã£o 9.1**: Para um processo AR(p) nÃ£o estacionÃ¡rio, a mÃ©dia amostral calculada a partir de uma Ãºnica realizaÃ§Ã£o da sÃ©rie temporal pode nÃ£o convergir para um valor estÃ¡vel Ã  medida que o tamanho da amostra aumenta.

*Proof:* (EsboÃ§o) Em um processo estacionÃ¡rio, a lei dos grandes nÃºmeros garante que a mÃ©dia amostral converge para a mÃ©dia populacional (mÃ©dia incondicional) Ã  medida que o tamanho da amostra aumenta. No entanto, para processos nÃ£o estacionÃ¡rios, essa convergÃªncia nÃ£o Ã© garantida, pois a distribuiÃ§Ã£o da sÃ©rie temporal muda ao longo do tempo. $\blacksquare$

Para fornecer uma prova mais formal da ProposiÃ§Ã£o 9.1, considere o seguinte:

*Proof:*

I. **DefiniÃ§Ã£o da MÃ©dia Amostral:** Seja $\{y_1, y_2, ..., y_n\}$ uma realizaÃ§Ã£o de um processo estocÃ¡stico. A mÃ©dia amostral Ã© definida como:
   $$
   \bar{y}_n = \frac{1}{n} \sum_{t=1}^{n} y_t
   $$

II. **Lei dos Grandes NÃºmeros (LLN):** Para um processo estacionÃ¡rio e ergÃ³dico, a Lei dos Grandes NÃºmeros (LLN) garante que a mÃ©dia amostral converge para a mÃ©dia populacional (mÃ©dia incondicional) Ã  medida que o tamanho da amostra aumenta:
    $$
    \lim_{n \to \infty} \bar{y}_n = E[y_t] = \mu
    $$
    onde $\mu$ Ã© a mÃ©dia incondicional do processo.

III. **NÃ£o Estacionariedade:** Se o processo nÃ£o Ã© estacionÃ¡rio, entÃ£o $E[y_t]$ pode depender de $t$, ou seja, $E[y_t] = \mu_t$. Neste caso, a mÃ©dia amostral pode ser escrita como:
     $$
     \bar{y}_n = \frac{1}{n} \sum_{t=1}^{n} y_t
     $$
     E a esperanÃ§a da mÃ©dia amostral Ã©:
     $$
     E[\bar{y}_n] = \frac{1}{n} \sum_{t=1}^{n} E[y_t] = \frac{1}{n} \sum_{t=1}^{n} \mu_t
     $$

IV. **ConvergÃªncia em Processos NÃ£o EstacionÃ¡rios:** Para processos nÃ£o estacionÃ¡rios, a sequÃªncia $\{\mu_t\}$ pode nÃ£o convergir para um valor fixo. Por exemplo, se $\mu_t = t$, entÃ£o $E[\bar{y}_n] = \frac{1}{n} \sum_{t=1}^{n} t = \frac{n(n+1)}{2n} = \frac{n+1}{2}$, que diverge para infinito Ã  medida que $n \to \infty$.

V. **ConclusÃ£o:** Portanto, para um processo AR(p) nÃ£o estacionÃ¡rio, a mÃ©dia amostral $\bar{y}_n$ pode nÃ£o convergir para um valor estÃ¡vel Ã  medida que o tamanho da amostra aumenta, pois a distribuiÃ§Ã£o da sÃ©rie temporal muda ao longo do tempo, e a mÃ©dia amostral converge para a mÃ©dia das mÃ©dias dependentes do tempo, que pode nÃ£o ser um valor estÃ¡vel. $\blacksquare$

> ğŸ’¡ **Exemplo NumÃ©rico:**
> Para ilustrar a ProposiÃ§Ã£o 9.1, vamos simular um passeio aleatÃ³rio e calcular a mÃ©dia amostral para diferentes tamanhos de amostra:
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
>
> # Simulate a random walk
> np.random.seed(42)
> n = 1000
> errors = np.random.randn(n)
> random_walk = np.cumsum(errors)
>
> # Calculate sample means for different sample sizes
> sample_sizes = [50, 100, 200, 500, 1000]
> sample_means = []
>
> for size in sample_sizes:
>     sample_means.append(np.mean(random_walk[:size]))
>
> print("Sample Means for Different Sample Sizes:", sample_means)
>
> # Plotting the random walk and sample means
> plt.figure(figsize=(12, 6))
> plt.plot(random_walk, label='Random Walk')
> plt.xlabel("Time")
> plt.ylabel("Value")
> plt.title("Random Walk with Different Sample Means")
>
> for i, size in enumerate(sample_sizes):
>     plt.axhline(y=sample_means[i], color=f'C{i+1}', linestyle='--', label=f'Mean (n={size})')
>
> plt.legend()
> plt.grid(True)
> plt.show()
> ```
> No exemplo acima, Ã© possÃ­vel visualizar que as mÃ©dias amostrais para diferentes tamanhos de amostra nÃ£o convergem para um valor estÃ¡vel, demonstrando a ProposiÃ§Ã£o 9.1.

### ImplementaÃ§Ã£o PrÃ¡tica

Na prÃ¡tica, a estimaÃ§Ã£o da mÃ©dia incondicional envolve estimar os parÃ¢metros do modelo AR(*p*) e, em seguida, usar a expressÃ£o $E(y_t) = \frac{c}{1 - \phi_1 - \phi_2 - \dots - \phi_p}$ para calcular a mÃ©dia. Ã‰ importante verificar a estacionariedade do processo antes de interpretar a mÃ©dia incondicional.

> ğŸ’¡ **Exemplo:** Usando os dados de vendas do exemplo anterior, podemos estimar os parÃ¢metros de um modelo AR(2) e calcular a mÃ©dia incondicional.
>
> ```python
> import numpy as np
> import pandas as pd
> import statsmodels.api as sm
> from statsmodels.tsa.arima.model import ARIMA
> import matplotlib.pyplot as plt
>
> # Sample Sales Data (replace with your actual data)
> np.random.seed(42)
> n = 100
> trend = np.linspace(100, 150, n)
> noise = np.random.randn(n) * 5  # Add some noise
> sales = trend + noise
>
> # Fit an AR(2) model
> model = ARIMA(sales, order=(2, 0, 0))  # AR(2) - (p, d, q)
> results = model.fit()
>
> # Extract parameters
> c = results.params[0]  # constant (intercept)
> phi1 = results.params[1] # AR(1) coefficient
> phi2 = results.params[2] # AR(2) coefficient
>
> # Calculate unconditional mean
> unconditional_mean = c / (1 - phi1 - phi2)
>
> print("Unconditional Mean:", unconditional_mean)
> ```

Se a sÃ©rie temporal nÃ£o for estacionÃ¡ria, pode ser necessÃ¡rio aplicar transformaÃ§Ãµes (como diferenciaÃ§Ã£o) para tornÃ¡-la estacionÃ¡ria antes de ajustar um modelo AR(*p*) e calcular a mÃ©dia incondicional.

Para complementar a discussÃ£o sobre transformaÃ§Ãµes para garantir a estacionariedade, Ã© Ãºtil mencionar o teste de raiz unitÃ¡ria.

**ObservaÃ§Ã£o**: O Teste de Dickey-Fuller Aumentado (ADF) Ã© um teste estatÃ­stico comum utilizado para verificar a presenÃ§a de raiz unitÃ¡ria em uma sÃ©rie temporal. A presenÃ§a de uma raiz unitÃ¡ria sugere que a sÃ©rie nÃ£o Ã© estacionÃ¡ria e pode necessitar de diferenciaÃ§Ã£o para se tornar estacionÃ¡ria.

> ğŸ’¡ **Exemplo NumÃ©rico**: Suponha que aplicamos o Teste ADF a uma sÃ©rie temporal de preÃ§os de aÃ§Ãµes e obtemos um p-valor de 0.6. Como o p-valor Ã© maior que 0.05 (nÃ­vel de significÃ¢ncia comum), falhamos em rejeitar a hipÃ³tese nula de que a sÃ©rie tem uma raiz unitÃ¡ria. Isso sugere que a sÃ©rie de preÃ§os de aÃ§Ãµes nÃ£o Ã© estacionÃ¡ria. Para tornÃ¡-la estacionÃ¡ria, podemos calcular a sÃ©rie de retornos (diferenciaÃ§Ã£o de primeira ordem) e aplicar o teste ADF novamente. Se o p-valor para a sÃ©rie de retornos for menor que 0.05, podemos concluir que a sÃ©rie de retornos Ã© estacionÃ¡ria.
>
> ```python
> import numpy as np
> import pandas as pd
> from statsmodels.tsa.stattools import adfuller
> import matplotlib.pyplot as plt
>
> # Generate a non-stationary time series (random walk)
> np.random.seed(42)
> n = 100
> random_walk = np.cumsum(np.random.randn(n))
>
> # Perform Augmented Dickey-Fuller test
> adf_result = adfuller(random_walk)
> print("ADF Test Results for Original Series:")
> print(f'ADF Statistic: {adf_result[0]}')
> print(f'p-value: {adf_result[1]}')
> print('Critical Values:')
> for key, value in adf_result[4].items():
>     print(f'   {key}: {value}')
>
> # Difference the series to make it stationary
> differenced_series = np.diff(random_walk)
>
> # Perform ADF test on the differenced series
> adf_result_diff = adfuller(differenced_series)
> print("\nADF Test Results for Differenced Series:")
> print(f'ADF Statistic: {adf_result_diff[0]}')
> print(f'p-value: {adf_result_diff[1]}')
> print('Critical Values:')
> for key, value in adf_result_diff[4].items():
>     print(f'   {key}: {value}')
>
> # Plotting
> plt.figure(figsize=(12, 6))
> plt.plot(random_walk, label='Original Series (Random Walk)')
> plt.plot(differenced_series, label='Differenced Series')
> plt.xlabel("Time")
> plt.ylabel("Value")
> plt.title("Original and Differenced Time Series")
> plt.legend()
> plt.grid(True)
> plt.show()
> ```

### ConclusÃ£o

Este capÃ­tulo forneceu uma anÃ¡lise detalhada da mÃ©dia incondicional em modelos AR(*p*) estacionÃ¡rios. Demonstramos formalmente como a mÃ©dia incondicional Ã© derivada, interpretada e utilizada na prÃ¡tica. Enfatizamos a importÃ¢ncia da estacionariedade em covariÃ¢ncia para a validade da mÃ©dia incondicional e discutimos como a nÃ£o estacionariedade afeta a interpretaÃ§Ã£o e modelagem de sÃ©ries temporais. Compreender a mÃ©dia incondicional Ã© essencial para a anÃ¡lise e previsÃ£o de sÃ©ries temporais, e a combinaÃ§Ã£o dos conceitos discutidos neste capÃ­tulo com os apresentados nos capÃ­tulos anteriores fornece uma base sÃ³lida para a modelagem de sÃ©ries temporais heteroscedÃ¡sticas.

### ReferÃªncias
[^1]: PÃ¡gina 657.
<!-- END -->