## A M√©dia Incondicional em Modelos AR(p) Estacion√°rios

### Introdu√ß√£o

Este cap√≠tulo aprofunda a an√°lise da **m√©dia incondicional** em **modelos Autoregressivos de ordem *p* (AR(*p*)) estacion√°rios**, expandindo os conceitos apresentados nos cap√≠tulos anteriores [^1]. A m√©dia incondicional, denotada por $E(y_t)$, representa o valor central em torno do qual a s√©rie temporal flutua a longo prazo. Neste cap√≠tulo, exploraremos em detalhe a deriva√ß√£o, interpreta√ß√£o e signific√¢ncia da m√©dia incondicional, bem como a sua rela√ß√£o com a estacionariedade em covari√¢ncia.

### Deriva√ß√£o Formal da M√©dia Incondicional

Como mencionado anteriormente, a m√©dia incondicional de um processo AR(*p*) estacion√°rio √© dada por [^1]:

$$ E(y_t) = \frac{c}{1 - \phi_1 - \phi_2 - \dots - \phi_p} $$

Essa express√£o √© v√°lida apenas se o processo AR(*p*) for estacion√°rio em covari√¢ncia. Para derivar formalmente essa express√£o, partimos da defini√ß√£o do modelo AR(*p*):

$$ y_t = c + \phi_1 y_{t-1} + \phi_2 y_{t-2} + \dots + \phi_p y_{t-p} + u_t $$

Tomamos a esperan√ßa matem√°tica de ambos os lados da equa√ß√£o:

$$ E(y_t) = E(c + \phi_1 y_{t-1} + \phi_2 y_{t-2} + \dots + \phi_p y_{t-p} + u_t) $$

Usando a propriedade da linearidade da esperan√ßa, temos:

$$ E(y_t) = E(c) + \phi_1 E(y_{t-1}) + \phi_2 E(y_{t-2}) + \dots + \phi_p E(y_{t-p}) + E(u_t) $$

Como o processo √© estacion√°rio em covari√¢ncia, a m√©dia $E(y_t)$ √© constante ao longo do tempo, ou seja, $E(y_t) = E(y_{t-1}) = E(y_{t-2}) = \dots = \mu$. Al√©m disso, o termo de erro $u_t$ tem m√©dia zero, ou seja, $E(u_t) = 0$. Substituindo essas informa√ß√µes na equa√ß√£o, obtemos:

$$ \mu = c + \phi_1 \mu + \phi_2 \mu + \dots + \phi_p \mu + 0 $$

Rearranjando a equa√ß√£o, temos:

$$ \mu = c + \mu (\phi_1 + \phi_2 + \dots + \phi_p) $$

Isolando $\mu$, obtemos:

$$ \mu - \mu (\phi_1 + \phi_2 + \dots + \phi_p) = c $$

$$ \mu (1 - \phi_1 - \phi_2 - \dots + \phi_p) = c $$

Finalmente, dividindo ambos os lados por $(1 - \phi_1 - \phi_2 - \dots - \phi_p)$, obtemos a express√£o para a m√©dia incondicional:

$$ \mu = E(y_t) = \frac{c}{1 - \phi_1 - \phi_2 - \dots - \phi_p} $$

Essa deriva√ß√£o demonstra formalmente como a m√©dia incondicional √© expressa em termos da constante *c* e dos coeficientes autoregressivos $\phi_i$.

**Teorema 8**: A m√©dia incondicional $E(y_t)$ de um processo AR(p) estacion√°rio √© finita se e somente se $1 - \phi_1 - \phi_2 - ... - \phi_p \neq 0$.

*Proof:* Da deriva√ß√£o acima, temos $E(y_t) = \frac{c}{1 - \phi_1 - \phi_2 - ... - \phi_p}$. Para que a m√©dia incondicional seja finita, o denominador deve ser diferente de zero. Se $1 - \phi_1 - \phi_2 - ... - \phi_p = 0$, ent√£o $E(y_t)$ seria indefinido (ou infinito), o que contradiz a estacionariedade do processo. $\blacksquare$

**Corol√°rio 8.1**: Se $1 - \phi_1 - \phi_2 - ... - \phi_p = 0$, o processo AR(p) n√£o √© estacion√°rio e a m√©dia incondicional n√£o est√° definida.

Para complementar a an√°lise da condi√ß√£o de estacionariedade e a exist√™ncia da m√©dia incondicional, podemos apresentar um resultado relacionado √†s ra√≠zes do polin√¥mio caracter√≠stico do processo AR(p).

**Teorema 8.2**: Um processo AR(p) √© estacion√°rio se e somente se todas as ra√≠zes do polin√¥mio caracter√≠stico $1 - \phi_1 z - \phi_2 z^2 - \dots - \phi_p z^p = 0$ est√£o fora do c√≠rculo unit√°rio no plano complexo (i.e., t√™m m√≥dulo maior que 1).

*Proof:* (Esbo√ßo) A estacionariedade de um processo AR(p) est√° relacionada √† sua capacidade de retornar ao seu valor m√©dio ap√≥s um choque.  Isto, por sua vez, est√° intimamente ligado √†s ra√≠zes do polin√¥mio caracter√≠stico. Se as ra√≠zes estiverem dentro do c√≠rculo unit√°rio, os choques ter√£o efeitos explosivos, levando √† n√£o-estacionariedade. Se as ra√≠zes estiverem fora do c√≠rculo unit√°rio, os efeitos dos choques diminuir√£o ao longo do tempo, garantindo a estacionariedade. A demonstra√ß√£o formal envolve a an√°lise da fun√ß√£o de autocovari√¢ncia do processo e sua rela√ß√£o com as ra√≠zes do polin√¥mio caracter√≠stico. $\blacksquare$

Para uma prova mais detalhada do Teorema 8.2, considere a seguinte:

*Proof:*

I.  **Defini√ß√£o do Polin√¥mio Caracter√≠stico:**
    O polin√¥mio caracter√≠stico de um processo AR(p) √© definido como:
    $$
    \phi(z) = 1 - \phi_1 z - \phi_2 z^2 - \dots - \phi_p z^p
    $$
    onde $z$ √© uma vari√°vel complexa.

II. **Rela√ß√£o entre Estacionariedade e Ra√≠zes:**
    Um processo AR(p) √© estacion√°rio se e somente se todas as ra√≠zes de $\phi(z) = 0$ est√£o fora do c√≠rculo unit√°rio no plano complexo. Ou seja, se $z_1, z_2, \dots, z_p$ s√£o as ra√≠zes de $\phi(z) = 0$, ent√£o $|z_i| > 1$ para todo $i = 1, 2, \dots, p$.

III. **Invers√£o das Ra√≠zes:**
     Seja $w_i = \frac{1}{z_i}$. Ent√£o $|w_i| < 1$ para todo $i$ se e somente se $|z_i| > 1$ para todo $i$. Considere o polin√¥mio cujas ra√≠zes s√£o $w_i$:
     $$
     \psi(w) = w^p \phi\left(\frac{1}{w}\right) = w^p - \phi_1 w^{p-1} - \phi_2 w^{p-2} - \dots - \phi_p
     $$

IV. **Fun√ß√£o de Autocovari√¢ncia:**
    A fun√ß√£o de autocovari√¢ncia $\gamma(k)$ de um processo AR(p) pode ser expressa em termos das ra√≠zes do polin√¥mio caracter√≠stico. Para um processo estacion√°rio, a fun√ß√£o de autocovari√¢ncia deve decair para zero √† medida que $k$ aumenta.  Isto ocorre se e somente se todas as ra√≠zes do polin√¥mio $\psi(w)$ estiverem dentro do c√≠rculo unit√°rio.

V.  **Condi√ß√£o de Decaimento:**
    A condi√ß√£o para que $\gamma(k)$ decaia √© equivalente √† condi√ß√£o de que a representa√ß√£o do processo AR(p) como uma soma ponderada de choques passados (sua representa√ß√£o de m√©dia m√≥vel infinita) seja convergente. Essa converg√™ncia √© garantida se e somente se as ra√≠zes do polin√¥mio caracter√≠stico estiverem fora do c√≠rculo unit√°rio.

VI. **Conclus√£o:**
    Portanto, um processo AR(p) √© estacion√°rio se e somente se todas as ra√≠zes do polin√¥mio caracter√≠stico $\phi(z) = 1 - \phi_1 z - \phi_2 z^2 - \dots - \phi_p z^p = 0$ estiverem fora do c√≠rculo unit√°rio no plano complexo. $\blacksquare$

> üí° **Exemplo Num√©rico:**
>
> 1. **Caso Estacion√°rio:** Considere um processo AR(1) com $c = 5$ e $\phi_1 = 0.7$. A m√©dia incondicional √© $E(y_t) = \frac{5}{1 - 0.7} = \frac{5}{0.3} \approx 16.67$. Isso significa que, a longo prazo, a s√©rie temporal flutua em torno de 16.67.
>
> 2. **Caso N√£o Estacion√°rio:** Considere um processo AR(1) com $c = 5$ e $\phi_1 = 1.0$. Neste caso, $1 - \phi_1 = 1 - 1 = 0$. A m√©dia incondicional seria $E(y_t) = \frac{5}{0}$, que √© indefinida. Este processo n√£o √© estacion√°rio.
>
> 3. **Caso AR(2) Estacion√°rio:** Considere um processo AR(2) com $c=10$, $\phi_1=0.4$ e $\phi_2=0.3$. A m√©dia incondicional √© $E(y_t)=\frac{10}{1-0.4-0.3} = \frac{10}{0.3} \approx 33.33$
>
> 4. **Caso AR(2) N√£o Estacion√°rio:** Considere um processo AR(2) com $c=10$, $\phi_1=0.7$ e $\phi_2=0.3$. Neste caso, $1 - \phi_1 - \phi_2 = 1 - 0.7 - 0.3 = 0$. A m√©dia incondicional √© indefinida, e o processo n√£o √© estacion√°rio.
>
> 5. **Ra√≠zes do Polin√¥mio Caracter√≠stico - AR(1):**
>
>    *   Seja um processo AR(1): $y_t = 0.5y_{t-1} + u_t$. O polin√¥mio caracter√≠stico √© $1 - 0.5z = 0$.
>    *   A raiz √© $z = \frac{1}{0.5} = 2$. Como $|2| > 1$, o processo √© estacion√°rio.
>
> 6. **Ra√≠zes do Polin√¥mio Caracter√≠stico - AR(2):**
>
>    *   Seja um processo AR(2): $y_t = 0.5y_{t-1} - 0.6y_{t-2} + u_t$. O polin√¥mio caracter√≠stico √© $1 - 0.5z + 0.6z^2 = 0$.
>    *   As ra√≠zes s√£o $z = \frac{0.5 \pm \sqrt{(-0.5)^2 - 4(0.6)(1)}}{2(0.6)} = \frac{0.5 \pm \sqrt{-2.15}}{1.2}$.
>    *   As ra√≠zes s√£o complexas: $z \approx 0.4167 \pm 1.336i$.
>    *   O m√≥dulo das ra√≠zes √© $|z| = \sqrt{0.4167^2 + 1.336^2} \approx 1.40$. Como $|z| > 1$, o processo √© estacion√°rio.
>
> 7. **Python code for roots of AR(2) process:**
> ```python
> import numpy as np
>
> # AR coefficients
> phi1 = 0.5
> phi2 = -0.6
>
> # Polynomial coefficients (1 - phi1*z - phi2*z^2 = 0) => (phi2*z^2 + phi1*z - 1 = 0)
> a = phi2
> b = phi1
> c = -1
>
> # Calculate roots
> delta = (b**2) - 4*(a*c)
>
> # Find roots
> if delta > 0:
>     x1 = (-b - np.sqrt(delta)) / (2*a)
>     x2 = (-b + np.sqrt(delta)) / (2*a)
>     print('Real and distinct roots')
>     print(f'Root 1: {x1}')
>     print(f'Root 2: {x2}')
> elif delta == 0:
>     x = (-b - np.sqrt(delta)) / (2 * a)
>     print('Real and equal root')
>     print(f'Root: {x}')
> else:
>     real_part = -b / (2*a)
>     imaginary_part = np.sqrt(abs(delta)) / (2*a)
>     x1 = complex(real_part, imaginary_part)
>     x2 = complex(real_part, -imaginary_part)
>     print('Complex roots')
>     print(f'Root 1: {x1}')
>     print(f'Root 2: {x2}')
>
> #Check that roots are outside the unit circle
> print(f'Absolute Value of Root 1: {np.abs(x1)}')
> print(f'Absolute Value of Root 2: {np.abs(x2)}')
>
> ```

### Interpreta√ß√£o e Significado da M√©dia Incondicional

A m√©dia incondicional $E(y_t)$ representa o valor m√©dio da s√©rie temporal a longo prazo, assumindo que o processo √© estacion√°rio. Ela fornece um ponto de refer√™ncia para entender o comportamento geral da s√©rie temporal.

1.  **Valor Central:** A s√©rie temporal flutua em torno da m√©dia incondicional. Em um processo estacion√°rio, os desvios da m√©dia s√£o tempor√°rios e a s√©rie tende a retornar a esse valor a longo prazo.

2.  **Ponto de Ancoragem:** A m√©dia incondicional serve como um ponto de ancoragem para a previs√£o a longo prazo. √Ä medida que o horizonte de previs√£o aumenta, a previs√£o linear √≥tima converge para a m√©dia incondicional.

3.  **Compara√ß√£o entre S√©ries:** A m√©dia incondicional permite comparar o n√≠vel m√©dio de diferentes s√©ries temporais. Se duas s√©ries temporais t√™m diferentes m√©dias incondicionais, isso indica que elas flutuam em torno de valores centrais diferentes.

> üí° **Exemplo Num√©rico:** Considere duas s√©ries temporais: uma representando os retornos de uma a√ß√£o e outra representando os retornos de um t√≠tulo do governo. Se a m√©dia incondicional dos retornos da a√ß√£o for 0.1 (10\%) e a m√©dia incondicional dos retornos do t√≠tulo for 0.03 (3\%), isso indica que, a longo prazo, espera-se que a a√ß√£o forne√ßa um retorno m√©dio maior do que o t√≠tulo do governo.
>
> Para criar este exemplo usando Python, podemos usar c√≥digo similar aos exemplos anteriores, apenas simulando duas s√©ries com diferentes par√¢metros para as suas m√©dias incondicionais, e ent√£o estimar essas m√©dias a partir dos dados gerados.
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
>
> # Parameters
> mean_stock_return = 0.1
> mean_bond_return = 0.03
> std_stock = 0.2
> std_bond = 0.05
> n = 100
>
> # Simulate returns
> np.random.seed(42)
> stock_returns = np.random.normal(mean_stock_return, std_stock, n)
> bond_returns = np.random.normal(mean_bond_return, std_bond, n)
>
> # Calculate sample means
> sample_mean_stock = np.mean(stock_returns)
> sample_mean_bond = np.mean(bond_returns)
>
> print(f"Sample Mean Stock Return: {sample_mean_stock:.4f}")
> print(f"Sample Mean Bond Return: {sample_mean_bond:.4f}")
>
> # Plotting
> plt.figure(figsize=(10, 6))
> plt.plot(stock_returns, label='Stock Returns')
> plt.plot(bond_returns, label='Bond Returns')
> plt.axhline(y=mean_stock_return, color='red', linestyle='--', label=f'Long-term Stock Mean ({mean_stock_return:.2f})')
> plt.axhline(y=mean_bond_return, color='green', linestyle='--', label=f'Long-term Bond Mean ({mean_bond_return:.2f})')
> plt.xlabel("Time")
> plt.ylabel("Returns")
> plt.title("Simulated Stock and Bond Returns")
> plt.legend()
> plt.grid(True)
> plt.show()
> ```

### M√©dia Incondicional e Estacionariedade em Covari√¢ncia

A estacionariedade em covari√¢ncia √© uma condi√ß√£o necess√°ria para que a m√©dia incondicional seja bem definida e interpret√°vel. Se o processo n√£o for estacion√°rio, a m√©dia n√£o ser√° constante ao longo do tempo e a express√£o $E(y_t) = \frac{c}{1 - \phi_1 - \phi_2 - \dots - \phi_p}$ n√£o ser√° v√°lida.

Em um processo n√£o estacion√°rio, a m√©dia pode variar ao longo do tempo, tornando a interpreta√ß√£o do "valor central" da s√©rie temporal mais complexa. Processos n√£o estacion√°rios podem apresentar tend√™ncias (crescentes ou decrescentes) ou outros padr√µes que fazem com que a m√©dia varie significativamente ao longo do tempo.

Para ilustrar como a m√©dia incondicional pode ser enganosa em processos n√£o estacion√°rios, podemos introduzir o conceito de passeio aleat√≥rio (random walk).

**Exemplo**: Considere um processo de passeio aleat√≥rio definido como $y_t = y_{t-1} + u_t$, onde $u_t$ √© um ru√≠do branco com m√©dia zero. Neste caso, $\phi_1 = 1$ e $c = 0$. Formalmente, a m√©dia incondicional seria indefinida (divis√£o por zero). Intuitivamente, o processo n√£o possui uma m√©dia para a qual ele retorna, pois ele "passeia" indefinidamente.

> üí° **Exemplo Num√©rico:** Considere uma s√©rie temporal representando o Produto Interno Bruto (PIB) de um pa√≠s. Se o PIB estiver crescendo ao longo do tempo, a s√©rie temporal n√£o ser√° estacion√°ria. Calcular uma "m√©dia incondicional" para toda a s√©rie n√£o capturar√° a tend√™ncia de crescimento. √â melhor modelar a tend√™ncia separadamente e analisar os desvios da tend√™ncia (que podem ser estacion√°rios).
>
> ```python
> import numpy as np
> import pandas as pd
> import matplotlib.pyplot as plt
>
> # Generate Sample GDP Data (with an increasing trend)
> np.random.seed(42)
> n = 100
> time = np.arange(n)
> trend = 2 * time
> noise = np.random.randn(n) * 10
> gdp = trend + noise
>
> # Calculate the mean GDP
> mean_gdp = np.mean(gdp)
>
> print("Mean GDP:", mean_gdp)
>
> # Plot the data
> plt.figure(figsize=(10, 6))
> plt.plot(gdp, label='GDP')
> plt.hlines(mean_gdp, xmin=0, xmax=n-1, color='red', label='Mean GDP')
> plt.xlabel("Time")
> plt.ylabel("GDP")
> plt.title("GDP Time Series with Increasing Trend")
> plt.legend()
> plt.grid(True)
> plt.show()
> ```
>
> Neste exemplo, podemos ver visualmente que a linha da m√©dia (em vermelho) n√£o representa bem o comportamento da s√©rie, devido √† tend√™ncia crescente.

**Proposi√ß√£o 9**: Se um processo AR(p) n√£o √© estacion√°rio, a express√£o $E(y_t) = \frac{c}{1 - \phi_1 - \phi_2 - ... - \phi_p}$ n√£o √© v√°lida e a m√©dia incondicional n√£o pode ser interpretada como o valor central em torno do qual a s√©rie flutua.

*Proof:* A deriva√ß√£o da express√£o para a m√©dia incondicional depende crucialmente da suposi√ß√£o de estacionariedade. Sem estacionariedade, $E(y_t) \neq E(y_{t-1})$ e a deriva√ß√£o n√£o se sustenta. A falta de estacionariedade invalida a interpreta√ß√£o da m√©dia como um valor central constante. $\blacksquare$

**Proposi√ß√£o 9.1**: Para um processo AR(p) n√£o estacion√°rio, a m√©dia amostral calculada a partir de uma √∫nica realiza√ß√£o da s√©rie temporal pode n√£o convergir para um valor est√°vel √† medida que o tamanho da amostra aumenta.

*Proof:* (Esbo√ßo) Em um processo estacion√°rio, a lei dos grandes n√∫meros garante que a m√©dia amostral converge para a m√©dia populacional (m√©dia incondicional) √† medida que o tamanho da amostra aumenta. No entanto, para processos n√£o estacion√°rios, essa converg√™ncia n√£o √© garantida, pois a distribui√ß√£o da s√©rie temporal muda ao longo do tempo. $\blacksquare$

Para fornecer uma prova mais formal da Proposi√ß√£o 9.1, considere o seguinte:

*Proof:*

I. **Defini√ß√£o da M√©dia Amostral:** Seja $\{y_1, y_2, ..., y_n\}$ uma realiza√ß√£o de um processo estoc√°stico. A m√©dia amostral √© definida como:
   $$
   \bar{y}_n = \frac{1}{n} \sum_{t=1}^{n} y_t
   $$

II. **Lei dos Grandes N√∫meros (LLN):** Para um processo estacion√°rio e erg√≥dico, a Lei dos Grandes N√∫meros (LLN) garante que a m√©dia amostral converge para a m√©dia populacional (m√©dia incondicional) √† medida que o tamanho da amostra aumenta:
    $$
    \lim_{n \to \infty} \bar{y}_n = E[y_t] = \mu
    $$
    onde $\mu$ √© a m√©dia incondicional do processo.

III. **N√£o Estacionariedade:** Se o processo n√£o √© estacion√°rio, ent√£o $E[y_t]$ pode depender de $t$, ou seja, $E[y_t] = \mu_t$. Neste caso, a m√©dia amostral pode ser escrita como:
     $$
     \bar{y}_n = \frac{1}{n} \sum_{t=1}^{n} y_t
     $$
     E a esperan√ßa da m√©dia amostral √©:
     $$
     E[\bar{y}_n] = \frac{1}{n} \sum_{t=1}^{n} E[y_t] = \frac{1}{n} \sum_{t=1}^{n} \mu_t
     $$

IV. **Converg√™ncia em Processos N√£o Estacion√°rios:** Para processos n√£o estacion√°rios, a sequ√™ncia $\{\mu_t\}$ pode n√£o convergir para um valor fixo. Por exemplo, se $\mu_t = t$, ent√£o $E[\bar{y}_n] = \frac{1}{n} \sum_{t=1}^{n} t = \frac{n(n+1)}{2n} = \frac{n+1}{2}$, que diverge para infinito √† medida que $n \to \infty$.

V. **Conclus√£o:** Portanto, para um processo AR(p) n√£o estacion√°rio, a m√©dia amostral $\bar{y}_n$ pode n√£o convergir para um valor est√°vel √† medida que o tamanho da amostra aumenta, pois a distribui√ß√£o da s√©rie temporal muda ao longo do tempo, e a m√©dia amostral converge para a m√©dia das m√©dias dependentes do tempo, que pode n√£o ser um valor est√°vel. $\blacksquare$

> üí° **Exemplo Num√©rico:**
> Para ilustrar a Proposi√ß√£o 9.1, vamos simular um passeio aleat√≥rio e calcular a m√©dia amostral para diferentes tamanhos de amostra:
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
>
> # Simulate a random walk
> np.random.seed(42)
> n = 1000
> errors = np.random.randn(n)
> random_walk = np.cumsum(errors)
>
> # Calculate sample means for different sample sizes
> sample_sizes = [50, 100, 200, 500, 1000]
> sample_means = []
>
> for size in sample_sizes:
>     sample_means.append(np.mean(random_walk[:size]))
>
> print("Sample Means for Different Sample Sizes:", sample_means)
>
> # Plotting the random walk and sample means
> plt.figure(figsize=(12, 6))
> plt.plot(random_walk, label='Random Walk')
> plt.xlabel("Time")
> plt.ylabel("Value")
> plt.title("Random Walk with Different Sample Means")
>
> for i, size in enumerate(sample_sizes):
>     plt.axhline(y=sample_means[i], color=f'C{i+1}', linestyle='--', label=f'Mean (n={size})')
>
> plt.legend()
> plt.grid(True)
> plt.show()
> ```
> No exemplo acima, √© poss√≠vel visualizar que as m√©dias amostrais para diferentes tamanhos de amostra n√£o convergem para um valor est√°vel, demonstrando a Proposi√ß√£o 9.1.

### Implementa√ß√£o Pr√°tica

Na pr√°tica, a estima√ß√£o da m√©dia incondicional envolve estimar os par√¢metros do modelo AR(*p*) e, em seguida, usar a express√£o $E(y_t) = \frac{c}{1 - \phi_1 - \phi_2 - \dots - \phi_p}$ para calcular a m√©dia. √â importante verificar a estacionariedade do processo antes de interpretar a m√©dia incondicional.

> üí° **Exemplo:** Usando os dados de vendas do exemplo anterior, podemos estimar os par√¢metros de um modelo AR(2) e calcular a m√©dia incondicional.
>
> ```python
> import numpy as np
> import pandas as pd
> import statsmodels.api as sm
> from statsmodels.tsa.arima.model import ARIMA
> import matplotlib.pyplot as plt
>
> # Sample Sales Data (replace with your actual data)
> np.random.seed(42)
> n = 100
> trend = np.linspace(100, 150, n)
> noise = np.random.randn(n) * 5  # Add some noise
> sales = trend + noise
>
> # Fit an AR(2) model
> model = ARIMA(sales, order=(2, 0, 0))  # AR(2) - (p, d, q)
> results = model.fit()
>
> # Extract parameters
> c = results.params[0]  # constant (intercept)
> phi1 = results.params[1] # AR(1) coefficient
> phi2 = results.params[2] # AR(2) coefficient
>
> # Calculate unconditional mean
> unconditional_mean = c / (1 - phi1 - phi2)
>
> print("Unconditional Mean:", unconditional_mean)
> ```

Se a s√©rie temporal n√£o for estacion√°ria, pode ser necess√°rio aplicar transforma√ß√µes (como diferencia√ß√£o) para torn√°-la estacion√°ria antes de ajustar um modelo AR(*p*) e calcular a m√©dia incondicional.

Para complementar a discuss√£o sobre transforma√ß√µes para garantir a estacionariedade, √© √∫til mencionar o teste de raiz unit√°ria.

**Observa√ß√£o**: O Teste de Dickey-Fuller Aumentado (ADF) √© um teste estat√≠stico comum utilizado para verificar a presen√ßa de raiz unit√°ria em uma s√©rie temporal. A presen√ßa de uma raiz unit√°ria sugere que a s√©rie n√£o √© estacion√°ria e pode necessitar de diferencia√ß√£o para se tornar estacion√°ria.

> üí° **Exemplo Num√©rico**: Suponha que aplicamos o Teste ADF a uma s√©rie temporal de pre√ßos de a√ß√µes e obtemos um p-valor de 0.6. Como o p-valor √© maior que 0.05 (n√≠vel de signific√¢ncia comum), falhamos em rejeitar a hip√≥tese nula de que a s√©rie tem uma raiz unit√°ria. Isso sugere que a s√©rie de pre√ßos de a√ß√µes n√£o √© estacion√°ria. Para torn√°-la estacion√°ria, podemos calcular a s√©rie de retornos (diferencia√ß√£o de primeira ordem) e aplicar o teste ADF novamente. Se o p-valor para a s√©rie de retornos for menor que 0.05, podemos concluir que a s√©rie de retornos √© estacion√°ria.
>
> ```python
> import numpy as np
> import pandas as pd
> from statsmodels.tsa.stattools import adfuller
> import matplotlib.pyplot as plt
>
> # Generate a non-stationary time series (random walk)
> np.random.seed(42)
> n = 100
> random_walk = np.cumsum(np.random.randn(n))
>
> # Perform Augmented Dickey-Fuller test
> adf_result = adfuller(random_walk)
> print("ADF Test Results for Original Series:")
> print(f'ADF Statistic: {adf_result[0]}')
> print(f'p-value: {adf_result[1]}')
> print('Critical Values:')
> for key, value in adf_result[4].items():
>     print(f'   {key}: {value}')
>
> # Difference the series to make it stationary
> differenced_series = np.diff(random_walk)
>
> # Perform ADF test on the differenced series
> adf_result_diff = adfuller(differenced_series)
> print("\nADF Test Results for Differenced Series:")
> print(f'ADF Statistic: {adf_result_diff[0]}')
> print(f'p-value: {adf_result_diff[1]}')
> print('Critical Values:')
> for key, value in adf_result_diff[4].items():
>     print(f'   {key}: {value}')
>
> # Plotting
> plt.figure(figsize=(12, 6))
> plt.plot(random_walk, label='Original Series (Random Walk)')
> plt.plot(differenced_series, label='Differenced Series')
> plt.xlabel("Time")
> plt.ylabel("Value")
> plt.title("Original and Differenced Time Series")
> plt.legend()
> plt.grid(True)
> plt.show()
> ```

### Conclus√£o

Este cap√≠tulo forneceu uma an√°lise detalhada da m√©dia incondicional em modelos AR(*p*) estacion√°rios. Demonstramos formalmente como a m√©dia incondicional √© derivada, interpretada e utilizada na pr√°tica. Enfatizamos a import√¢ncia da estacionariedade em covari√¢ncia para a validade da m√©dia incondicional e discutimos como a n√£o estacionariedade afeta a interpreta√ß√£o e modelagem de s√©ries temporais. Compreender a m√©dia incondicional √© essencial para a an√°lise e previs√£o de s√©ries temporais, e a combina√ß√£o dos conceitos discutidos neste cap√≠tulo com os apresentados nos cap√≠tulos anteriores fornece uma base s√≥lida para a modelagem de s√©ries temporais heterosced√°sticas.

### Refer√™ncias
[^1]: P√°gina 657.
<!-- END -->