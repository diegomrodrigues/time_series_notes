## Condi√ß√µes para a Positividade Definida em Modelos MGARCH via Decomposi√ß√£o de Cholesky

### Introdu√ß√£o

Em Modelos GARCH Multivariados (MGARCH), garantir que a matriz de covari√¢ncia condicional $H_t$ seja positiva definida √© crucial para a validade do modelo. Como vimos anteriormente, uma maneira de assegurar isso √© parametrizar a matriz constante $K$ na equa√ß√£o do MGARCH como $PP'$, onde $P$ √© uma matriz triangular inferior. Este cap√≠tulo aprofunda-se nas condi√ß√µes sob as quais essa parametriza√ß√£o garante a positividade definida de $K$, e, por extens√£o, da matriz $H_t$. O lema que formaliza essa garantia foi previamente apresentado [^Previous Topics]. Aqui, estendemos a discuss√£o com provas e exemplos adicionais.

### Condi√ß√µes Suficientes para a Positividade Definida de K

Para recapitular, consideremos a generaliza√ß√£o vetorial do modelo GARCH(r, m) [^670]:

$$
H_t = K + \Delta_1 H_{t-1}\Delta_1' + \Delta_2 H_{t-2}\Delta_2' + \dots + \Delta_r H_{t-r}\Delta_r' + A_0 u_{t-1}u_{t-1}'A_0' + A_1 u_{t-2}u_{t-2}'A_1' + \dots + A_m u_{t-m}u_{t-m}'A_m'
$$

onde $K, \Delta_i$ e $A_j$ s√£o matrizes $n \times n$ de par√¢metros. A refer√™ncia [^670] argumenta que a positividade definida de $H_t$ √© garantida se $K$ √© positiva definida. Uma forma comum de garantir que $K$ seja positiva definida √© atrav√©s da decomposi√ß√£o de Cholesky, onde $K$ √© escrita como o produto de uma matriz triangular inferior $P$ e sua transposta $P'$, ou seja, $K = PP'$.

**Teorema 3:** Se $P$ √© uma matriz triangular inferior com elementos diagonais estritamente positivos, ent√£o a matriz $K = PP'$ √© sim√©trica e positiva definida.

*Prova:*

I. *Simetria:* Primeiro, mostramos que $K$ √© sim√©trica. Temos $K' = (PP')' = (P')'P' = PP' = K$. Portanto, $K$ √© sim√©trica.

II. *Positividade Definida:* Seja $x$ um vetor n√£o nulo em $\mathbb{R}^n$. Queremos mostrar que $x'Kx > 0$. Substituindo $K = PP'$, temos $x'Kx = x'PP'x = (P'x)'(P'x) = ||P'x||^2$, onde $||\cdot||$ denota a norma Euclidiana. Como a norma √© sempre n√£o negativa, temos $||P'x||^2 \geq 0$. Para provar que $x'Kx > 0$, precisamos mostrar que $||P'x||^2 \neq 0$ quando $x \neq 0$.

III. Suponha, por contradi√ß√£o, que $||P'x||^2 = 0$. Ent√£o $P'x = 0$. Como $P$ √© triangular inferior com elementos diagonais estritamente positivos, $P$ √© invert√≠vel (seu determinante √© o produto dos elementos diagonais, que √© estritamente positivo). Portanto, $P'$ tamb√©m √© invert√≠vel. Assim, a √∫nica solu√ß√£o para $P'x = 0$ √© $x = 0$. Isso contradiz a suposi√ß√£o de que $x$ √© n√£o nulo.

IV. Portanto, para todo $x \neq 0$, temos $x'Kx = ||P'x||^2 > 0$. Isso demonstra que $K$ √© positiva definida. ‚ñ†

> üí° **Exemplo Num√©rico:**
>
> Suponha que temos uma matriz triangular inferior $P$:
>
> $$
> P = \begin{bmatrix}
> 2 & 0 \\
> 1 & 3
> \end{bmatrix}
> $$
>
> Os elementos diagonais s√£o estritamente positivos (2 e 3). Vamos calcular $K = PP'$:
>
> $$
> K = \begin{bmatrix}
> 2 & 0 \\
> 1 & 3
> \end{bmatrix} \begin{bmatrix}
> 2 & 1 \\
> 0 & 3
> \end{bmatrix} = \begin{bmatrix}
> 4 & 2 \\
> 2 & 10
> \end{bmatrix}
> $$
>
> Para verificar se $K$ √© positiva definida, podemos calcular $x'Kx$ para um vetor arbitr√°rio $x = \begin{bmatrix} a \\ b \end{bmatrix}$:
>
> $$
> x'Kx = \begin{bmatrix} a & b \end{bmatrix} \begin{bmatrix}
> 4 & 2 \\
> 2 & 10
> \end{bmatrix} \begin{bmatrix} a \\ b \end{bmatrix} = 4a^2 + 4ab + 10b^2
> $$
>
> Podemos reescrever isso como:
>
> $$
> 4a^2 + 4ab + 10b^2 = (2a + b)^2 + 9b^2
> $$
>
> Como $(2a + b)^2 \geq 0$ e $9b^2 \geq 0$, e pelo menos um dos termos √© estritamente positivo se $x$ √© n√£o nulo, $x'Kx > 0$ para todo $x \neq 0$. Portanto, $K$ √© positiva definida.
>
> ```python
> import numpy as np
>
> P = np.array([[2, 0], [1, 3]])
> K = P @ P.T  # Correctly calculates PP'
> print("Matriz P:\n", P)
> print("Matriz K = PP':\n", K)
>
> # Verificando a positividade definida calculando os autovalores
> eigenvalues = np.linalg.eigvals(K)
> print("Autovalores de K:", eigenvalues)
> ```

**Corol√°rio 3.1:** Se $P$ √© uma matriz triangular inferior com elementos diagonais n√£o negativos e pelo menos um elemento diagonal estritamente positivo, e $P'x \neq 0$ para todo $x \neq 0$, ent√£o a matriz $K = PP'$ √© sim√©trica e positiva semidefinida.

*Prova:* A simetria segue como no Teorema 3. Para positividade semidefinida, $x'Kx = ||P'x||^2 \geq 0$ para todo $x$. Se $P'x = 0$ para algum $x \neq 0$, ent√£o $x'Kx = 0$. Caso contr√°rio, $x'Kx > 0$. Logo, $K$ √© positiva semidefinida. ‚ñ†

> üí° **Exemplo Num√©rico:**
>
> Considere a matriz triangular inferior:
>
> $$
> P = \begin{bmatrix}
> 2 & 0 \\
> 1 & 0
> \end{bmatrix}
> $$
>
> Note que um dos elementos diagonais √© zero. Calculamos $K = PP'$:
>
> $$
> K = \begin{bmatrix}
> 2 & 0 \\
> 1 & 0
> \end{bmatrix} \begin{bmatrix}
> 2 & 1 \\
> 0 & 0
> \end{bmatrix} = \begin{bmatrix}
> 4 & 2 \\
> 2 & 1
> \end{bmatrix}
> $$
>
> Agora, seja $x = \begin{bmatrix} 1 \\ -2 \end{bmatrix}$. Ent√£o:
>
> $$
> x'Kx = \begin{bmatrix} 1 & -2 \end{bmatrix} \begin{bmatrix}
> 4 & 2 \\
> 2 & 1
> \end{bmatrix} \begin{bmatrix} 1 \\ -2 \end{bmatrix} = \begin{bmatrix} 0 & 0 \end{bmatrix} \begin{bmatrix} 1 \\ -2 \end{bmatrix} = 0
> $$
>
> Como encontramos um vetor n√£o nulo $x$ tal que $x'Kx = 0$, a matriz $K$ √© positiva semidefinida, mas n√£o positiva definida.
>
> ```python
> import numpy as np
>
> P = np.array([[2, 0], [1, 0]])
> K = P @ P.T
> print("Matriz P:\n", P)
> print("Matriz K = PP':\n", K)
>
> # Verificando a positividade semidefinida calculando os autovalores
> eigenvalues = np.linalg.eigvals(K)
> print("Autovalores de K:", eigenvalues)
> ```
>
> A sa√≠da dos autovalores ser√° algo pr√≥ximo de `[5. 0.]`, confirmando que a matriz √© positiva semidefinida (um autovalor √© zero).

**Teorema 3.2:** Seja $K$ uma matriz sim√©trica positiva definida. Ent√£o, existe uma √∫nica matriz triangular inferior $P$ com elementos diagonais estritamente positivos tal que $K = PP'$.

*Prova (Esbo√ßo):* A prova construtiva deste teorema fornece um algoritmo (Decomposi√ß√£o de Cholesky) para calcular $P$ a partir de $K$. A unicidade pode ser demonstrada mostrando que se existissem duas tais matrizes $P_1$ e $P_2$, ent√£o $P_1P_1' = P_2P_2'$, o que implicaria $P_2^{-1}P_1 = P_2'(P_1')^{-1}$. Como o lado esquerdo √© triangular inferior e o lado direito √© triangular superior, ambas devem ser diagonais. Usando o fato de que os elementos diagonais de $P_1$ e $P_2$ s√£o positivos, pode-se mostrar que $P_1 = P_2$. ‚ñ†

> üí° **Exemplo Num√©rico:**
>
> Seja $K = \begin{bmatrix} 4 & 2 \\ 2 & 5 \end{bmatrix}$. $K$ √© sim√©trica e positiva definida (verifique os autovalores ou o determinante e o primeiro elemento diagonal). Vamos encontrar a matriz $P$ tal que $K = PP'$.
>
> A matriz $P$ tem a forma $\begin{bmatrix} p_{11} & 0 \\ p_{21} & p_{22} \end{bmatrix}$. Ent√£o:
>
> $$
> PP' = \begin{bmatrix} p_{11} & 0 \\ p_{21} & p_{22} \end{bmatrix} \begin{bmatrix} p_{11} & p_{21} \\ 0 & p_{22} \end{bmatrix} = \begin{bmatrix} p_{11}^2 & p_{11}p_{21} \\ p_{11}p_{21} & p_{21}^2 + p_{22}^2 \end{bmatrix}
> $$
>
> Comparando com $K$, temos:
>
> 1. $p_{11}^2 = 4 \Rightarrow p_{11} = 2$ (j√° que $p_{11} > 0$)
> 2. $p_{11}p_{21} = 2 \Rightarrow 2p_{21} = 2 \Rightarrow p_{21} = 1$
> 3. $p_{21}^2 + p_{22}^2 = 5 \Rightarrow 1^2 + p_{22}^2 = 5 \Rightarrow p_{22}^2 = 4 \Rightarrow p_{22} = 2$ (j√° que $p_{22} > 0$)
>
> Portanto, $P = \begin{bmatrix} 2 & 0 \\ 1 & 2 \end{bmatrix}$. Podemos verificar que $PP' = K$.
>
> ```python
> import numpy as np
> import numpy.linalg as la
>
> K = np.array([[4, 2], [2, 5]])
>
> # Usando a fun√ß√£o cholesky para encontrar a matriz P
> P = la.cholesky(K) # The result of this function is an upper triangular matrix, need to transpose it
> P = P.T
>
> print("Matriz K:\n", K)
> print("Matriz P (Decomposi√ß√£o de Cholesky):\n", P)
>
> # Verificando se PP' = K
> print("PP':\n", P @ P.T)
> ```

**Corol√°rio 4:** Seja $P$ uma matriz triangular superior com elementos diagonais estritamente positivos. Ent√£o, a matriz $K = P'P$ √© sim√©trica e positiva definida.

*Prova:*

I. *Simetria:* Temos $K' = (P'P)' = P'(P')' = P'P = K$. Portanto, $K$ √© sim√©trica.

II. *Positividade Definida:* Seja $x$ um vetor n√£o nulo em $\mathbb{R}^n$. Queremos mostrar que $x'Kx > 0$. Substituindo $K = P'P$, temos $x'Kx = x'P'Px = (Px)'(Px) = ||Px||^2$, onde $||\cdot||$ denota a norma Euclidiana. Como a norma √© sempre n√£o negativa, temos $||Px||^2 \geq 0$. Para provar que $x'Kx > 0$, precisamos mostrar que $||Px||^2 \neq 0$ quando $x \neq 0$.

III. Suponha, por contradi√ß√£o, que $||Px||^2 = 0$. Ent√£o $Px = 0$. Como $P$ √© triangular superior com elementos diagonais estritamente positivos, $P$ √© invert√≠vel (seu determinante √© o produto dos elementos diagonais, que √© estritamente positivo). Assim, a √∫nica solu√ß√£o para $Px = 0$ √© $x = 0$. Isso contradiz a suposi√ß√£o de que $x$ √© n√£o nulo.

IV. Portanto, para todo $x \neq 0$, temos $x'Kx = ||Px||^2 > 0$. Isso demonstra que $K$ √© positiva definida. ‚ñ†

> üí° **Exemplo Num√©rico:**
>
> Considere a matriz triangular superior:
>
> $$
> P = \begin{bmatrix}
> 2 & 1 \\
> 0 & 3
> \end{bmatrix}
> $$
>
> Calculamos $K = P'P$:
>
> $$
> K = \begin{bmatrix}
> 2 & 0 \\
> 1 & 3
> \end{bmatrix} \begin{bmatrix}
> 2 & 1 \\
> 0 & 3
> \end{bmatrix} = \begin{bmatrix}
> 4 & 2 \\
> 2 & 10
> \end{bmatrix}
> $$
>
> Esta √© a mesma matriz $K$ que obtivemos no primeiro exemplo, e j√° mostramos que √© positiva definida.
>
> ```python
> import numpy as np
>
> P = np.array([[2, 1], [0, 3]])
> K = P.T @ P
> print("Matriz P:\n", P)
> print("Matriz K = P'P:\n", K)
>
> # Verificando a positividade definida calculando os autovalores
> eigenvalues = np.linalg.eigvals(K)
> print("Autovalores de K:", eigenvalues)
> ```

### Considera√ß√µes Pr√°ticas e Parametriza√ß√£o

Na pr√°tica, ao implementar modelos MGARCH, essa decomposi√ß√£o √© √∫til para reduzir o n√∫mero de par√¢metros livres a serem estimados e para garantir que a matriz $K$ seja, de fato, positiva definida. Isso √© especialmente importante porque a positividade definida de $K$ √© uma condi√ß√£o suficiente para garantir que a matriz de covari√¢ncia condicional $H_t$ seja positiva definida, o que √© uma exig√™ncia fundamental para a consist√™ncia e a interpretabilidade do modelo.

Para ilustrar, considere um caso simples com dois ativos (n=2). A matriz $P$ pode ser parametrizada como:

$$
P = \begin{bmatrix}
p_{11} & 0 \\
p_{21} & p_{22}
\end{bmatrix}
$$

onde $p_{11} > 0$ e $p_{22} > 0$. Ent√£o,

$$
K = PP' = \begin{bmatrix}
p_{11}^2 & p_{11}p_{21} \\
p_{11}p_{21} & p_{21}^2 + p_{22}^2
\end{bmatrix}
$$

Para garantir que $p_{11}$ e $p_{22}$ sejam positivos, podemos parametriz√°-los como exponenciais de outros par√¢metros irrestritos, por exemplo, $p_{11} = e^{\alpha}$ e $p_{22} = e^{\beta}$, onde $\alpha$ e $\beta$ s√£o par√¢metros reais a serem estimados. A vantagem dessa abordagem √© que a restri√ß√£o de positividade √© automaticamente satisfeita durante a estima√ß√£o, simplificando o processo de otimiza√ß√£o e garantindo a validade dos resultados.

> üí° **Exemplo Num√©rico:**
>
> Seja $\alpha = 0.5$ e $\beta = 0.7$, e $p_{21} = 0.3$. Ent√£o $p_{11} = e^{0.5} \approx 1.6487$ e $p_{22} = e^{0.7} \approx 2.0138$. Portanto:
>
> $$
> P = \begin{bmatrix}
> 1.6487 & 0 \\
> 0.3 & 2.0138
> \end{bmatrix}
> $$
>
> E:
>
> $$
> K = PP' = \begin{bmatrix}
> 1.6487^2 & 1.6487 \times 0.3 \\
> 1.6487 \times 0.3 & 0.3^2 + 2.0138^2
> \end{bmatrix} = \begin{bmatrix}
> 2.7182 & 0.4946 \\
> 0.4946 & 4.1455
> \end{bmatrix}
> $$
>
> Podemos verificar que $K$ √© positiva definida calculando seus autovalores (como feito no exemplo anterior).
>
> ```python
> import numpy as np
>
> alpha = 0.5
> beta = 0.7
> p21 = 0.3
>
> p11 = np.exp(alpha)
> p22 = np.exp(beta)
>
> P = np.array([[p11, 0], [p21, p22]])
> K = P @ P.T
>
> print("Matriz P:\n", P)
> print("Matriz K = PP':\n", K)
>
> # Verificando a positividade definida calculando os autovalores
> eigenvalues = np.linalg.eigvals(K)
> print("Autovalores de K:", eigenvalues)
> ```

**Proposi√ß√£o 5:** Seja $A$ uma matriz sim√©trica $n \times n$. Ent√£o $A$ √© positiva definida se e somente se todos os seus autovalores s√£o estritamente positivos.

*Prova:*

I. *Defini√ß√£o de Matriz Positiva Definida:* Uma matriz sim√©trica $A$ √© positiva definida se e somente se $x'Ax > 0$ para todo vetor n√£o nulo $x$.

II. *Decomposi√ß√£o Espectral:* Como $A$ √© sim√©trica, existe uma matriz ortogonal $Q$ (isto √©, $Q'Q = I$) e uma matriz diagonal $\Lambda$ tal que $A = Q\Lambda Q'$, onde $\Lambda$ cont√©m os autovalores de $A$ na diagonal.

III. *Transforma√ß√£o da Desigualdade:* Seja $x$ um vetor n√£o nulo. Ent√£o, $x'Ax = x'Q\Lambda Q'x$. Definindo $y = Q'x$, temos $x'Ax = y'\Lambda y$. Como $Q$ √© ortogonal e $x$ √© n√£o nulo, $y$ tamb√©m √© n√£o nulo.

IV. *Express√£o em Termos de Autovalores:* Seja $\lambda_i$ o $i$-√©simo autovalor de $A$. Ent√£o, $y'\Lambda y = \sum_{i=1}^n \lambda_i y_i^2$.

V. *Condi√ß√£o para Positividade Definida:* Para que $A$ seja positiva definida, precisamos que $\sum_{i=1}^n \lambda_i y_i^2 > 0$ para todo vetor n√£o nulo $y$. Isso s√≥ √© poss√≠vel se todos os autovalores $\lambda_i$ forem estritamente positivos.

VI. *Conclus√£o:* Portanto, $A$ √© positiva definida se e somente se todos os seus autovalores s√£o estritamente positivos. ‚ñ†

Portanto, uma alternativa √† verifica√ß√£o da positividade definida de $K$ ap√≥s a estima√ß√£o (como feito no exemplo a seguir) √© calcular seus autovalores e verificar se s√£o todos positivos.

### Exemplo Num√©rico Detalhado

Considere um modelo MGARCH(1,1) com dois ativos (n=2) e a parametriza√ß√£o $K = PP'$ descrita acima. Suponha que, ap√≥s a estima√ß√£o, obtivemos os seguintes valores para os par√¢metros: $\alpha = 0.5$, $\beta = 0.7$, e $p_{21} = 0.3$. Ent√£o, $p_{11} = e^{0.5} \approx 1.6487$ e $p_{22} = e^{0.7} \approx 2.0138$. A matriz $P$ √©, portanto:

$$
P = \begin{bmatrix}
1.6487 & 0 \\
0.3 & 2.0138
\end{bmatrix}
$$

E a matriz $K$ √©:

$$
K = PP' = \begin{bmatrix}
1.6487^2 & 1.6487 \cdot 0.3 \\
1.6487 \cdot 0.3 & 0.3^2 + 2.0138^2
\end{bmatrix} = \begin{bmatrix}
2.7182 & 0.4946 \\
0.4946 & 4.1455
\end{bmatrix}
$$

Para verificar numericamente que $K$ √© positiva definida, podemos calcular seus autovalores:

```python
import numpy as np

K = np.array([[2.7182, 0.4946], [0.4946, 4.1455]])
eigenvalues = np.linalg.eigvals(K)
print(eigenvalues)
```

A sa√≠da √© `[2.63149368 4.23220632]`. Como ambos os autovalores s√£o positivos, confirmamos que $K$ √© positiva definida.

### Conclus√£o

A parametriza√ß√£o da matriz constante $K$ como $PP'$, onde $P$ √© uma matriz triangular inferior com elementos diagonais estritamente positivos, √© uma t√©cnica eficaz para garantir a positividade definida de $K$ em modelos MGARCH. Essa condi√ß√£o √© crucial para assegurar que a matriz de covari√¢ncia condicional $H_t$ seja v√°lida, o que √© fundamental para a consist√™ncia e a interpretabilidade do modelo. Al√©m disso, o uso de transforma√ß√µes exponenciais nos elementos diagonais de $P$ simplifica o processo de estima√ß√£o, garantindo que as restri√ß√µes de positividade sejam automaticamente satisfeitas. A decomposi√ß√£o de Cholesky n√£o s√≥ facilita a estima√ß√£o, mas tamb√©m assegura que o modelo seja economicamente significativo e interpretabilidade dos resultados, sendo uma t√©cnica padr√£o na modelagem de volatilidade multivariada.

### Refer√™ncias

[^670]: Cap√≠tulo 21, Se√ß√£o "Multivariate GARCH Models".
<!-- END -->