## Estima√ß√£o de M√°xima Verossimilhan√ßa (MLE) para Modelos Heterosced√°sticos

### Introdu√ß√£o

Este cap√≠tulo explora o m√©todo de **Estima√ß√£o de M√°xima Verossimilhan√ßa (MLE)** no contexto de modelos de s√©ries temporais com heteroscedasticidade, especificamente para modelos **ARCH** (Autoregressive Conditional Heteroskedasticity). O objetivo √© fornecer uma compreens√£o detalhada de como estimar os par√¢metros desses modelos, considerando tanto a formula√ß√£o da fun√ß√£o de log-verossimilhan√ßa quanto os m√©todos de otimiza√ß√£o num√©rica utilizados.

### Conceitos Fundamentais

Dado um modelo de regress√£o com perturba√ß√µes **ARCH**, a estima√ß√£o dos par√¢metros torna-se um problema de maximiza√ß√£o da fun√ß√£o de verossimilhan√ßa [^21.1.17]. Assume-se que a equa√ß√£o de regress√£o √© da forma:

$y_t = x_t'\beta + u_t$

onde $y_t$ √© a vari√°vel dependente, $x_t$ √© um vetor de vari√°veis explicativas predeterminadas, $\beta$ √© o vetor de coeficientes a serem estimados, e $u_t$ √© o termo de perturba√ß√£o que segue um processo **ARCH** [^21.1.17].

> üí° **Exemplo Num√©rico:** Suponha que estamos modelando o retorno di√°rio de uma a√ß√£o ($y_t$) em fun√ß√£o do retorno di√°rio do √≠ndice de mercado ($x_t$). Ent√£o, $y_t$ seria o retorno da a√ß√£o no dia *t*, $x_t$ seria o retorno do √≠ndice no dia *t*, e $\beta$ representaria a sensibilidade da a√ß√£o ao mercado (beta). $u_t$ representa o erro n√£o explicado pelo modelo linear, que iremos modelar como um processo ARCH.

Assume-se tamb√©m que $u_t$ satisfaz [^21.1.9, 21.1.10]:
$u_t = \sqrt{h_t}v_t$
onde $v_t$ √© uma sequ√™ncia i.i.d. com m√©dia zero e vari√¢ncia unit√°ria, e $h_t$ evolui de acordo com um processo **ARCH**.

> üí° **Exemplo Num√©rico:** Se $h_t = 0.01$, ent√£o o desvio padr√£o condicional de $u_t$ √© $\sqrt{0.01} = 0.1$. Isso significa que, dado o hist√≥rico at√© o momento *t*, esperamos que o erro $u_t$ se desvie de zero, em m√©dia, por 0.1. $v_t$ √© o choque padronizado, geralmente assumido como Normal(0,1).
Para realizar a estima√ß√£o por **M√°xima Verossimilhan√ßa**, √© necess√°rio formular a fun√ß√£o de log-verossimilhan√ßa. Condicionando nas primeiras *m* observa√ß√µes (onde *m* √© a ordem do processo **ARCH**), e utilizando as observa√ß√µes $t = 1, 2, ..., T$, a fun√ß√£o de log-verossimilhan√ßa amostral condicional √© dada por [^21.1.20]:

$$L(\theta) = \sum_{t=1}^{T} \log f(y_t|x_t, Y_{t-1}; \theta) = -\frac{T}{2}\log(2\pi) - \frac{1}{2}\sum_{t=1}^{T} \log(h_t) - \frac{1}{2}\sum_{t=1}^{T} \frac{(y_t - x_t'\beta)^2}{h_t}$$

onde $\theta$ √© o vetor de todos os par√¢metros a serem estimados, incluindo os coeficientes da regress√£o $\beta$ e os par√¢metros que governam a evolu√ß√£o da vari√¢ncia condicional $h_t$. O termo $Y_{t-1}$ denota o vetor de observa√ß√µes at√© a data $t$, ou seja, $Y_t = (y_t, y_{t-1},\ldots, y_1, y_0,\ldots, y_{-m+1}, x_t', x_{t-1}',\ldots, x_1', x_0',\ldots, x_{-m+1}')$[^21.1.17].

**Observa√ß√£o 1:** A fun√ß√£o de log-verossimilhan√ßa acima assume que os erros $v_t$ seguem uma distribui√ß√£o normal. No entanto, outras distribui√ß√µes podem ser consideradas, como a distribui√ß√£o *t* de Student, que √© mais robusta √† presen√ßa de outliers.

> üí° **Exemplo Num√©rico:** Se $T = 250$ (dias √∫teis em um ano), e para um certo dia $t$, $h_t = 0.01$ e $(y_t - x_t'\beta)^2 = u_t^2 = 0.0081$, ent√£o a contribui√ß√£o desse dia para a fun√ß√£o de log-verossimilhan√ßa seria: $-\frac{1}{2}\log(2\pi) - \frac{1}{2}\log(0.01) - \frac{1}{2} \frac{0.0081}{0.01} \approx -0.9189 - (-2.3026) - 0.405 \approx 0.9787$. Note que estamos maximizando a *soma* dessas contribui√ß√µes.

Para uma dada avalia√ß√£o num√©rica do vetor de par√¢metros $\theta$, a sequ√™ncia de vari√¢ncias condicionais pode ser calculada a partir de [^21.1.19]:

$h_t = \zeta + \alpha_1(y_{t-1} - x_{t-1}'\beta)^2 + \alpha_2(y_{t-2} - x_{t-2}'\beta)^2 + \ldots + \alpha_m(y_{t-m} - x_{t-m}'\beta)^2$

$h_t = [z(\beta)]'\delta$

onde $\zeta$, $\alpha_1$, $\alpha_2$, ..., $\alpha_m$ s√£o os par√¢metros do modelo **ARCH**, $z(\beta)$ √© um vetor de regressores, e $\delta = (\zeta, \alpha_1, \alpha_2,\ldots, \alpha_m)'$ [^21.1.19].

> üí° **Exemplo Num√©rico:** Considere um modelo ARCH(1): $h_t = \zeta + \alpha_1(y_{t-1} - x_{t-1}'\beta)^2$. Se $\zeta = 0.005$ e $\alpha_1 = 0.4$, e $(y_{t-1} - x_{t-1}'\beta)^2 = 0.01$, ent√£o $h_t = 0.005 + 0.4 * 0.01 = 0.009$. Isso significa que a volatilidade condicional no dia *t* √© influenciada pela magnitude do choque n√£o explicado no dia *t-1*. Um $\alpha_1$ maior implica que choques passados t√™m um impacto maior na volatilidade atual.

A estima√ß√£o dos par√¢metros $\theta$ √© realizada maximizando a fun√ß√£o $L(\theta)$ numericamente, pois geralmente n√£o existe uma solu√ß√£o anal√≠tica [^21.1.20]. Os m√©todos num√©ricos para maximizar a fun√ß√£o de log-verossimilhan√ßa s√£o abordados na se√ß√£o 5.7 [^21.1.20].

> üí° **Exemplo Num√©rico:** Podemos usar um algoritmo de otimiza√ß√£o como o BFGS (Broyden‚ÄìFletcher‚ÄìGoldfarb‚ÄìShanno) para encontrar os valores de $\beta$, $\zeta$, e $\alpha_1$ que maximizam a fun√ß√£o de log-verossimilhan√ßa. Estes algoritmos requerem um valor inicial para os par√¢metros e iterativamente atualizam estes valores at√© que a fun√ß√£o de log-verossimilhan√ßa convirja para um m√°ximo.

A derivada do log da verossimilhan√ßa condicional da *t*-√©sima observa√ß√£o com rela√ß√£o ao vetor de par√¢metros $\theta$, conhecida como *t*-√©simo score, √© dada por [^21.1.21]:

$$s_t(\theta) = \frac{\partial \log f(y_t|x_t, Y_{t-1}; \theta)}{\partial \theta} = \begin{bmatrix} \frac{u_t^2 - h_t}{2h_t^2} \frac{\partial h_t}{\partial \theta} + \frac{(x_t u_t)}{h_t} \\ 0 \end{bmatrix} = \begin{bmatrix} \frac{(u_t^2 - h_t)}{2h_t^2} \frac{\partial h_t}{\partial \theta} \\ 0 \end{bmatrix} + \begin{bmatrix} \frac{(x_t u_t)}{h_t} \\ 0 \end{bmatrix}$$

$$s_t(\theta) = \begin{bmatrix} {(u_t^2 - h_t)/(2h_t^2)} \end{bmatrix} \begin{bmatrix} \frac{\partial h_t}{\partial \theta} \end{bmatrix} + \begin{bmatrix} {(x_t u_t)/h_t} \\ 0 \end{bmatrix}$$

$$s_t(\theta) = \begin{bmatrix} {(u_t^2 - h_t)/(2h_t)} \end{bmatrix} \begin{bmatrix} {z_t(\beta)} \end{bmatrix} + \begin{bmatrix} {(x_t u_t)/h_t} \\ 0 \end{bmatrix}$$

onde $z_t(\beta)$ consiste em derivadas de primeira ordem de $h_t$.

A fun√ß√£o de verossimilhan√ßa pode ser maximizada utilizando o m√©todo de *scoring*, como em Engle (1982, p. 997) [^21.1.21], ou utilizando o algoritmo de Berndt, Hall, Hall, e Hausman (1974), como em Bollerslev (1986, p. 317) [^21.1.21]. Alternativamente, o gradiente da fun√ß√£o de log-verossimilhan√ßa pode ser calculado analiticamente a partir da soma dos *scores*:

$\nabla L(\theta) = \sum_{t=1}^{T} s_t(\theta)$

ou numericamente por diferencia√ß√£o num√©rica da fun√ß√£o de log-verossimilhan√ßa [^21.1.20]. O gradiente avaliado analiticamente ou numericamente pode ser utilizado com qualquer um dos procedimentos de otimiza√ß√£o num√©rica descritos na Se√ß√£o 5.7.

√â importante notar que a imposi√ß√£o das condi√ß√µes de estacionariedade ($\sum_{i=1}^m \alpha_i < 1$) e de n√£o negatividade ($\alpha_i \geq 0$ para todo *i*) pode ser dif√≠cil na pr√°tica [^21.1.21]. Tipicamente, o valor de *m* √© mantido pequeno ou alguma estrutura *ad hoc* √© imposta na sequ√™ncia {$\alpha_i$}$_{i=1}^m$, como em Engle (1982, equa√ß√£o (38)) [^21.1.21].

> üí° **Exemplo Num√©rico:** No modelo ARCH(1), a condi√ß√£o de estacionariedade √© simplesmente $\alpha_1 < 1$. Se estimarmos $\alpha_1 = 1.2$, isso indicaria que o processo n√£o √© estacion√°rio, e a vari√¢ncia incondicional seria infinita. Na pr√°tica, isso sugere que o modelo precisa ser reespecificado (e.g., incluir mais lags ou usar um modelo GARCH).

**Teorema 1:** Sob certas condi√ß√µes de regularidade, os estimadores de m√°xima verossimilhan√ßa dos par√¢metros do modelo ARCH s√£o consistentes e assintoticamente normais. A matriz de covari√¢ncia assint√≥tica pode ser estimada utilizando a matriz de informa√ß√£o de Fisher ou o estimador de Huber-White robusto √† heteroscedasticidade.

> üí° **Exemplo Num√©rico:** Ap√≥s a estima√ß√£o, podemos obter intervalos de confian√ßa para os par√¢metros. Por exemplo, um intervalo de confian√ßa de 95% para $\alpha_1$ pode ser [0.3, 0.5]. Isso significa que, sob as condi√ß√µes do teorema, temos 95% de confian√ßa que o verdadeiro valor de $\alpha_1$ est√° dentro desse intervalo.

**Proposi√ß√£o 1:** A condi√ß√£o de estacionariedade $\sum_{i=1}^m \alpha_i < 1$ para o modelo ARCH(m) garante que a vari√¢ncia incondicional do processo $u_t$ seja finita.

*Proof:*
A vari√¢ncia incondicional √© dada por $E[u_t^2] = E[h_t]$. Tomando esperan√ßas na equa√ß√£o da vari√¢ncia condicional:
$E[h_t] = \zeta + \alpha_1 E[u_{t-1}^2] + \ldots + \alpha_m E[u_{t-m}^2]$.
Sob estacionariedade, $E[u_t^2] = E[u_{t-1}^2] = \ldots = E[u_{t-m}^2] = E[h_t] = \sigma^2$.
Portanto, $\sigma^2 = \zeta + \alpha_1 \sigma^2 + \ldots + \alpha_m \sigma^2 = \zeta + \sigma^2 \sum_{i=1}^m \alpha_i$.
Resolvendo para $\sigma^2$, obtemos: $\sigma^2 = \frac{\zeta}{1 - \sum_{i=1}^m \alpha_i}$.
Para que $\sigma^2$ seja finita e positiva, √© necess√°rio que $1 - \sum_{i=1}^m \alpha_i > 0$, ou seja, $\sum_{i=1}^m \alpha_i < 1$.

‚ñ†

> üí° **Exemplo Num√©rico:** Se $\zeta = 0.005$ e $\alpha_1 = 0.4$, ent√£o a vari√¢ncia incondicional √© $\sigma^2 = \frac{0.005}{1 - 0.4} = \frac{0.005}{0.6} \approx 0.00833$. Se $\alpha_1 = 1.2$, a vari√¢ncia incondicional seria negativa, o que √© imposs√≠vel, ou, mais precisamente, indefinida, indicando n√£o estacionariedade.

### Conclus√£o

A **Estima√ß√£o de M√°xima Verossimilhan√ßa** √© uma ferramenta fundamental para a estima√ß√£o de modelos de s√©ries temporais com heteroscedasticidade condicional, como os modelos **ARCH**. A formula√ß√£o da fun√ß√£o de log-verossimilhan√ßa e a aplica√ß√£o de m√©todos de otimiza√ß√£o num√©rica permitem obter estimativas consistentes e eficientes dos par√¢metros do modelo. √â crucial considerar as restri√ß√µes de estacionariedade e n√£o negatividade durante o processo de estima√ß√£o, e explorar diferentes abordagens de otimiza√ß√£o num√©rica para garantir a converg√™ncia e a precis√£o dos resultados.

### Refer√™ncias
[^21.1.9]: $u_t = \sqrt{h_t}v_t$, where {$v_t$} is an i.i.d. sequence with zero mean and unit variance: $E(v_t) = 0$, $E(v_t^2) = 1$.
[^21.1.10]: If $h_t$ evolves according to $h_t = \zeta + \alpha_1 u_{t-1}^2 + \alpha_2 u_{t-2}^2 + \ldots + \alpha_m u_{t-m}^2$
[^21.1.17]: $y_t = x_t\beta + u_t$.
[^21.1.19]: $h_t = \zeta + \alpha_1(y_{t-1} - x_{t-1}\beta)^2 + \alpha_2(y_{t-2} - x_{t-2}\beta)^2 + \ldots + \alpha_m(y_{t-m}\beta)^2 = [z(\beta)]'\delta$
[^21.1.20]: $L(\theta) = \sum_{t=1}^{T} \log f(y_t|x_t, Y_{t-1}; \theta) = -\frac{T}{2}\log(2\pi) - \frac{1}{2}\sum_{t=1}^{T} \log(h_t) - \frac{1}{2}\sum_{t=1}^{T} \frac{(y_t - x_t\beta)^2}{h_t}$
[^21.1.21]: $s_t(\theta) = \frac{\partial \log f(y_t|x_t, Y_{t-1}; \theta)}{\partial \theta} $
<!-- END -->