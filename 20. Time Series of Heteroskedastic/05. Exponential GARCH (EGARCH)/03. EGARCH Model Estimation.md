## Estima√ß√£o de Modelos EGARCH via M√°xima Verossimilhan√ßa

### Introdu√ß√£o
Este cap√≠tulo detalha o processo de estima√ß√£o de modelos EGARCH por meio do m√©todo de M√°xima Verossimilhan√ßa (MLE), com √™nfase na especifica√ß√£o da densidade para a inova√ß√£o $v_t$ [^660]. Particularmente, exploraremos o uso da distribui√ß√£o generalizada de erro (GED) normalizada, uma escolha flex√≠vel que acomoda diferentes graus de caudas pesadas nos res√≠duos [^668]. A seguir, apresentaremos a fun√ß√£o de log-verossimilhan√ßa e discutiremos aspectos pr√°ticos da maximiza√ß√£o.

### Conceitos Fundamentais
Como discutido anteriormente, os modelos EGARCH, modelam o logaritmo da vari√¢ncia condicional, permitindo a captura de efeitos assim√©tricos e garantindo a positividade da vari√¢ncia condicional [^668]. A estima√ß√£o dos par√¢metros do modelo EGARCH, tipicamente, √© realizada atrav√©s do m√©todo de M√°xima Verossimilhan√ßa (MLE) [^660].

O m√©todo de M√°xima Verossimilhan√ßa envolve a maximiza√ß√£o da fun√ß√£o de verossimilhan√ßa (ou, equivalentemente, a fun√ß√£o de log-verossimilhan√ßa) em rela√ß√£o aos par√¢metros do modelo. Para construir a fun√ß√£o de verossimilhan√ßa, √© necess√°rio especificar a distribui√ß√£o condicional da vari√°vel de interesse (no nosso caso, a s√©rie temporal $y_t$) dado o hist√≥rico passado e a vari√¢ncia condicional $h_t$ [^660].

Em geral, assumimos que a distribui√ß√£o condicional de $y_t$ dado o hist√≥rico passado √© da forma:

$$
y_t | \mathcal{F}_{t-1} \sim f(y_t | h_t, \theta)
$$

Onde:

*   $\mathcal{F}_{t-1}$ representa o conjunto de informa√ß√µes dispon√≠veis at√© o tempo $t-1$.
*   $h_t$ √© a vari√¢ncia condicional no tempo $t$, modelada pelo EGARCH.
*   $\theta$ representa o vetor de par√¢metros do modelo.

A fun√ß√£o de verossimilhan√ßa √© ent√£o dada pelo produto das densidades condicionais:

$$
L(\theta | y_1, \dots, y_T) = \prod_{t=1}^T f(y_t | h_t, \theta)
$$

E a fun√ß√£o de log-verossimilhan√ßa √©:

$$
\mathcal{L}(\theta | y_1, \dots, y_T) = \sum_{t=1}^T \log f(y_t | h_t, \theta)
$$

Para maximizar a fun√ß√£o de log-verossimilhan√ßa, √© necess√°rio especificar uma forma funcional para a densidade condicional $f(y_t | h_t, \theta)$. Uma escolha comum √© assumir que a inova√ß√£o $v_t$ (onde $y_t = \sqrt{h_t} v_t$) segue uma distribui√ß√£o Normal padr√£o [^660]. No entanto, como discutido anteriormente, s√©ries temporais financeiras frequentemente exibem caudas mais pesadas do que as permitidas pela distribui√ß√£o Normal. Para acomodar este comportamento, √© comum especificar uma distribui√ß√£o com caudas mais pesadas para $v_t$, como a distribui√ß√£o *t* de Student generalizada [^662] ou a distribui√ß√£o de erro generalizada (GED) [^668].

> üí° **Exemplo Num√©rico:** Suponha que temos uma s√©rie temporal de 1000 retornos di√°rios de um √≠ndice de a√ß√µes. Assumimos que o modelo correto √© um EGARCH(1,1) e que os retornos, condicional √† informa√ß√£o passada, s√£o normalmente distribu√≠dos. Ent√£o, para cada dia $t$, calculamos a vari√¢ncia condicional $h_t$ baseada no modelo EGARCH(1,1) e os par√¢metros atuais. A fun√ß√£o de log-verossimilhan√ßa para o dia $t$ √© ent√£o $\log f(y_t | h_t, \theta) = -\frac{1}{2} \log(2\pi h_t) - \frac{y_t^2}{2h_t}$. Somamos estes valores de todos os 1000 dias para obter a fun√ß√£o de log-verossimilhan√ßa total que ser√° maximizada.

Antes de prosseguirmos para a Distribui√ß√£o de Erro Generalizada (GED), conv√©m estabelecer um resultado geral sobre a consist√™ncia do estimador de m√°xima verossimilhan√ßa.

**Teorema 1** (Consist√™ncia do Estimador de M√°xima Verossimilhan√ßa):
Sob certas condi√ß√µes de regularidade, o estimador de m√°xima verossimilhan√ßa $\hat{\theta}$ converge em probabilidade para o verdadeiro valor do par√¢metro $\theta_0$ quando o tamanho da amostra $T$ tende ao infinito, ou seja, $\hat{\theta} \xrightarrow{p} \theta_0$ quando $T \rightarrow \infty$.

*Condi√ß√µes de Regularidade:* As condi√ß√µes de regularidade tipicamente incluem a identificabilidade do modelo, a diferenciabilidade da fun√ß√£o de log-verossimilhan√ßa e a exist√™ncia de momentos finitos. A verifica√ß√£o dessas condi√ß√µes √© fundamental para garantir a validade assint√≥tica da infer√™ncia baseada em MLE.

> üí° **Exemplo Num√©rico:** Considere uma simula√ß√£o simples onde geramos dados de um modelo EGARCH(1,1) com par√¢metros conhecidos. Repetimos o processo de estima√ß√£o MLE com diferentes tamanhos de amostra (e.g., T = 100, 500, 1000). Observaremos que, √† medida que T aumenta, as estimativas dos par√¢metros do modelo convergem para os verdadeiros valores utilizados na simula√ß√£o. Isso ilustra a consist√™ncia do estimador MLE.

### Distribui√ß√£o de Erro Generalizada (GED)
A distribui√ß√£o de erro generalizada (GED), tamb√©m conhecida como distribui√ß√£o de pot√™ncia exponencial, √© uma fam√≠lia de distribui√ß√µes de probabilidade sim√©tricas que inclui a distribui√ß√£o Normal (Gaussiana) e a distribui√ß√£o de Laplace como casos especiais. A GED √© caracterizada por um par√¢metro de forma, $\nu$, que controla a espessura das caudas [^668].

A fun√ß√£o densidade de probabilidade (pdf) da GED √© dada por [^668]:

$$
f(v_t) = \frac{\nu \exp[-(1/2) |v_t/\lambda|^\nu]}{\lambda 2^{1+1/\nu} \Gamma(1/\nu)}
$$

Onde:

*   $\Gamma(\cdot)$ √© a fun√ß√£o gama.
*   $\nu > 0$ √© o par√¢metro de forma (tail-thickness parameter).
*   $\lambda = \left[ \frac{2^{-2/\nu} \Gamma(1/\nu)}{\Gamma(3/\nu)} \right]^{1/2}$ √© um fator de escala que garante que a distribui√ß√£o tenha vari√¢ncia unit√°ria.

#### Propriedades da GED
*   **Cauda Pesada:** O par√¢metro $\nu$ controla a espessura das caudas da distribui√ß√£o. Para $\nu < 2$, a GED tem caudas mais pesadas do que a distribui√ß√£o Normal. Para $\nu > 2$, a GED tem caudas mais finas do que a distribui√ß√£o Normal. Quando $\nu = 2$, a GED se torna a distribui√ß√£o Normal.
*   **Normaliza√ß√£o:** O fator de escala $\lambda$ garante que a distribui√ß√£o tenha vari√¢ncia unit√°ria, o que √© importante para a estima√ß√£o do modelo EGARCH.
*   **Simetria:** A GED √© uma distribui√ß√£o sim√©trica em torno de zero.

> üí° **Exemplo Num√©rico:** Se $\nu = 1$, a GED torna-se a distribui√ß√£o de Laplace, que tem caudas mais pesadas que a Normal. Se $\nu = 2$, a GED √© a distribui√ß√£o Normal. Se $\nu = 3$, a GED tem caudas mais leves que a Normal. O par√¢metro $\lambda$ ajusta-se para garantir que a vari√¢ncia seja sempre 1. Por exemplo, se $\nu=1$, $\lambda = 1/\sqrt{2}$. Se $\nu=2$, $\lambda = 1$.

Para aplicar a GED no contexto da estima√ß√£o do modelo EGARCH, √© necess√°rio garantir que a distribui√ß√£o tenha m√©dia zero e vari√¢ncia unit√°ria. A normaliza√ß√£o garante a vari√¢ncia unit√°ria, e a simetria garante a m√©dia zero.

**Proposi√ß√£o 1** (Momentos da GED):
A distribui√ß√£o GED com par√¢metro de forma $\nu$ tem m√©dia zero e vari√¢ncia unit√°ria. Al√©m disso, seus momentos de ordem superior podem ser expressos em termos da fun√ß√£o Gama. Em particular, a curtose da GED √© dada por:

$$
Kurtosis = \frac{\Gamma(5/\nu)\Gamma(1/\nu)}{\Gamma(3/\nu)^2} - 3
$$

*Demonstra√ß√£o:*
A demonstra√ß√£o envolve o c√°lculo dos momentos usando a integral da fun√ß√£o densidade da GED. A m√©dia √© trivialmente zero devido √† simetria. A vari√¢ncia √© imposta como unit√°ria pela escolha do fator de escala $\lambda$. O c√°lculo da curtose envolve a avalia√ß√£o da integral $\int_{-\infty}^{\infty} v^4 f(v) dv$, que pode ser expressa em termos de fun√ß√µes Gama.

> üí° **Exemplo Num√©rico:** Se $\nu = 4$, ent√£o a curtose da GED √© calculada como $Kurtosis = \frac{\Gamma(5/4)\Gamma(1/4)}{\Gamma(3/4)^2} - 3 \approx -0.417$. Este valor indica que a GED com $\nu = 4$ √© platic√∫rtica (caudas mais leves) em rela√ß√£o √† distribui√ß√£o Normal (curtose = 0). Se $\nu = 1.5$, ent√£o $Kurtosis = \frac{\Gamma(5/1.5)\Gamma(1/1.5)}{\Gamma(3/1.5)^2} - 3 \approx 3.35$. Este valor indica que a GED com $\nu = 1.5$ √© leptoc√∫rtica (caudas mais pesadas) em rela√ß√£o √† distribui√ß√£o Normal.

#### Fun√ß√£o de Log-Verossimilhan√ßa com GED
Se assumirmos que a inova√ß√£o $v_t$ segue uma distribui√ß√£o GED, a fun√ß√£o de log-verossimilhan√ßa condicional √© dada por:

$$
\mathcal{L}(\theta | y_1, \dots, y_T) = \sum_{t=1}^T \log \left[ \frac{\nu \exp[-(1/2) |v_t/\lambda|^\nu]}{\lambda 2^{1+1/\nu} \Gamma(1/\nu)} \right]
$$

Simplificando a express√£o, obtemos:

$$
\mathcal{L}(\theta | y_1, \dots, y_T) = \sum_{t=1}^T \left[ \log \nu - \frac{1}{2} \left| \frac{y_t}{\lambda \sqrt{h_t}} \right|^\nu - \log \lambda - \log 2 - \frac{1}{\nu} \log 2 - \log \Gamma \left( \frac{1}{\nu} \right) \right]
$$

Onde $v_t = \frac{y_t}{\sqrt{h_t}}$, e $h_t$ √© determinado pela equa√ß√£o do modelo EGARCH. O vetor de par√¢metros $\theta$ inclui os par√¢metros do modelo EGARCH ($\kappa$, $\beta_i$, $\alpha_j$, $\theta$) e o par√¢metro de forma da GED ($\nu$).

> üí° **Exemplo Num√©rico:** Suponha que $y_t = 0.01$, $h_t = 0.0004$ (vari√¢ncia condicional), $\nu = 1.5$ e os par√¢metros do EGARCH j√° est√£o estimados. Primeiro, calculamos $v_t = \frac{0.01}{\sqrt{0.0004}} = 0.5$. Ent√£o, $\lambda = \left[ \frac{2^{-2/1.5} \Gamma(1/1.5)}{\Gamma(3/1.5)} \right]^{1/2} \approx 0.75$. A contribui√ß√£o de este ponto de dado para a fun√ß√£o de log-verossimilhan√ßa √©:
>
> $\log(1.5) - \frac{1}{2} \left| \frac{0.01}{0.75 \sqrt{0.0004}} \right|^{1.5} - \log(0.75) - \log(2) - \frac{1}{1.5} \log(2) - \log \Gamma \left( \frac{1}{1.5} \right) \approx -2.34$
>
> Este valor √© calculado para cada observa√ß√£o na s√©rie temporal e, em seguida, somado para obter a fun√ß√£o de log-verossimilhan√ßa total.

Para fins de infer√™ncia, √© √∫til obter as condi√ß√µes de primeira ordem da fun√ß√£o de log-verossimilhan√ßa.

**Proposi√ß√£o 2** (Condi√ß√µes de Primeira Ordem):
As condi√ß√µes de primeira ordem para a maximiza√ß√£o da fun√ß√£o de log-verossimilhan√ßa com GED s√£o obtidas derivando $\mathcal{L}(\theta | y_1, \dots, y_T)$ em rela√ß√£o a cada par√¢metro em $\theta$ e igualando a zero.  Essas condi√ß√µes definem as equa√ß√µes que devem ser satisfeitas no ponto de m√°ximo.

*Observa√ß√£o:*
A obten√ß√£o das condi√ß√µes de primeira ordem √© um passo crucial na estima√ß√£o via MLE. Em geral, as equa√ß√µes resultantes n√£o t√™m solu√ß√£o anal√≠tica, o que justifica o uso de m√©todos num√©ricos de otimiza√ß√£o.

> üí° **Exemplo Num√©rico:** Para encontrar as condi√ß√µes de primeira ordem, precisamos calcular as derivadas parciais de $\mathcal{L}$ em rela√ß√£o a cada par√¢metro do EGARCH (e.g., $\kappa$, $\beta_1$, $\alpha_1$, $\theta$) e em rela√ß√£o ao par√¢metro de forma da GED, $\nu$. Por exemplo, a derivada de $\mathcal{L}$ em rela√ß√£o a $\nu$ √©:
>
> $\frac{\partial \mathcal{L}}{\partial \nu} = \sum_{t=1}^T \left[ \frac{1}{\nu} + \frac{1}{2} \left| \frac{y_t}{\lambda \sqrt{h_t}} \right|^\nu \log \left| \frac{y_t}{\lambda \sqrt{h_t}} \right| - \frac{\lambda'}{\lambda} - \frac{1}{\nu^2} \log 2 + \frac{1}{\nu^2} \Psi\left(\frac{1}{\nu}\right) \right]$,
>
> onde $\Psi(\cdot)$ √© a fun√ß√£o digamma (derivada logar√≠tmica da fun√ß√£o gama). Igualamos esta derivada a zero e resolvemos numericamente para $\nu$. Procedimentos semelhantes s√£o feitos para os outros par√¢metros.

#### Maximiza√ß√£o da Fun√ß√£o de Log-Verossimilhan√ßa
A estima√ß√£o dos par√¢metros do modelo EGARCH com GED envolve a maximiza√ß√£o da fun√ß√£o de log-verossimilhan√ßa $\mathcal{L}(\theta | y_1, \dots, y_T)$ em rela√ß√£o ao vetor de par√¢metros $\theta$. Esta maximiza√ß√£o geralmente √© realizada usando algoritmos de otimiza√ß√£o num√©rica [^661], tais como:

*   **BFGS (Broyden‚ÄìFletcher‚ÄìGoldfarb‚ÄìShanno):** Um algoritmo de otimiza√ß√£o quase-Newton que aproxima a matriz Hessiana para encontrar a dire√ß√£o de busca.
*   **Nelder-Mead:** Um m√©todo simplex que n√£o requer o c√°lculo de derivadas e √© adequado para fun√ß√µes n√£o suaves.
*   **Algoritmos de Gradiente:** Algoritmos que usam o gradiente da fun√ß√£o de log-verossimilhan√ßa para encontrar o ponto de m√°ximo.

√â importante notar que a escolha do algoritmo de otimiza√ß√£o pode afetar significativamente a efici√™ncia e a precis√£o da estima√ß√£o. Al√©m disso, √© crucial verificar se a solu√ß√£o encontrada pelo algoritmo de otimiza√ß√£o corresponde a um m√°ximo global e n√£o a um m√°ximo local.

**Lema 1** (Converg√™ncia dos Algoritmos de Otimiza√ß√£o): A converg√™ncia de algoritmos de otimiza√ß√£o num√©rica depende da suavidade da fun√ß√£o objetivo (neste caso, a fun√ß√£o de log-verossimilhan√ßa) e da escolha dos par√¢metros do algoritmo. Algoritmos como BFGS exibem converg√™ncia superlinear sob condi√ß√µes de suavidade e convexidade local.

> üí° **Exemplo Num√©rico:** Suponha que, ap√≥s 100 itera√ß√µes do algoritmo BFGS, a diferen√ßa entre a fun√ß√£o de log-verossimilhan√ßa na itera√ß√£o atual e na itera√ß√£o anterior √© menor que $10^{-6}$. Isto pode ser usado como um crit√©rio de converg√™ncia. No entanto, √© importante verificar se a Hessiana da fun√ß√£o de log-verossimilhan√ßa √© definida negativa no ponto de converg√™ncia para garantir que encontramos um m√°ximo local (ou global) e n√£o um ponto de sela.

Para a estima√ß√£o do modelo EGARCH com GED, podemos usar o seguinte procedimento:

1.  Especificar o modelo EGARCH(r, m) e a distribui√ß√£o GED para a inova√ß√£o $v_t$.
2.  Construir a fun√ß√£o de log-verossimilhan√ßa $\mathcal{L}(\theta | y_1, \dots, y_T)$.
3.  Escolher um algoritmo de otimiza√ß√£o num√©rica e fornecer chutes iniciais para os par√¢metros.
4.  Maximizar a fun√ß√£o de log-verossimilhan√ßa em rela√ß√£o aos par√¢metros $\theta$ usando o algoritmo de otimiza√ß√£o escolhido.
5.  Verificar a converg√™ncia do algoritmo e a validade da solu√ß√£o encontrada.
6.  Realizar testes de diagn√≥stico para verificar a adequa√ß√£o do modelo.

> üí° **Exemplo Num√©rico:** Suponha que temos uma s√©rie temporal de retornos de a√ß√µes e queremos estimar um modelo EGARCH(1,1) com distribui√ß√£o GED. Podemos implementar o seguinte c√≥digo em Python usando a biblioteca `scipy.optimize` para a otimiza√ß√£o num√©rica:

![Generated plot](./../images/plot_1.png)

Este c√≥digo ilustra como a fun√ß√£o de log-verossimilhan√ßa com GED √© constru√≠da e otimizada para obter as estimativas dos par√¢metros. A fun√ß√£o `scipy.special.gamma` √© usada para calcular a fun√ß√£o gama.

### Aspectos Pr√°ticos da Maximiza√ß√£o
A maximiza√ß√£o da fun√ß√£o de log-verossimilhan√ßa em modelos EGARCH pode ser um processo computacionalmente intensivo e desafiador [^661]. Aqui est√£o alguns aspectos pr√°ticos a serem considerados:

*   **Chutes Iniciais:** A escolha dos chutes iniciais para os par√¢metros pode afetar significativamente a converg√™ncia do algoritmo de otimiza√ß√£o. √â recomend√°vel experimentar diferentes conjuntos de chutes iniciais para garantir que a solu√ß√£o encontrada corresponda a um m√°ximo global.
*   **Algoritmo de Otimiza√ß√£o:** Diferentes algoritmos de otimiza√ß√£o podem ter diferentes propriedades de converg√™ncia e efici√™ncia. √â importante escolher um algoritmo adequado para o problema em quest√£o e ajustar os par√¢metros do algoritmo para obter um desempenho ideal.
*   **Restri√ß√µes:** Em alguns casos, pode ser necess√°rio impor restri√ß√µes nos par√¢metros para garantir que a solu√ß√£o encontrada seja v√°lida. Por exemplo, podemos restringir o par√¢metro $\nu$ da GED para ser maior que zero.
*   **Testes de Diagn√≥stico:** Ap√≥s a estima√ß√£o dos par√¢metros, √© importante realizar testes de diagn√≥stico para verificar a adequa√ß√£o do modelo. Isso pode incluir a an√°lise dos res√≠duos para verificar se eles s√£o independentes e identicamente distribu√≠dos, e a realiza√ß√£o de testes de especifica√ß√£o para verificar se o modelo captura adequadamente as caracter√≠sticas dos dados.

> üí° **Exemplo Num√©rico:** Se os chutes iniciais para os par√¢metros do EGARCH(1,1) forem pr√≥ximos de zero (e.g., [0.001, 0.01, 0.001, 0.001, 2]), o algoritmo de otimiza√ß√£o pode convergir para um m√≠nimo local onde a vari√¢ncia condicional √© quase constante. Para evitar isso, podemos usar chutes iniciais baseados em estat√≠sticas descritivas dos dados (e.g., usar a vari√¢ncia amostral como um chute inicial para o n√≠vel da vari√¢ncia condicional).

Al√©m dos testes de diagn√≥stico mencionados, √© crucial avaliar a signific√¢ncia estat√≠stica dos par√¢metros estimados.

**Teorema 2** (Infer√™ncia Assint√≥tica): Sob as condi√ß√µes de regularidade do Teorema 1, o estimador de m√°xima verossimilhan√ßa $\hat{\theta}$ √© assintoticamente normal, ou seja:
$$\sqrt{T}(\hat{\theta} - \theta_0) \xrightarrow{d} N(0, I(\theta_0)^{-1})$$
onde $I(\theta_0)$ √© a matriz de informa√ß√£o de Fisher avaliada no verdadeiro valor do par√¢metro $\theta_0$.

*Demonstra√ß√£o:*

I. Seja $L(\theta)$ a fun√ß√£o de verossimilhan√ßa e $\ell(\theta) = \log L(\theta)$ a fun√ß√£o de log-verossimilhan√ßa.

II. Expanda $\frac{\partial \ell(\hat{\theta})}{\partial \theta}$ em torno do verdadeiro valor $\theta_0$ usando uma expans√£o de Taylor de primeira ordem:

$$\frac{\partial \ell(\hat{\theta})}{\partial \theta} = \frac{\partial \ell(\theta_0)}{\partial \theta} + \frac{\partial^2 \ell(\theta^*)}{\partial \theta \partial \theta'} (\hat{\theta} - \theta_0)$$

Onde $\theta^*$ est√° entre $\hat{\theta}$ e $\theta_0$.

III. Como $\hat{\theta}$ √© o estimador de m√°xima verossimilhan√ßa, $\frac{\partial \ell(\hat{\theta})}{\partial \theta} = 0$.  Rearranjando a equa√ß√£o:

$$0 = \frac{\partial \ell(\theta_0)}{\partial \theta} + \frac{\partial^2 \ell(\theta^*)}{\partial \theta \partial \theta'} (\hat{\theta} - \theta_0)$$

IV. Multiplique por $\frac{1}{\sqrt{T}}$:

$$0 = \frac{1}{\sqrt{T}} \frac{\partial \ell(\theta_0)}{\partial \theta} + \frac{1}{T} \frac{\partial^2 \ell(\theta^*)}{\partial \theta \partial \theta'} \sqrt{T}(\hat{\theta} - \theta_0)$$

V. Pela Lei dos Grandes N√∫meros, $-\frac{1}{T} \frac{\partial^2 \ell(\theta^*)}{\partial \theta \partial \theta'}$ converge para a matriz de informa√ß√£o de Fisher $I(\theta_0)$ quando $T \to \infty$. Pelo Teorema do Limite Central, $\frac{1}{\sqrt{T}} \frac{\partial \ell(\theta_0)}{\partial \theta} \xrightarrow{d} N(0, I(\theta_0))$.

VI. Portanto,

$$0 = N(0, I(\theta_0)) - I(\theta_0) \sqrt{T}(\hat{\theta} - \theta_0)$$

VII. Rearranjando e multiplicando por $I(\theta_0)^{-1}$:

$$\sqrt{T}(\hat{\theta} - \theta_0) \xrightarrow{d} N(0, I(\theta_0)^{-1})$$

‚ñ†

*Implica√ß√µes:*
Este resultado permite construir intervalos de confian√ßa assint√≥ticos para os par√¢metros e realizar testes de hip√≥teses sobre seus valores. A matriz de informa√ß√£o de Fisher pode ser estimada pela Hessiana da fun√ß√£o de log-verossimilhan√ßa avaliada em $\hat{\theta}$.

> üí° **Exemplo Num√©rico:** Suponha que estimamos um modelo EGARCH(1,1) com GED e obtemos $\hat{\theta} = [0.01, 0.9, 0.1, -0.05, 2.0]$ como estimativas dos par√¢metros. Ap√≥s calcular (numericamente) a matriz Hessiana da fun√ß√£o de log-verossimilhan√ßa e invert√™-la para obter uma estimativa da matriz de covari√¢ncia, encontramos que o erro padr√£o associado √† estimativa de $\beta_1$ (o coeficiente de persist√™ncia) √© 0.05. Ent√£o, um intervalo de confian√ßa de 95% para $\beta_1$ √© [0.9 - 1.96*0.05, 0.9 + 1.96*0.05] = [0.802, 0.998]. Se 1 estivesse dentro deste intervalo, n√£o poder√≠amos rejeitar a hip√≥tese nula de que a s√©rie temporal √© n√£o estacion√°ria.

### Conclus√£o
A estima√ß√£o de modelos EGARCH via m√°xima verossimilhan√ßa com GED oferece uma abordagem flex√≠vel e poderosa para modelar a heteroscedasticidade condicional em s√©ries temporais financeiras [^668]. A escolha da distribui√ß√£o GED permite capturar diferentes graus de caudas pesadas nos res√≠duos, o que √© importante para modelar as caracter√≠sticas emp√≠ricas de muitas s√©ries temporais financeiras. No entanto, a estima√ß√£o dos par√¢metros requer cuidado e aten√ß√£o, e √© importante considerar os aspectos pr√°ticos da maximiza√ß√£o da fun√ß√£o de log-verossimilhan√ßa.

### Refer√™ncias
[^660]: P√°gina 660.
[^661]: P√°gina 661.
[^662]: P√°gina 662.
[^668]: P√°gina 668.
<!-- END -->