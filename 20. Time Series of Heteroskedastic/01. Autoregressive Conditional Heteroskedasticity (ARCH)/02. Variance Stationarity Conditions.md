## Condi√ß√µes de N√£o-Negatividade e Estacionariedade em Modelos ARCH(m)

### Introdu√ß√£o

Este cap√≠tulo aprofunda a an√°lise do modelo **ARCH(m)** (Autoregressive Conditional Heteroskedasticity de ordem *m*) [^1], focando em condi√ß√µes cruciais para a validade e aplicabilidade do modelo. Especificamente, exploraremos as condi√ß√µes de n√£o-negatividade para garantir que a vari√¢ncia condicional seja sempre positiva, e as condi√ß√µes de estacionariedade em covari√¢ncia para assegurar que as propriedades estat√≠sticas do processo sejam bem definidas e est√°veis ao longo do tempo.

### Condi√ß√£o de N√£o-Negatividade

Para garantir que o modelo ARCH(m) seja uma representa√ß√£o sens√≠vel da heteroskedasticidade condicional, √© essencial que o quadrado do termo de erro, $u_t^2$, seja sempre n√£o-negativo. Isso se traduz em restri√ß√µes sobre os par√¢metros do modelo [^1]. A equa√ß√£o fundamental do modelo √©:

$$
u_t^2 = \zeta + \alpha_1 u_{t-1}^2 + \alpha_2 u_{t-2}^2 + \dots + \alpha_m u_{t-m}^2 + w_t
$$

onde [^1]:

*   $u_t$ √© o termo de erro no tempo $t$.
*   $\zeta$ √© uma constante.
*   $\alpha_j$ s√£o os coeficientes autorregressivos para $j = 1, 2, \dots, m$.
*   $w_t$ √© um processo de ru√≠do branco.

Para assegurar que $u_t^2 \geq 0$, as seguintes condi√ß√µes devem ser satisfeitas [^1]:

1.  $\zeta > 0$: A constante $\zeta$ deve ser estritamente positiva. Isso garante que, mesmo na aus√™ncia de efeitos autorregressivos (ou seja, quando todos os $u_{t-j}^2$ s√£o zero), a vari√¢ncia condicional tenha um valor positivo m√≠nimo.
2.  $\alpha_j \geq 0$ para $j = 1, 2, \dots, m$: Todos os coeficientes autorregressivos $\alpha_j$ devem ser n√£o-negativos. Isso impede que erros quadr√°ticos passados reduzam a vari√¢ncia condicional no presente.

Al√©m dessas condi√ß√µes [^1], √© necess√°rio que o processo de ru√≠do branco $w_t$ seja limitado inferiormente. Isso significa que existe um valor m√≠nimo que $w_t$ pode assumir. Se $w_t$ n√£o for limitado inferiormente, ele poderia, em teoria, assumir valores suficientemente negativos para tornar $u_t^2$ negativo, mesmo com $\zeta > 0$ e $\alpha_j \geq 0$. Em pr√°tica, essa limita√ß√£o √© geralmente assegurada pelas propriedades da distribui√ß√£o escolhida para $w_t$ (por exemplo, se $w_t$ segue uma distribui√ß√£o normal ou t-Student, √© necess√°rio garantir que $\zeta$ seja grande o suficiente para que a probabilidade de $w_t$ ser menor que $-\zeta$ seja desprez√≠vel).

> üí° **Exemplo Num√©rico:** Considere um modelo ARCH(1) com $\zeta = 0.02$ e $\alpha_1 = 0.3$. Suponha que $u_{t-1}^2 = 0.05$. Ent√£o, $u_t^2 = 0.02 + 0.3 \times 0.05 + w_t = 0.035 + w_t$. Para garantir $u_t^2 \geq 0$, precisamos que $w_t \geq -0.035$. Se $w_t$ segue uma distribui√ß√£o normal com m√©dia 0 e desvio padr√£o 0.01, a probabilidade de $w_t < -0.035$ √© muito baixa, mas n√£o nula. Para reduzir essa probabilidade, poder√≠amos aumentar $\zeta$.
>
> ```python
> import numpy as np
> import scipy.stats as st
> import matplotlib.pyplot as plt
>
> # Par√¢metros do modelo ARCH(1)
> zeta = 0.02
> alpha1 = 0.3
>
> # Valor passado de u^2
> u_tm1_squared = 0.05
>
> # Calculando u_t^2 sem o termo de erro
> u_t_squared_base = zeta + alpha1 * u_tm1_squared
>
> # Definindo a distribui√ß√£o de w_t (Normal com m√©dia 0 e desvio padr√£o 0.01)
> mu = 0
> sigma = 0.01
> dist = st.norm(mu, sigma)
>
> # Calculando a probabilidade de w_t < -u_t_squared_base
> prob_negativa = dist.cdf(-u_t_squared_base)
>
> print(f"Valor base de u_t^2 (sem w_t): {u_t_squared_base}")
> print(f"Probabilidade de w_t < -u_t_squared_base: {prob_negativa}")
>
> # Visualiza√ß√£o
> plt.figure(figsize=(10, 6))
> x = np.linspace(-0.05, 0.05, 1000)
> plt.plot(x, dist.pdf(x), label='Densidade de Probabilidade de w_t')
> plt.axvline(x=-u_t_squared_base, color='red', linestyle='--', label=f'Limite Inferior de w_t ({-u_t_squared_base:.3f})')
> plt.title('Distribui√ß√£o de w_t e Limite Inferior para N√£o-Negatividade de u_t^2')
> plt.xlabel('Valores de w_t')
> plt.ylabel('Densidade de Probabilidade')
> plt.legend()
> plt.grid(True)
> plt.show()
>
> ```

Para complementar a an√°lise da condi√ß√£o de n√£o-negatividade, podemos definir formalmente a restri√ß√£o sobre o ru√≠do branco $w_t$:

**Proposi√ß√£o 1:** Para um modelo ARCH(m) com $\zeta > 0$ e $\alpha_j \geq 0$ para $j = 1, 2, \dots, m$, a condi√ß√£o necess√°ria e suficiente para a n√£o-negatividade de $u_t^2$ √© que $w_t \geq -\zeta - \sum_{j=1}^{m} \alpha_j u_{t-j}^2$ para todo $t$.

*Prova da Proposi√ß√£o 1:*
I.  **Necessidade:** Se $u_t^2 \geq 0$ para todo $t$, ent√£o da equa√ß√£o $u_t^2 = \zeta + \alpha_1 u_{t-1}^2 + \alpha_2 u_{t-2}^2 + \dots + \alpha_m u_{t-m}^2 + w_t$, segue que $w_t = u_t^2 - \zeta - \sum_{j=1}^{m} \alpha_j u_{t-j}^2$.  Como $u_t^2 \geq 0$, temos $w_t \geq -\zeta - \sum_{j=1}^{m} \alpha_j u_{t-j}^2$.

II. **Sufici√™ncia:** Se $w_t \geq -\zeta - \sum_{j=1}^{m} \alpha_j u_{t-j}^2$ para todo $t$, ent√£o $u_t^2 = \zeta + \alpha_1 u_{t-1}^2 + \alpha_2 u_{t-2}^2 + \dots + \alpha_m u_{t-m}^2 + w_t \geq \zeta + \alpha_1 u_{t-1}^2 + \alpha_2 u_{t-2}^2 + \dots + \alpha_m u_{t-m}^2 - \zeta - \sum_{j=1}^{m} \alpha_j u_{t-j}^2 = 0$. Portanto, $u_t^2 \geq 0$. $\blacksquare$

### Condi√ß√£o de Estacionariedade em Covari√¢ncia

Al√©m de garantir a n√£o-negatividade, √© crucial que o modelo ARCH(m) seja covariance-stationary [^1]. A estacionariedade implica que as propriedades estat√≠sticas do processo (m√©dia, vari√¢ncia, autocovari√¢ncia) n√£o mudam ao longo do tempo. No contexto de modelos ARCH, a estacionariedade √© importante para assegurar que as infer√™ncias estat√≠sticas sejam v√°lidas e que as previs√µes sejam razo√°veis.

A condi√ß√£o para estacionariedade em covari√¢ncia em um modelo ARCH(m) √© que as ra√≠zes da seguinte equa√ß√£o caracter√≠stica estejam fora do c√≠rculo unit√°rio [^1]:

$$
1 - \alpha_1 z - \alpha_2 z^2 - \dots - \alpha_m z^m = 0
$$

onde $z$ √© uma vari√°vel complexa. Essa condi√ß√£o √© equivalente a exigir que o polin√¥mio $1 - \alpha_1 L - \alpha_2 L^2 - \dots - \alpha_m L^m$ seja invert√≠vel, onde $L$ √© o operador de defasagem (lag operator).

Sob a restri√ß√£o de que todos os coeficientes $\alpha_j$ s√£o n√£o-negativos (como exigido para a n√£o-negatividade), a condi√ß√£o de estacionariedade se simplifica para [^1]:

$$
\alpha_1 + \alpha_2 + \dots + \alpha_m < 1
$$

Essa condi√ß√£o [^1] estabelece que a soma dos coeficientes autorregressivos deve ser menor que 1. Intuitivamente, isso significa que o impacto dos erros quadr√°ticos passados sobre a vari√¢ncia condicional presente deve decair ao longo do tempo, garantindo que a vari√¢ncia n√£o exploda para o infinito.

Se a condi√ß√£o de estacionariedade for satisfeita, a vari√¢ncia incondicional do processo $u_t$ √© finita e dada por [^1]:

$$
\sigma^2 = E(u_t^2) = \frac{\zeta}{1 - \alpha_1 - \alpha_2 - \dots - \alpha_m}
$$

Essa express√£o [^1] mostra que a vari√¢ncia incondicional √© uma fun√ß√£o da constante $\zeta$ e da soma dos coeficientes $\alpha_j$.

> üí° **Exemplo Num√©rico:** Considere um modelo ARCH(2) com $\zeta = 0.01$, $\alpha_1 = 0.3$ e $\alpha_2 = 0.2$. Primeiro, verificamos a condi√ß√£o de n√£o-negatividade: $\zeta > 0$, $\alpha_1 \geq 0$ e $\alpha_2 \geq 0$, o que √© satisfeito. Em seguida, verificamos a condi√ß√£o de estacionariedade:
>
> $\alpha_1 + \alpha_2 = 0.3 + 0.2 = 0.5 < 1$
>
> A condi√ß√£o de estacionariedade √© satisfeita. A vari√¢ncia incondicional √©:
>
> $\sigma^2 = \frac{0.01}{1 - 0.3 - 0.2} = \frac{0.01}{0.5} = 0.02$
>
> Agora, consideremos um modelo ARCH(2) com os mesmos $\zeta$ e $\alpha_1$, mas com $\alpha_2 = 0.7$. A condi√ß√£o de n√£o-negatividade ainda √© satisfeita. No entanto, $\alpha_1 + \alpha_2 = 0.3 + 0.7 = 1$, o que viola a condi√ß√£o de estacionariedade. Neste caso, a vari√¢ncia incondicional seria infinita.
>
> ```python
> import numpy as np
>
> # Caso 1: Modelo ARCH(2) estacion√°rio
> zeta1 = 0.01
> alpha1_1 = 0.3
> alpha2_1 = 0.2
>
> # Caso 2: Modelo ARCH(2) n√£o estacion√°rio
> zeta2 = 0.01
> alpha1_2 = 0.3
> alpha2_2 = 0.7
>
> # Verificando as condi√ß√µes e calculando a vari√¢ncia incondicional para o Caso 1
> nao_negatividade1 = zeta1 > 0 and alpha1_1 >= 0 and alpha2_1 >= 0
> estacionaridade1 = alpha1_1 + alpha2_1 < 1
>
> if nao_negatividade1 and estacionaridade1:
>     variancia_incondicional1 = zeta1 / (1 - alpha1_1 - alpha2_1)
>     print(f"Caso 1: Vari√¢ncia incondicional = {variancia_incondicional1}")
> else:
>     print("Caso 1: As condi√ß√µes de n√£o-negatividade e/ou estacionaridade n√£o s√£o satisfeitas.")
>
> # Verificando as condi√ß√µes e calculando a vari√¢ncia incondicional para o Caso 2
> nao_negatividade2 = zeta2 > 0 and alpha1_2 >= 0 and alpha2_2 >= 0
> estacionaridade2 = alpha1_2 + alpha2_2 < 1
>
> if nao_negatividade2 and estacionaridade2:
>     variancia_incondicional2 = zeta2 / (1 - alpha1_2 - alpha2_2)
>     print(f"Caso 2: Vari√¢ncia incondicional = {variancia_incondicional2}")
> else:
>     print("Caso 2: As condi√ß√µes de n√£o-negatividade e/ou estacionaridade n√£o s√£o satisfeitas.")
> ```

**Lema 2:** Se a condi√ß√£o de estacionariedade ($\alpha_1 + \alpha_2 + \dots + \alpha_m < 1$) n√£o for satisfeita, a vari√¢ncia incondicional do processo ARCH(m) ser√° infinita.

*Prova do Lema 2:*
I. Assumimos que a condi√ß√£o de estacionariedade n√£o √© satisfeita, ou seja, $\alpha_1 + \alpha_2 + \dots + \alpha_m \geq 1$.

II. Partimos da express√£o para a vari√¢ncia incondicional:
   $$\sigma^2 = \frac{\zeta}{1 - \alpha_1 - \alpha_2 - \dots - \alpha_m}$$

III. Se $\alpha_1 + \alpha_2 + \dots + \alpha_m = 1$, ent√£o o denominador da express√£o para $\sigma^2$ se torna zero:
    $$\sigma^2 = \frac{\zeta}{1 - 1} = \frac{\zeta}{0}$$
    Neste caso, a vari√¢ncia incondicional √© indefinida (ou, formalmente, tende ao infinito).

IV. Se $\alpha_1 + \alpha_2 + \dots + \alpha_m > 1$, ent√£o o denominador se torna negativo:
   $$\sigma^2 = \frac{\zeta}{1 - (\alpha_1 + \alpha_2 + \dots + \alpha_m)}$$
    Como $\zeta > 0$, a vari√¢ncia incondicional seria negativa, o que n√£o √© fisicamente poss√≠vel para uma vari√¢ncia.

V. Em ambos os casos (denominador zero ou negativo), a vari√¢ncia incondicional n√£o √© finita e bem definida. No caso em que a soma √© igual a 1,  dizemos que o processo √© "integrated" e, no caso em que a soma √© maior que 1, o processo √© explorivo.

VI. Portanto, se a condi√ß√£o de estacionariedade n√£o for satisfeita, a vari√¢ncia incondicional do processo ARCH(m) ser√° infinita ou indefinida. $\blacksquare$

Al√©m da vari√¢ncia incondicional, √© √∫til analisar a m√©dia incondicional do processo $u_t^2$.

**Proposi√ß√£o 2:** Se o modelo ARCH(m) √© covariance-stationary (isto √©, $\alpha_1 + \alpha_2 + \dots + \alpha_m < 1$), ent√£o a m√©dia incondicional de $u_t^2$ √© dada por $E[u_t^2] = \frac{\zeta}{1 - \alpha_1 - \alpha_2 - \dots - \alpha_m}$.

*Prova da Proposi√ß√£o 2:*
I.  Tomamos a esperan√ßa da equa√ß√£o do modelo ARCH(m):
   $$E[u_t^2] = E[\zeta + \alpha_1 u_{t-1}^2 + \alpha_2 u_{t-2}^2 + \dots + \alpha_m u_{t-m}^2 + w_t]$$

II. Usando a linearidade da esperan√ßa e o fato de que $\zeta$ √© uma constante, temos:
   $$E[u_t^2] = \zeta + \alpha_1 E[u_{t-1}^2] + \alpha_2 E[u_{t-2}^2] + \dots + \alpha_m E[u_{t-m}^2] + E[w_t]$$

III. Sob a condi√ß√£o de estacionariedade, a m√©dia de $u_t^2$ √© constante ao longo do tempo, ou seja, $E[u_t^2] = E[u_{t-1}^2] = \dots = E[u_{t-m}^2] = \sigma^2$. Al√©m disso, assumimos que $E[w_t] = 0$ (o que √© comum para ru√≠do branco).  Substituindo, obtemos:
   $$\sigma^2 = \zeta + \alpha_1 \sigma^2 + \alpha_2 \sigma^2 + \dots + \alpha_m \sigma^2 + 0$$

IV. Fatorando $\sigma^2$, temos:
   $$\sigma^2 = \zeta + \sigma^2 (\alpha_1 + \alpha_2 + \dots + \alpha_m)$$

V. Resolvendo para $\sigma^2$, obtemos:
   $$\sigma^2 (1 - \alpha_1 - \alpha_2 - \dots - \alpha_m) = \zeta$$
   $$\sigma^2 = \frac{\zeta}{1 - \alpha_1 - \alpha_2 - \dots - \alpha_m}$$

VI. Portanto, a m√©dia incondicional de $u_t^2$ √© $E[u_t^2] = \frac{\zeta}{1 - \alpha_1 - \alpha_2 - \dots - \alpha_m}$. $\blacksquare$

### Conclus√£o

As condi√ß√µes de n√£o-negatividade e estacionariedade em covari√¢ncia s√£o fundamentais para a correta especifica√ß√£o e interpreta√ß√£o de modelos ARCH(m) [^1]. A condi√ß√£o de n√£o-negatividade garante que a vari√¢ncia condicional seja sempre positiva, refletindo a natureza da volatilidade. A condi√ß√£o de estacionariedade assegura que as propriedades estat√≠sticas do processo sejam est√°veis ao longo do tempo, permitindo infer√™ncias e previs√µes consistentes. A viola√ß√£o dessas condi√ß√µes pode levar a resultados sem sentido ou a modelos que n√£o conseguem capturar adequadamente a din√¢mica da volatilidade.

### Refer√™ncias

[^1]: Cap√≠tulo 21 do texto fornecido.
<!-- END -->