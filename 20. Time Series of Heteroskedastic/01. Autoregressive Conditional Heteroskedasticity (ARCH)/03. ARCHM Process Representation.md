## Representa√ß√£o Alternativa e Inova√ß√µes em Modelos ARCH(m)

### Introdu√ß√£o

Este cap√≠tulo explora uma representa√ß√£o alternativa para o modelo **ARCH(m)** (Autoregressive Conditional Heteroskedasticity de ordem *m*) [^1], que oferece uma perspectiva valiosa sobre a estrutura e as propriedades do processo. Focaremos na decomposi√ß√£o do termo de erro $u_t$ em termos de uma vari√¢ncia condicional $h_t$ e uma sequ√™ncia i.i.d. (independent and identically distributed) $v_t$ com m√©dia zero e vari√¢ncia unit√°ria. Al√©m disso, examinaremos a inova√ß√£o $w_t$ na representa√ß√£o AR(m) para $u_t^2$ e suas propriedades.

### Representa√ß√£o Alternativa do Modelo ARCH(m)

Uma representa√ß√£o alternativa para o processo ARCH(m) √© dada por [^1]:

$$
u_t = \sqrt{h_t} \cdot v_t
$$

onde [^1]:

*   $u_t$ √© o termo de erro no tempo $t$.
*   $h_t$ √© a vari√¢ncia condicional no tempo $t$.
*   $v_t$ √© uma sequ√™ncia i.i.d. com m√©dia zero e vari√¢ncia unit√°ria, ou seja, $E(v_t) = 0$ e $E(v_t^2) = 1$ [^1].

A vari√¢ncia condicional $h_t$ √© modelada como [^1]:

$$
h_t = \zeta + \alpha_1 u_{t-1}^2 + \alpha_2 u_{t-2}^2 + \dots + \alpha_m u_{t-m}^2
$$

onde [^1]:

*   $\zeta$ √© uma constante.
*   $\alpha_j$ s√£o os coeficientes autorregressivos para $j = 1, 2, \dots, m$.

Esta representa√ß√£o [^1] decomp√µe o termo de erro $u_t$ em dois componentes: a raiz quadrada da vari√¢ncia condicional ($ \sqrt{h_t} $), que captura a escala da volatilidade, e a sequ√™ncia i.i.d. $v_t$, que representa os choques aleat√≥rios normalizados.

> üí° **Exemplo Num√©rico:** Considere uma s√©rie temporal de retornos financeiros modelada por um ARCH(2). Os par√¢metros s√£o estimados como $\zeta = 0.0001$, $\alpha_1 = 0.3$, e $\alpha_2 = 0.2$. No tempo $t-1$, $u_{t-1} = 0.01$ (1%) e no tempo $t-2$, $u_{t-2} = -0.005$ (-0.5%). A vari√¢ncia condicional no tempo $t$ √©:
>
> $h_t = 0.0001 + 0.3 \times (0.01)^2 + 0.2 \times (-0.005)^2 = 0.0001 + 0.00003 + 0.000005 = 0.000135$
>
> Agora, suponha que $v_t = -0.8$. Ent√£o, $u_t = \sqrt{0.000135} \times (-0.8) \approx -0.0011$, o que representa um choque negativo de -0.11%. Este exemplo ilustra como os retornos passados afetam a volatilidade atual e, consequentemente, o valor do erro no tempo $t$.
>
> ```python
> import numpy as np
>
> # Par√¢metros do modelo ARCH(2)
> zeta = 0.0001
> alpha1 = 0.3
> alpha2 = 0.2
>
> # Valores
> u_tm1 = 0.01
> u_tm2 = -0.005
> v_t = -0.8
>
> # Calculando h_t
> h_t = zeta + alpha1 * u_tm1**2 + alpha2 * u_tm2**2
>
> # Calculando u_t
> u_t = np.sqrt(h_t) * v_t
>
> print(f"Valor de h_t: {h_t}")
> print(f"Valor de u_t: {u_t}")
> ```

Sob esta especifica√ß√£o, a proje√ß√£o linear de $u_t^2$ nos valores passados √© tamb√©m a esperan√ßa condicional [^1]:

$$
E(u_t^2 | u_{t-1}, u_{t-2}, \dots) = E((\sqrt{h_t} \cdot v_t)^2 | u_{t-1}, u_{t-2}, \dots) = E(h_t \cdot v_t^2 | u_{t-1}, u_{t-2}, \dots) = h_t E(v_t^2 | u_{t-1}, u_{t-2}, \dots) = h_t \cdot 1 = h_t
$$

j√° que $v_t$ √© i.i.d. e $E(v_t^2) = 1$.

> üí° **Exemplo Num√©rico:** Considere um modelo ARCH(1) com $\zeta = 0.01$ e $\alpha_1 = 0.6$. Suponha que $u_{t-1} = 0.2$. Ent√£o:
>
> $h_t = 0.01 + 0.6 \times (0.2)^2 = 0.01 + 0.6 \times 0.04 = 0.034$
>
> Se $v_t = 1.5$, ent√£o $u_t = \sqrt{0.034} \times 1.5 \approx 0.175$.
>
> ```python
> import numpy as np
>
> # Par√¢metros do modelo ARCH(1)
> zeta = 0.01
> alpha1 = 0.6
>
> # Valores
> u_tm1 = 0.2
> v_t = 1.5
>
> # Calculando h_t
> h_t = zeta + alpha1 * u_tm1**2
>
> # Calculando u_t
> u_t = np.sqrt(h_t) * v_t
>
> print(f"Valor de h_t: {h_t}")
> print(f"Valor de u_t: {u_t}")
> ```

A especifica√ß√£o do modelo ARCH(m) como $u_t = \sqrt{h_t} v_t$ permite derivar propriedades importantes sobre o processo e facilita a an√°lise e estima√ß√£o dos par√¢metros do modelo.

**Proposi√ß√£o 1.** *Sob a representa√ß√£o alternativa do modelo ARCH(m), a esperan√ßa incondicional de $u_t$ √© zero, ou seja, $E(u_t) = 0$.*

*Prova:*
Como $u_t = \sqrt{h_t} v_t$, temos que $E(u_t) = E(\sqrt{h_t} v_t)$. Pela lei das expectativas iteradas, $E(u_t) = E(E(\sqrt{h_t} v_t | u_{t-1}, u_{t-2}, \dots))$. Como $h_t$ √© fun√ß√£o de $u_{t-1}, u_{t-2}, \dots$ e $v_t$ √© independente de $u_{t-1}, u_{t-2}, \dots$, temos $E(\sqrt{h_t} v_t | u_{t-1}, u_{t-2}, \dots) = \sqrt{h_t} E(v_t | u_{t-1}, u_{t-2}, \dots) = \sqrt{h_t} E(v_t) = \sqrt{h_t} \cdot 0 = 0$. Portanto, $E(u_t) = E(0) = 0$. $\blacksquare$

*Prova detalhada da Proposi√ß√£o 1:*
I. Iniciamos com a defini√ß√£o de $u_t$ no modelo ARCH(m):
   $$u_t = \sqrt{h_t} v_t$$

II. Tomamos a esperan√ßa condicional de $u_t$ dado as informa√ß√µes at√© $t-1$, denotadas por $\mathcal{F}_{t-1}$:
    $$E(u_t | \mathcal{F}_{t-1}) = E(\sqrt{h_t} v_t | \mathcal{F}_{t-1})$$

III. Como $h_t$ √© fun√ß√£o de $u_{t-1}, u_{t-2}, \dots$, √© conhecido dado $\mathcal{F}_{t-1}$. Al√©m disso, $v_t$ √© independente de $\mathcal{F}_{t-1}$ por defini√ß√£o:
     $$E(\sqrt{h_t} v_t | \mathcal{F}_{t-1}) = \sqrt{h_t} E(v_t | \mathcal{F}_{t-1}) = \sqrt{h_t} E(v_t)$$

IV. Dado que $E(v_t) = 0$ (por defini√ß√£o de $v_t$), temos:
    $$\sqrt{h_t} E(v_t) = \sqrt{h_t} \cdot 0 = 0$$

V. Portanto, $E(u_t | \mathcal{F}_{t-1}) = 0$.

VI. Agora, tomamos a esperan√ßa incondicional de $u_t$:
     $$E(u_t) = E(E(u_t | \mathcal{F}_{t-1})) = E(0) = 0$$

Assim, provamos que a esperan√ßa incondicional de $u_t$ √© zero. $\blacksquare$

### Inova√ß√£o na Representa√ß√£o AR(m)

A representa√ß√£o AR(m) para $u_t^2$ √© dada por:

$$
u_t^2 = \zeta + \alpha_1 u_{t-1}^2 + \alpha_2 u_{t-2}^2 + \dots + \alpha_m u_{t-m}^2 + w_t
$$

A inova√ß√£o $w_t$ nesta representa√ß√£o pode ser expressa em termos de $h_t$ e $v_t$ como [^1]:

$$
w_t = h_t (v_t^2 - 1)
$$

*Prova da Deriva√ß√£o de $w_t$:*
I.  Come√ßamos com a representa√ß√£o alternativa $u_t = \sqrt{h_t} v_t$. Elevando ao quadrado, temos $u_t^2 = h_t v_t^2$.

II. Expressamos $h_t$ em termos dos valores passados de $u^2$:
    $$h_t = \zeta + \alpha_1 u_{t-1}^2 + \alpha_2 u_{t-2}^2 + \dots + \alpha_m u_{t-m}^2$$

III. Substitu√≠mos $h_t$ na equa√ß√£o para $u_t^2$:
     $$u_t^2 = (\zeta + \alpha_1 u_{t-1}^2 + \alpha_2 u_{t-2}^2 + \dots + \alpha_m u_{t-m}^2) v_t^2$$

IV. Queremos expressar isso na forma $u_t^2 = \zeta + \alpha_1 u_{t-1}^2 + \alpha_2 u_{t-2}^2 + \dots + \alpha_m u_{t-m}^2 + w_t$, ent√£o reescrevemos a equa√ß√£o:
    $$u_t^2 = \zeta + \alpha_1 u_{t-1}^2 + \alpha_2 u_{t-2}^2 + \dots + \alpha_m u_{t-m}^2 + (\zeta v_t^2 - \zeta) + (\alpha_1 u_{t-1}^2 v_t^2 - \alpha_1 u_{t-1}^2) + \dots + (\alpha_m u_{t-m}^2 v_t^2 - \alpha_m u_{t-m}^2)$$
    $$u_t^2 = \zeta + \alpha_1 u_{t-1}^2 + \alpha_2 u_{t-2}^2 + \dots + \alpha_m u_{t-m}^2 + \zeta(v_t^2 - 1) + \alpha_1 u_{t-1}^2 (v_t^2 - 1) + \dots + \alpha_m u_{t-m}^2 (v_t^2 - 1)$$
    $$u_t^2 = \zeta + \alpha_1 u_{t-1}^2 + \alpha_2 u_{t-2}^2 + \dots + \alpha_m u_{t-m}^2 + (v_t^2 - 1)(\zeta + \alpha_1 u_{t-1}^2 + \alpha_2 u_{t-2}^2 + \dots + \alpha_m u_{t-m}^2) $$
   $$u_t^2 = \zeta + \alpha_1 u_{t-1}^2 + \alpha_2 u_{t-2}^2 + \dots + \alpha_m u_{t-m}^2 + (v_t^2 - 1)h_t$$

V. Portanto, $w_t = h_t (v_t^2 - 1)$. $\blacksquare$

O valor esperado de $w_t$ √©:

$$
E(w_t) = E[h_t (v_t^2 - 1)] = E(h_t) E(v_t^2 - 1) = E(h_t) (E(v_t^2) - 1) = E(h_t) (1 - 1) = 0
$$

Isso confirma que $w_t$ tem m√©dia zero.

A vari√¢ncia de $w_t$ √© dada por [^1]:

$$
E(w_t^2) = E[h_t^2 (v_t^2 - 1)^2] = E(h_t^2) E[(v_t^2 - 1)^2] = E(h_t^2) E[v_t^4 - 2v_t^2 + 1] = E(h_t^2) (E(v_t^4) - 2E(v_t^2) + 1) = E(h_t^2) (E(v_t^4) - 1)
$$

Se definirmos $\lambda^2 = E(w_t^2)$, ent√£o $\lambda^2 = E(h_t^2)(E(v_t^4)-1)$ [^1]. Note que $\lambda^2$ reflete o quarto momento de $u_t$.

> üí° **Exemplo Num√©rico:** Suponha que $h_t = 0.034$ e $v_t$ segue uma distribui√ß√£o normal padr√£o (N(0,1)). Ent√£o, $E(v_t^4) = 3$ (para a distribui√ß√£o normal padr√£o). Assim,
>
> $E(w_t^2) = E(h_t^2)(E(v_t^4)-1) = (0.034)^2 * (3 - 1) = 0.001156 * 2 = 0.002312$.
>
>  ```python
> import numpy as np
>
> # Valores
> h_t = 0.034
>
> # E(v_t^4) para uma distribui√ß√£o normal padr√£o
> E_v_t_4 = 3
>
> # Calculando E(w_t^2)
> E_w_t_2 = h_t**2 * (E_v_t_4 - 1)
>
> print(f"Valor de E(w_t^2): {E_w_t_2}")
> ```
>
> Este resultado mostra que a vari√¢ncia da inova√ß√£o $w_t$ depende tanto da vari√¢ncia condicional $h_t$ quanto da distribui√ß√£o de $v_t$. No caso de uma distribui√ß√£o normal, $E(v_t^4) = 3$, resultando em uma vari√¢ncia maior para $w_t$ em compara√ß√£o com uma distribui√ß√£o com menor curtose.

**Proposi√ß√£o 2.** *A covari√¢ncia entre $w_t$ e $u_{t-k}^2$ √© zero para $k > 0$.*

*Prova:*
$Cov(w_t, u_{t-k}^2) = E(w_t u_{t-k}^2) - E(w_t)E(u_{t-k}^2)$. J√° sabemos que $E(w_t) = 0$, ent√£o $Cov(w_t, u_{t-k}^2) = E(w_t u_{t-k}^2)$.
Substituindo $w_t = h_t(v_t^2 - 1)$, temos $Cov(w_t, u_{t-k}^2) = E(h_t (v_t^2 - 1) u_{t-k}^2)$.
Usando a lei das expectativas iteradas, $Cov(w_t, u_{t-k}^2) = E(E(h_t (v_t^2 - 1) u_{t-k}^2 | u_{t-1}, u_{t-2}, \dots))$.
Dado $u_{t-1}, u_{t-2}, \dots$, $h_t$ e $u_{t-k}^2$ s√£o conhecidos, e $v_t$ √© independente deles.
Portanto, $E(h_t (v_t^2 - 1) u_{t-k}^2 | u_{t-1}, u_{t-2}, \dots) = h_t u_{t-k}^2 E(v_t^2 - 1 | u_{t-1}, u_{t-2}, \dots) = h_t u_{t-k}^2 E(v_t^2 - 1) = h_t u_{t-k}^2 (E(v_t^2) - 1) = h_t u_{t-k}^2 (1 - 1) = 0$.
Assim, $Cov(w_t, u_{t-k}^2) = E(0) = 0$. $\blacksquare$

*Prova detalhada da Proposi√ß√£o 2:*

I. Come√ßamos com a defini√ß√£o de covari√¢ncia:
   $$Cov(w_t, u_{t-k}^2) = E[w_t u_{t-k}^2] - E[w_t]E[u_{t-k}^2]$$

II. Sabemos que $E[w_t] = 0$, ent√£o a equa√ß√£o simplifica para:
    $$Cov(w_t, u_{t-k}^2) = E[w_t u_{t-k}^2]$$

III. Substitu√≠mos $w_t$ por sua express√£o em termos de $h_t$ e $v_t$:
     $$Cov(w_t, u_{t-k}^2) = E[h_t (v_t^2 - 1) u_{t-k}^2]$$

IV. Aplicamos a lei das expectativas iteradas, condicionando na informa√ß√£o dispon√≠vel no tempo $t-1$ e tempos anteriores, denotada por $\mathcal{F}_{t-1}$:
    $$Cov(w_t, u_{t-k}^2) = E[E[h_t (v_t^2 - 1) u_{t-k}^2 | \mathcal{F}_{t-1}]]$$

V. Dado $\mathcal{F}_{t-1}$, $h_t$ √© uma fun√ß√£o de $u_{t-1}, u_{t-2}, ...$ e $u_{t-k}^2$ tamb√©m pertence a $\mathcal{F}_{t-1}$ (j√° que $k > 0$). Al√©m disso, $v_t$ √© independente de $\mathcal{F}_{t-1}$. Portanto,
   $$E[h_t (v_t^2 - 1) u_{t-k}^2 | \mathcal{F}_{t-1}] = h_t u_{t-k}^2 E[(v_t^2 - 1) | \mathcal{F}_{t-1}] = h_t u_{t-k}^2 E[v_t^2 - 1]$$

VI. Como $E[v_t^2] = 1$, temos:
    $$h_t u_{t-k}^2 E[v_t^2 - 1] = h_t u_{t-k}^2 (1 - 1) = 0$$

VII. Substituindo de volta na equa√ß√£o para a covari√¢ncia:
     $$Cov(w_t, u_{t-k}^2) = E[0] = 0$$

Portanto, a covari√¢ncia entre $w_t$ e $u_{t-k}^2$ √© zero para $k > 0$. $\blacksquare$

### An√°lise da Inova√ß√£o

A an√°lise da inova√ß√£o $w_t$ √© fundamental para entender a estrutura do modelo ARCH(m). Note que, embora a sequ√™ncia $v_t$ seja i.i.d., a inova√ß√£o $w_t$ n√£o √© i.i.d. porque sua vari√¢ncia condicional muda ao longo do tempo, dependendo de $h_t$. Especificamente, embora a vari√¢ncia incondicional de $w_t$ seja constante (e igual a $\lambda^2$), sua vari√¢ncia condicional muda ao longo do tempo. Este √© um reflexo da heteroskedasticidade presente no modelo ARCH(m).

> üí° **Exemplo Num√©rico:** Para visualizar como a vari√¢ncia condicional de $w_t$ muda ao longo do tempo, considere simular um modelo ARCH(1) com $\zeta = 0.0001$ e $\alpha_1 = 0.4$. Simulamos 200 valores de $u_t$ e calculamos $h_t$ e $w_t$. O gr√°fico de $h_t$ e $w_t^2$ mostrar√° a variabilidade ao longo do tempo, refletindo a heteroskedasticidade.
>
> ![image-20250213141524734](./image-20250213141524734.png)
> 
> A plotagem demonstrar√° visualmente como a vari√¢ncia condicional ($h_t$) e a inova√ß√£o ao quadrado ($w_t^2$) variam ao longo do tempo, exibindo os efeitos da heteroskedasticidade condicional inerente ao modelo ARCH. Note que, embora $v_t$ seja i.i.d., $w_t$ n√£o √©, devido √† sua depend√™ncia de $h_t$.

### Conclus√£o

A representa√ß√£o alternativa $u_t = \sqrt{h_t} v_t$ oferece uma forma clara de decompor o termo de erro em um componente de escala (volatilidade) e um componente de choque normalizado. Sob esta especifica√ß√£o, a proje√ß√£o linear torna-se tamb√©m a esperan√ßa condicional. A an√°lise da inova√ß√£o $w_t$ na representa√ß√£o AR(m) revela que, embora a vari√¢ncia incondicional de $w_t$ seja constante, a vari√¢ncia condicional muda ao longo do tempo, refletindo a heteroskedasticidade do modelo ARCH(m) [^1].

### Refer√™ncias

[^1]: Cap√≠tulo 21 do texto fornecido.
<!-- END -->