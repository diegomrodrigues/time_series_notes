## Inicializa√ß√£o da Sequ√™ncia de Vari√¢ncias Condicionais em Modelos GARCH

### Introdu√ß√£o
A implementa√ß√£o pr√°tica de modelos **GARCH (Generalized Autoregressive Conditional Heteroskedasticity)** requer o c√°lculo de uma sequ√™ncia de vari√¢ncias condicionais $\{h_t\}$. Como a vari√¢ncia condicional no tempo *t* depende dos valores passados de $h_t$ e dos erros ao quadrado $u_t^2$, √© necess√°rio definir valores pr√©-amostrais para inicializar o processo recursivo. Este cap√≠tulo explora o m√©todo comum de inicializa√ß√£o da sequ√™ncia de vari√¢ncias condicionais, definindo $h_j = u_j^2 = \sigma^2$ para $j = -p + 1, \dots, 0$, onde $\sigma^2$ √© a vari√¢ncia incondicional amostral de $u_t$, e discute as implica√ß√µes desta escolha [^666].

Para formalizar a depend√™ncia da vari√¢ncia condicional em modelos GARCH, podemos expressar a equa√ß√£o geral de um modelo GARCH(r, m) como:

$$
h_t = \kappa + \sum_{i=1}^{r} \delta_i h_{t-i} + \sum_{j=1}^{m} \alpha_j u_{t-j}^2
$$

Onde:

*   $h_t$ √© a vari√¢ncia condicional no tempo *t*.
*   $\kappa$ √© uma constante.
*   $\delta_i$ s√£o os coeficientes autorregressivos.
*   $\alpha_j$ s√£o os coeficientes dos erros ao quadrado.
*   $r$ √© a ordem da parte autorregressiva.
*   $m$ √© a ordem da parte de m√©dias m√≥veis.

### M√©todo de Inicializa√ß√£o: Vari√¢ncia Incondicional Amostral
Em modelos GARCH(r, m), o c√°lculo da sequ√™ncia de vari√¢ncias condicionais $\{h_t\}_{t=1}^T$ requer a especifica√ß√£o de valores iniciais para $h_j$ e $u_j^2$ para $j = -p + 1, \dots, 0$, onde $p = \max\{r, m\}$. Uma abordagem comum √© definir esses valores iniciais como iguais √† vari√¢ncia incondicional amostral de $u_t$, denotada por $\sigma^2$ [^666].

Formalmente, o m√©todo de inicializa√ß√£o √© dado por:

$$
h_j = u_j^2 = \hat{\sigma}^2 \quad \text{para } j = -p + 1, \dots, 0
$$

Onde $\hat{\sigma}^2$ √© a vari√¢ncia incondicional amostral de $u_t$, calculada como [^666]:

$$
\hat{\sigma}^2 = \frac{1}{T} \sum_{t=1}^{T} (y_t - x_t' \hat{\beta})^2
$$

Onde:

*   $T$ √© o n√∫mero de observa√ß√µes na amostra.
*   $y_t$ √© a vari√°vel observada no tempo *t*.
*   $x_t$ √© um vetor de vari√°veis explicativas no tempo *t*.
*   $\hat{\beta}$ √© o vetor de par√¢metros estimados da regress√£o de $y_t$ em $x_t$.

Este m√©todo de inicializa√ß√£o assume que, antes do in√≠cio da amostra, a volatilidade era constante e igual √† sua m√©dia de longo prazo estimada a partir dos dados dispon√≠veis.

> üí° **Exemplo Num√©rico:** Suponha que temos uma amostra de 250 retornos di√°rios de um √≠ndice de a√ß√µes ($y_t$). Para simplificar, consideramos que $x_t$ inclui apenas uma constante (um modelo de m√©dia constante para os retornos). Ap√≥s estimar a m√©dia amostral dos retornos di√°rios como $\hat{\mu} = 0.0005$ (0.05% ao dia), calculamos os res√≠duos $u_t = y_t - \hat{\mu}$. A vari√¢ncia incondicional amostral dos res√≠duos √© ent√£o:
>
> $$
> \hat{\sigma}^2 = \frac{1}{250} \sum_{t=1}^{250} (y_t - 0.0005)^2
> $$
>
> Suponha que este c√°lculo resulte em $\hat{\sigma}^2 = 0.0001$ (ou seja, 0.01%).
>
> Agora, vamos considerar um modelo GARCH(1,1):
>
> $$
> h_t = \kappa + \delta_1 h_{t-1} + \alpha_1 u_{t-1}^2
> $$
>
> Para inicializar, precisamos de $h_0$ e $u_0^2$. Usamos $\hat{\sigma}^2$:
>
> $$
> h_0 = u_0^2 = \hat{\sigma}^2 = 0.0001
> $$
>
> Se, ap√≥s a estima√ß√£o do modelo, obtivermos $\kappa = 0.00001$, $\delta_1 = 0.8$, e $\alpha_1 = 0.15$, podemos calcular $h_1$:
>
> $$
> h_1 = 0.00001 + 0.8 \times 0.0001 + 0.15 \times u_0^2
> $$
> $$
> h_1 = 0.00001 + 0.00008 + 0.15 \times 0.0001 = 0.000105
> $$
>
> Isso significa que a vari√¢ncia condicional estimada para o dia 1 √© ligeiramente superior √† vari√¢ncia incondicional amostral.
>
> üí° **Exemplo Num√©rico:** Para um modelo GARCH(2,1) com $h_t = \kappa + \delta_1 h_{t-1} + \delta_2 h_{t-2} + \alpha_1 u_{t-1}^2$, onde estimamos $\kappa = 0.000005$, $\delta_1 = 0.6$, $\delta_2 = 0.2$ e $\alpha_1 = 0.1$, e mantemos $\hat{\sigma}^2 = 0.0001$ como antes, precisamos de dois valores passados para $h_t$ e um para $u_t^2$. Inicializamos:
>
> $$
> h_0 = h_{-1} = u_0^2 = 0.0001
> $$
>
> Ent√£o, podemos calcular $h_1$:
>
> $$
> h_1 = 0.000005 + 0.6 \times 0.0001 + 0.2 \times 0.0001 + 0.1 \times 0.0001
> $$
> $$
> h_1 = 0.000005 + 0.00006 + 0.00002 + 0.00001 = 0.000095
> $$
>
> Neste caso, a vari√¢ncia condicional estimada para o dia 1 √© ligeiramente inferior √† vari√¢ncia incondicional amostral devido aos par√¢metros espec√≠ficos do modelo.
>
> Para visualizar essa sequ√™ncia de vari√¢ncias condicionais, podemos usar Python e simular alguns per√≠odos.
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
>
> # Par√¢metros do modelo GARCH(1,1)
> kappa = 0.00001
> delta1 = 0.8
> alpha1 = 0.15
> sigma2_hat = 0.0001
>
> # N√∫mero de per√≠odos
> T = 100
>
> # Inicializa√ß√£o
> h = np.zeros(T)
> u2 = np.zeros(T)
> h[0] = sigma2_hat
> u2[0] = sigma2_hat
>
> # Simula√ß√£o de res√≠duos (assumindo distribui√ß√£o normal para demonstra√ß√£o)
> np.random.seed(42)  # para reproducibilidade
> u = np.random.normal(0, np.sqrt(sigma2_hat), T)
> u2 = u**2
>
> # C√°lculo das vari√¢ncias condicionais
> for t in range(1, T):
>     h[t] = kappa + delta1 * h[t-1] + alpha1 * u2[t-1]
>
> # Visualiza√ß√£o
> plt.figure(figsize=(10, 6))
> plt.plot(h, label='Vari√¢ncia Condicional $h_t$')
> plt.axhline(y=sigma2_hat, color='r', linestyle='--', label='Vari√¢ncia Incondicional Amostral $\\hat{\\sigma}^2$')
> plt.title('Sequ√™ncia de Vari√¢ncias Condicionais GARCH(1,1)')
> plt.xlabel('Tempo (t)')
> plt.ylabel('Vari√¢ncia')
> plt.legend()
> plt.grid(True)
> plt.show()
> ```
>
> Este c√≥digo gera um gr√°fico mostrando como a vari√¢ncia condicional evolui ao longo do tempo, come√ßando com o valor inicial $\hat{\sigma}^2$. A linha vermelha tracejada representa a vari√¢ncia incondicional amostral para compara√ß√£o.

**Lema 1**: Dado que $u_t = y_t - x_t' \hat{\beta}$ s√£o os res√≠duos da regress√£o linear, a vari√¢ncia incondicional amostral $\hat{\sigma}^2$ pode ser expressa como a m√©dia amostral dos res√≠duos ao quadrado.

*Prova do Lema 1*:
A vari√¢ncia incondicional amostral $\hat{\sigma}^2$ √© definida como:
$$
\hat{\sigma}^2 = \frac{1}{T} \sum_{t=1}^{T} (y_t - x_t' \hat{\beta})^2
$$
Como $u_t = y_t - x_t' \hat{\beta}$ s√£o os res√≠duos da regress√£o linear, ent√£o
$$
\hat{\sigma}^2 = \frac{1}{T} \sum_{t=1}^{T} u_t^2
$$
Portanto, a vari√¢ncia incondicional amostral $\hat{\sigma}^2$ √© a m√©dia amostral dos res√≠duos ao quadrado. $\blacksquare$

**Lema 1.1**: A vari√¢ncia incondicional amostral $\hat{\sigma}^2$ √© um estimador consistente da vari√¢ncia incondicional populacional $\sigma^2$ sob certas condi√ß√µes de regularidade.

*Prova do Lema 1.1*:
Sob as condi√ß√µes de regularidade usuais para a regress√£o linear, $\hat{\beta}$ converge em probabilidade para $\beta$.  Se os res√≠duos $u_t$ s√£o i.i.d. com m√©dia zero e vari√¢ncia constante $\sigma^2$, ent√£o pela lei dos grandes n√∫meros, a m√©dia amostral dos res√≠duos ao quadrado converge em probabilidade para a esperan√ßa dos res√≠duos ao quadrado, que √© a vari√¢ncia $\sigma^2$. Formalmente,
$$
\text{plim}_{T \to \infty} \hat{\sigma}^2 = \text{plim}_{T \to \infty} \frac{1}{T} \sum_{t=1}^{T} u_t^2 = E[u_t^2] = \sigma^2
$$
Portanto, $\hat{\sigma}^2$ √© um estimador consistente de $\sigma^2$. $\blacksquare$

### Implica√ß√µes da Inicializa√ß√£o com a Vari√¢ncia Incondicional Amostral

A escolha de inicializar a sequ√™ncia de vari√¢ncias condicionais com a vari√¢ncia incondicional amostral tem diversas implica√ß√µes:

1.  **Simplicidade:** √â um m√©todo simples e f√°cil de implementar, pois requer apenas o c√°lculo da vari√¢ncia amostral dos res√≠duos.

2.  **Converg√™ncia:** Inicializar com a vari√¢ncia incondicional amostral ajuda na converg√™ncia do algoritmo de estima√ß√£o, pois fornece um valor inicial razo√°vel para a volatilidade.

3.  **Vi√©s Inicial:** Este m√©todo introduz um vi√©s inicial na sequ√™ncia de vari√¢ncias condicionais, pois for√ßa os primeiros valores a serem iguais √† m√©dia de longo prazo. Este vi√©s pode afetar as primeiras previs√µes de volatilidade, especialmente se a volatilidade no in√≠cio da amostra for significativamente diferente da m√©dia de longo prazo.

4.  **Influ√™ncia da Amostra:** A escolha da vari√¢ncia incondicional amostral como valor inicial implica que a inicializa√ß√£o depende da amostra utilizada. Amostras diferentes podem levar a diferentes valores iniciais e, portanto, a diferentes sequ√™ncias de vari√¢ncias condicionais.

**Teorema 2**: A sequ√™ncia de vari√¢ncias condicionais $\{h_t\}$ gerada por um modelo GARCH(r, m) √© assintoticamente estacion√°ria se e somente se as ra√≠zes do polin√¥mio caracter√≠stico associado estiverem fora do c√≠rculo unit√°rio.

*Prova do Teorema 2*:
A estacionariedade da sequ√™ncia $\{h_t\}$ depende das propriedades dos coeficientes $\delta_i$ na equa√ß√£o GARCH. Para provar essa afirma√ß√£o, vamos analisar a equa√ß√£o do modelo GARCH(r,m):
$$
h_t = \kappa + \sum_{i=1}^{r} \delta_i h_{t-i} + \sum_{j=1}^{m} \alpha_j u_{t-j}^2
$$

I.  **Transforma√ß√£o da Equa√ß√£o:** Podemos reescrever essa equa√ß√£o em termos do operador de defasagem $L$ (onde $Lh_t = h_{t-1}$):
    $$
    h_t - \sum_{i=1}^{r} \delta_i h_{t-i} = \kappa + \sum_{j=1}^{m} \alpha_j u_{t-j}^2
    $$
    $$
    \left(1 - \sum_{i=1}^{r} \delta_i L^i\right) h_t = \kappa + \sum_{j=1}^{m} \alpha_j u_{t-j}^2
    $$

II. **Defini√ß√£o do Polin√¥mio Caracter√≠stico:** Definimos o polin√¥mio caracter√≠stico como:
    $$
    \phi(L) = 1 - \sum_{i=1}^{r} \delta_i L^i
    $$
    Ent√£o, a equa√ß√£o pode ser escrita como:
    $$
    \phi(L) h_t = \kappa + \sum_{j=1}^{m} \alpha_j u_{t-j}^2
    $$

III. **Condi√ß√£o de Estacionariedade:** Para que a sequ√™ncia $\{h_t\}$ seja estacion√°ria, o operador $\phi(L)$ deve ser invert√≠vel. Isso ocorre se todas as ra√≠zes do polin√¥mio $\phi(z) = 1 - \sum_{i=1}^{r} \delta_i z^i$ estiverem fora do c√≠rculo unit√°rio (ou seja, $|z_i| > 1$ para todas as ra√≠zes $z_i$).

IV. **Intui√ß√£o:** Se alguma raiz estiver dentro ou sobre o c√≠rculo unit√°rio ($|z_i| \le 1$), ent√£o as solu√ß√µes para $h_t$ podem explodir ou oscilar indefinidamente, o que viola a condi√ß√£o de estacionariedade. A condi√ß√£o de que todas as ra√≠zes estejam fora do c√≠rculo unit√°rio garante que as influ√™ncias de choques passados (os $u_{t-j}^2$) diminuam exponencialmente ao longo do tempo, e que a vari√¢ncia condicional $h_t$ retorne a um n√≠vel est√°vel.

V. **Conclus√£o:** Portanto, a sequ√™ncia de vari√¢ncias condicionais $\{h_t\}$ gerada por um modelo GARCH(r, m) √© assintoticamente estacion√°ria se e somente se as ra√≠zes do polin√¥mio caracter√≠stico associado estiverem fora do c√≠rculo unit√°rio. $\blacksquare$

### Alternativas para a Inicializa√ß√£o
Embora a inicializa√ß√£o com a vari√¢ncia incondicional amostral seja uma pr√°tica comum, outras abordagens podem ser consideradas:

1.  **Otimiza√ß√£o Conjunta:** Estimar os valores iniciais $h_j$ e $u_j^2$ juntamente com os par√¢metros do modelo GARCH, maximizando a fun√ß√£o de verossimilhan√ßa. Essa abordagem √© computacionalmente mais intensiva, mas pode levar a estimativas mais precisas da volatilidade inicial.

2.  **Valores Fixos:** Definir os valores iniciais com base em informa√ß√µes externas, como a volatilidade impl√≠cita de op√ß√µes de ativos similares ou estimativas de volatilidade de outras fontes.

3.  **Burn-in Period:** Utilizar um "burn-in period" no in√≠cio da amostra, onde as vari√¢ncias condicionais s√£o calculadas iterativamente sem serem utilizadas para infer√™ncia. Ap√≥s esse per√≠odo, as vari√¢ncias condicionais s√£o consideradas "aquecidas" e s√£o utilizadas para a estima√ß√£o dos par√¢metros e a previs√£o da volatilidade.

> üí° **Exemplo Num√©rico:** Para ilustrar o "burn-in period", considere que temos 500 observa√ß√µes, mas usamos apenas as √∫ltimas 400 para a estima√ß√£o do modelo e as primeiras 100 como "burn-in".  Durante o "burn-in", calculamos $h_t$ iterativamente, mas n√£o usamos esses valores para estimar os par√¢metros $\kappa$, $\delta_i$ e $\alpha_j$. Ap√≥s o per√≠odo de "burn-in", usamos as 400 observa√ß√µes restantes para a estima√ß√£o e infer√™ncia. Isso pode reduzir o vi√©s da inicializa√ß√£o, especialmente se os primeiros 100 retornos tiverem uma volatilidade muito diferente da m√©dia de longo prazo.
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
>
> # Par√¢metros do modelo GARCH(1,1)
> kappa = 0.00001
> delta1 = 0.8
> alpha1 = 0.15
> sigma2_hat = 0.0001
>
> # N√∫mero total de observa√ß√µes
> T_total = 500
>
> # Tamanho do burn-in period
> burn_in = 100
>
> # N√∫mero de observa√ß√µes para estima√ß√£o
> T = T_total - burn_in
>
> # Inicializa√ß√£o
> h = np.zeros(T_total)
> u2 = np.zeros(T_total)
> h[0] = sigma2_hat
> u2[0] = sigma2_hat
>
> # Simula√ß√£o de res√≠duos para todo o per√≠odo
> np.random.seed(42)
> u = np.random.normal(0, np.sqrt(sigma2_hat), T_total)
> u2 = u**2
>
> # C√°lculo das vari√¢ncias condicionais para todo o per√≠odo, incluindo o burn-in
> for t in range(1, T_total):
>     h[t] = kappa + delta1 * h[t-1] + alpha1 * u2[t-1]
>
> # Vari√¢ncias condicionais usadas para a estima√ß√£o (ap√≥s o burn-in)
> h_estimation = h[burn_in:]
>
> # Visualiza√ß√£o
> plt.figure(figsize=(12, 6))
> plt.plot(h, label='Vari√¢ncia Condicional $h_t$ (com Burn-in)')
> plt.plot(range(burn_in, T_total), h_estimation, label='Vari√¢ncia Condicional para Estima√ß√£o')
> plt.axvline(x=burn_in, color='k', linestyle='--', label='Fim do Burn-in Period')
> plt.axhline(y=sigma2_hat, color='r', linestyle='--', label='Vari√¢ncia Incondicional Amostral $\\hat{\\sigma}^2$')
> plt.title('Efeito do Burn-in Period na Sequ√™ncia de Vari√¢ncias Condicionais GARCH(1,1)')
> plt.xlabel('Tempo (t)')
> plt.ylabel('Vari√¢ncia')
> plt.legend()
> plt.grid(True)
> plt.show()
> ```
>
> Este c√≥digo simula um modelo GARCH(1,1) com um per√≠odo de "burn-in" e mostra como a sequ√™ncia de vari√¢ncias condicionais se ajusta antes de ser usada para a estima√ß√£o. A linha vertical indica o fim do per√≠odo de "burn-in", e a linha vermelha tracejada representa a vari√¢ncia incondicional amostral.

**Proposi√ß√£o 3**: O uso de um "burn-in period" pode reduzir o vi√©s inicial na sequ√™ncia de vari√¢ncias condicionais, mas aumenta o custo computacional da estima√ß√£o do modelo GARCH.

*Justificativa*: O "burn-in period" permite que a sequ√™ncia de vari√¢ncias condicionais se ajuste aos dados antes que as estimativas sejam usadas para infer√™ncia, reduzindo o impacto da inicializa√ß√£o arbitr√°ria. No entanto, o c√°lculo iterativo das vari√¢ncias condicionais durante o "burn-in period" aumenta o tempo de computa√ß√£o.

### Conclus√£o
A inicializa√ß√£o da sequ√™ncia de vari√¢ncias condicionais √© uma etapa crucial na implementa√ß√£o de modelos GARCH [^666]. Embora a defini√ß√£o dos valores pr√©-amostrais $h_j$ e $u_j^2$ como iguais √† vari√¢ncia incondicional amostral $\hat{\sigma}^2$ seja uma abordagem comum devido √† sua simplicidade e converg√™ncia, √© importante estar ciente do vi√©s inicial introduzido por este m√©todo. M√©todos alternativos de inicializa√ß√£o, como a otimiza√ß√£o conjunta ou a utiliza√ß√£o de um "burn-in period", podem mitigar este vi√©s e levar a estimativas mais precisas da volatilidade, mas √† custa de maior complexidade computacional.

### Refer√™ncias
[^666]: Cap√≠tulo 21 do texto original, p√°gina 666.
<!-- END -->