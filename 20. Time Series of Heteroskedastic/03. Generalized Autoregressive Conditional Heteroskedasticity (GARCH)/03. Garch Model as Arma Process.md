## M√©dia Incondicional e Representa√ß√£o ARMA do Modelo GARCH

### Introdu√ß√£o
Este cap√≠tulo estende a an√°lise dos modelos **GARCH (Generalized Autoregressive Conditional Heteroskedasticity)**, focando na deriva√ß√£o da m√©dia incondicional da s√©rie de erros ao quadrado ($u_t^2$) sob a condi√ß√£o de estacionariedade, e na demonstra√ß√£o de como o modelo GARCH pode ser reescrito como um processo **ARMA (Autoregressive Moving Average)** aplicado a $u_t^2$ [^665]. Esses resultados s√£o fundamentais para entender as propriedades estat√≠sticas e a modelagem do modelo GARCH.

### M√©dia Incondicional sob Estacionariedade

Sob a condi√ß√£o de estacionariedade em covari√¢ncia, a m√©dia incondicional de $u_t^2$ em um modelo GARCH(r, m) √© dada por [^666]:

$$
\sigma^2 = E(u_t^2) = \frac{\kappa}{1 - (\delta_1 + \alpha_1) - (\delta_2 + \alpha_2) - \dots - (\delta_p + \alpha_p)}
$$

Onde:

*   $\sigma^2$ √© a m√©dia incondicional de $u_t^2$.
*   $\kappa$ √© a constante na equa√ß√£o da vari√¢ncia condicional.
*   $\delta_i$ s√£o os coeficientes das defasagens da vari√¢ncia condicional.
*   $\alpha_i$ s√£o os coeficientes dos quadrados dos erros passados.
*   $p = \max\{m, r\}$.

Esta f√≥rmula √© v√°lida somente se a condi√ß√£o de estacionariedade $\sum_{i=1}^{p} (\delta_i + \alpha_i) < 1$ for satisfeita. Caso contr√°rio, a m√©dia incondicional n√£o √© definida, como discutido no cap√≠tulo anterior.

> üí° **Exemplo Num√©rico:** Considere um modelo GARCH(1,1) com $\kappa = 0.01$, $\delta_1 = 0.8$, e $\alpha_1 = 0.1$. A m√©dia incondicional de $u_t^2$ √©:
>
> $$
> \sigma^2 = E(u_t^2) = \frac{0.01}{1 - (0.8 + 0.1)} = \frac{0.01}{1 - 0.9} = \frac{0.01}{0.1} = 0.1
> $$
>
> Isso significa que, em m√©dia, o valor esperado do quadrado do erro √© 0.1, dado que o modelo √© estacion√°rio.
>
> üí° **Exemplo Num√©rico:** Agora, considere um GARCH(1,2) com $\kappa = 0.005$, $\delta_1 = 0.6$, $\alpha_1 = 0.1$ e $\alpha_2 = 0.2$. Aqui, $p = \max(1, 2) = 2$. A m√©dia incondicional √©:
>
> $$
> \sigma^2 = E(u_t^2) = \frac{0.005}{1 - (0.6 + 0.1) - (0 + 0.2)} = \frac{0.005}{1 - 0.9} = \frac{0.005}{0.1} = 0.05
> $$
>
> Observe que $\delta_2 = 0$ j√° que n√£o existe um segundo termo autorregressivo na vari√¢ncia condicional. Este exemplo demonstra como a f√≥rmula se estende para modelos GARCH com diferentes ordens.
>
> üí° **Exemplo Num√©rico:** Vejamos um caso onde a condi√ß√£o de estacionariedade n√£o √© satisfeita. Considere um GARCH(1,1) com $\kappa = 0.02$, $\delta_1 = 0.9$, e $\alpha_1 = 0.2$.
>
> Aqui, $\delta_1 + \alpha_1 = 0.9 + 0.2 = 1.1 > 1$. Portanto, o modelo n√£o √© estacion√°rio, e a m√©dia incondicional $E(u_t^2)$ n√£o √© definida (ou seja, tende ao infinito).

**Teorema 1** (Deriva√ß√£o da M√©dia Incondicional): A m√©dia incondicional de $u_t^2$ sob a condi√ß√£o de estacionariedade para um modelo GARCH(r, m) √© dada por:
$$
E(u_t^2) = \frac{\kappa}{1 - \sum_{i=1}^{p} (\delta_i + \alpha_i)}
$$

*Prova do Teorema 1:*
Para derivar a m√©dia incondicional, come√ßamos com a equa√ß√£o do GARCH(r, m) para a vari√¢ncia condicional:

$$
h_t = \kappa + \delta_1 h_{t-1} + \delta_2 h_{t-2} + \dots + \delta_r h_{t-r} + \alpha_1 u_{t-1}^2 + \alpha_2 u_{t-2}^2 + \dots + \alpha_m u_{t-m}^2
$$

I. Tomamos a esperan√ßa incondicional de ambos os lados:
$$
E(h_t) = E(\kappa + \delta_1 h_{t-1} + \delta_2 h_{t-2} + \dots + \delta_r h_{t-r} + \alpha_1 u_{t-1}^2 + \alpha_2 u_{t-2}^2 + \dots + \alpha_m u_{t-m}^2)
$$

II. Sob a condi√ß√£o de estacionariedade, $E(h_t) = E(h_{t-1}) = \dots = E(h_{t-r})$ e $E(u_t^2) = E(u_{t-1}^2) = \dots = E(u_{t-m}^2)$. Assim,
$$
E(h_t) = \kappa + \delta_1 E(h_t) + \dots + \delta_r E(h_t) + \alpha_1 E(u_t^2) + \dots + \alpha_m E(u_t^2)
$$

III. Sabemos que $u_t = \sqrt{h_t} \cdot v_t$, onde $v_t$ √© um ru√≠do branco com m√©dia zero e vari√¢ncia unit√°ria. Portanto, $E(u_t^2 | \mathcal{F}_{t-1}) = h_t E(v_t^2) = h_t$, onde $\mathcal{F}_{t-1}$ denota o conjunto de informa√ß√µes at√© o tempo $t-1$. Tomando a esperan√ßa incondicional, temos $E(u_t^2) = E(h_t)$.

IV. Substitu√≠mos $E(h_t)$ por $E(u_t^2)$ na equa√ß√£o:
$$
E(u_t^2) = \kappa + \delta_1 E(u_t^2) + \dots + \delta_r E(u_t^2) + \alpha_1 E(u_t^2) + \dots + \alpha_m E(u_t^2)
$$

V. Reorganizando os termos:
$$
E(u_t^2) - \delta_1 E(u_t^2) - \dots - \delta_r E(u_t^2) - \alpha_1 E(u_t^2) - \dots - \alpha_m E(u_t^2) = \kappa
$$
$$
E(u_t^2) (1 - \delta_1 - \dots - \delta_r - \alpha_1 - \dots - \alpha_m) = \kappa
$$
$$
E(u_t^2) \left(1 - \sum_{i=1}^{p} (\delta_i + \alpha_i)\right) = \kappa
$$

VI. Finalmente, dividindo ambos os lados por $1 - \sum_{i=1}^{p} (\delta_i + \alpha_i)$, obtemos:
$$
E(u_t^2) = \frac{\kappa}{1 - \sum_{i=1}^{p} (\delta_i + \alpha_i)}
$$

Portanto, a m√©dia incondicional de $u_t^2$ √© dada por $\sigma^2 = E(u_t^2) = \frac{\kappa}{1 - \sum_{i=1}^{p} (\delta_i + \alpha_i)}$. $\blacksquare$

**Lema 1** (Condi√ß√£o Suficiente para a Exist√™ncia da M√©dia Incondicional): Se $\sum_{i=1}^{p} (\delta_i + \alpha_i) < 1$, ent√£o a m√©dia incondicional de $u_t^2$ existe e √© finita.

*Prova do Lema 1:*
A prova segue diretamente da f√≥rmula da m√©dia incondicional derivada no Teorema 1. Se $\sum_{i=1}^{p} (\delta_i + \alpha_i) < 1$, ent√£o o denominador da express√£o $\frac{\kappa}{1 - \sum_{i=1}^{p} (\delta_i + \alpha_i)}$ √© diferente de zero e positivo.  Como $\kappa$ √© uma constante finita, a fra√ß√£o resultante √© finita, o que implica que a m√©dia incondicional de $u_t^2$ existe e √© finita. $\blacksquare$

### Representa√ß√£o ARMA do Modelo GARCH
Um resultado importante √© que o modelo GARCH(r, m) pode ser reescrito como um processo ARMA(p, r) aplicado a $u_t^2$, onde $p = \max\{m, r\}$ [^665]. Este resultado oferece uma perspectiva valiosa sobre a estrutura de depend√™ncia temporal dos quadrados dos erros em modelos GARCH.

Para demonstrar isso, definimos $w_t = u_t^2 - h_t$ como o erro de previs√£o da vari√¢ncia condicional. Reorganizando a equa√ß√£o do GARCH(r, m), obtemos [^665]:

$$
u_t^2 = \kappa + \sum_{i=1}^{r} \delta_i h_{t-i} + \sum_{i=1}^{m} \alpha_i u_{t-i}^2 + w_t
$$
$$
u_t^2 = \kappa + \sum_{i=1}^{r} \delta_i (u_{t-i}^2 - w_{t-i}) + \sum_{i=1}^{m} \alpha_i u_{t-i}^2 + w_t
$$
$$
u_t^2 = \kappa + \sum_{i=1}^{p} (\delta_i + \alpha_i) u_{t-i}^2 - \sum_{i=1}^{r} \delta_i w_{t-i} + w_t
$$
Onde definimos $\alpha_i = 0$ para $i > m$ e $\delta_i = 0$ para $i > r$. Esta equa√ß√£o representa um processo ARMA(p, r) para $u_t^2$, onde os termos autorregressivos s√£o determinados pelos coeficientes $\delta_i + \alpha_i$ e os termos de m√©dia m√≥vel s√£o determinados pelos coeficientes $\delta_i$.

> üí° **Exemplo Num√©rico:** Considere um modelo GARCH(1,1) onde $h_t = \kappa + \delta_1 h_{t-1} + \alpha_1 u_{t-1}^2$. Reescrevendo em termos de $u_t^2$, obtemos:
>
> $u_t^2 = \kappa + \delta_1 h_{t-1} + \alpha_1 u_{t-1}^2 + w_t$
> $w_t = u_t^2 - h_t$, ent√£o $h_t = u_t^2 - w_t$, substituindo:
> $u_t^2 = \kappa + \delta_1 (u_{t-1}^2 - w_{t-1}) + \alpha_1 u_{t-1}^2 + w_t$
> $u_t^2 = \kappa + (\delta_1 + \alpha_1) u_{t-1}^2 - \delta_1 w_{t-1} + w_t$
>
> Esta √© a forma ARMA(1,1) para $u_t^2$.
>
> üí° **Exemplo Num√©rico:** Suponha um modelo GARCH(2,1) com $\kappa = 0.01$, $\delta_1 = 0.5$, $\delta_2 = 0.2$ e $\alpha_1 = 0.1$. Podemos escrever a equa√ß√£o ARMA correspondente para $u_t^2$. Primeiro, note que $p = \max(2, 1) = 2$.
>
> $h_t = \kappa + \delta_1 h_{t-1} + \delta_2 h_{t-2} + \alpha_1 u_{t-1}^2$
>
> $u_t^2 = h_t + w_t$, ent√£o $h_t = u_t^2 - w_t$. Substituindo:
>
> $u_t^2 - w_t = \kappa + \delta_1 (u_{t-1}^2 - w_{t-1}) + \delta_2 (u_{t-2}^2 - w_{t-2}) + \alpha_1 u_{t-1}^2$
>
> $u_t^2 = \kappa + (\delta_1 + \alpha_1) u_{t-1}^2 + \delta_2 u_{t-2}^2 - \delta_1 w_{t-1} - \delta_2 w_{t-2} + w_t$
>
> $u_t^2 = 0.01 + (0.5 + 0.1) u_{t-1}^2 + 0.2 u_{t-2}^2 - 0.5 w_{t-1} - 0.2 w_{t-2} + w_t$
>
> $u_t^2 = 0.01 + 0.6 u_{t-1}^2 + 0.2 u_{t-2}^2 + w_t - 0.5 w_{t-1} - 0.2 w_{t-2}$
>
> Portanto, a representa√ß√£o ARMA(2, 2) para $u_t^2$ √©: $u_t^2 = 0.01 + 0.6 u_{t-1}^2 + 0.2 u_{t-2}^2 + w_t - 0.5 w_{t-1} - 0.2 w_{t-2}$.

**Teorema 2** (Representa√ß√£o ARMA do GARCH): Um modelo GARCH(r, m) pode ser expresso como um processo ARMA(p, r) para $u_t^2$, com a seguinte forma:
$$
u_t^2 = \kappa + \sum_{i=1}^{p} (\delta_i + \alpha_i) u_{t-i}^2 + w_t - \sum_{i=1}^{r} \delta_i w_{t-i}
$$
Onde $w_t = u_t^2 - h_t$ e $p = \max\{m, r\}$.

*Prova do Teorema 2:*

Come√ßamos com a equa√ß√£o do GARCH(r, m) para a vari√¢ncia condicional:
$$
h_t = \kappa + \sum_{i=1}^{r} \delta_i h_{t-i} + \sum_{i=1}^{m} \alpha_i u_{t-i}^2
$$

I. Definimos $w_t = u_t^2 - h_t$. Ent√£o, $h_t = u_t^2 - w_t$. Substituindo $h_{t-i}$ por $u_{t-i}^2 - w_{t-i}$ na equa√ß√£o GARCH, obtemos:

$$
u_t^2 - w_t = \kappa + \sum_{i=1}^{r} \delta_i (u_{t-i}^2 - w_{t-i}) + \sum_{i=1}^{m} \alpha_i u_{t-i}^2
$$

II. Reorganizando os termos, obtemos:
$$
u_t^2 = \kappa + \sum_{i=1}^{r} \delta_i u_{t-i}^2 - \sum_{i=1}^{r} \delta_i w_{t-i} + \sum_{i=1}^{m} \alpha_i u_{t-i}^2 + w_t
$$

III. Combinando os termos de soma e definindo $p = \max\{r, m\}$:

$$
u_t^2 = \kappa + \sum_{i=1}^{p} (\delta_i + \alpha_i) u_{t-i}^2 + w_t - \sum_{i=1}^{r} \delta_i w_{t-i}
$$

Esta √© a equa√ß√£o de um processo ARMA(p, r) para $u_t^2$, onde os termos autorregressivos s√£o ponderados por $(\delta_i + \alpha_i)$ e os termos de m√©dia m√≥vel s√£o ponderados por $\delta_i$. $\blacksquare$

> üí° **Exemplo Num√©rico:** Para um GARCH(2,1), a equa√ß√£o ARMA resultante √©:
>
> $u_t^2 = \kappa + (\delta_1 + \alpha_1) u_{t-1}^2 + \delta_2 u_{t-2}^2 + w_t - \delta_1 w_{t-1} - \delta_2 w_{t-2}$
>
> Aqui, $p = \max(2, 1) = 2$ e o processo ARMA resultante √© de ordem (2, 2) para $u_t^2$.
>
> üí° **Exemplo Num√©rico:** Vamos ilustrar a representa√ß√£o ARMA com um exemplo simulado em Python. Consideraremos um modelo GARCH(1,1) com par√¢metros: $\kappa = 0.05$, $\delta_1 = 0.7$, e $\alpha_1 = 0.2$. Simularmos 200 valores e ent√£o calculamos os termos $w_t$.
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
>
> # Par√¢metros do GARCH(1,1)
> kappa = 0.05
> delta1 = 0.7
> alpha1 = 0.2
>
> # N√∫mero de simula√ß√µes
> num_sim = 200
>
> # Inicializa√ß√£o
> h = np.zeros(num_sim)
> u = np.zeros(num_sim)
> w = np.zeros(num_sim)
>
> # Simula√ß√£o
> np.random.seed(42)  # Garante reprodutibilidade
> v = np.random.normal(0, 1, num_sim)  # Ru√≠do branco
>
> # Valores iniciais
> h[0] = kappa / (1 - delta1 - alpha1)  # M√©dia incondicional
> u[0] = np.sqrt(h[0]) * v[0]
>
> for t in range(1, num_sim):
>     h[t] = kappa + delta1 * h[t-1] + alpha1 * u[t-1]**2
>     u[t] = np.sqrt(h[t]) * v[t]
>     w[t] = u[t]**2 - h[t]
>
> # Plotando u_t^2 e w_t
> plt.figure(figsize=(12, 6))
> plt.plot(u**2, label='$u_t^2$')
> plt.plot(w, label='$w_t$')
> plt.xlabel('Tempo')
> plt.ylabel('Valor')
> plt.title('S√©rie Temporal de $u_t^2$ e $w_t$ para GARCH(1,1)')
> plt.legend()
> plt.grid(True)
> plt.show()
>
> # Plotando ACF de u_t^2
> import statsmodels.api as sm
> from statsmodels.graphics.tsaplots import plot_acf
>
> fig, ax = plt.subplots(figsize=(12, 6))
> plot_acf(u**2, lags=20, ax=ax, title='ACF de $u_t^2$')
> plt.xlabel('Lag')
> plt.ylabel('Autocorrela√ß√£o')
> plt.grid(True)
> plt.show()
>
> ```
> Este c√≥digo simula um processo GARCH(1,1), calcula $u_t^2$ e $w_t$, e ent√£o plota as s√©ries temporais resultantes junto com a Fun√ß√£o de Autocorrela√ß√£o (ACF) de $u_t^2$. A ACF ajuda a visualizar a correla√ß√£o serial em $u_t^2$, o que est√° relacionado com a estrutura ARMA.

**Corol√°rio 1** (Interpreta√ß√£o dos Coeficientes ARMA): No processo ARMA resultante da representa√ß√£o do GARCH(r, m), os coeficientes autorregressivos representam a persist√™ncia dos choques na volatilidade, enquanto os coeficientes da m√©dia m√≥vel representam o impacto dos erros de previs√£o da vari√¢ncia condicional.

**Teorema 2.1** (Estacionariedade do Processo ARMA Representado): O processo ARMA(p, r) representado por $u_t^2$ √© estacion√°rio se e somente se as ra√≠zes do polin√¥mio autorregressivo $1 - \sum_{i=1}^{p} (\delta_i + \alpha_i)L^i$ estiverem fora do c√≠rculo unit√°rio, onde $L$ √© o operador de defasagem.

*Prova do Teorema 2.1:*
A estacionariedade de um processo ARMA depende das ra√≠zes do polin√¥mio autorregressivo.  Especificamente, para um processo ARMA da forma:
$$
X_t = \phi_1 X_{t-1} + \phi_2 X_{t-2} + \dots + \phi_p X_{t-p} + \epsilon_t + \theta_1 \epsilon_{t-1} + \dots + \theta_q \epsilon_{t-q}
$$
I. o processo √© estacion√°rio se todas as ra√≠zes do polin√¥mio $1 - \phi_1 L - \phi_2 L^2 - \dots - \phi_p L^p = 0$ estiverem fora do c√≠rculo unit√°rio (ou seja, tiverem m√≥dulo maior que 1).

II. No contexto da representa√ß√£o ARMA do GARCH, o polin√¥mio autorregressivo √© $1 - \sum_{i=1}^{p} (\delta_i + \alpha_i)L^i$. Portanto, o processo ARMA representado por $u_t^2$ √© estacion√°rio se e somente se as ra√≠zes deste polin√¥mio estiverem fora do c√≠rculo unit√°rio. $\blacksquare$

> üí° **Exemplo Num√©rico:** Considere o GARCH(1,1) do exemplo anterior, onde $u_t^2 = \kappa + (\delta_1 + \alpha_1) u_{t-1}^2 + w_t - \delta_1 w_{t-1}$. O polin√¥mio autorregressivo √© $1 - (\delta_1 + \alpha_1)L = 1 - (0.7 + 0.2)L = 1 - 0.9L$.
>
> Para encontrar a raiz, resolvemos $1 - 0.9L = 0$, o que d√° $L = \frac{1}{0.9} \approx 1.11$. Como $|L| > 1$, o processo ARMA √© estacion√°rio.
>
> üí° **Exemplo Num√©rico:** Agora, considere um caso n√£o estacion√°rio onde $\delta_1 = 0.6$ e $\alpha_1 = 0.4$. Ent√£o, o polin√¥mio autorregressivo √© $1 - (0.6 + 0.4)L = 1 - L$. A raiz √© $L = 1$. Como $|L| = 1$, o processo ARMA n√£o √© estritamente estacion√°rio, o que se alinha com a condi√ß√£o de estacionariedade para o GARCH, onde a soma dos coeficientes deve ser menor que 1.

### Implica√ß√µes Pr√°ticas
A representa√ß√£o ARMA do modelo GARCH oferece diversas implica√ß√µes pr√°ticas:

1.  **Diagn√≥stico do Modelo**: A an√°lise das fun√ß√µes de autocorrela√ß√£o e autocorrela√ß√£o parcial (ACF e PACF) de $u_t^2$ pode auxiliar na identifica√ß√£o da ordem apropriada (r, m) do modelo GARCH.

2.  **Previs√£o da Volatilidade**: A representa√ß√£o ARMA pode ser utilizada para prever a volatilidade futura com base nos valores passados de $u_t^2$ e $w_t$.

3.  **Interpreta√ß√£o da Din√¢mica da Volatilidade**: A magnitude e o sinal dos coeficientes AR e MA fornecem insights sobre a persist√™ncia e a resposta da volatilidade a choques passados.

### Conclus√£o
Este cap√≠tulo apresentou dois resultados fundamentais sobre o modelo GARCH: a deriva√ß√£o da m√©dia incondicional de $u_t^2$ sob a condi√ß√£o de estacionariedade, e a demonstra√ß√£o de que o modelo GARCH pode ser reescrito como um processo ARMA aplicado a $u_t^2$. Esses resultados fornecem uma base s√≥lida para a compreens√£o das propriedades estat√≠sticas do modelo GARCH e para sua aplica√ß√£o na modelagem e previs√£o da volatilidade.

### Refer√™ncias
[^665]: Cap√≠tulo 21 do texto original, p√°gina 665.
[^666]: Cap√≠tulo 21 do texto original, p√°gina 666.
<!-- END -->