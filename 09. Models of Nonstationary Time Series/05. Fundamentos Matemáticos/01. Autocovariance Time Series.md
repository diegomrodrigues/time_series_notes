## Autocovari√¢ncia e Persist√™ncia em S√©ries Temporais N√£o Estacion√°rias

### Introdu√ß√£o
Este cap√≠tulo explora modelos de s√©ries temporais n√£o estacion√°rias, expandindo a an√°lise para al√©m dos processos estacion√°rios abordados em cap√≠tulos anteriores [^1]. A n√£o estacionariedade introduz complexidades, particularmente no que diz respeito √† autocovari√¢ncia e √† persist√™ncia de choques. A autocovari√¢ncia, uma medida de como os valores de uma s√©rie temporal est√£o correlacionados em diferentes pontos do tempo, torna-se crucial para entender as propriedades din√¢micas desses modelos. Em particular, analisaremos como a fun√ß√£o de autocovari√¢ncia de um processo com raiz unit√°ria se comporta quando avaliada em $z=1$ e sua rela√ß√£o com a persist√™ncia de choques.

### Conceitos Fundamentais
Conforme discutido anteriormente [^1], modelos de s√©ries temporais estacion√°rias podem ser expressos como:
$$ y_t = \mu + \epsilon_t + \psi_1\epsilon_{t-1} + \psi_2\epsilon_{t-2} + \ldots = \mu + \psi(L)\epsilon_t $$
onde $\sum_{j=0}^\infty |\psi_j| < \infty$, as ra√≠zes de $\psi(z) = 0$ est√£o fora do c√≠rculo unit√°rio, e $\{\epsilon_t\}$ √© uma sequ√™ncia de ru√≠do branco com m√©dia zero e vari√¢ncia $\sigma^2$. Uma caracter√≠stica fundamental desses processos √© que a esperan√ßa incondicional √© constante, $E(y_t) = \mu$, e que as previs√µes convergem para essa m√©dia conforme o horizonte de previs√£o aumenta [^1].

> üí° **Exemplo Num√©rico:**
>
> Considere um processo AR(1) estacion√°rio dado por $y_t = 5 + 0.7\epsilon_{t-1} + \epsilon_t$, onde $\mu = 5$, $\psi_1 = 0.7$, e $\epsilon_t$ √© um ru√≠do branco com vari√¢ncia $\sigma^2 = 1$. A esperan√ßa incondicional √© $E(y_t) = 5$. Se $y_1 = 6$, ent√£o $y_2 = 5 + 0.7(y_1 - 5) + \epsilon_2 = 5 + 0.7(1) + \epsilon_2 = 5.7 + \epsilon_2$.  Conforme o tempo aumenta, a influ√™ncia de um choque inicial diminui, e a previs√£o tende a 5.

Entretanto, muitas s√©ries temporais econ√¥micas e financeiras exibem tend√™ncias que tornam inadequada a modelagem como processos estacion√°rios. Dois m√©todos comuns para incorporar tais tend√™ncias s√£o:

1.  **Tend√™ncia Determin√≠stica:** Substitui-se a m√©dia $\mu$ por uma fun√ß√£o linear do tempo $t$, resultando em um processo *trend-stationary*:
    $$y_t = \alpha + \delta t + \psi(L)\epsilon_t$$  [^1]
    Nesse caso, o processo torna-se estacion√°rio ap√≥s a remo√ß√£o da tend√™ncia $\alpha + \delta t$.

> üí° **Exemplo Num√©rico:**
>
> Suponha que $y_t = 2 + 0.5t + 0.8\epsilon_{t-1} + \epsilon_t$, onde $\alpha = 2$, $\delta = 0.5$, e $\psi_1 = 0.8$. Para $t=1$, temos $y_1 = 2 + 0.5(1) + 0.8\epsilon_0 + \epsilon_1$. Para $t=2$, $y_2 = 2 + 0.5(2) + 0.8\epsilon_1 + \epsilon_2$. A tend√™ncia determin√≠stica $(2 + 0.5t)$ aumenta linearmente com o tempo. Se removermos a tend√™ncia, o que resta √© um processo estacion√°rio.

2.  **Processo com Raiz Unit√°ria:** A s√©rie √© modelada de forma que sua primeira diferen√ßa seja estacion√°ria:
    $$(1 - L)y_t = \delta + \psi(L)\epsilon_t$$ [^1]
    Aqui, $\Delta y_t = y_t - y_{t-1}$ √© estacion√°rio.

> üí° **Exemplo Num√©rico:**
>
> Seja $(1 - L)y_t = 0.1 + 0.6\epsilon_{t-1} + \epsilon_t$.  Expandindo, temos $y_t - y_{t-1} = 0.1 + 0.6\epsilon_{t-1} + \epsilon_t$, ou $y_t = y_{t-1} + 0.1 + 0.6\epsilon_{t-1} + \epsilon_t$. Se $y_0 = 5$,  e $\epsilon_1 = 1$, e $\epsilon_2 = -0.5$, ent√£o $y_1 = 5 + 0.1 + 0.6(0) + 1 = 6.1$ e $y_2 = 6.1 + 0.1 + 0.6(1) - 0.5 = 6.3$. Observe que o choque inicial ($\epsilon_1$) afeta permanentemente o n√≠vel de y.

A fun√ß√£o de autocovari√¢ncia, definida como $cov(y_t, y_{t-k})$, descreve como os valores de uma s√©rie temporal em diferentes pontos no tempo est√£o relacionados.  Para um processo estacion√°rio, essa fun√ß√£o decai com o aumento de *k*. Em processos n√£o estacion√°rios, como os com raiz unit√°ria, essa fun√ß√£o n√£o apresenta o mesmo comportamento, indicando depend√™ncia de longo prazo.

A import√¢ncia da raiz unit√°ria reside no fato de que ela introduz uma persist√™ncia nos choques. Um choque $\epsilon_t$ em um processo com raiz unit√°ria afeta permanentemente o n√≠vel da s√©rie, ao contr√°rio de processos estacion√°rios, onde o efeito do choque diminui ao longo do tempo [^2].

**Autocovari√¢ncia em Processos com Raiz Unit√°ria**

Para um processo com raiz unit√°ria, a autocovari√¢ncia da s√©rie original n√£o √© estacion√°ria, isto √©, $cov(y_t, y_{t-k})$ n√£o depende apenas da diferen√ßa *k*. Contudo, a autocovari√¢ncia da primeira diferen√ßa ($\Delta y_t$) pode ser estacion√°ria.
Considere o processo com raiz unit√°ria dado por [^1]:
$$(1 - L)y_t = \delta + \psi(L)\epsilon_t$$
Definindo $x_t = (1 - L)y_t$, temos $x_t = \delta + \psi(L)\epsilon_t$, onde $x_t$ √© uma s√©rie estacion√°ria. A fun√ß√£o geradora de autocovari√¢ncia de $(1-L)y_t$ √© dada por [^1]:

$$g_{\Delta y}(z) = \psi(z)\sigma^2\psi(z^{-1})$$
Quando avaliamos esta fun√ß√£o em $z=1$, obtemos:

$$g_{\Delta y}(1) = [\psi(1)]^2\sigma^2$$
Essa express√£o √© fundamental. Note que $\psi(1)$ representa a soma dos coeficientes do polin√¥mio $\psi(L)$. Se $\psi(1) \neq 0$, ent√£o $g_{\Delta y}(1)$ √© n√£o nulo. Isso indica que o espectro de pot√™ncia de $\Delta y_t$ em frequ√™ncia zero, dado por $S_{\Delta y}(0) = \frac{1}{2\pi}g_{\Delta y}(1)$, √© positivo.

> üí° **Exemplo Num√©rico:**
>
> Considere $(1-L)y_t = 0.2 + (1 + 0.5L)\epsilon_t$. Ent√£o $\psi(L) = 1 + 0.5L$, e $\psi(1) = 1 + 0.5 = 1.5$. Se $\sigma^2 = 1$, ent√£o $g_{\Delta y}(1) = (1.5)^2 \times 1 = 2.25$. Isso significa que o espectro de pot√™ncia de $\Delta y_t$ na frequ√™ncia zero √© $S_{\Delta y}(0) = \frac{1}{2\pi}(2.25) \approx 0.358$, um valor positivo.

**Lema 1**
Seja $\psi(L) = 1 + \psi_1 L + \psi_2 L^2 + \ldots$ um polin√¥mio com $\sum_{j=0}^\infty |\psi_j| < \infty$. Ent√£o $\psi(1) = \sum_{j=0}^\infty \psi_j$ √© bem definido e convergente.
*Prova:*
I. A condi√ß√£o dada √© que $\sum_{j=0}^\infty |\psi_j| < \infty$. Isso significa que a s√©rie dos valores absolutos dos coeficientes $\psi_j$ converge.
II.  Pelo crit√©rio de converg√™ncia absoluta, se uma s√©rie de valores absolutos converge, ent√£o a s√©rie original tamb√©m converge. Ou seja, se $\sum_{j=0}^\infty |\psi_j|$ converge, ent√£o $\sum_{j=0}^\infty \psi_j$ converge.
III. Portanto, $\psi(1) = \sum_{j=0}^\infty \psi_j$ √© bem definido e convergente.‚ñ†

Al√©m disso, podemos explicitar a rela√ß√£o entre a fun√ß√£o geradora de autocovari√¢ncia da s√©rie original $y_t$ e a fun√ß√£o geradora de autocovari√¢ncia da sua primeira diferen√ßa $\Delta y_t$:

**Lema 2**
Seja $y_t$ uma s√©rie temporal tal que $(1-L)y_t = x_t$, onde $x_t$ √© uma s√©rie estacion√°ria com fun√ß√£o geradora de autocovari√¢ncia $g_x(z)$. Ent√£o a fun√ß√£o geradora de autocovari√¢ncia da s√©rie original $y_t$, denotada por $g_y(z)$, est√° relacionada com $g_x(z)$ por:
$$g_x(z) = (1-z)(1-z^{-1})g_y(z)$$
*Prova:*
I. Seja $g_y(z) = \sum_{k=-\infty}^{\infty} \gamma_k z^k$, onde $\gamma_k = cov(y_t, y_{t-k})$. Ent√£o, a fun√ß√£o geradora de autocovari√¢ncia de $\Delta y_t = y_t - y_{t-1}$ √© dada por:
$$g_{\Delta y}(z) = \sum_{k=-\infty}^{\infty} cov(\Delta y_t, \Delta y_{t-k}) z^k $$
II.  Expandindo a express√£o da autocovari√¢ncia:
$$g_{\Delta y}(z) = \sum_{k=-\infty}^{\infty} cov(y_t - y_{t-1}, y_{t-k} - y_{t-k-1}) z^k$$
III. Usando a propriedade da linearidade da covari√¢ncia:
$$g_{\Delta y}(z) = \sum_{k=-\infty}^{\infty} [cov(y_t, y_{t-k}) - cov(y_t, y_{t-k-1}) - cov(y_{t-1}, y_{t-k}) + cov(y_{t-1}, y_{t-k-1})]z^k$$
IV. Substituindo $\gamma_k = cov(y_t, y_{t-k})$ na express√£o acima:
$$g_{\Delta y}(z) = \sum_{k=-\infty}^{\infty}[\gamma_k - \gamma_{k+1} - \gamma_{k-1} + \gamma_k] z^k$$
V. Reorganizando os termos:
$$g_{\Delta y}(z) = \sum_{k=-\infty}^{\infty}\gamma_k(1-z^{-1}-z+1)z^k$$
VI. Fatorando a express√£o dentro dos par√™nteses:
$$g_{\Delta y}(z) = \sum_{k=-\infty}^{\infty}\gamma_k(2-z-z^{-1})z^k = \sum_{k=-\infty}^{\infty}\gamma_k(1-z)(1-z^{-1})z^k$$
VII. Extraindo o termo comum $(1-z)(1-z^{-1})$:
$$g_{\Delta y}(z) = (1-z)(1-z^{-1}) \sum_{k=-\infty}^{\infty} \gamma_k z^k$$
VIII. Substituindo $g_y(z) = \sum_{k=-\infty}^{\infty} \gamma_k z^k$:
$$g_{\Delta y}(z) = (1-z)(1-z^{-1})g_y(z)$$
IX. Como $x_t = \Delta y_t$, segue que $g_x(z) = g_{\Delta y}(z)$. Portanto:
$$g_x(z) = (1-z)(1-z^{-1})g_y(z)$$‚ñ†

Este resultado nos permite analisar a fun√ß√£o geradora de autocovari√¢ncia de $y_t$ a partir da fun√ß√£o geradora de autocovari√¢ncia de sua diferen√ßa $\Delta y_t$.

Isso contrasta com um processo *trend-stationary* [^1]:
$$ y_t = \alpha + \delta t + \psi(L)\epsilon_t $$
onde a autocovari√¢ncia de $(1-L)y_t$ √© dada por [^1]:

$$g_{\Delta y}(z) = (1-z)\psi(z)\sigma^2\psi(z^{-1})(1-z^{-1})$$
e avaliando em $z=1$:
$$g_{\Delta y}(1) = 0$$
O espectro em frequ√™ncia zero √© $S_{\Delta y}(0)=0$.

> üí° **Exemplo Num√©rico:**
>
> Considere o processo trend-stationary $y_t = 1 + 0.2t + (1 + 0.7L)\epsilon_t$, onde $\alpha = 1$, $\delta = 0.2$, e $\psi(L) = 1 + 0.7L$. A primeira diferen√ßa √© $\Delta y_t = 0.2 + (1-L)(1 + 0.7L)\epsilon_t$.  Aqui, $\psi(z) = 1 + 0.7z$, e assim, $(1-z)\psi(z) = (1-z)(1+0.7z) = 1 - 0.3z -0.7z^2$. Avaliando em $z=1$, temos $1 - 0.3 - 0.7 = 0$. Portanto, $g_{\Delta y}(1) = 0$ e  $S_{\Delta y}(0) = 0$. Isso ilustra que para processos trend-stationary, a persist√™ncia dos choques desaparece ap√≥s a diferencia√ß√£o.

**Implica√ß√µes da Autocovari√¢ncia e Persist√™ncia**

A diferen√ßa entre $g_{\Delta y}(1) \neq 0$ para processos com raiz unit√°ria e $g_{\Delta y}(1) = 0$ para processos *trend-stationary* √© crucial. A fun√ß√£o de autocovari√¢ncia avaliada em $z=1$ est√° diretamente ligada √† persist√™ncia dos choques na s√©rie temporal. Em processos com raiz unit√°ria, a presen√ßa de $\psi(1) \neq 0$ significa que choques t√™m um efeito permanente no n√≠vel da s√©rie, pois a autocovari√¢ncia de $\Delta y_t$ n√£o decai para zero em frequ√™ncias baixas. Em outras palavras, a mem√≥ria da s√©rie n√£o se dissipa, o que √© evidenciado pela n√£o nulidade da fun√ß√£o geradora de autocovari√¢ncia em $z=1$.

Em contraste, nos processos *trend-stationary*, o espectro de $\Delta y_t$ em frequ√™ncia zero ser nulo implica que os choques s√£o transit√≥rios e n√£o afetam o n√≠vel da s√©rie a longo prazo. Este fato √© uma distin√ß√£o chave e tem implica√ß√µes diretas em como os choques se propagam na s√©rie e na constru√ß√£o de previs√µes [^2].

**Teorema 1**
Seja $y_t$ um processo com raiz unit√°ria dado por $(1-L)y_t = \delta + \psi(L)\epsilon_t$, onde $\psi(L)$ √© um polin√¥mio com $\sum_{j=0}^\infty |\psi_j| < \infty$ e $\psi(1) \neq 0$. Ent√£o a vari√¢ncia de $y_t$ tende para infinito quando $t \to \infty$.
*Prova:*
I. Sabemos que $g_{\Delta y}(1) = [\psi(1)]^2\sigma^2$. Pelo Lema 2, a fun√ß√£o geradora de autocovari√¢ncia de $y_t$ satisfaz $g_{\Delta y}(z) = (1-z)(1-z^{-1})g_y(z)$.
II. Assim, podemos expressar a fun√ß√£o geradora de autocovari√¢ncia de $y_t$ em termos de $g_{\Delta y}(z)$:
$$g_y(z) = \frac{g_{\Delta y}(z)}{(1-z)(1-z^{-1})}$$
III. Como $g_{\Delta y}(1) \neq 0$ e $(1-z)(1-z^{-1}) = (1-z)(1-1/z) = - (1-z)^2/z$ tem um zero de ordem 2 em $z=1$, podemos concluir que a fun√ß√£o geradora de autocovari√¢ncia $g_y(z)$ apresenta um polo de ordem 2 em $z=1$.
IV. A presen√ßa de um polo de ordem 2 em $z=1$ implica que a expans√£o em s√©rie de Laurent da fun√ß√£o $g_y(z)$, dada por $\gamma_0 = \sum_{k=-\infty}^{\infty} \gamma_k z^k$, onde $\gamma_0 = cov(y_t, y_t)$,  diverge quando avaliada em $z=1$ e quando $t \to \infty$.
V. Isso implica que a vari√¢ncia de $y_t$, dada por $\gamma_0 = cov(y_t, y_t)$, tende para infinito quando $t \to \infty$. ‚ñ†

> üí° **Exemplo Num√©rico:**
>
> Considere novamente o processo com raiz unit√°ria $(1-L)y_t = 0.2 + (1+0.5L)\epsilon_t$. Sabemos que $g_{\Delta y}(1) = 2.25$ (calculado anteriormente).  A vari√¢ncia de $y_t$, $\gamma_0$,  √© proporcional a $g_y(1)$.  Como $g_y(z) = \frac{g_{\Delta y}(z)}{(1-z)(1-z^{-1})}$, e o denominador tende a zero em $z=1$, enquanto o numerador √© $2.25$,  ent√£o  $g_y(1) = \infty$, indicando que a vari√¢ncia de $y_t$ tende a infinito conforme $t \to \infty$. Isso demonstra a n√£o estacionariedade e a persist√™ncia de choques no processo com raiz unit√°ria.

### Conclus√£o
Neste cap√≠tulo, examinamos a import√¢ncia da autocovari√¢ncia para a an√°lise de modelos de s√©ries temporais n√£o estacion√°rias, particularmente aqueles com raiz unit√°ria. A diferen√ßa fundamental reside no comportamento da fun√ß√£o geradora de autocovari√¢ncia quando avaliada em $z=1$. Em processos com raiz unit√°ria, essa avalia√ß√£o resulta em um valor n√£o nulo, refletindo a persist√™ncia dos choques e a n√£o estacionariedade da s√©rie original. Esta caracter√≠stica √© fundamental para modelar e prever s√©ries temporais com tend√™ncias e mem√≥ria de longo prazo, contrastando com processos *trend-stationary*, nos quais os efeitos dos choques desaparecem com o tempo. Essa an√°lise √© essencial para as discuss√µes nos pr√≥ximos cap√≠tulos, incluindo testes de raiz unit√°ria e suas implica√ß√µes estat√≠sticas [^2].
### Refer√™ncias
[^1]: 15.1. Introduction
[^2]: 15.3. Comparison of Trend-Stationary and Unit Root Processes
<!-- END -->
