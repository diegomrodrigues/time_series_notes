## S√©ries Temporais como Elementos de um Espa√ßo Vetorial

### Introdu√ß√£o

Em continuidade √† nossa discuss√£o sobre modelos de s√©ries temporais n√£o estacion√°rias e a import√¢ncia da autocovari√¢ncia para analisar a persist√™ncia de choques [^1], este cap√≠tulo introduz uma perspectiva abstrata e poderosa: tratar s√©ries temporais como elementos de um espa√ßo vetorial. Essa abordagem nos permite aplicar ferramentas da an√°lise funcional, como normas, produtos internos e operadores lineares, para descrever e manipular as s√©ries, oferecendo novas perspectivas sobre suas propriedades e comportamentos. Como vimos anteriormente, a an√°lise de s√©ries temporais n√£o estacion√°rias requer uma aten√ß√£o especial √†s suas propriedades de autocovari√¢ncia e √† persist√™ncia dos choques [^1]. Ao empregar a estrutura de espa√ßos vetoriais, podemos formalizar e generalizar essas no√ß√µes, abrindo caminho para uma compreens√£o mais profunda e sofisticada das s√©ries temporais.

### Conceitos Fundamentais

Para iniciarmos, recordemos que uma s√©rie temporal $\{y_t\}_{t=-\infty}^\infty$ pode ser vista como uma sequ√™ncia de n√∫meros reais ou complexos, onde $t$ representa o √≠ndice de tempo. Em ess√™ncia, essa sequ√™ncia pode ser entendida como um vetor infinito. Essa vis√£o abre portas para tratar s√©ries temporais como elementos de um espa√ßo vetorial, o que nos permite aplicar os conceitos e ferramentas da an√°lise funcional.

Um **espa√ßo vetorial** √© um conjunto de objetos, chamados vetores, munido de duas opera√ß√µes: adi√ß√£o de vetores e multiplica√ß√£o por um escalar, que satisfazem um conjunto de axiomas. A ideia √© que, com essas opera√ß√µes e axiomas, podemos manipular vetores de forma consistente.

Podemos definir o **espa√ßo vetorial** $\mathcal{S}$ de s√©ries temporais como o conjunto de todas as sequ√™ncias $\{y_t\}_{t=-\infty}^\infty$ de n√∫meros reais ou complexos. Definimos a adi√ß√£o de duas s√©ries temporais $x = \{x_t\}$ e $y = \{y_t\}$ como a s√©rie $x + y = \{x_t + y_t\}$ e a multiplica√ß√£o por um escalar $c$ como $cx = \{cx_t\}$. Com essas opera√ß√µes, $\mathcal{S}$ se torna um espa√ßo vetorial.

#### Norma e Produto Interno

Em um espa√ßo vetorial, podemos introduzir a no√ß√£o de **norma**, que quantifica o "comprimento" ou "magnitude" de um vetor.  Uma norma √© uma fun√ß√£o $||\cdot||: \mathcal{S} \to \mathbb{R}$ que satisfaz as seguintes propriedades:

1.  $\|x\| \geq 0$ e $\|x\| = 0$ se e somente se $x = 0$ (n√£o negatividade e defini√ß√£o positiva).
2.  $\|cx\| = |c|\|x\|$ para todo escalar $c$ (homogeneidade).
3.  $\|x + y\| \leq \|x\| + \|y\|$ (desigualdade triangular).

Uma poss√≠vel norma para s√©ries temporais √© a norma $\ell^2$, que, para uma s√©rie $x = \{x_t\}$, √© dada por:

$$\|x\|_2 = \sqrt{\sum_{t=-\infty}^{\infty} |x_t|^2}$$

No entanto, essa norma s√≥ √© finita para s√©ries temporais que convergem para zero suficientemente r√°pido, o que nem sempre √© o caso para s√©ries n√£o estacion√°rias.

> üí° **Exemplo Num√©rico:**
>
> Considere a s√©rie temporal $x = \{1, 0.5, 0.25, 0.125, \ldots\}$, onde $x_t = (0.5)^{t-1}$ para $t \geq 1$ e $x_t = 0$ para $t < 1$. Calculando a norma $\ell^2$ para os primeiros 4 termos:
>
>   $\|x\|_2 \approx \sqrt{1^2 + 0.5^2 + 0.25^2 + 0.125^2} = \sqrt{1 + 0.25 + 0.0625 + 0.015625} \approx \sqrt{1.328} \approx 1.152$.
>
>  A norma $\ell^2$ dessa s√©rie converge. Agora, vamos considerar a s√©rie $y = \{1, 1, 1, 1, \ldots\}$. Se tentarmos calcular a norma $\ell^2$ para os primeiros 4 termos, obteremos:
>
>  $\|y\|_2 \approx \sqrt{1^2 + 1^2 + 1^2 + 1^2} = \sqrt{4} = 2$.
>
>  No entanto, para uma s√©rie infinita de "1s", $\|y\|_2 = \sqrt{\sum_{t=1}^{\infty} 1^2} = \sqrt{\infty} = \infty$, ou seja, ela diverge, ilustrando que a norma $\ell^2$ n√£o √© adequada para todas as s√©ries temporais, especialmente as n√£o estacion√°rias.

Para complementar a no√ß√£o de norma, podemos definir um **produto interno**, que √© uma fun√ß√£o $\langle \cdot, \cdot \rangle : \mathcal{S} \times \mathcal{S} \to \mathbb{C}$ que associa a cada par de vetores $x$ e $y$ um escalar e satisfaz as seguintes propriedades:

1.  $\langle x, y \rangle = \overline{\langle y, x \rangle}$ (simetria hermitiana)
2.  $\langle x + z, y \rangle = \langle x, y \rangle + \langle z, y \rangle$ (linearidade na primeira componente).
3.  $\langle cx, y \rangle = c\langle x, y \rangle$ para todo escalar $c$ (homogeneidade na primeira componente).
4.  $\langle x, x \rangle \geq 0$ e $\langle x, x \rangle = 0$ se e somente se $x = 0$ (n√£o negatividade e defini√ß√£o positiva).

Um produto interno comum para s√©ries temporais √© definido como:

$$\langle x, y \rangle = \sum_{t=-\infty}^{\infty} x_t \overline{y_t}$$

Essa defini√ß√£o, similar √† norma $\ell^2$, tamb√©m pode ter problemas de converg√™ncia. No contexto de s√©ries temporais, o produto interno frequentemente √© definido em rela√ß√£o a um operador de esperan√ßa:

$$ \langle x, y \rangle = E[x_t \overline{y_t}] = \sum_{t=-\infty}^\infty x_t \overline{y_t} $$

Essa defini√ß√£o de produto interno est√° intimamente ligada √† autocovari√¢ncia, um conceito essencial na an√°lise de s√©ries temporais, conforme explorado anteriormente [^1].

> üí° **Exemplo Num√©rico:**
>
> Considere duas s√©ries temporais $x = \{1, 2, 3, 0, 0, \ldots\}$ e $y = \{0, 1, 2, 3, 0, 0, \ldots\}$. O produto interno de $x$ e $y$ √©:
> $$\langle x, y \rangle = 1\cdot 0 + 2\cdot 1 + 3\cdot 2 + 0\cdot 3 + 0 \cdot 0 + \cdots = 8$$
> Isso nos d√° uma medida de "semelhan√ßa" entre as duas s√©ries no espa√ßo vetorial que definimos.
>
>  Agora, vamos considerar $a = \{1, 2, 1, 0, 0, \ldots\}$ e $b = \{2, 1, 2, 0, 0, \ldots\}$.  Ent√£o, $\langle a, b \rangle = 1\cdot 2 + 2\cdot 1 + 1\cdot 2 + 0 \cdot 0 + \ldots = 2 + 2 + 2 = 6$.
>
> Se considerarmos $c = \{1, 0, 0, \ldots\}$, temos $\langle a, c \rangle = 1\cdot 1 + 2\cdot 0 + 1\cdot 0 + 0 \cdot 0 + \ldots = 1$. Este exemplo demonstra como o produto interno quantifica a similaridade e alinhamento entre diferentes s√©ries temporais.

#### Operadores Lineares

Al√©m dos conceitos de norma e produto interno, operadores lineares desempenham um papel fundamental na an√°lise de s√©ries temporais em espa√ßos vetoriais. Um operador linear √© uma fun√ß√£o $T: \mathcal{S} \to \mathcal{S}$ que preserva as opera√ß√µes de adi√ß√£o e multiplica√ß√£o por escalar:

1.  $T(x + y) = T(x) + T(y)$ para todos $x, y \in \mathcal{S}$
2.  $T(cx) = cT(x)$ para todo escalar $c$ e todo $x \in \mathcal{S}$

Um exemplo de operador linear √© o **operador de deslocamento** (lag operator), denotado por $L$, que age sobre uma s√©rie temporal $x = \{x_t\}$ da seguinte forma:

$$Lx = \{x_{t-1}\}$$

O operador de diferen√ßa $\Delta = (1-L)$ √© outro exemplo de operador linear, onde $\Delta x = \{x_t - x_{t-1}\}$. A aplica√ß√£o desses operadores nos permite estudar transforma√ß√µes e propriedades das s√©ries temporais dentro da estrutura de espa√ßos vetoriais.

O operador $\psi(L)$ que vimos na representa√ß√£o dos modelos de s√©ries temporais [^1], √© tamb√©m um operador linear:
$$ \psi(L) \epsilon_t = \epsilon_t + \psi_1\epsilon_{t-1} + \psi_2\epsilon_{t-2} + \ldots $$

Operadores lineares podem ser compostos, resultando em novos operadores. A composi√ß√£o de operadores $T$ e $S$ √© definida como $T(S(x))$. A identidade $I$, definida como $I(x) = x$ para todo $x$, desempenha o papel de elemento neutro na composi√ß√£o de operadores.

> üí° **Exemplo Num√©rico:**
>
>  Seja $x = \{1, 2, 3, 4, \ldots\}$ e consideremos os operadores $L$ (deslocamento) e $\Delta = 1 - L$.  Ent√£o $Lx = \{0, 1, 2, 3, \ldots\}$ e $\Delta x = x - Lx = \{1, 1, 1, 1, \ldots\}$. Aplicando $\Delta$ a $Lx$, temos $\Delta Lx = \{1, 1, 1, \ldots\}$.  Aqui, o operador $\Delta L$ √© linear, pois preserva a adi√ß√£o e a multiplica√ß√£o por escalar.
>
>  Vamos considerar $x=\{1, 2, 4, 8, \ldots\}$, onde $x_t = 2^{t-1}$ para $t\geq 1$ e zero para $t<1$. Ent√£o, $Lx = \{0, 1, 2, 4, 8, \ldots\}$ e $\Delta x = \{1, 2-1, 4-2, 8-4, \ldots\} = \{1, 1, 2, 4, \ldots\}$. Observe que $\Delta x_t = x_t - x_{t-1}$, que √© uma s√©rie com diferen√ßas entre os termos originais. Se usarmos o operador $(1-0.5L)$ temos: $(1-0.5L)x = \{1, 2 - 0.5, 4 - 1, 8 - 2, \ldots\} = \{1, 1.5, 3, 6, \ldots\}$. Este exemplo demonstra que operadores lineares aplicados a s√©ries temporais transformam a s√©rie de maneira previs√≠vel e linear.

##### Representa√ß√£o de S√©ries Temporais

No contexto de espa√ßos vetoriais, as s√©ries temporais podem ser representadas de formas diversas, como combina√ß√µes lineares de elementos base. Uma base √© um conjunto de vetores linearmente independentes que podem gerar qualquer outro vetor no espa√ßo. No espa√ßo de s√©ries temporais, uma base pode ser formada por sequ√™ncias de impulsos unit√°rios deslocados no tempo, o que leva √† representa√ß√£o MA(‚àû):

$$ y_t = \sum_{j=0}^\infty \psi_j \epsilon_{t-j} $$

Essa representa√ß√£o, que √© central em muitos modelos de s√©ries temporais, expressa a s√©rie temporal $y_t$ como uma combina√ß√£o linear de ru√≠dos brancos passados, com pesos determinados pelos coeficientes $\psi_j$.

A no√ß√£o de espa√ßos vetoriais tamb√©m nos permite introduzir a ideia de **espa√ßos de Hilbert**, que s√£o espa√ßos vetoriais completos com um produto interno, onde podemos utilizar ferramentas da an√°lise funcional com mais rigor. Essa no√ß√£o est√° intrinsecamente ligada ao estudo da autocovari√¢ncia e do espectro das s√©ries temporais.

**Defini√ß√£o 1** Um espa√ßo de Hilbert $\mathcal{H}$ √© um espa√ßo vetorial com produto interno $\langle \cdot, \cdot \rangle$ que √© completo com respeito √† norma induzida pelo produto interno $\|x\| = \sqrt{\langle x, x \rangle}$. Em outras palavras, toda sequ√™ncia de Cauchy em $\mathcal{H}$ converge para um elemento de $\mathcal{H}$.

**Observa√ß√£o:** Nem todo espa√ßo vetorial com um produto interno √© um espa√ßo de Hilbert. A propriedade de completude √© crucial para garantir a converg√™ncia de certas opera√ß√µes e para a aplica√ß√£o de muitos resultados da an√°lise funcional. O espa√ßo de s√©ries temporais com a norma $\ell^2$ e o produto interno associado n√£o √© completo, o que leva √† necessidade de considerar completamentos para o estudo de s√©ries temporais.

### Autocovari√¢ncia e Persist√™ncia sob a Perspectiva de Espa√ßos Vetoriais

A autocovari√¢ncia de uma s√©rie temporal, como discutido anteriormente [^1], pode ser vista como uma medida de correla√ß√£o entre a s√©rie e sua vers√£o deslocada no tempo. Em termos de espa√ßos vetoriais, isso se traduz na an√°lise de como a s√©rie se projeta sobre seus deslocamentos temporais.

Para um processo estacion√°rio, a autocovari√¢ncia decai com o aumento do atraso no tempo, refletindo a perda de mem√≥ria do processo. Em contraste, processos com raiz unit√°ria, conforme discutido anteriormente [^1], exibem uma persist√™ncia de choques, indicada pelo fato da fun√ß√£o de autocovari√¢ncia avaliada em z=1 ser diferente de zero. Podemos revisitar esses conceitos na perspectiva de espa√ßos vetoriais.

A fun√ß√£o geradora de autocovari√¢ncia de um processo estacion√°rio $x_t$ √© dada por:
$$g_x(z) = \sum_{k=-\infty}^{\infty} \gamma_k z^k$$
onde $\gamma_k = cov(x_t, x_{t-k})$.

Em um processo com raiz unit√°ria, a n√£o estacionariedade da s√©rie $y_t$ implica que sua fun√ß√£o de autocovari√¢ncia n√£o se comporta da mesma forma que para s√©ries estacion√°rias. No entanto, a primeira diferen√ßa $\Delta y_t$ √© estacion√°ria e sua fun√ß√£o geradora de autocovari√¢ncia √© dada por [^1]:
$$g_{\Delta y}(z) = \psi(z)\sigma^2\psi(z^{-1})$$
Quando avaliamos em z=1, obtemos:
$$g_{\Delta y}(1) = [\psi(1)]^2\sigma^2$$
Se $\psi(1) \neq 0$, o espectro de pot√™ncia de $\Delta y_t$ na frequ√™ncia zero √© positivo, o que indica que os choques s√£o persistentes, ou seja, impactam o n√≠vel da s√©rie no longo prazo. Em termos de produto interno, podemos ver que o produto interno entre $\Delta y_t$ e $\Delta y_{t-k}$ n√£o decai rapidamente para zero conforme $k$ aumenta.

Em processos trend-stationary, por outro lado, o espectro de $\Delta y_t$ em frequ√™ncia zero √© nulo: $g_{\Delta y}(1) = 0$, o que indica que os choques s√£o transit√≥rios.

> üí° **Exemplo Num√©rico:**
>
> Vamos considerar um processo com raiz unit√°ria $\Delta y_t = (1 + 0.8L) \epsilon_t$, onde $y_t$ √© um processo com raiz unit√°ria. Vimos anteriormente que nesse caso,  $\psi(1) = 1 + 0.8 = 1.8$.  Se $\sigma^2 = 1$, temos $g_{\Delta y}(1) = 1.8^2 = 3.24$. Isso indica a persist√™ncia dos choques na s√©rie. A norma de $y_t$ no espa√ßo vetorial tende a infinito conforme o tempo avan√ßa, refletindo a n√£o estacionariedade da s√©rie.
>
> Agora, vamos simular essa s√©rie com $\epsilon_t$ sendo um ru√≠do branco com vari√¢ncia 1. Podemos simular $\Delta y_t$ e calcular a autocovari√¢ncia para lags maiores.
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
>
> np.random.seed(42)
>
> def simulate_unit_root_process(T, psi_1, sigma):
>     epsilon = np.random.normal(0, sigma, T)
>     delta_y = np.zeros(T)
>     for t in range(1, T):
>         delta_y[t] = epsilon[t] + psi_1 * epsilon[t-1]
>     return delta_y
>
> T = 200
> psi_1 = 0.8
> sigma = 1
> delta_y = simulate_unit_root_process(T, psi_1, sigma)
>
> def autocovariance(x, k):
>     n = len(x)
>     if k >= n:
>       return 0
>     x_mean = np.mean(x)
>     cov = np.mean((x[:n-k] - x_mean) * (x[k:] - x_mean))
>     return cov
>
> lags = range(0, 20)
> autocovs = [autocovariance(delta_y, lag) for lag in lags]
>
> plt.figure(figsize=(10, 6))
> plt.stem(lags, autocovs, use_line_collection=True)
> plt.title("Autocovari√¢ncia de $\Delta y_t$")
> plt.xlabel("Lag (k)")
> plt.ylabel("Autocovari√¢ncia")
> plt.grid(True)
> plt.show()
>
> ```
>
> Ao gerar esse gr√°fico, voc√™ observar√° que a autocovari√¢ncia da primeira diferen√ßa decai, mas de forma mais lenta do que para um processo estacion√°rio, refletindo a persist√™ncia dos choques. O valor de autocovari√¢ncia no lag 0 representa a vari√¢ncia da s√©rie.

**Proposi√ß√£o 1** _A persist√™ncia de choques em s√©ries temporais n√£o estacion√°rias pode ser formalizada em espa√ßos de Hilbert atrav√©s da an√°lise da converg√™ncia das proje√ß√µes da s√©rie sobre seus deslocamentos temporais._

*Proof Outline:* Em espa√ßos de Hilbert, a proje√ß√£o de um vetor $x$ sobre um subespa√ßo $Y$ √© o vetor em $Y$ que minimiza a dist√¢ncia a $x$. Em s√©ries temporais, podemos projetar a s√©rie $y_t$ sobre o espa√ßo gerado pelos seus valores passados. Se os choques s√£o persistentes, a proje√ß√£o de $y_t$ sobre o espa√ßo de seus valores passados n√£o converge rapidamente, o que se manifesta na autocovari√¢ncia n√£o decaindo rapidamente para zero.

**Lema 1** *Se $\{x_t\}$ √© uma s√©rie temporal estacion√°ria com fun√ß√£o de autocovari√¢ncia $\gamma_k$, ent√£o o produto interno entre $x_t$ e $x_{t-k}$ √© dado por $\langle x_t, x_{t-k} \rangle = \gamma_k$.*

*Proof:*
I. Pela defini√ß√£o do produto interno para s√©ries temporais, temos:
$$\langle x_t, x_{t-k} \rangle = E[x_t \overline{x_{t-k}}]$$
II. Sabemos que, para uma s√©rie temporal estacion√°ria, a fun√ß√£o de autocovari√¢ncia √© definida como:
$$ \gamma_k =  cov(x_t, x_{t-k}) = E[(x_t - E[x_t])(\overline{x_{t-k}} - E[\overline{x_{t-k}}])]$$
III. Se $x_t$ √© uma s√©rie com m√©dia zero, ent√£o $E[x_t] = 0$ e $E[\overline{x_{t-k}}] = 0$. Assim,
$$ \gamma_k = E[x_t \overline{x_{t-k}}]$$
IV. Portanto, o produto interno $\langle x_t, x_{t-k} \rangle$ √© igual √† fun√ß√£o de autocovari√¢ncia $\gamma_k$:
$$\langle x_t, x_{t-k} \rangle = E[x_t \overline{x_{t-k}}] = \gamma_k$$ ‚ñ†

**Corol√°rio 1** _Em um processo estacion√°rio, o decaimento da fun√ß√£o de autocovari√¢ncia $\gamma_k$ com o aumento de $k$ est√° diretamente relacionado ao decaimento do produto interno $\langle x_t, x_{t-k} \rangle$ no espa√ßo vetorial de s√©ries temporais._

*Proof:*
I.  Pelo Lema 1, sabemos que $\langle x_t, x_{t-k} \rangle = \gamma_k$ para uma s√©rie temporal estacion√°ria.
II. Se a fun√ß√£o de autocovari√¢ncia $\gamma_k$ decai √† medida que $k$ aumenta, significa que a correla√ß√£o entre $x_t$ e seus valores defasados no tempo diminui.
III. Como o produto interno $\langle x_t, x_{t-k} \rangle$ √© igual a $\gamma_k$, seu decaimento com o aumento de $k$ espelha diretamente o decaimento da autocovari√¢ncia.
IV. Portanto, o decaimento da autocovari√¢ncia est√° diretamente relacionado ao decaimento do produto interno no espa√ßo vetorial de s√©ries temporais. ‚ñ†

### Conclus√£o

Neste cap√≠tulo, exploramos a abordagem de tratar s√©ries temporais como elementos de espa√ßos vetoriais, permitindo-nos aplicar ferramentas poderosas da an√°lise funcional. Introduzimos conceitos como norma, produto interno e operadores lineares, mostrando como eles podem ser utilizados para descrever e manipular s√©ries temporais, de forma similar a como manipulamos vetores em espa√ßos euclidianos. Vimos como essa perspectiva nos permite revisitar o conceito de autocovari√¢ncia e persist√™ncia, oferecendo uma compreens√£o mais profunda e abstrata das propriedades desses processos, complementando a an√°lise realizada em cap√≠tulos anteriores [^1]. Essa abordagem matem√°tica rigorosa fornece a base para os resultados estat√≠sticos e econom√©tricos que ser√£o explorados em cap√≠tulos subsequentes [^2], onde a an√°lise de s√©ries temporais n√£o estacion√°rias ser√° aprofundada.

### Refer√™ncias

[^1]: 15.1. Introduction
[^2]: 15.3. Comparison of Trend-Stationary and Unit Root Processes
<!-- END -->
