## Operadores Lineares em S√©ries Temporais: M√©dia M√≥vel e Auto-Regressivos

### Introdu√ß√£o
Em continuidade √† nossa explora√ß√£o das s√©ries temporais sob a perspectiva de espa√ßos vetoriais e an√°lise espectral [^1, ^2, ^3, ^4, ^5], este cap√≠tulo se dedica ao estudo detalhado dos **operadores lineares**, em particular, os operadores de m√©dia m√≥vel (MA) e auto-regressivos (AR). Esses operadores s√£o transforma√ß√µes lineares que atuam sobre s√©ries temporais, e suas propriedades (como invertibilidade e estacionariedade) s√£o cruciais na teoria de s√©ries temporais. Ao longo deste cap√≠tulo, vamos formalizar esses operadores, explorar suas caracter√≠sticas matem√°ticas e analisar seu impacto sobre as s√©ries temporais. Este estudo complementa nossa discuss√£o pr√©via sobre a decomposi√ß√£o da vari√¢ncia atrav√©s da an√°lise espectral, e sobre a distin√ß√£o entre processos estacion√°rios e n√£o estacion√°rios.

### Operadores Lineares: Formaliza√ß√£o
Conforme introduzido em cap√≠tulos anteriores [^2], um operador linear $T$ age sobre uma s√©rie temporal $x = \{x_t\}$ e produz outra s√©rie temporal $y = \{y_t\}$, tal que:

1.  $T(x+z) = T(x) + T(z)$, para quaisquer s√©ries temporais $x$ e $z$
2.  $T(cx) = cT(x)$, para qualquer escalar $c$ e s√©rie temporal $x$

Esses operadores preservam as opera√ß√µes de adi√ß√£o e multiplica√ß√£o por escalar, o que os torna trat√°veis matematicamente e aplic√°veis no contexto de espa√ßos vetoriais de s√©ries temporais.

O operador de deslocamento $L$, definido como $Lx = \{x_{t-1}\}$, e o operador de diferen√ßa $(1-L)$ s√£o exemplos de operadores lineares. Os operadores de m√©dia m√≥vel e auto-regressivos, que exploraremos em detalhe, tamb√©m s√£o operadores lineares.

#### Operador de M√©dia M√≥vel (MA)
O operador de m√©dia m√≥vel (MA) √© um operador linear que transforma uma sequ√™ncia de ru√≠do branco em uma s√©rie temporal por meio de uma combina√ß√£o linear de ru√≠dos brancos passados. Um operador MA de ordem *q*, denotado por MA(*q*), √© definido como:

$$ y_t = \epsilon_t + \theta_1 \epsilon_{t-1} + \theta_2 \epsilon_{t-2} + \cdots + \theta_q \epsilon_{t-q} $$

onde $\epsilon_t$ √© um ru√≠do branco com m√©dia zero e vari√¢ncia $\sigma^2$, e $\theta_1, \theta_2, \ldots, \theta_q$ s√£o os coeficientes do operador MA. Usando o operador de deslocamento $L$, a representa√ß√£o MA(*q*) pode ser expressa de forma compacta como:

$$ y_t = (1 + \theta_1 L + \theta_2 L^2 + \cdots + \theta_q L^q) \epsilon_t = \theta(L)\epsilon_t $$

onde $\theta(L) = 1 + \theta_1 L + \theta_2 L^2 + \cdots + \theta_q L^q$ √© o polin√¥mio do operador MA.

O operador MA √© um filtro que aplica uma m√©dia ponderada a ru√≠dos brancos passados para gerar a s√©rie temporal. Ele √© um operador linear, pois satisfaz as condi√ß√µes de linearidade mencionadas anteriormente. Se definirmos o operador $T_q$, tal que $T_q(\epsilon_t) = \sum_{j=0}^q \theta_j \epsilon_{t-j}$, ent√£o $T_q$ √© um operador linear.

> üí° **Exemplo Num√©rico:**
>
> Considere um processo MA(2) dado por $y_t = \epsilon_t + 0.5\epsilon_{t-1} - 0.3\epsilon_{t-2}$. Aqui, $\theta_1 = 0.5$ e $\theta_2 = -0.3$. Usando o operador de deslocamento, podemos reescrever como:
>
> $$y_t = (1 + 0.5L - 0.3L^2)\epsilon_t$$
>
> Se $\epsilon_t$ for uma sequ√™ncia de ru√≠do branco com vari√¢ncia 1, a vari√¢ncia de $y_t$ ser√° dada por $Var(y_t) = (1^2 + 0.5^2 + (-0.3)^2)\sigma^2 = (1 + 0.25 + 0.09)1 = 1.34$.
>
> O impacto desse operador sobre a s√©rie temporal $\epsilon_t$ √© transformar ru√≠do branco em uma s√©rie com autocorrela√ß√£o entre valores passados. Se $\epsilon_1 = 1, \epsilon_2 = -1, \epsilon_3 = 0, \epsilon_4 = 0.5$ e todos os outros $\epsilon_t$ forem zero, ent√£o $y_1 = \epsilon_1 = 1, y_2 = \epsilon_2 + 0.5\epsilon_1 = -1 + 0.5 = -0.5, y_3 = \epsilon_3 + 0.5\epsilon_2 - 0.3\epsilon_1 = 0 + 0.5(-1) -0.3(1) = -0.8, y_4 = \epsilon_4 + 0.5\epsilon_3 - 0.3\epsilon_2 = 0.5 + 0.5(0) -0.3(-1) = 0.8$.
>
> Vamos simular esse processo e plotar a s√©rie temporal resultante:
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
>
> def simulate_ma(T, theta, sigma):
>     epsilon = np.random.normal(0, sigma, T)
>     y = np.zeros(T)
>     q = len(theta)
>     for t in range(q, T):
>         y[t] = epsilon[t]
>         for j in range(q):
>             y[t] += theta[j] * epsilon[t - (j+1)]
>     return y
>
> np.random.seed(42)
> T = 100
> theta = [0.5, -0.3] # MA(2) coefficients
> sigma = 1
> y_ma = simulate_ma(T, theta, sigma)
>
> plt.figure(figsize=(8, 6))
> plt.plot(y_ma)
> plt.title("Simula√ß√£o de um processo MA(2)")
> plt.xlabel("Tempo (t)")
> plt.ylabel("y_t")
> plt.grid(True)
> plt.show()
> ```
>
> O gr√°fico resultante exibir√° uma s√©rie temporal com depend√™ncia serial entre os valores, demonstrando o efeito do operador de m√©dia m√≥vel.
>
> üí° **Exemplo Num√©rico:**
>
> Vamos calcular a fun√ß√£o de autocorrela√ß√£o (ACF) de um processo MA(1) para ilustrar o conceito de depend√™ncia serial. Suponha um processo MA(1) dado por $y_t = \epsilon_t + \theta \epsilon_{t-1}$, onde $\theta = 0.7$. A vari√¢ncia de $y_t$ √© $Var(y_t) = (1 + \theta^2)\sigma^2 = (1 + 0.7^2)\sigma^2 = 1.49\sigma^2$.
>
>  A autocovari√¢ncia no lag 1 √© $Cov(y_t, y_{t-1}) = E[(\epsilon_t + \theta \epsilon_{t-1})(\epsilon_{t-1} + \theta \epsilon_{t-2})] = E[\theta \epsilon_{t-1}^2] = \theta \sigma^2 = 0.7\sigma^2$.
>
>  A autocovari√¢ncia em lags maiores do que 1 s√£o zero. Portanto, a autocorrela√ß√£o no lag 1 √© $\rho_1 = \frac{Cov(y_t, y_{t-1})}{\sqrt{Var(y_t)Var(y_{t-1})}} = \frac{0.7\sigma^2}{1.49\sigma^2} = \frac{0.7}{1.49} \approx 0.47$. E $\rho_k=0$ para $k>1$.
>
> A ACF de um processo MA(1) tem um corte no lag 1, com $\rho_1 \neq 0$ e $\rho_k = 0$ para $k > 1$. Isso demonstra como o operador MA cria depend√™ncia serial nos dados.
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
> import statsmodels.api as sm
>
> def autocovariance(y, k):
>    n = len(y)
>    mean_y = np.mean(y)
>    if k >= n:
>      return 0
>    cov = np.sum([(y[t] - mean_y) * (y[t - k] - mean_y) for t in range(k, n)])
>    return cov/(n-k)
>
> def autocorrelation(y, k):
>     if k == 0:
>      return 1
>     return autocovariance(y, k) / autocovariance(y, 0)
>
>
> np.random.seed(42)
> T = 100
> theta = 0.7
> sigma = 1
> epsilon = np.random.normal(0, sigma, T)
> y_ma1 = np.zeros(T)
> for t in range(1, T):
>     y_ma1[t] = epsilon[t] + theta * epsilon[t-1]
>
> lags = 10
> acf_values = [autocorrelation(y_ma1,k) for k in range(lags+1)]
>
>
> plt.figure(figsize=(8, 6))
> plt.stem(range(lags+1), acf_values)
> plt.title("ACF de um processo MA(1) com theta=0.7")
> plt.xlabel("Lag (k)")
> plt.ylabel("Autocorrela√ß√£o")
> plt.grid(True)
> plt.show()
> ```

**Defini√ß√£o 1:**  O polin√¥mio $\theta(z) = 1 + \theta_1 z + \theta_2 z^2 + \ldots + \theta_q z^q$ √© dito invert√≠vel se todas as suas ra√≠zes estiverem fora do c√≠rculo unit√°rio no plano complexo, ou seja, se $|z_i| > 1$ para todas as ra√≠zes $z_i$ de $\theta(z)=0$.

Se $\theta(z)$ √© invert√≠vel, ent√£o existe um operador $\theta(L)^{-1}$, tal que $\theta(L) \theta(L)^{-1} = I$, onde $I$ √© o operador identidade. Ou seja, se $\theta(L)$ √© invert√≠vel, podemos expressar $\epsilon_t$ em fun√ß√£o de $y_t$.

**Invertibilidade:** A propriedade de invertibilidade de um operador MA est√° relacionada √† possibilidade de expressar o ru√≠do branco $\epsilon_t$ em termos dos valores passados da s√©rie temporal $y_t$. Um operador MA √© invert√≠vel se todas as ra√≠zes do polin√¥mio $\theta(z)$ estiverem fora do c√≠rculo unit√°rio. Em outras palavras, se as ra√≠zes de $\theta(z)=0$ s√£o dadas por $z_1, z_2, \dots, z_q$, ent√£o o operador ser√° invert√≠vel se $|z_i| > 1$ para $i=1,2,\dots,q$.

A condi√ß√£o de invertibilidade √© importante para a estima√ß√£o e previs√£o de s√©ries temporais, pois garante que o modelo √© bem comportado e que as previs√µes baseadas nos dados passados n√£o se tornam arbitrariamente grandes com o aumento do horizonte de previs√£o. A condi√ß√£o de invertibilidade tamb√©m garante que a representa√ß√£o MA tenha uma representa√ß√£o AR(‚àû) equivalente.

> üí° **Exemplo Num√©rico:**
>
> Vamos analisar a invertibilidade de um operador MA(1) e um MA(2). Considere o operador MA(1) dado por $y_t = \epsilon_t + \theta_1 \epsilon_{t-1}$.  O polin√¥mio associado √© $\theta(z) = 1 + \theta_1 z$.  Para que o operador seja invert√≠vel, a raiz desse polin√¥mio ($z = -1/\theta_1$) deve estar fora do c√≠rculo unit√°rio. Isso significa que $|-1/\theta_1| > 1$, ou $|\theta_1| < 1$. Portanto, um operador MA(1) √© invert√≠vel se o coeficiente $\theta_1$ estiver entre -1 e 1.
>
> Agora considere um operador MA(2) dado por $y_t = \epsilon_t + 0.5\epsilon_{t-1} - 0.6\epsilon_{t-2}$. O polin√¥mio associado √© $\theta(z) = 1 + 0.5z - 0.6z^2$. As ra√≠zes desse polin√¥mio s√£o encontradas resolvendo $1 + 0.5z - 0.6z^2 = 0$.
>
> As ra√≠zes s√£o dadas por $z = \frac{-0.5 \pm \sqrt{0.5^2 - 4(-0.6)(1)}}{2(-0.6)}$, que s√£o $z \approx 1.667$ e $z \approx -0.833$.  Como uma raiz tem m√≥dulo menor do que 1, o operador n√£o √© invert√≠vel. Se as ra√≠zes fossem $1.667$ e $-1.8$, o operador seria invert√≠vel.
>
> O gr√°fico das ra√≠zes no plano complexo deve estar fora do c√≠rculo unit√°rio para que o operador seja invert√≠vel.
>
> Para um processo MA(1), por exemplo, se $\theta_1 = 0.5$, a raiz √© $-1/0.5 = -2$.  Como |-2| > 1, o operador √© invert√≠vel. Se $\theta_1 = 1.5$, a raiz √© $-1/1.5 = -2/3$, e o operador n√£o √© invert√≠vel pois $|-2/3| < 1$.
>
> üí° **Exemplo Num√©rico:**
>
> Para ilustrar a invertibilidade, vamos analisar um MA(1) com $\theta_1 = 0.8$ e outro com $\theta_1 = 1.2$.
>
> Caso 1: $\theta_1 = 0.8$. O polin√¥mio √© $\theta(z) = 1 + 0.8z$. A raiz √© $z = -1/0.8 = -1.25$. Como $|-1.25| > 1$, o processo √© invert√≠vel.
>
> Caso 2: $\theta_1 = 1.2$. O polin√¥mio √© $\theta(z) = 1 + 1.2z$. A raiz √© $z = -1/1.2 \approx -0.83$. Como $|-0.83| < 1$, o processo n√£o √© invert√≠vel.
>
> Podemos plotar a regi√£o de invertibilidade do MA(1) no plano cartesiano. A regi√£o de invertibilidade √© o intervalo entre -1 e 1 no eixo de $\theta_1$.
> ```python
> import matplotlib.pyplot as plt
>
> plt.figure(figsize=(6, 4))
> plt.plot([-1, 1], [0, 0], marker='o', linestyle='-', color='black', label='Regi√£o de invertibilidade')
> plt.scatter(0.8,0, marker='x', color='blue', label='Invert√≠vel')
> plt.scatter(1.2, 0, marker='x', color='red', label='N√£o Invert√≠vel')
> plt.axvline(x=-1, color='gray', linestyle='--')
> plt.axvline(x=1, color='gray', linestyle='--')
>
> plt.title("Regi√£o de Invertibilidade do MA(1)")
> plt.xlabel(r'$\theta_1$')
> plt.yticks([])
> plt.legend()
> plt.grid(True)
> plt.show()
> ```
>
> Este gr√°fico mostra claramente que valores de $\theta_1$ dentro do intervalo (-1, 1) resultam em um operador MA(1) invert√≠vel.
**Proposi√ß√£o 1:** _Um processo MA(1) √© invert√≠vel se e somente se $|\theta_1|<1$._
*Prova*:
I. A invertibilidade de um processo MA(1) implica que a raiz do polin√¥mio $\theta(z) = 1 + \theta_1 z$ est√° fora do c√≠rculo unit√°rio.
II. A raiz √© dada por $z = -1/\theta_1$.
III. Para que $|z| > 1$, devemos ter $|-1/\theta_1| > 1$, o que √© equivalente a $|\theta_1| < 1$.
IV. Reciprocamente, se $|\theta_1|<1$ ent√£o $|-1/\theta_1|>1$, e o processo √© invert√≠vel.
$\blacksquare$

#### Operador Auto-Regressivo (AR)
O operador auto-regressivo (AR) √© outro operador linear importante em s√©ries temporais. Em um processo AR de ordem *p*, denotado por AR(*p*), o valor atual da s√©rie √© expresso como uma combina√ß√£o linear dos seus valores passados, mais um ru√≠do branco:

$$ y_t = \phi_1 y_{t-1} + \phi_2 y_{t-2} + \cdots + \phi_p y_{t-p} + \epsilon_t $$

onde $\phi_1, \phi_2, \ldots, \phi_p$ s√£o os coeficientes do operador AR e $\epsilon_t$ √© um ru√≠do branco com m√©dia zero e vari√¢ncia $\sigma^2$. Usando o operador de deslocamento $L$, podemos escrever:

$$ y_t - \phi_1 y_{t-1} - \phi_2 y_{t-2} - \cdots - \phi_p y_{t-p} = \epsilon_t $$
$$ (1 - \phi_1 L - \phi_2 L^2 - \cdots - \phi_p L^p) y_t = \epsilon_t $$
$$ \phi(L) y_t = \epsilon_t $$

onde $\phi(L) = 1 - \phi_1 L - \phi_2 L^2 - \cdots - \phi_p L^p$ √© o polin√¥mio do operador AR.

O operador AR √© um filtro que aplica pesos aos valores passados da pr√≥pria s√©rie para gerar o valor atual. Ele √© linear, pois preserva a adi√ß√£o e a multiplica√ß√£o por escalar.

> üí° **Exemplo Num√©rico:**
>
> Considere um processo AR(2) dado por $y_t = 0.8y_{t-1} - 0.5y_{t-2} + \epsilon_t$. Aqui, $\phi_1 = 0.8$ e $\phi_2 = -0.5$. Usando o operador de deslocamento, podemos expressar como:
>
> $$(1 - 0.8L + 0.5L^2) y_t = \epsilon_t$$
>
> Este operador transforma a s√©rie temporal $y_t$ de forma que a parte previs√≠vel da s√©rie possa ser expressa a partir de valores passados. Se $y_1 = 1, y_2 = 2, \epsilon_3 = 1, \epsilon_4 = -1$, todos os outros $\epsilon_t$ forem zero, ent√£o $y_3 = 0.8y_2 - 0.5y_1 + \epsilon_3 = 0.8(2) - 0.5(1) + 1 = 2.1$, $y_4 = 0.8y_3 - 0.5y_2 + \epsilon_4 = 0.8(2.1) - 0.5(2) - 1 = -0.32$.
>
> Vamos simular esse processo e plotar a s√©rie temporal resultante:
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
>
> def simulate_ar(T, phi, sigma):
>   epsilon = np.random.normal(0, sigma, T)
>   y = np.zeros(T)
>   p = len(phi)
>   for t in range(p, T):
>     y[t] = epsilon[t]
>     for j in range(p):
>        y[t] += phi[j] * y[t - (j+1)]
>   return y
>
> np.random.seed(42)
> T = 100
> phi = [0.8, -0.5] # AR(2) coefficients
> sigma = 1
> y_ar = simulate_ar(T, phi, sigma)
>
> plt.figure(figsize=(8, 6))
> plt.plot(y_ar)
> plt.title("Simula√ß√£o de um processo AR(2)")
> plt.xlabel("Tempo (t)")
> plt.ylabel("y_t")
> plt.grid(True)
> plt.show()
> ```
> O gr√°fico resultante exibir√° uma s√©rie temporal com valores que dependem de valores passados, demonstrando o efeito do operador auto-regressivo.
>
> üí° **Exemplo Num√©rico:**
>
> Para um processo AR(1), $y_t = \phi y_{t-1} + \epsilon_t$, podemos calcular a fun√ß√£o de autocorrela√ß√£o (ACF). Assumindo que o processo √© estacion√°rio, temos $E[y_t] = 0$ e $Var(y_t) = \frac{\sigma^2}{1 - \phi^2}$.
>
> A autocovari√¢ncia de lag 1 √© $Cov(y_t, y_{t-1}) = E[y_t y_{t-1}] = E[(\phi y_{t-1} + \epsilon_t)y_{t-1}] = \phi E[y_{t-1}^2] = \phi Var(y_{t-1}) = \frac{\phi \sigma^2}{1 - \phi^2}$.
>
> A autocorrela√ß√£o no lag 1 √© $\rho_1 = \frac{Cov(y_t, y_{t-1})}{\sqrt{Var(y_t)Var(y_{t-1})}} = \frac{\phi \sigma^2 / (1 - \phi^2)}{\sigma^2/(1 - \phi^2)} = \phi$.
>
> Para um lag k, $\rho_k = \phi^k$. Portanto, a ACF de um processo AR(1) decai exponencialmente para zero se $|\phi|<1$. Se $\phi=0.8$, ent√£o $\rho_1=0.8, \rho_2=0.64, \rho_3=0.512$, etc.
>
> Vamos plotar a ACF para $\phi=0.8$ usando a simula√ß√£o:
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
>
> def autocovariance(y, k):
>    n = len(y)
>    mean_y = np.mean(y)
>    if k >= n:
>      return 0
>    cov = np.sum([(y[t] - mean_y) * (y[t - k] - mean_y) for t in range(k, n)])
>    return cov/(n-k)
>
> def autocorrelation(y, k):
>     if k == 0:
>      return 1
>     return autocovariance(y, k) / autocovariance(y, 0)
>
> np.random.seed(42)
> T = 100
> phi = 0.8
> sigma = 1
> epsilon = np.random.normal(0, sigma, T)
> y_ar1 = np.zeros(T)
> for t in range(1, T):
>   y_ar1[t] = phi * y_ar1[t-1] + epsilon[t]
>
> lags = 10
> acf_values = [autocorrelation(y_ar1,k) for k in range(lags+1)]
>
> plt.figure(figsize=(8, 6))
> plt.stem(range(lags+1), acf_values)
> plt.title("ACF de um processo AR(1) com phi=0.8")
> plt.xlabel("Lag (k)")
> plt.ylabel("Autocorrela√ß√£o")
> plt.grid(True)
> plt.show()
> ```
> O gr√°fico mostra o decaimento exponencial da ACF, caracter√≠stico de um processo AR(1) estacion√°rio.

**Defini√ß√£o 2:** O polin√¥mio $\phi(z) = 1 - \phi_1 z - \phi_2 z^2 - \ldots - \phi_p z^p$ √© dito *estacion√°rio* se todas as suas ra√≠zes estiverem fora do c√≠rculo unit√°rio no plano complexo, ou seja, se $|z_i| > 1$ para todas as ra√≠zes $z_i$ de $\phi(z)=0$.

Se $\phi(z)$ √© estacion√°rio, ent√£o existe um operador $\phi(L)^{-1}$, tal que $\phi(L)^{-1} \phi(L) = I$, onde $I$ √© o operador identidade. Ou seja, se $\phi(L)$ √© estacion√°rio, podemos expressar $y_t$ em fun√ß√£o de $\epsilon_t$.

**Estacionariedade:** A propriedade de estacionariedade de um operador AR est√° relacionada √† estabilidade da s√©rie temporal. Um operador AR √© estacion√°rio se todas as ra√≠zes do polin√¥mio $\phi(z)$ estiverem fora do c√≠rculo unit√°rio. Em outras palavras, se as ra√≠zes de $\phi(z)=0$ s√£o dadas por $z_1, z_2, \dots, z_p$, ent√£o o operador ser√° estacion√°rio se $|z_i| > 1$ para $i=1,2,\dots,p$.

A condi√ß√£o de estacionariedade garante que os valores passados da s√©rie tenham um efeito decrescente sobre o valor atual, de forma que o processo n√£o explode ou se torna inst√°vel. Essa condi√ß√£o √© necess√°ria para garantir que a vari√¢ncia da s√©rie seja finita e que o processo tenha um comportamento previs√≠vel.

> üí° **Exemplo Num√©rico:**
>
> Vamos analisar a estacionariedade de um operador AR(1) e AR(2). Considere um operador AR(1) dado por $y_t = \phi_1 y_{t-1} + \epsilon_t$. O polin√¥mio associado √© $\phi(z) = 1 - \phi_1 z$. Para que o operador seja estacion√°rio, a raiz desse polin√¥mio (dada por $z=1/\phi_1$) deve estar fora do c√≠rculo unit√°rio. Isso significa que $|1/\phi_1| > 1$, ou $|\phi_1| < 1$. Portanto, um operador AR(1) √© estacion√°rio se o coeficiente $\phi_1$ estiver entre -1 e 1.
>
> Agora, considere um operador AR(2) dado por $y_t = 0.8y_{t-1} - 0.5y_{t-2} + \epsilon_t$. O polin√¥mio associado √© $\phi(z) = 1 - 0.8z + 0.5z^2$. As ra√≠zes desse polin√¥mio s√£o encontradas resolvendo $1 - 0.8z + 0.5z^2 = 0$.
>
> As ra√≠zes s√£o dadas por $z = \frac{0.8 \pm \sqrt{0.8^2 - 4(0.5)(1)}}{2(0.5)}$, que resultam em $z = 0.8 \pm i1.11$. O m√≥dulo dessas ra√≠zes √© $|z| = \sqrt{0.8^2 + 1.11^2} \approx 1.37 > 1$.  Portanto, o processo √© estacion√°rio.
>
> üí° **Exemplo Num√©rico:**
>
> Vamos analisar a estacionariedade de um AR(1) com $\phi_1 = 0.7$ e outro com $\phi_1 = 1.2$.
>
> Caso 1: $\phi_1 = 0.7$. O polin√¥mio √© $\phi(z) = 1 - 0.7z$. A raiz √© $z = 1/0.7 \approx 1.43$. Como $|1.43| > 1$, o processo √© estacion√°rio.
>
> Caso 2: $\phi_1 = 1.2$. O polin√¥mio √© $\phi(z) = 1 - 1.2z$. A raiz √© $z = 1/1.2 \approx 0.83$. Como $|0.83| < 1$, o processo n√£o √© estacion√°rio.
>
> Podemos plotar a regi√£o de estacionariedade do AR(1) no plano cartesiano. A regi√£o de estacionariedade √© o intervalo entre -1 e 1 no eixo de $\phi_1$.
>
> ```python
> import matplotlib.pyplot as plt
>
> plt.figure(figsize=(6, 4))
> plt.plot([-1, 1], [0, 0], marker='o', linestyle='-', color='black', label='Regi√£o de estacionariedade')
> plt.scatter(0.7,0, marker='x', color='blue', label='Estacion√°rio')
> plt.scatter(1.2, 0, marker='x', color='red', label='N√£o Estacion√°rio')
> plt.axvline(x=-1, color='gray', linestyle='--')
> plt.axvline(x=1, color='gray', linestyle='--')
>
> plt.title("Regi√£o de Estacionariedade do AR(1)")
> plt.xlabel(r'$\phi_1$')
> plt.yticks([])
> plt.legend()
> plt.grid(True)
> plt.show()
> ```
>
> Este gr√°fico mostra que valores de $\phi_1$ dentro do intervalo (-1, 1) resultam em um operador AR(1) estacion√°rio.
>
> üí° **Exemplo Num√©rico:**
>
> Considere um processo AR(2) dado por $y_t = \phi_1 y_{t-1} + \phi_2 y_{t-2} + \epsilon_t$. A regi√£o de estacionariedade para AR(2) √© dada por:
> 1. $\phi_1 + \phi_2 < 1$
> 2. $\phi_2 - \phi_1 < 1$
> 3. $|\phi_2| < 1$
>
> Vamos visualizar isso:
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
>
> # Define the region boundaries
> x = np.linspace(-2, 2, 400)
> y = np.linspace(-2, 2, 400)
> X, Y = np.meshgrid(x, y)
>
> # Conditions for stationarity
> condition1 = X + Y < 1
> condition2 = Y - X < 1
> condition3 = np.abs(Y) < 1
>
> # Combine conditions for stationary region
> stationary_region = condition1 & condition2 & condition3
>
> # Create the plot
> plt.figure(figsize=(8, 6))
> plt.contourf(X, Y, stationary_region, levels=[0, 1], colors=['white', 'lightgreen'])
> plt.xlabel(r'$\phi_1$')
> plt.ylabel(r'$\phi_2$')
> plt.title("Regi√£o de Estacionariedade para AR(2)")
> plt.grid(True)
> plt.show()
> ```
> O gr√°fico resultante mostrar√° a regi√£o no plano $(\phi_1, \phi_2)$ onde o processo AR(2) √© estacion√°rio. A regi√£o de estacionariedade √© um tri√¢ngulo limitado pelas condi√ß√µes mencionadas.

**Proposi√ß√£o 2:** _Um processo AR(1) √© estacion√°rio se e somente se $|\phi_1|<1$._

*Prova*:
I. A estacionariedade de um processo AR(1) implica que a raiz do polin√¥mio $\phi(z) = 1 - \phi_1 z$ est√° fora do c√≠rculo unit√°rio.
II. A raiz √© dada por $z = 1/\phi_1$.
III. Para que $|z| > 1$, devemos ter $|1/\phi_1| > 1$, o que √© equivalente a $|\phi_1| < 1$.
IV. Reciprocamente, se $|\phi_1| < 1$ ent√£o $|1/\phi_1|>1$, e o processo √© estacion√°rio.
$\blacksquare$

### Rela√ß√£o entre os Operadores MA e AR

Os operadores MA e AR podem ser combinados para formar modelos mais gerais, como os modelos ARMA (Auto-Regressivo M√©dia M√≥vel). Um modelo ARMA(p, q) √© dado por:

$$ y_t = \phi_1 y_{t-1} + \phi_2 y_{t-2} + \cdots + \phi_p y_{t-p} + \epsilon_t + \theta_1 \epsilon_{t-1} + \theta_2 \epsilon_{t-2} + \cdots + \theta_q \epsilon_{t-q} $$
$$ \phi(L) y_t = \theta(L) \epsilon_t $$

A rela√ß√£o entre operadores MA e AR tamb√©m pode ser expressa na forma de uma representa√ß√£o MA(‚àû) para um processo AR estacion√°rio:
$$y_t = \frac{1}{\phi(L)} \epsilon_t = (1 + \psi_1 L + \psi_2 L^2 + \ldots) \epsilon_t$$
e uma representa√ß√£o AR(‚àû) para um processo MA invert√≠vel:
$$ \epsilon_t = \frac{1}{\theta(L)} y_t = (1 + \pi_1 L + \pi_2 L^2 + \ldots ) y_t$$
onde $\psi_i$ e $\pi_i$ s√£o os coeficientes da representa√ß√£o MA(‚àû) e AR(‚àû) respectivamente.

A representa√ß√£o MA(‚àû) de um processo AR estacion√°rio mostra que ele pode ser expresso como uma combina√ß√£o linear infinita de ru√≠dos brancos passados, e a representa√ß√£o AR(‚àû) de um processo MA invert√≠vel mostra que o ru√≠do branco pode ser expresso como uma combina√ß√£o linear infinita dos valores passados da s√©rie.

Essa rela√ß√£o entre os operadores MA e AR √© fundamental para a an√°lise e modelagem de s√©ries temporais, pois permite escolher a representa√ß√£o mais conveniente para um determinado processo, dependendo de suas propriedades de estacionariedade e invertibilidade.

**Lema 1:** _Se $\phi(L)$ √© o polin√¥mio de um operador AR estacion√°rio, ent√£o a s√©rie $\phi(L)^{-1}$ tem soma absolutamente convergente._

*Prova:*
I. Se $\phi(L)$ √© o polin√¥mio de um operador AR estacion√°rio, ent√£o todas as suas ra√≠zes est√£o fora do c√≠rculo unit√°rio, ou seja, se $\phi(z_i) = 0$, ent√£o $|z_i| > 1$, e podemos escrever
$$
\phi(z) = \prod_{i=1}^p (1 - z/z_i)
$$
Como $|z_i| > 1$, podemos escrever $1/z_i = \alpha_i$, com $|\alpha_i| < 1$, e assim
$$
\phi(z) = \prod_{i=1}^p (1 - \alpha_i z)
$$
que √© a forma usual do polin√¥mio.

II. Agora, para encontrar $\phi(L)^{-1}$, podemos usar a expans√£o em s√©rie geom√©trica para cada fator:
$$
\frac{1}{1 - \alpha_i L} = \sum_{j=0}^{\infty} \alpha_i^j L^j
$$
Como $|\alpha_i| < 1$, a s√©rie converge absolutamente.
Portanto,
$$
\phi(L)^{-1} = \prod_{i=1}^p \left(\sum_{j=0}^{\infty} \alpha_i^j L^j\right)
$$
Quando multiplicamos as s√©ries, obteremos uma s√©rie da forma $\sum_{k=0}^{\infty} \psi_k L^k$.
Como cada s√©rie individual converge absolutamente, o produto tamb√©m converge absolutamente. Isto significa que $\sum_{k=0}^{\infty} |\psi_k| < \infty$.
Portanto, os coeficientes $\psi_k$ de $\phi(L)^{-1}$ t√™m soma absolutamente convergente. $\blacksquare$

*Teorema (Wold)*
Todo processo estoc√°stico estacion√°rio puramente n√£o determin√≠stico pode ser representado como um processo ARMA(p, q) ou como um processo MA($\infty$).

*Prova* (Uma vis√£o geral)
O teorema de Wold estabelece que qualquer processo estoc√°stico estacion√°rio pode ser decomposto em duas partes: uma parte determin√≠stica (previs√≠vel) e uma parte puramente n√£o-determin√≠stica (imprevis√≠vel), ou seja, um processo de ru√≠do branco. A parte n√£o-determin√≠stica, que √© essencial para modelagem, pode sempre ser representada como uma combina√ß√£o linear infinita de choques aleat√≥rios passados (como um processo MA($\infty$)). Se tamb√©m admitirmos depend√™ncia a m√©dio prazo, chegamos aos modelos ARMA.
O teorema de Wold garante que podemos modelar processos estoc√°sticos estacion√°rios por meio de modelos ARMA ou MA, que s√£o representa√ß√µes lineares e trat√°veis, embora a representa√ß√£o possa envolver somas infinitas, como em um MA($\infty$). A demonstra√ß√£o rigorosa requer ferramentas de an√°lise funcional e teoria da medida. $\blacksquare$

*Observa√ß√£o:*
A import√¢ncia deste teorema √© que ele estabelece uma base te√≥rica para a modelagem de s√©ries temporais. Ele permite modelar quase todos os processos estacion√°rios como uma combina√ß√£o linear de ru√≠do branco.

<!-- END -->
