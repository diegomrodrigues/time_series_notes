## A HipÃ³tese de Quebras Ocasionais na TendÃªncia em SÃ©ries Temporais NÃ£o EstacionÃ¡rias

### IntroduÃ§Ã£o
Em continuidade Ã  discussÃ£o sobre modelos de sÃ©ries temporais nÃ£o estacionÃ¡rias, este capÃ­tulo explora a hipÃ³tese de **quebras ocasionais na tendÃªncia**, uma alternativa Ã  modelagem tradicional com tendÃªncia determinÃ­stica ou raiz unitÃ¡ria, jÃ¡ abordadas em capÃ­tulos anteriores [^1]. Enquanto modelos *trend-stationary* e de raiz unitÃ¡ria assumem tendÃªncias contÃ­nuas, o mÃ©todo de quebras ocasionais na tendÃªncia busca capturar mudanÃ§as discretas na tendÃªncia, que podem refletir eventos econÃ´micos, polÃ­ticos ou outros choques que afetam o comportamento da sÃ©rie temporal [^1]. A importÃ¢ncia desta hipÃ³tese reside na sua capacidade de modelar situaÃ§Ãµes onde a tendÃªncia nÃ£o Ã© estÃ¡vel ao longo do tempo, um fenÃ´meno comum em dados macroeconÃ´micos e financeiros [^1].

### Conceitos Fundamentais

#### Modelagem de Quebras Ocasionais na TendÃªncia
Como visto anteriormente, a modelagem de sÃ©ries temporais nÃ£o estacionÃ¡rias pode ser desafiadora, especialmente quando o comportamento da tendÃªncia nÃ£o Ã© constante. Os modelos tradicionais assumem que a tendÃªncia Ã© uma funÃ§Ã£o linear do tempo ou que a sÃ©rie segue um processo estocÃ¡stico com raiz unitÃ¡ria. No entanto, a hipÃ³tese de quebras ocasionais na tendÃªncia propÃµe que a sÃ©rie pode ser estacionÃ¡ria em torno de uma tendÃªncia, mas essa tendÃªncia pode sofrer quebras discretas, geralmente associadas a eventos especÃ­ficos [^1].

Um modelo simples com uma Ãºnica quebra pode ser formalizado como:

$$y_t = \begin{cases}
    \alpha_1 + \delta t + \epsilon_t & \text{para } t < T_0 \\
    \alpha_2 + \delta t + \epsilon_t & \text{para } t \geq T_0
\end{cases}$$ [15.5.7]

onde $y_t$ Ã© a sÃ©rie temporal, $\alpha_1$ e $\alpha_2$ sÃ£o os nÃ­veis da tendÃªncia antes e depois da quebra, $\delta$ Ã© a inclinaÃ§Ã£o da tendÃªncia (assumida constante neste caso), $\epsilon_t$ Ã© um erro aleatÃ³rio, e $T_0$ Ã© o instante em que ocorre a quebra na tendÃªncia [^1]. Este modelo, portanto, propÃµe que a sÃ©rie temporal exibe uma tendÃªncia linear antes de $T_0$ e outra apÃ³s $T_0$, com a inclinaÃ§Ã£o $\delta$ constante.

Ã‰ importante notar que, embora a inclinaÃ§Ã£o $\delta$ seja constante neste modelo simples, pode-se, em outros modelos mais complexos, permitir que a inclinaÃ§Ã£o da tendÃªncia tambÃ©m mude em $T_0$. A principal caracterÃ­stica desta modelagem Ã© a descontinuidade da tendÃªncia em $T_0$, o que a distingue dos modelos com raiz unitÃ¡ria que implicam em alteraÃ§Ãµes contÃ­nuas e estocÃ¡sticas da tendÃªncia.

> ğŸ’¡ **Exemplo:** Para ilustrar o efeito de quebras na tendÃªncia, imagine uma sÃ©rie temporal que representa o PIB de um paÃ­s. Antes de uma grande reforma econÃ´mica ($T_0$), o PIB cresce a uma taxa constante. ApÃ³s a reforma, o nÃ­vel do PIB ajusta-se para um novo patamar, mantendo a mesma taxa de crescimento. Este cenÃ¡rio Ã© bem modelado por um modelo com quebra na tendÃªncia como o da equaÃ§Ã£o [15.5.7].

Uma forma alternativa de visualizar o modelo de quebra na tendÃªncia Ã© atravÃ©s da primeira diferenÃ§a da sÃ©rie:

$$\Delta y_t = \xi_t + \delta + \epsilon_t - \epsilon_{t-1}$$ [15.5.8]

onde $\Delta y_t = y_t - y_{t-1}$ representa a diferenÃ§a primeira, e $\xi_t = \alpha_2 - \alpha_1$ quando $t = T_0$ e zero caso contrÃ¡rio [^1].  Neste contexto, $\xi_t$ representa o choque instantÃ¢neo na tendÃªncia no tempo $T_0$.

Se considerarmos $\xi_t$ como uma variÃ¡vel aleatÃ³ria com a seguinte distribuiÃ§Ã£o:

$$\xi_t = \begin{cases}
    \alpha_2 - \alpha_1 & \text{com probabilidade } p \\
    0 & \text{com probabilidade } 1 - p
\end{cases}$$

onde $p$ Ã© a probabilidade de ocorrer uma quebra, o modelo pode ser reformulado como:

$$\Delta y_t = \mu + \eta_t$$ [15.5.9]

onde $\mu = p(\alpha_2 - \alpha_1) + \delta$ e $\eta_t = \xi_t - p(\alpha_2 - \alpha_1) + \epsilon_t - \epsilon_{t-1}$ [^1].  Aqui, $\mu$ representa a mÃ©dia da primeira diferenÃ§a da sÃ©rie, e $\eta_t$ representa o termo de erro, que Ã© uma combinaÃ§Ã£o de um processo de ruÃ­do branco e um processo MA(1).  Com isso, a variaÃ§Ã£o $\Delta y_t$ pode ser modelada como um processo ARIMA(0,1,1):

$$\Delta y_t = \mu + \nu_t + \theta\nu_{t-1}$$

onde $\nu_t$ Ã© uma inovaÃ§Ã£o com distribuiÃ§Ã£o nÃ£o-Gaussiana [^1].

> ğŸ’¡ **Exemplo NumÃ©rico:** Considere uma sÃ©rie temporal com uma quebra discreta na tendÃªncia, como exemplificado no cÃ³digo a seguir.
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
>
> # Define parÃ¢metros
> T = 100
> T0 = 50
> alpha1 = 10
> alpha2 = 20
> delta = 0.5
> np.random.seed(42)
> epsilon = np.random.normal(0, 1, T)
>
> # Cria a sÃ©rie temporal com quebra
> time = np.arange(1, T + 1)
> y = np.zeros(T)
> for t in range(T):
>    if t < T0:
>        y[t] = alpha1 + delta * time[t] + epsilon[t]
>    else:
>        y[t] = alpha2 + delta * time[t] + epsilon[t]
>
> # Plota a sÃ©rie temporal original
> plt.figure(figsize=(10, 6))
> plt.plot(time, y, label='SÃ©rie com Quebra na TendÃªncia')
> plt.axvline(x=T0, color='r', linestyle='--', label='Quebra em T0')
> plt.xlabel('Tempo')
> plt.ylabel('Valor')
> plt.title('SÃ©rie Temporal com Quebra na TendÃªncia')
> plt.legend()
> plt.show()
> ```
>
> Este cÃ³digo gera uma sÃ©rie temporal com um Ãºnico ponto de quebra na tendÃªncia em $t=50$. A figura resultante demonstra claramente a mudanÃ§a abrupta no nÃ­vel da sÃ©rie, mantendo a inclinaÃ§Ã£o constante, que Ã© uma caracterÃ­stica fundamental de modelos de quebra ocasional.

> ğŸ’¡ **Exemplo NumÃ©rico:** Para ilustrar o impacto das quebras no modelo de primeira diferenÃ§a, vamos gerar os dados como no exemplo anterior e calcular a primeira diferenÃ§a da sÃ©rie.
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
>
> # Define parÃ¢metros (como no exemplo anterior)
> T = 100
> T0 = 50
> alpha1 = 10
> alpha2 = 20
> delta = 0.5
> np.random.seed(42)
> epsilon = np.random.normal(0, 1, T)
>
> # Cria a sÃ©rie temporal com quebra (como no exemplo anterior)
> time = np.arange(1, T + 1)
> y = np.zeros(T)
> for t in range(T):
>    if t < T0:
>        y[t] = alpha1 + delta * time[t] + epsilon[t]
>    else:
>        y[t] = alpha2 + delta * time[t] + epsilon[t]
>
> # Calcula a primeira diferenÃ§a
> dy = np.diff(y)
>
> # Cria vetor de tempo para a primeira diferenÃ§a
> time_dy = time[1:]
>
> # Plota a primeira diferenÃ§a
> plt.figure(figsize=(10, 6))
> plt.plot(time_dy, dy, label='Primeira DiferenÃ§a da SÃ©rie')
> plt.axvline(x=T0, color='r', linestyle='--', label='Quebra em T0')
> plt.xlabel('Tempo')
> plt.ylabel('Primeira DiferenÃ§a')
> plt.title('Primeira DiferenÃ§a da SÃ©rie Temporal com Quebra na TendÃªncia')
> plt.legend()
> plt.show()
>
> # Calcula e imprime o valor de xi
> xi = alpha2 - alpha1
> print(f"O valor da quebra xi Ã©: {xi}")
> ```
>
> No grÃ¡fico da primeira diferenÃ§a, observa-se um pico no tempo $T_0$, que corresponde ao valor de $\xi_t = \alpha_2 - \alpha_1$. Este pico representa o choque na tendÃªncia, conforme definido na equaÃ§Ã£o [15.5.8]. O valor impresso de $\xi$ confirma o salto na tendÃªncia.

#### ImplicaÃ§Ãµes da HipÃ³tese de Quebra Ocasional

A hipÃ³tese de quebras ocasionais na tendÃªncia tem implicaÃ§Ãµes importantes na modelagem e previsÃ£o de sÃ©ries temporais.  Ao contrÃ¡rio dos modelos de raiz unitÃ¡ria, em que cada inovaÃ§Ã£o gera um efeito permanente, o modelo com quebra ocasional implica que apenas eventos especÃ­ficos (quebras) alteram permanentemente o nÃ­vel da sÃ©rie [^1]. A regra de previsÃ£o linear Ã³tima neste caso Ã©:

$$\mathbb{E}(y_{t+s} | y_t, y_{t-1}, \ldots) = \mu s + y_t + \theta \nu_t$$

que demonstra que o peso nas inovaÃ§Ãµes $\nu_t$ nÃ£o desaparece quando $s \rightarrow \infty$. Isso ocorre porque cada perÃ­odo fornece uma nova informaÃ§Ã£o sobre a variÃ¡vel $\xi_t$, e a realizaÃ§Ã£o de $\xi_t$ tem um efeito permanente no nÃ­vel da sÃ©rie [^1].

**ProposiÃ§Ã£o 2**
Testes de raiz unitÃ¡ria podem indicar nÃ£o estacionariedade quando o que existe na verdade sÃ£o quebras ocasionais na tendÃªncia.
*Proof:*
Provaremos que a presenÃ§a de quebras ocasionais na tendÃªncia pode levar testes de raiz unitÃ¡ria a concluir erroneamente sobre a nÃ£o estacionariedade da sÃ©rie.
I.  Testes de raiz unitÃ¡ria, como o teste de Dickey-Fuller, sÃ£o projetados para detectar a presenÃ§a de raiz unitÃ¡ria, que indica nÃ£o estacionariedade e um efeito permanente de inovaÃ§Ãµes sobre a sÃ©rie temporal.
II. Quebras ocasionais na tendÃªncia introduzem uma persistÃªncia na sÃ©rie, pois apÃ³s uma quebra, a sÃ©rie nÃ£o retorna ao seu nÃ­vel anterior na tendÃªncia anterior. Isso faz com que a sÃ©rie pareÃ§a ter uma memÃ³ria longa.
III. Essa persistÃªncia causada pelas quebras ocasionais pode levar os testes de raiz unitÃ¡ria a identificarem a sÃ©rie como nÃ£o estacionÃ¡ria, mesmo que ela seja estacionÃ¡ria em torno de uma tendÃªncia com quebras.
IV.  A dificuldade em distinguir entre uma raiz unitÃ¡ria e quebras ocasionais surge porque ambas as caracterÃ­sticas causam efeitos de longo prazo na sÃ©rie temporal.
V.  Portanto, a presenÃ§a de quebras ocasionais na tendÃªncia pode confundir testes de raiz unitÃ¡ria, levando a resultados errÃ´neos sobre a existÃªncia de uma raiz unitÃ¡ria e, portanto, nÃ£o estacionariedade da sÃ©rie temporal.â– 

**Teorema 1**
Uma sÃ©rie temporal com quebras ocasionais na tendÃªncia Ã© fracamente estacionÃ¡ria ao redor da tendÃªncia segmentada.
*Proof:*
Para provar que a sÃ©rie $y_t$ com quebras na tendÃªncia Ã© fracamente estacionÃ¡ria ao redor de sua tendÃªncia segmentada, precisamos mostrar que a sÃ©rie de erros $\epsilon_t$ Ã© fracamente estacionÃ¡ria, que as mÃ©dias e autocovariÃ¢ncias da sÃ©rie sÃ£o constantes no tempo.
I. A sÃ©rie original Ã© definida por $y_t = \alpha_i + \delta t + \epsilon_t$, onde $\alpha_i$ representa o nÃ­vel da tendÃªncia em diferentes segmentos (antes e depois de quebras), e $\epsilon_t$ Ã© o termo de erro.
II.  Definimos a tendÃªncia segmentada como $T_t = \alpha_i + \delta t$. EntÃ£o podemos expressar a sÃ©rie como $y_t = T_t + \epsilon_t$.
III.  Se subtrairmos a tendÃªncia segmentada da sÃ©rie $y_t$, obtemos a sÃ©rie de erros $\epsilon_t = y_t - T_t$.
IV. Para que a sÃ©rie seja fracamente estacionÃ¡ria ao redor da tendÃªncia segmentada, $\epsilon_t$ deve ser fracamente estacionÃ¡ria. Isso implica que:
     a) $E[\epsilon_t] = 0$ para todo $t$.
     b) $Var[\epsilon_t] = \sigma^2 < \infty$ para todo $t$.
     c) $Cov[\epsilon_t, \epsilon_{t-k}] = \gamma_k$, que depende apenas de $k$ e nÃ£o de $t$.
V.  Se assumirmos que $\epsilon_t$ Ã© um ruÃ­do branco com mÃ©dia zero e variÃ¢ncia constante $\sigma^2$, entÃ£o as condiÃ§Ãµes para estacionariedade fraca estÃ£o satisfeitas.
VI.  Portanto, a sÃ©rie $y_t$ com quebras ocasionais na tendÃªncia Ã© fracamente estacionÃ¡ria ao redor da sua tendÃªncia segmentada, jÃ¡ que a sÃ©rie de erros $\epsilon_t$ Ã© fracamente estacionÃ¡ria.â– 

**Lema 1**
Sob condiÃ§Ãµes adequadas, a estimativa do ponto de quebra $\hat{T_0}$ converge para o verdadeiro ponto de quebra $T_0$ quando o tamanho da amostra tende ao infinito.
*Proof:*
I. Considere o modelo com uma Ãºnica quebra na tendÃªncia:
$$y_t = \begin{cases}
    \alpha_1 + \delta t + \epsilon_t & \text{para } t < T_0 \\
    \alpha_2 + \delta t + \epsilon_t & \text{para } t \geq T_0
\end{cases}$$
II.  Para estimar $T_0$, podemos usar um procedimento de busca, onde, para cada possÃ­vel ponto de quebra $\tau$, estimamos os parÃ¢metros $\alpha_1(\tau)$, $\alpha_2(\tau)$, e $\delta(\tau)$ minimizando a soma dos erros ao quadrado (OLS) em duas amostras separadas antes e depois de $\tau$.
III. A soma dos erros ao quadrado (SSR) Ã© dada por
$$SSR(\tau) = \sum_{t=1}^{\tau} (y_t - \alpha_1(\tau) - \delta(\tau)t)^2 + \sum_{t=\tau+1}^{T} (y_t - \alpha_2(\tau) - \delta(\tau)t)^2$$
IV.  O estimador $\hat{T_0}$ Ã© o valor de $\tau$ que minimiza $SSR(\tau)$:
$$\hat{T_0} = \text{argmin}_{\tau} SSR(\tau)$$
V. Sob condiÃ§Ãµes regulares (como a convergÃªncia em probabilidade de $\frac{1}{T} \sum_{t=1}^T \epsilon_t^2$ para a variÃ¢ncia de $\epsilon_t$, e outras condiÃ§Ãµes de regularidade), e sob a condiÃ§Ã£o que $\alpha_1 \neq \alpha_2$, podemos provar que $\hat{T_0}$ converge em probabilidade para $T_0$.
VI. A convergÃªncia Ã© garantida porque a minimizaÃ§Ã£o da SSR em torno do verdadeiro ponto de quebra gera os menores resÃ­duos. Quando o tamanho da amostra tende ao infinito, a variabilidade na estimaÃ§Ã£o de $\hat{T_0}$ diminui, levando-o a convergir para $T_0$. â– 

> ğŸ’¡ **Exemplo NumÃ©rico:** Para demonstrar como a estimativa do ponto de quebra $\hat{T_0}$ converge para o verdadeiro ponto de quebra $T_0$, vamos simular dados com uma quebra conhecida e estimar o ponto de quebra usando um procedimento de busca.
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
>
> def generate_data_with_break(T, T0, alpha1, alpha2, delta, seed=42):
>    np.random.seed(seed)
>    epsilon = np.random.normal(0, 1, T)
>    time = np.arange(1, T + 1)
>    y = np.zeros(T)
>    for t in range(T):
>        if t < T0:
>            y[t] = alpha1 + delta * time[t] + epsilon[t]
>        else:
>            y[t] = alpha2 + delta * time[t] + epsilon[t]
>    return time, y
>
> def estimate_break_point(time, y):
>    T = len(y)
>    best_ssr = float('inf')
>    best_T0_hat = None
>
>    for tau in range(2, T - 1):  # Avoid testing endpoints
>        y1 = y[:tau]
>        time1 = time[:tau]
>        y2 = y[tau:]
>        time2 = time[tau:]
>
>        X1 = np.column_stack((np.ones(len(time1)), time1))
>        X2 = np.column_stack((np.ones(len(time2)), time2))
>
>        beta1 = np.linalg.lstsq(X1, y1, rcond=None)[0]
>        beta2 = np.linalg.lstsq(X2, y2, rcond=None)[0]
>
>        ssr = np.sum((y1 - (X1 @ beta1))**2) + np.sum((y2 - (X2 @ beta2))**2)
>
>        if ssr < best_ssr:
>            best_ssr = ssr
>            best_T0_hat = tau
>
>    return best_T0_hat
>
> # Define os parÃ¢metros
> T = 200
> T0 = 100
> alpha1 = 10
> alpha2 = 20
> delta = 0.5
>
> # Gera os dados
> time, y = generate_data_with_break(T, T0, alpha1, alpha2, delta)
>
> # Estima o ponto de quebra
> T0_hat = estimate_break_point(time, y)
>
> # Plota a sÃ©rie temporal e o ponto de quebra estimado
> plt.figure(figsize=(10, 6))
> plt.plot(time, y, label='SÃ©rie com Quebra')
> plt.axvline(x=T0, color='r', linestyle='--', label='Quebra Verdadeira (T0)')
> plt.axvline(x=T0_hat, color='g', linestyle='--', label='Quebra Estimada (T0_hat)')
> plt.xlabel('Tempo')
> plt.ylabel('Valor')
> plt.title('Estimativa do Ponto de Quebra')
> plt.legend()
> plt.show()
>
> print(f"Verdadeiro ponto de quebra (T0): {T0}")
> print(f"Ponto de quebra estimado (T0_hat): {T0_hat}")
>
> # Para mostrar convergÃªncia, vamos rodar com tamanhos amostrais maiores e visualizar
> T_values = [100, 200, 500, 1000]
> T0_hat_values = []
>
> for T in T_values:
>    time, y = generate_data_with_break(T, T0, alpha1, alpha2, delta)
>    T0_hat = estimate_break_point(time, y)
>    T0_hat_values.append(T0_hat)
>
> plt.figure(figsize=(10,6))
> plt.plot(T_values, T0_hat_values, marker='o')
> plt.axhline(y=T0, color='r', linestyle='--', label='Quebra Verdadeira (T0)')
> plt.xlabel('Tamanho da Amostra (T)')
> plt.ylabel('Ponto de Quebra Estimado (T0_hat)')
> plt.title('ConvergÃªncia da Estimativa do Ponto de Quebra')
> plt.legend()
> plt.show()
> ```
>
> Este exemplo demonstra como o ponto de quebra estimado $\hat{T_0}$ se aproxima do verdadeiro ponto de quebra $T_0$ Ã  medida que o tamanho da amostra aumenta. O grÃ¡fico final ilustra a convergÃªncia do ponto de quebra estimado em relaÃ§Ã£o ao tamanho da amostra.

**CorolÃ¡rio 1**
Se a hipÃ³tese nula de nÃ£o-quebra na tendÃªncia for rejeitada por um teste de quebra, entÃ£o um modelo de quebra na tendÃªncia deve ser preferido em vez de um modelo sem quebra.
*Proof:*
I. Um teste de quebra na tendÃªncia avalia a hipÃ³tese nula de que nÃ£o hÃ¡ quebra na tendÃªncia.
II. Se este teste rejeitar a hipÃ³tese nula (por exemplo, atravÃ©s de um teste F), hÃ¡ evidÃªncias estatÃ­sticas de que houve uma quebra na tendÃªncia.
III. Ao rejeitar a hipÃ³tese nula de nÃ£o-quebra, os dados sugerem que a modelagem mais adequada Ã© aquela que leva em consideraÃ§Ã£o a presenÃ§a de quebras.
IV. Portanto, o modelo de quebra na tendÃªncia Ã© uma melhor representaÃ§Ã£o da dinÃ¢mica da sÃ©rie do que um modelo que ignora a quebra, uma vez que a quebra Ã© estatisticamente significante.
V.  A escolha de um modelo com quebra quando existe quebra melhora a adequaÃ§Ã£o do modelo, a precisÃ£o das previsÃµes e a interpretaÃ§Ã£o dos parÃ¢metros.â– 

AlÃ©m disso, Ã© possÃ­vel considerar modelos com mÃºltiplas quebras na tendÃªncia, o que pode ser Ãºtil para modelar sÃ©ries temporais que sofrem vÃ¡rias mudanÃ§as estruturais.

**Teorema 1.1**
A generalizaÃ§Ã£o do modelo para *m* quebras pode ser formulada como:
$$
y_t = \alpha_0 + \sum_{j=1}^{m} (\alpha_j - \alpha_{j-1}) D_{jt} + \delta t + \epsilon_t
$$
onde $D_{jt} = 1$ se $T_{j-1} < t \leq T_j$ e 0 caso contrÃ¡rio, com $T_0 = 0$.
*Proof:*
I.  O modelo original com uma quebra Ã© dado por:
$$y_t = \begin{cases}
    \alpha_1 + \delta t + \epsilon_t & \text{para } t < T_0 \\
    \alpha_2 + \delta t + \epsilon_t & \text{para } t \geq T_0
\end{cases}$$
II. Podemos reformular este modelo usando uma variÃ¡vel *dummy* indicadora da quebra,  $D_{1t} = 1$ se $t \geq T_0$ e 0 caso contrÃ¡rio. EntÃ£o, o modelo torna-se:
$$y_t = \alpha_1 + (\alpha_2 - \alpha_1)D_{1t} + \delta t + \epsilon_t$$
III. Generalizando para *m* quebras em tempos $T_1, T_2, ..., T_m$, podemos definir variÃ¡veis *dummy*  $D_{jt}$ que indicam quando a sÃ©rie estÃ¡ em cada segmento.
IV. Definimos $D_{jt} = 1$ se $T_{j-1} < t \leq T_j$ e $0$ caso contrÃ¡rio. Note que $T_0 = 0$ e $T_{m+1}=T$.
V.  Com essa notaÃ§Ã£o, a sÃ©rie $y_t$ pode ser escrita como:
$$y_t = \alpha_0 + \sum_{j=1}^{m} (\alpha_j - \alpha_{j-1}) D_{jt} + \delta t + \epsilon_t$$
onde $\alpha_j$ Ã© o nÃ­vel da tendÃªncia no *j*-Ã©simo segmento, e o termo $(\alpha_j - \alpha_{j-1})$ capta o efeito da quebra na tendÃªncia no ponto $T_j$.
VI. Esta formulaÃ§Ã£o representa uma sÃ©rie temporal com *m* quebras na tendÃªncia, permitindo que o nÃ­vel da tendÃªncia mude em cada ponto de quebra $T_j$.
VII. Cada intervalo $T_{j-1} < t \leq T_j$ Ã© chamado de regime, ou segmento da tendÃªncia, o que generaliza o modelo inicial para uma Ãºnica quebra. â– 

**Lema 1.1**
A estimativa dos pontos de quebra $\hat{T_1}, \hat{T_2}, ..., \hat{T_m}$ convergem para os verdadeiros pontos de quebra $T_1, T_2, ..., T_m$ quando o tamanho da amostra tende ao infinito, sob condiÃ§Ãµes regulares.

*Proof:*
A demonstraÃ§Ã£o segue de forma anÃ¡loga ao Lema 1, onde ao invÃ©s de um ponto de quebra, procuramos os $m$ pontos que minimizam a soma dos erros ao quadrado em todos os $m+1$ segmentos. Sob as condiÃ§Ãµes regulares de convergÃªncia, os estimadores $\hat{T_j}$ convergem para os verdadeiros pontos de quebra $T_j$. â– 

**ObservaÃ§Ã£o 1**
A inclusÃ£o de mÃºltiplas quebras permite uma representaÃ§Ã£o mais flexÃ­vel e realista de sÃ©ries temporais que exibem mudanÃ§as estruturais complexas, porÃ©m aumenta a complexidade da estimaÃ§Ã£o e teste de hipÃ³teses. A quantidade de pontos de quebra, bem como sua localizaÃ§Ã£o, sÃ£o geralmente desconhecidas e devem ser inferidas a partir dos dados.

> ğŸ’¡ **Exemplo NumÃ©rico:** Para ilustrar a modelagem com mÃºltiplas quebras, vamos simular uma sÃ©rie temporal com duas quebras na tendÃªncia e ajustar o modelo.
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
>
> def generate_data_with_multiple_breaks(T, T1, T2, alpha1, alpha2, alpha3, delta, seed=42):
>  np.random.seed(seed)
>  epsilon = np.random.normal(0, 1, T)
>  time = np.arange(1, T + 1)
>  y = np.zeros(T)
>  for t in range(T):
>    if t < T1:
>      y[t] = alpha1 + delta * time[t] + epsilon[t]
>    elif t < T2:
>      y[t] = alpha2 + delta * time[t] + epsilon[t]
>    else:
>      y[t] = alpha3 + delta * time[t] + epsilon[t]
>  return time, y
>
> def estimate_multiple_break_points(time, y, max_breaks=2):
>    T = len(y)
>    best_ssr = float('inf')
>    best_break_points = None
>
>    if max_breaks == 1:
>        best_break_points = [estimate_break_point(time, y)]
>        return best_break_points
>
>    for tau1 in range(2, T - max_breaks):
>      for tau2 in range(tau1 + 1, T-1):
>            y1 = y[:tau1]
>            time1 = time[:tau1]
>            y2 = y[tau1:tau2]
>            time2 = time[tau1:tau2]
>            y3 = y[tau2:]
>            time3 = time[tau2:]
>
>            X1 = np.column_stack((np.ones(len(time1)), time1))
>            X2 = np.column_stack((np.ones(len(time2)), time2))
>            X3 = np.column_stack((np.ones(len(time3)), time3))
>
>            beta1 = np.linalg.lstsq(X1, y1, rcond=None)[0]
>            beta2 = np.linalg.lstsq(X2, y2, rcond=None)[0]
>            beta3 = np.linalg.lstsq(X3, y3, rcond=None)[0]
>
>            ssr = np.sum((y1 - (X1 @ beta1))**2) + np.sum((y2 - (X2 @ beta2))**2) + np.sum((y3 - (X3 @ beta3))**2)
>
>            if ssr < best_ssr:
>                best_ssr = ssr
>                best_break_points = [tau1, tau2]
>
>    return best_break_points
>
> # Define parÃ¢metros
> T = 300
> T1 = 100
> T2 = 200
> alpha1 = 10
> alpha2 = 20
> alpha3 = 15
> delta = 0.3
>
> # Gera os dados
> time, y = generate_data_with_multiple_breaks(T, T1, T2, alpha1, alpha2, alpha3, delta)
>
> # Estima os pontos de quebra
> break_points = estimate_multiple_break_points(time, y)
>
> # Plota a sÃ©rie e os pontos de quebra
> plt.figure(figsize=(10, 6))
> plt.plot(time, y, label='SÃ©rie com MÃºltiplas Quebras')
> plt.axvline(x=T1, color='r', linestyle='--', label='Quebra Verdadeira (T1)')
> plt.axvline(x=T2, color='b', linestyle='--', label='Quebra Verdadeira (T2)')
> if break_points:
>  if len(break_points) > 1:
>    plt.axvline(x=break_points[0], color='g', linestyle='--', label='Quebra Estimada (T1_hat)')
>    plt.axvline(x=break_points[1], color='m', linestyle='--', label='Quebra Estimada (T2_hat)')
>  elif len(break_points) == 1:
>    plt.axvline(x=break_points[0], color='g', linestyle='--', label='Quebra Estimada (T1_hat)')
>
> plt.xlabel('Tempo')
> plt.ylabel('Valor')
> plt.title('SÃ©rie Temporal com MÃºltiplas Quebras e Estimativas')
> plt.legend()
> plt.show()
>
> print(f"Verdadeiros pontos de quebra (T1, T2): {T1}, {T2}")
> if break_points:
>    print(f"Pontos de quebra estimados: {break_points}")
> ```
>
> Este exemplo simula dados com duas quebras e mostra a estimativa dos pontos de quebra, indicando que o modelo se adapta a mÃºltiplos pontos de quebra na tendÃªncia.

### ConclusÃ£o
A hipÃ³tese de quebras ocasionais na tendÃªncia oferece uma alternativa valiosa para a modelagem de sÃ©ries temporais nÃ£o estacionÃ¡rias, especialmente quando a tendÃªncia nÃ£o Ã© constante ao longo do tempo [^1]. Esta abordagem permite modelar mudanÃ§as discretas na tendÃªncia causadas por eventos econÃ´micos ou polÃ­ticos, que nÃ£o sÃ£o capturadas pelos modelos tradicionais *trend-stationary* ou de raiz unitÃ¡ria [^1]. A modelagem de quebras na tendÃªncia Ã© crucial para uma anÃ¡lise precisa de sÃ©ries temporais, e o reconhecimento de quebras Ã© importante para evitar conclusÃµes errÃ´neas sobre a presenÃ§a de raiz unitÃ¡ria. Como vimos, a modelagem de quebras ocasionais na tendÃªncia exige cuidado na escolha do modelo e na interpretaÃ§Ã£o dos resultados, para que a modelagem seja consistente com os fenÃ´menos que afetam as sÃ©ries temporais.

### ReferÃªncias
[^1]: CapÃ­tulo 15 do livro "Time Series Analysis" (informaÃ§Ãµes retiradas de todo o capÃ­tulo).
<!-- END -->
