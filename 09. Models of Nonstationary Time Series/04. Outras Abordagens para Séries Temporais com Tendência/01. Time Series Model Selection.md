## Modelos de SÃ©ries Temporais NÃ£o EstacionÃ¡rias: DiferenciaÃ§Ã£o FracionÃ¡ria e Quebras Ocasionais na TendÃªncia
### IntroduÃ§Ã£o
Como vimos anteriormente, a anÃ¡lise de sÃ©ries temporais frequentemente envolve a modelagem de processos nÃ£o estacionÃ¡rios. Os modelos de sÃ©ries temporais nÃ£o estacionÃ¡rias sÃ£o mais complexos do que os estacionÃ¡rios, pois exigem abordagens que levem em consideraÃ§Ã£o tendÃªncias determinÃ­sticas ou estocÃ¡sticas. Os capÃ­tulos anteriores nos introduziram aos modelos trend-stationary, que incluem uma tendÃªncia determinÃ­stica, e aos modelos com raiz unitÃ¡ria, que modelam tendÃªncias estocÃ¡sticas [^1]. Este capÃ­tulo se aprofunda em abordagens alternativas para a modelagem de sÃ©ries temporais nÃ£o estacionÃ¡rias, explorando a diferenciaÃ§Ã£o fracionÃ¡ria e as quebras ocasionais na tendÃªncia.

### Conceitos Fundamentais

#### Modelos com DiferenciaÃ§Ã£o FracionÃ¡ria
A abordagem de **diferenciaÃ§Ã£o fracionÃ¡ria** surge como uma alternativa para modelar sÃ©ries temporais que exibem dependÃªncias de longo prazo que nÃ£o sÃ£o adequadamente capturadas por modelos tradicionais [^1]. Em vez de usar a primeira ou segunda diferenÃ§a para tornar uma sÃ©rie estacionÃ¡ria, como nos modelos com raiz unitÃ¡ria, a diferenciaÃ§Ã£o fracionÃ¡ria permite uma integraÃ§Ã£o de ordem nÃ£o inteira. O modelo geral de um processo integrado de ordem *d* pode ser escrito como:

$$(1-L)^d y_t = \psi(L)\epsilon_t$$ [15.5.1]

onde $L$ Ã© o operador de defasagem, $\psi(L)$ Ã© um polinÃ´mio em $L$, e $\epsilon_t$ Ã© um ruÃ­do branco [^1]. Tipicamente, assume-se que $d=1$ ou $d=2$, indicando que a primeira ou segunda diferenÃ§a da sÃ©rie Ã© estacionÃ¡ria. No entanto, conforme apontado por Granger e Joyeux (1980) e Hosking (1981), valores nÃ£o inteiros de $d$ tambÃ©m podem ser Ãºteis [^1].

> ğŸ’¡ **Exemplo NumÃ©rico:** Vamos considerar uma sÃ©rie temporal simulada que apresenta dependÃªncia de longo prazo. Para isso, usaremos um ruÃ­do branco e aplicaremos a diferenciaÃ§Ã£o fracionÃ¡ria com d=0.4.
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
>
> # Simula um ruÃ­do branco
> np.random.seed(42)
> T = 100
> white_noise = np.random.normal(0, 1, T)
>
> # FunÃ§Ã£o para calcular os coeficientes h_j
> def fractional_diff_weights(d, length):
>     weights = [1]
>     for j in range(1, length):
>         weights.append(weights[-1] * (j - 1 - d) / j)
>     return np.array(weights)
>
> # Calcula os pesos h_j para d = 0.4
> d = 0.4
> weights = fractional_diff_weights(d, T)
>
> # Aplica a diferenciaÃ§Ã£o fracionÃ¡ria
> fractional_diff_series = np.convolve(white_noise, weights, mode='full')[:T]
>
> # Plot das sÃ©ries
> plt.figure(figsize=(10, 6))
> plt.plot(white_noise, label='RuÃ­do Branco')
> plt.plot(fractional_diff_series, label=f'SÃ©rie com DiferenciaÃ§Ã£o FracionÃ¡ria (d={d})')
> plt.legend()
> plt.title('SÃ©rie Temporal Original e com DiferenciaÃ§Ã£o FracionÃ¡ria')
> plt.xlabel('Tempo')
> plt.ylabel('Valor')
> plt.show()
> ```
>
> Este cÃ³digo gera um ruÃ­do branco e aplica a diferenciaÃ§Ã£o fracionÃ¡ria com `d=0.4`. O grÃ¡fico resultante mostra que a sÃ©rie diferenciada fracionariamente exibe um comportamento mais suave e dependÃªncias de longo prazo, diferentemente do ruÃ­do branco original. Isso ilustra como valores nÃ£o inteiros de `d` introduzem memÃ³ria de longo prazo.

Para entender o significado de valores nÃ£o inteiros de $d$, considere a representaÃ§Ã£o MA(âˆ) implÃ­cita na equaÃ§Ã£o [15.5.1]. A equaÃ§Ã£o [15.5.2] mostra que multiplicando ambos os lados de [15.5.1] por $(1-L)^{-d}$ obtemos:

$$y_t = (1-L)^{-d}\psi(L)\epsilon_t$$ [15.5.2]

Para entender como $(1-L)^{-d}$ age, considere a funÃ§Ã£o $f(z) = (1-z)^{-d}$. Podemos usar expansÃ£o de Taylor para expressar essa funÃ§Ã£o como uma sÃ©rie de potÃªncias. As derivadas dessa funÃ§Ã£o sÃ£o dadas por:

$$\frac{\partial f}{\partial z} = d(1-z)^{-d-1}$$
$$\frac{\partial^2 f}{\partial z^2} = (d+1)d(1-z)^{-d-2}$$
$$\frac{\partial^3 f}{\partial z^3} = (d+2)(d+1)d(1-z)^{-d-3}$$
$$\frac{\partial^j f}{\partial z^j} = (d+j-1)\ldots(d+1)d(1-z)^{-d-j}$$

A expansÃ£o de sÃ©rie de potÃªncia para $f(z)$ em torno de $z=0$ Ã© dada por:

$$(1-z)^{-d} = f(0) + \frac{1}{1!}\frac{\partial f}{\partial z}|_{z=0}z + \frac{1}{2!}\frac{\partial^2 f}{\partial z^2}|_{z=0}z^2 + \frac{1}{3!}\frac{\partial^3 f}{\partial z^3}|_{z=0}z^3 + \ldots$$

$$= 1 + dz + \frac{(d+1)d}{2!}z^2 + \frac{(d+2)(d+1)d}{3!}z^3 + \ldots$$

Com isso, podemos representar o operador $(1-L)^{-d}$ como um filtro, obtendo a equaÃ§Ã£o [15.5.3]:

$$(1-L)^{-d} = 1 + dL + \frac{(d+1)d}{2!}L^2 + \frac{(d+2)(d+1)d}{3!}L^3 + \ldots = \sum_{j=0}^{\infty} h_jL^j$$ [15.5.3]

onde $h_0 = 1$ e $h_j = \frac{1}{j!}(d+j-1)(d+j-2)\ldots(d+1)d$ [15.5.4]. A equaÃ§Ã£o [15.5.5] estabelece que, para grandes valores de $j$, $h_j$ pode ser aproximado por $h_j \approx (j+1)^{d-1}$ [^1].

A principal diferenÃ§a entre o modelo de diferenciaÃ§Ã£o fracionÃ¡ria e os modelos ARMA tradicionais estÃ¡ na forma como os coeficientes de resposta ao impulso ($h_j$) decaem. Em processos ARMA estacionÃ¡rios, os coeficientes decaem geometricamente, enquanto em processos com diferenciaÃ§Ã£o fracionÃ¡ria, decaem de forma mais lenta [^1]. Isso permite que os modelos de diferenciaÃ§Ã£o fracionÃ¡ria capturem dependÃªncias de longo prazo nas sÃ©ries temporais, ou seja, a memÃ³ria longa.

> ğŸ’¡ **Exemplo NumÃ©rico:** Vamos calcular os primeiros trÃªs coeficientes $h_j$ para $d=0.3$:
>
> $\text{Passo 1: } h_0 = 1$
>
> $\text{Passo 2: } h_1 = \frac{1}{1!}(0.3) = 0.3$
>
> $\text{Passo 3: } h_2 = \frac{1}{2!}(0.3+1)(0.3) = \frac{1}{2}(1.3)(0.3) = 0.195$
>
> Estes coeficientes mostram como o impacto das defasagens $\epsilon_{t-j}$ decresce lentamente com o aumento de $j$. Em modelos ARMA, este decaimento seria muito mais rÃ¡pido, o que ilustra a capacidade da diferenciaÃ§Ã£o fracionÃ¡ria de modelar dependÃªncias de longo prazo.

A equaÃ§Ã£o [15.5.6] apresenta o modelo de sÃ©rie temporal resultante:

$$y_t = (1-L)^{-d}\epsilon_t = h_0\epsilon_t + h_1\epsilon_{t-1} + h_2\epsilon_{t-2} + \ldots$$ [15.5.6]

Ã‰ importante notar que a sequÃªncia dos coeficientes da mÃ©dia mÃ³vel ($h_j$) Ã© somÃ¡vel ao quadrado se $d< \frac{1}{2}$. Caso contrÃ¡rio, a sÃ©rie deve ser diferenciada antes de ser modelada usando as equaÃ§Ãµes [15.5.2] e [15.5.6].

**CondiÃ§Ãµes para IntegraÃ§Ã£o FracionÃ¡ria:** A integraÃ§Ã£o fracionÃ¡ria pode surgir devido Ã  agregaÃ§Ã£o de outros processos. Granger (1980), Geweke e Porter-Hudak (1983) e Sowell (1992) propuseram mÃ©todos para estimar o parÃ¢metro $d$. Diebold e Rudebusch (1989) e Lo (1991) aplicaram essa abordagem para analisar a persistÃªncia em dados de PNB e nos preÃ§os de aÃ§Ãµes, respectivamente [^1].

**Lema 1**
A expansÃ£o do operador $(1-L)^{-d}$ pode ser expressa usando a funÃ§Ã£o gama.
*Proof:*
Provaremos que $h_j = \frac{1}{j!}(d+j-1)(d+j-2)\ldots(d+1)d$ pode ser expressa usando a funÃ§Ã£o gama.

I.  Definimos $h_j = \frac{1}{j!}(d+j-1)(d+j-2)\ldots(d+1)d$.

II.  Multiplicamos e dividimos a expressÃ£o por $\Gamma(d)$, onde $\Gamma$ Ã© a funÃ§Ã£o gama, para introduzir a forma necessÃ¡ria para a funÃ§Ã£o gama.

$$h_j = \frac{1}{j!} \frac{(d+j-1)(d+j-2)\ldots(d+1)d \Gamma(d)}{\Gamma(d)}$$

III.  Reconhecemos que $(d+j-1)(d+j-2)\ldots(d+1)d \Gamma(d)$ Ã© equivalente a $\Gamma(d+j)$.  Portanto:

$$h_j = \frac{\Gamma(d+j)}{j! \Gamma(d)}$$

IV. Usamos a definiÃ§Ã£o de coeficientes binomiais generalizados, que diz que $\binom{n}{k} = \frac{\Gamma(n+1)}{\Gamma(k+1)\Gamma(n-k+1)}$, para expressar $h_j$ na forma de um coeficiente binomial. No nosso caso temos $\binom{d+j-1}{j} = \frac{\Gamma(d+j)}{\Gamma(j+1)\Gamma(d)}$ e $\frac{1}{j!} = \frac{1}{\Gamma(j+1)}$. Assim, temos que

$$h_j = \binom{d+j-1}{j}$$

V. Sabemos que $\binom{n}{k} = (-1)^k \binom{k-n-1}{k}$. Assim, podemos escrever $\binom{d+j-1}{j} = (-1)^j\binom{-d}{j}$. Portanto,

$$h_j =  \binom{-d}{j}(-1)^j$$

VI. Assim, a expansÃ£o do operador pode ser expressa como:
$$(1-L)^{-d} =  \sum_{j=0}^{\infty} \binom{d+j-1}{j} L^j = \sum_{j=0}^{\infty} \frac{\Gamma(d+j)}{\Gamma(j+1) \Gamma(d)} L^j$$
Isso mostra que os coeficientes $h_j$ podem ser expressos usando a funÃ§Ã£o gama. â– 

#### Modelos com Quebras Ocasionais na TendÃªncia

Outra abordagem para modelar nÃ£o estacionariedades Ã© atravÃ©s da incorporaÃ§Ã£o de **quebras ocasionais na tendÃªncia**. Ao contrÃ¡rio dos modelos de raiz unitÃ¡ria que assumem que eventos ocorrem constantemente e afetam permanentemente a sÃ©rie, esta abordagem modela quebras discretas na tendÃªncia [^1]. Um modelo simples com uma quebra pode ser expresso como:

$$y_t = \begin{cases} \alpha_1 + \delta t + \epsilon_t & \text{para } t < T_0 \\ \alpha_2 + \delta t + \epsilon_t & \text{para } t \geq T_0 \end{cases}$$ [15.5.7]

onde $T_0$ Ã© o tempo da quebra. Este modelo sugere que a sÃ©rie Ã© estacionÃ¡ria em torno de uma tendÃªncia com uma quebra no nÃ­vel em $T_0$ [^1].  No entanto, a presenÃ§a dessas quebras pode levar a sÃ©rie a parecer ter um comportamento de raiz unitÃ¡ria quando analisada com testes padrÃ£o [^1].

> ğŸ’¡ **Exemplo NumÃ©rico:** Considere uma sÃ©rie temporal com uma quebra no tempo $T_0 = 50$.
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
>
> # Define parÃ¢metros
> T = 100
> T0 = 50
> alpha1 = 10
> alpha2 = 20
> delta = 0.5
> np.random.seed(42)
> epsilon = np.random.normal(0, 1, T)
>
> # Cria a sÃ©rie temporal com quebra
> time = np.arange(1, T + 1)
> y = np.zeros(T)
> for t in range(T):
>    if t < T0:
>        y[t] = alpha1 + delta * time[t] + epsilon[t]
>    else:
>        y[t] = alpha2 + delta * time[t] + epsilon[t]
>
> # Plot da sÃ©rie temporal
> plt.figure(figsize=(10, 6))
> plt.plot(time, y)
> plt.axvline(x=T0, color='r', linestyle='--', label='Quebra na TendÃªncia')
> plt.title('SÃ©rie Temporal com Quebra na TendÃªncia')
> plt.xlabel('Tempo')
> plt.ylabel('Valor')
> plt.legend()
> plt.show()
> ```
>
> O grÃ¡fico gerado mostra uma clara mudanÃ§a no nÃ­vel da sÃ©rie em $T_0=50$, enquanto a inclinaÃ§Ã£o da tendÃªncia permanece constante. Este exemplo ilustra como uma quebra na tendÃªncia afeta a sÃ©rie temporal.

Uma maneira alternativa de pensar sobre este processo Ã© expressÃ¡-lo como:

$$\Delta y_t = \xi_t + \delta + \epsilon_t - \epsilon_{t-1}$$ [15.5.8]

onde $\xi_t = \alpha_2 - \alpha_1$ se $t = T_0$ e 0 caso contrÃ¡rio [^1]. Se $\xi_t$ Ã© considerada uma variÃ¡vel aleatÃ³ria com distribuiÃ§Ã£o de probabilidade dada por:

$$\xi_t = \begin{cases} \alpha_2 - \alpha_1 & \text{com probabilidade } p \\ 0 & \text{com probabilidade } 1 - p \end{cases}$$

onde $p$ Ã© pequeno, o processo pode ser reescrito como:

$$\Delta y_t = \mu + \eta_t$$ [15.5.9]

onde $\mu = p(\alpha_2 - \alpha_1) + \delta$ e $\eta_t = \xi_t - p(\alpha_2 - \alpha_1) + \epsilon_t - \epsilon_{t-1}$ [^1].  Neste caso, $\eta_t$ Ã© uma soma de um processo de ruÃ­do branco com mÃ©dia zero e um processo MA(1) independente. Assim, $\Delta y_t$ pode ser expressa como um processo ARIMA(0, 1, 1):

$$\Delta y_t = \mu + \nu_t + \theta\nu_{t-1}$$

onde $\nu_t$ Ã© uma distribuiÃ§Ã£o nÃ£o-Gaussiana [^1].

A regra de previsÃ£o linear Ã³tima para este processo Ã© dada por $\mathbb{E}(y_{t+s}|y_t,y_{t-1},\ldots) = \mu s + y_t + \theta\nu_t$, que mostra que as inovaÃ§Ãµes  $\nu_t$ tÃªm peso que nÃ£o desaparece conforme $s \to \infty$. Isso implica que a realizaÃ§Ã£o de uma variÃ¡vel $\xi_t$ tem consequÃªncias permanentes no nÃ­vel da sÃ©rie.

**ProposiÃ§Ã£o 1**
A presenÃ§a de quebras na tendÃªncia pode levar a um viÃ©s na estimativa de parÃ¢metros em modelos de raiz unitÃ¡ria.
*Proof:*
Provaremos que a presenÃ§a de quebras na tendÃªncia pode levar a estimativas viesadas em modelos de raiz unitÃ¡ria.
I. Os testes de raiz unitÃ¡ria, como o teste de Dickey-Fuller, baseiam-se na hipÃ³tese nula de que existe uma raiz unitÃ¡ria na sÃ©rie temporal.
II.  Os testes de raiz unitÃ¡ria analisam a persistÃªncia nos dados. Quebras na tendÃªncia introduzem um comportamento persistente na sÃ©rie temporal, uma vez que a sÃ©rie nÃ£o retorna ao seu nÃ­vel anterior apÃ³s uma quebra.
III. Uma sÃ©rie com uma quebra na tendÃªncia pode parecer ter um comportamento semelhante a uma sÃ©rie com raiz unitÃ¡ria, mesmo que seja de fato estacionÃ¡ria ao redor de uma tendÃªncia com quebras, jÃ¡ que tanto uma raiz unitÃ¡ria quanto uma quebra na tendÃªncia introduzem persistÃªncia na sÃ©rie temporal.
IV. Os testes de raiz unitÃ¡ria padrÃ£o podem ter dificuldade em distinguir entre persistÃªncia devido a raiz unitÃ¡ria e persistÃªncia devido a quebras na tendÃªncia.
V. Se uma sÃ©rie com quebras na tendÃªncia for erroneamente identificada como tendo raiz unitÃ¡ria, a estimativa dos parÃ¢metros em modelos de raiz unitÃ¡ria serÃ¡ afetada pelo viÃ©s induzido pela quebra na tendÃªncia. Isso pode levar a conclusÃµes errÃ´neas sobre a nÃ£o estacionariedade da sÃ©rie temporal.
Portanto, a presenÃ§a de quebras na tendÃªncia pode levar a um viÃ©s na estimativa dos parÃ¢metros em modelos de raiz unitÃ¡ria. â– 

Modelos similares com mudanÃ§as na inclinaÃ§Ã£o da tendÃªncia foram estudados por Lam (1990), onde ele usou cadeias de Markov para modelar as mudanÃ§as na inclinaÃ§Ã£o e permitiu que o PNB real dos EUA seguisse um processo autoregressivo estacionÃ¡rio de terceira ordem em torno dessa tendÃªncia [^1]. Suas descobertas sugerem que os eventos que mudaram permanentemente o nÃ­vel do PNB coincidiram com as recessÃµes de 1957, 1973 e 1980 [^1].

#### Escolhendo o modelo adequado
A escolha entre um modelo trend-stationary, um modelo com raiz unitÃ¡ria ou um modelo com quebras ocasionais na tendÃªncia depende da natureza da sÃ©rie temporal e da questÃ£o de pesquisa. Modelos trend-stationary sÃ£o adequados para sÃ©ries com tendÃªncias determinÃ­sticas, enquanto modelos de raiz unitÃ¡ria sÃ£o mais apropriados para sÃ©ries com tendÃªncias estocÃ¡sticas. Modelos com diferenciaÃ§Ã£o fracionÃ¡ria sÃ£o Ãºteis quando os dados exibem dependÃªncias de longo prazo nÃ£o capturadas por modelos tradicionais. Os modelos com quebras ocasionais na tendÃªncia podem ser mais adequados para sÃ©ries temporais que exibem mudanÃ§as abruptas na tendÃªncia em perÃ­odos especÃ­ficos.

### ConclusÃ£o
Modelar sÃ©ries temporais nÃ£o estacionÃ¡rias Ã© um desafio. Como foi visto, modelos trend-stationary, com raiz unitÃ¡ria, diferenciaÃ§Ã£o fracionÃ¡ria e quebras ocasionais na tendÃªncia sÃ£o abordagens que buscam capturar as nuances destas sÃ©ries. A diferenciaÃ§Ã£o fracionÃ¡ria oferece uma flexibilidade adicional para modelar dependÃªncias de longo prazo, enquanto os modelos de quebra ocasional podem ser mais adequados para sÃ©ries com mudanÃ§as de tendÃªncia discretas. A escolha do modelo adequado depende da natureza dos dados e da pergunta de pesquisa. O entendimento de cada uma dessas abordagens Ã© um passo fundamental para a anÃ¡lise e modelagem eficazes de sÃ©ries temporais nÃ£o estacionÃ¡rias.

### ReferÃªncias
[^1]: CapÃ­tulo 15 do livro "Time Series Analysis" (informaÃ§Ãµes retiradas de todo o capÃ­tulo).
<!-- END -->
