## Integração Fracionária em Séries Temporais Não Estacionárias

### Introdução
Como discutido em capítulos anteriores, a modelagem de séries temporais não estacionárias apresenta desafios devido à presença de tendências e dependências de longo prazo. A **integração fracionária** emerge como uma ferramenta poderosa para modelar essas dependências, representando uma alternativa aos modelos tradicionais de raiz unitária e tendências determinísticas [^1]. Este capítulo explora em detalhes o conceito de integração fracionária, como um processo integrado de ordem *$d$* pode ser representado, e como valores não inteiros de *$d$* (especialmente *$d$* < ½) são usados para capturar a dependência de longo prazo. Além disso, analisaremos a representação MA(∞) de uma série temporal com integração fracionária, investigando as propriedades de decaimento dos coeficientes da resposta ao impulso e a condição de quadrado-somabilidade desses coeficientes [^1].

### Conceitos Fundamentais
#### Representação da Integração Fracionária
Um processo com **integração fracionária** de ordem *$d$* é definido pela seguinte equação:
$$(1-L)^d y_t = \psi(L)\epsilon_t$$ [15.5.1]
onde $L$ é o operador de defasagem, $y_t$ é a série temporal, $\psi(L)$ é um polinômio em $L$ representando uma estrutura de média móvel (MA) e $\epsilon_t$ é um ruído branco. O parâmetro *$d$* pode assumir valores não inteiros, o que diferencia este modelo dos modelos tradicionais de diferenciação inteira [^1].

> A principal diferença entre diferenciação inteira e fracionária reside na forma como o operador $(1-L)$ é aplicado. Na diferenciação inteira, $(1-L)^1$ representa a primeira diferença e $(1-L)^2$ representa a segunda diferença. A integração fracionária permite que *$d$* seja um valor não inteiro, resultando em operações de diferenciação e integração mais sutis [^1].

Para entender a implicação de *$d$* não inteiro, vamos analisar a representação da série temporal $y_t$ em termos de inovações passadas $\epsilon_t$. Manipulando a equação [15.5.1], obtemos:
$$y_t = (1-L)^{-d} \psi(L)\epsilon_t$$ [15.5.2]
A expressão $(1-L)^{-d}$ representa um filtro que pode ser expandido como uma série de potências. Para um escalar *$z$*, podemos definir a função:
$$f(z) = (1-z)^{-d}$$
A série de Taylor de $f(z)$ em torno de $z = 0$ é dada por:
$$f(z) = (1-z)^{-d} = 1 + dz + \frac{(d+1)d}{2!}z^2 + \frac{(d+2)(d+1)d}{3!}z^3 + \ldots$$
Isso nos permite representar o operador $(1-L)^{-d}$ como:
$$(1-L)^{-d} = 1 + dL + \frac{(d+1)d}{2!}L^2 + \frac{(d+2)(d+1)d}{3!}L^3 + \ldots = \sum_{j=0}^{\infty} h_jL^j$$ [15.5.3]
onde os coeficientes $h_j$ são dados por:
$$h_j = \frac{1}{j!}(d+j-1)(d+j-2)\ldots(d+1)d$$ [15.5.4]

A substituição da equação [15.5.3] na equação [15.5.2] nos dá a representação MA(∞):
$$y_t =  \left( \sum_{j=0}^{\infty} h_jL^j \right)  \psi(L)\epsilon_t = \sum_{j=0}^{\infty} a_j\epsilon_{t-j}$$
onde $a_j$ incorpora os coeficientes $h_j$ e os coeficientes do operador $\psi(L)$. A relação recursiva para o cálculo dos coeficientes $h_j$ é dada por:
$$h_0 = 1$$
$$h_j = h_{j-1}\frac{d+j-1}{j}$$
Essa relação recursiva é computacionalmente mais eficiente que a equação [15.5.4].

> 💡 **Exemplo Numérico:**
> Vamos calcular os primeiros coeficientes $h_j$ para $d=0.4$ usando a relação recursiva:
>
> - $h_0 = 1$
> - $h_1 = h_0 \frac{0.4 + 1 - 1}{1} = 1 \cdot \frac{0.4}{1} = 0.4$
> - $h_2 = h_1 \frac{0.4 + 2 - 1}{2} = 0.4 \cdot \frac{1.4}{2} = 0.28$
> - $h_3 = h_2 \frac{0.4 + 3 - 1}{3} = 0.28 \cdot \frac{2.4}{3} = 0.224$
>
> Esses coeficientes representam o peso das inovações passadas $\epsilon_{t-j}$ na determinação do valor atual $y_t$. O fato de eles serem positivos e decrescentes indica que inovações passadas têm influência sobre $y_t$, mas essa influência diminui ao longo do tempo.

#### Dependência de Longo Prazo com Integração Fracionária (d<½)

Valores não inteiros de *$d$*  permitem modelar dependências de longo prazo nas séries temporais [^1]. Em particular, quando *$d$* < ½, os coeficientes $h_j$ da representação MA(∞) decaem lentamente com o aumento de *$j$*, o que indica que inovações passadas têm um efeito persistente sobre a série temporal, embora esse efeito não seja permanente como em modelos com raiz unitária [^1]. O decaimento lento desses coeficientes é caracterizado por um decaimento hiperbólico.

Para grandes valores de *$j$*, podemos usar a seguinte aproximação para os coeficientes $h_j$:
$$h_j \approx (j+1)^{d-1}$$ [15.5.5]
Essa aproximação, para valores de *$d$* < ½, mostra que $h_j$ decai lentamente, mas, ao contrário da raiz unitária (em que *$d$=1), decai para zero à medida que *$j$* aumenta, capturando a dependência de longo prazo, mas mantendo a série estacionária, ainda que marginalmente.

>  A persistência das inovações, ou memória longa, pode ser vista através do decaimento lento das autocorrelações da série temporal. Em modelos estacionários tradicionais, as autocorrelações decaem exponencialmente, enquanto em modelos com integração fracionária, as autocorrelações decaem hiperbolicamente, um comportamento mais lento [^1].

> Para o caso especial em que *$d$=0, temos o processo de ruído branco, caracterizado por $h_0=1$ e $h_j=0$ para $j>0$. Quando *$d$=1, o processo resulta em um passeio aleatório, com $h_j=1$ para todo $j$. Valores de *$d$* entre 0 e 1 podem ser vistos como um interpolador entre essas duas situações [^1].

> 💡 **Exemplo Numérico:**
>
> Vamos comparar o decaimento de $h_j$ para diferentes valores de *$d$*:
>
> - Para $d=0.2$: $h_j \approx (j+1)^{-0.8}$. Assim, $h_1 \approx 1^{-0.8}=1$, $h_5 \approx 6^{-0.8} \approx 0.26$, $h_{10} \approx 11^{-0.8} \approx 0.16$.
> - Para $d=0.4$: $h_j \approx (j+1)^{-0.6}$. Assim, $h_1 \approx 1^{-0.6}=1$, $h_5 \approx 6^{-0.6} \approx 0.45$, $h_{10} \approx 11^{-0.6} \approx 0.29$.
> - Para $d=0.8$: $h_j \approx (j+1)^{-0.2}$. Assim, $h_1 \approx 1^{-0.2}=1$, $h_5 \approx 6^{-0.2} \approx 0.70$, $h_{10} \approx 11^{-0.2} \approx 0.60$.
>
> Observe que para $d=0.2$, os coeficientes decaem mais rapidamente do que para $d=0.4$. No entanto, mesmo com $d=0.4$, o decaimento é hiperbólico, indicando dependência de longo prazo.  Para $d=0.8$, o decaimento é muito mais lento, e os coeficientes são elevados para grandes valores de *$j$*, o que indica não estacionariedade.
>
> ```mermaid
> graph LR
>     A[j] --> B(h_j for d=0.2);
>     A --> C(h_j for d=0.4);
>     A --> D(h_j for d=0.8);
>     style B fill:#f9f,stroke:#333,stroke-width:2px
>     style C fill:#ccf,stroke:#333,stroke-width:2px
>     style D fill:#aaf,stroke:#333,stroke-width:2px
> ```
>
> A visualização acima exemplifica como os coeficientes decrescem em função de *$j$* para cada valor de *$d$*.

#### Quadratura-Somabilidade da Sequência de Coeficientes

Uma propriedade crucial para garantir a estacionariedade da série temporal $y_t$ com integração fracionária é que a sequência de coeficientes $h_j$ seja quadrado-somável, ou seja:

$$\sum_{j=0}^{\infty} h_j^2 < \infty$$
Essa condição implica que a série temporal tem variância finita. No caso de um processo fracionalmente integrado, essa condição é satisfeita se $d < \frac{1}{2}$ [^1].

**Teorema 1:** Se um processo fracionalmente integrado é definido como $(1-L)^d y_t = \psi(L)\epsilon_t$, e a série temporal $y_t$ for representada como uma MA(∞) com coeficientes $a_j$, então a condição de quadrado-somabilidade dos coeficientes $a_j$, $\sum_{j=0}^{\infty} a_j^2 < \infty$, é garantida se e somente se $d < \frac{1}{2}$.

*Prova*:
I. O processo integrado fracionário é definido como $(1-L)^d y_t = \psi(L)\epsilon_t$, que pode ser reescrito como $y_t = (1-L)^{-d} \psi(L)\epsilon_t$.
II. A representação MA(∞) de $y_t$ é $y_t = \sum_{j=0}^{\infty} a_j\epsilon_{t-j}$, onde os coeficientes $a_j$ combinam os efeitos de $(1-L)^{-d}$ e $\psi(L)$.
III. A condição para estacionariedade é que a variância de $y_t$ seja finita, o que requer que a soma dos quadrados dos coeficientes $a_j$ convirja: $\sum_{j=0}^{\infty} a_j^2 < \infty$.
IV. Os coeficientes $h_j$ de $(1-L)^{-d}$ podem ser aproximados para grandes valores de *$j$* como $h_j \approx (j+1)^{d-1}$. Se assumirmos que $\psi(L)$ é um polinômio de ordem finita, então os coeficientes $a_j$ comportam-se assintoticamente como $h_j$.
V.  A soma dos quadrados dos coeficientes $h_j$ é dada por $\sum_{j=0}^{\infty} h_j^2 \approx \sum_{j=0}^{\infty} (j+1)^{2(d-1)}$.
VI. Para que essa soma convirja, é necessário que a integral $\int_{1}^{\infty} x^{2(d-1)}dx$ seja finita.
VII. A integral $\int_{1}^{\infty} x^{2(d-1)}dx$ converge se e somente se $2(d-1) < -1$, o que equivale a $d-1 < -\frac{1}{2}$, ou seja, $d < \frac{1}{2}$.
VIII. Portanto, a condição para que a sequência de coeficientes $a_j$ seja quadrado-somável é que $d < \frac{1}{2}$. ■

**Corolário 1:** Para um processo fracionalmente integrado com *$d$* ≥ ½, a variância da série temporal tende ao infinito conforme o tempo avança.

*Prova:* A prova segue diretamente do Teorema 1. Se $d\ge \frac{1}{2}$, então $\sum_{j=0}^{\infty} h_j^2 = \infty$. Uma vez que a variância de $y_t$ é dada por $\sigma^2_y = \sigma^2 \sum_{j=0}^{\infty} a_j^2$, e os coeficientes $a_j$ incorporam o efeito dos coeficientes $h_j$, a variância de $y_t$ também tenderá ao infinito. Isso indica um comportamento não estacionário da série, característico de processos com raiz unitária ou com integração fracionária de ordem igual ou superior a ½. ■

**Lema 1:** Os coeficientes $h_j$ da expansão $(1-L)^{-d}$ são sempre positivos para $d > 0$.
*Prova:*
  I.  A expressão para $h_j$ é dada por $h_j = \frac{1}{j!}(d+j-1)(d+j-2)\ldots(d+1)d$ (equação 15.5.4).
  II.  Para $j=0$, temos $h_0 = 1$, que é positivo.
  III. Para $j>0$, todos os termos na expressão $(d+j-1), (d+j-2), \ldots, (d+1), d$ são positivos se $d>0$, pois $j$ é um número inteiro positivo.
  IV. O produto de termos positivos é sempre positivo, e $1/j!$ é sempre positivo para qualquer inteiro $j \ge 0$.
  V.  Portanto, $h_j$ é sempre positivo quando $d>0$. ■

**Lema 1.1:** Se $0 < d < 1$, então os coeficientes $h_j$ são monotonicamente decrescentes.
*Prova:*
    I.  Para mostrar que $h_j$ são monotonicamente decrescentes, precisamos provar que $h_j < h_{j-1}$ para todo $j > 0$.
    II.  Sabemos que $h_j = h_{j-1}\frac{d+j-1}{j}$.
    III. Portanto, $h_j < h_{j-1}$ se e somente se $\frac{d+j-1}{j} < 1$.
    IV.  Isso se reduz a $d+j-1 < j$, ou $d < 1$.
    V. Como dado que $0<d<1$, a desigualdade $d<1$ é sempre válida.
    VI. Portanto, os coeficientes $h_j$ são monotonicamente decrescentes para $0<d<1$. ■

**Observação 1:** Lema 1 e Lema 1.1 mostram que para $0 < d < 1$ os coeficientes $h_j$ são positivos e decrescem monotonicamente para zero.

> A condição $d < \frac{1}{2}$ é fundamental para garantir a estacionariedade de um processo fracionalmente integrado. Quando $d < \frac{1}{2}$, a série exibe um comportamento estacionário, apesar da dependência de longo prazo. Isso torna a modelagem de integração fracionária com $d < \frac{1}{2}$ particularmente útil para modelar fenômenos com memória de longo prazo, como em economia e finanças, onde a persistência de inovações é relevante.

> 💡 **Exemplo Numérico:**
> Considere $d = 0.4$ e os coeficientes $h_j$ calculados no exemplo anterior. Vamos verificar se $\sum_{j=0}^{\infty} h_j^2 < \infty$.
>
> Calculamos os primeiros coeficientes:
>
> - $h_0 = 1$
> - $h_1 = 0.4$
> - $h_2 = 0.28$
> - $h_3 = 0.224$
>
> A soma dos quadrados dos primeiros termos é $1^2 + 0.4^2 + 0.28^2 + 0.224^2 = 1 + 0.16 + 0.0784 + 0.050176 \approx 1.2886$. A soma dos quadrados dos coeficientes continua a decrescer, tendendo a um valor finito, como previsto pela teoria ($d < 0.5$).
>
> Agora, se considerarmos um valor de d que não satisfaça essa condição, como $d = 0.6$, teremos:
> - $h_0=1$
> - $h_1 = 0.6$
> - $h_2 = 0.6 \cdot \frac{1.6}{2} = 0.48$
> - $h_3 = 0.48 \cdot \frac{2.6}{3} = 0.416$
>
> Os coeficientes decrescem mais lentamente do que com d=0.4.  Nesse caso, a soma dos quadrados dos coeficientes, $\sum h_j^2$,  não converge e a série não seria estacionária.

> Em contraste, quando $d \geq \frac{1}{2}$, a série torna-se não estacionária, pois as inovações tem efeito não desaparece ao longo do tempo. No caso em que $d=1$, a série é um passeio aleatório, e nos casos em que $d > 1$ a série necessita ser diferenciada para modelagem.

> A modelagem de integração fracionária permite um nível de flexibilidade que não existe nos modelos tradicionais com diferenciação inteira ou raiz unitária. Ao escolher um valor para *$d$* entre 0 e 0.5, podemos controlar o nível de persistência das inovações e modelar séries temporais que se encontram em um ponto intermediário entre séries com memória curta (sem persistência de inovações) e séries com memória infinita (com efeito permanente das inovações).

### Conclusão
A integração fracionária oferece uma abordagem flexível e poderosa para a modelagem de dependências de longo prazo em séries temporais não estacionárias. Ao permitir valores não inteiros para o parâmetro de integração *$d$*, a modelagem de integração fracionária permite capturar a persistência de inovações de maneira mais realista do que os modelos tradicionais de diferenciação inteira ou raiz unitária. A condição de quadrado-somabilidade dos coeficientes da resposta ao impulso, garantida quando *$d$* < ½, assegura a estacionariedade do processo, tornando a integração fracionária uma ferramenta valiosa para modelagem de processos com memória longa. A representação MA(∞), derivada a partir da série de potências, permite uma análise detalhada do comportamento da série, da persistência das inovações e do decaimento dos coeficientes. A compreensão desses conceitos é fundamental para a aplicação correta de modelos com integração fracionária em diversas áreas.

### Referências
[^1]: Capítulo 15 do livro "Time Series Analysis" (informações retiradas de todo o capítulo).
<!-- END -->
