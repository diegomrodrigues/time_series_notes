## Modelagem de Quebras Ocasionais na TendÃªncia: Uma AnÃ¡lise Detalhada

### IntroduÃ§Ã£o
Em continuidade Ã  nossa exploraÃ§Ã£o de modelos para sÃ©ries temporais nÃ£o estacionÃ¡rias, este capÃ­tulo se dedica a uma anÃ¡lise detalhada da modelagem de **quebras ocasionais e discretas na tendÃªncia**, contrastando com a modelagem de uma tendÃªncia constante. Como abordado anteriormente, sÃ©ries temporais podem exibir comportamentos que nÃ£o sÃ£o adequadamente descritos por modelos com tendÃªncias determinÃ­sticas fixas ou por modelos de raiz unitÃ¡ria, e por isso modelos de quebras ocasionais na tendÃªncia surgem como uma alternativa para capturar a dinÃ¢mica de eventos com efeitos discretos e potencialmente permanentes na trajetÃ³ria de uma sÃ©rie [^1]. A introduÃ§Ã£o de quebras na tendÃªncia permite que a sÃ©rie temporal se ajuste a diferentes trajetÃ³rias ao longo do tempo, refletindo eventos econÃ´micos, polÃ­ticos ou tecnolÃ³gicos que possam causar mudanÃ§as abruptas na sua dinÃ¢mica.

### Conceitos Fundamentais

#### Modelagem de Quebras na TendÃªncia

A modelagem de quebras ocasionais na tendÃªncia reconhece que a dinÃ¢mica de uma sÃ©rie temporal $y_t$ pode ser afetada por eventos discretos que causam mudanÃ§as abruptas no nÃ­vel ou na inclinaÃ§Ã£o da tendÃªncia. Ao contrÃ¡rio dos modelos com tendÃªncias determinÃ­sticas lineares ou nÃ£o lineares, que assumem uma trajetÃ³ria suave e contÃ­nua, ou de modelos de raiz unitÃ¡ria, que assumem que inovaÃ§Ãµes causam mudanÃ§as permanentes, mas de forma suave, os modelos com quebras ocasionais na tendÃªncia permitem acomodar mudanÃ§as abruptas causadas por eventos pontuais.

A representaÃ§Ã£o matemÃ¡tica bÃ¡sica de um modelo com uma Ãºnica quebra na tendÃªncia pode ser expressa como:
$$
y_t =
\begin{cases}
    \alpha_1 + \delta t + \epsilon_t & \text{para } t < T_0 \\
    \alpha_2 + \delta t + \epsilon_t & \text{para } t \geq T_0
\end{cases}
$$ [15.5.7]
onde:

*   $y_t$ Ã© a sÃ©rie temporal no tempo $t$.
*   $T_0$ Ã© o ponto no tempo em que ocorre a quebra na tendÃªncia.
*   $\alpha_1$ Ã© o nÃ­vel da tendÃªncia antes da quebra.
*   $\alpha_2$ Ã© o nÃ­vel da tendÃªncia apÃ³s a quebra.
*   $\delta$ Ã© a inclinaÃ§Ã£o da tendÃªncia (assumida constante neste modelo).
*   $\epsilon_t$ Ã© um ruÃ­do branco com mÃ©dia zero e variÃ¢ncia constante $\sigma^2_\epsilon$, representando o componente estocÃ¡stico da sÃ©rie.

Nessa representaÃ§Ã£o, a sÃ©rie temporal segue uma tendÃªncia linear com inclinaÃ§Ã£o $\delta$ atÃ© o tempo $T_0$, quando ocorre uma mudanÃ§a abrupta no nÃ­vel da tendÃªncia de $\alpha_1$ para $\alpha_2$, mantendo a inclinaÃ§Ã£o $\delta$ inalterada. A diferenÃ§a entre $\alpha_2$ e $\alpha_1$ representa a magnitude da quebra no nÃ­vel da tendÃªncia.

> A modelagem de quebras na tendÃªncia Ã© uma ferramenta Ãºtil para modelar sÃ©ries temporais que sÃ£o afetadas por eventos discretos com efeitos significativos, tais como mudanÃ§as na polÃ­tica econÃ´mica, crises financeiras, desastres naturais ou novas tecnologias, que podem levar a alteraÃ§Ãµes abruptas e permanentes na trajetÃ³ria de uma sÃ©rie temporal.

> ğŸ’¡ **Exemplo NumÃ©rico:** Suponha que temos uma sÃ©rie temporal que representa o PIB de um paÃ­s. Antes de uma crise econÃ´mica que ocorre no perÃ­odo $T_0 = 100$, o PIB cresce a uma taxa constante, mas apÃ³s a crise, o nÃ­vel do PIB se ajusta a uma nova trajetÃ³ria, com a mesma inclinaÃ§Ã£o. Os parÃ¢metros do modelo sÃ£o:
> *   $\alpha_1 = 100$ (nÃ­vel inicial do PIB antes da crise)
> *   $\alpha_2 = 90$ (nÃ­vel do PIB apÃ³s a crise)
> *   $\delta = 2$ (crescimento anual do PIB)
> Nesse exemplo, o nÃ­vel do PIB decresceria em 10 unidades no momento da crise, ajustando-se a uma nova trajetÃ³ria. Este cenÃ¡rio pode ser representado com o modelo acima.
>
> Podemos ilustrar a sÃ©rie com uma simulaÃ§Ã£o e um grÃ¡fico:
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
>
> # ParÃ¢metros
> alpha1 = 100
> alpha2 = 90
> delta = 2
> T0 = 100
> n = 200  # NÃºmero total de perÃ­odos
> sigma_epsilon = 5  # Desvio padrÃ£o do ruÃ­do branco
>
> # Gerar ruÃ­do branco
> np.random.seed(42) # Definindo uma seed para reprodutibilidade
> epsilon = np.random.normal(0, sigma_epsilon, n)
>
> # Gerar sÃ©rie temporal
> y = np.zeros(n)
> for t in range(n):
>     if t < T0:
>         y[t] = alpha1 + delta * t + epsilon[t]
>     else:
>         y[t] = alpha2 + delta * t + epsilon[t]
>
> # Plot da sÃ©rie temporal
> plt.figure(figsize=(10, 6))
> plt.plot(range(n), y, label='SÃ©rie Temporal com Quebra')
> plt.axvline(x=T0, color='r', linestyle='--', label='Quebra em T0')
> plt.xlabel('Tempo (t)')
> plt.ylabel('PIB (yt)')
> plt.title('SÃ©rie Temporal com Quebra na TendÃªncia')
> plt.legend()
> plt.grid(True)
> plt.show()
> ```
>
> Este grÃ¡fico demonstra visualmente o efeito da quebra no nÃ­vel da sÃ©rie, onde antes de $T_0=100$ a sÃ©rie segue uma trajetÃ³ria com nÃ­vel $\alpha_1=100$ e apÃ³s $T_0$ o nÃ­vel muda para $\alpha_2=90$, mantendo a mesma inclinaÃ§Ã£o.

#### A RepresentaÃ§Ã£o $\Delta y_t = \mu + \eta_t$ e sua RelaÃ§Ã£o com Modelos de Raiz UnitÃ¡ria

Uma forma alternativa de expressar o modelo com quebras na tendÃªncia Ã© utilizando a primeira diferenÃ§a da sÃ©rie temporal, como jÃ¡ demonstrado em capÃ­tulos anteriores [^1]:
$$ \Delta y_t = \xi_t + \delta + \epsilon_t - \epsilon_{t-1} $$ [15.5.8]
onde $\Delta y_t = y_t - y_{t-1}$ e $\xi_t$ representa a mudanÃ§a no nÃ­vel da sÃ©rie no tempo $T_0$, tal que $\xi_t = \alpha_2 - \alpha_1$ se $t=T_0$ e $\xi_t = 0$ caso contrÃ¡rio.
Essa representaÃ§Ã£o pode ser ainda escrita como:
$$ \Delta y_t = \mu + \eta_t $$ [15.5.9]
onde:
*   $\mu = p(\alpha_2 - \alpha_1) + \delta$ Ã© a mudanÃ§a mÃ©dia por perÃ­odo, englobando o efeito mÃ©dio da quebra ($p$ Ã© a probabilidade da quebra) e da tendÃªncia determinÃ­stica.
*   $\eta_t = \xi_t - p(\alpha_2 - \alpha_1) + \epsilon_t - \epsilon_{t-1}$ representa o desvio da variaÃ§Ã£o mÃ©dia, incorporando os efeitos das quebras e das inovaÃ§Ãµes estocÃ¡sticas.

Essa representaÃ§Ã£o Ã© interessante pois revela a relaÃ§Ã£o entre modelos com quebras ocasionais na tendÃªncia e modelos de raiz unitÃ¡ria.  O processo Ã© visto como um processo com raiz unitÃ¡ria, dado que ao tomar a primeira diferenÃ§a obtemos uma sÃ©rie que se ajusta a um processo estacionÃ¡rio do tipo MA(1).  Contudo, a distribuiÃ§Ã£o de $\eta_t$ nÃ£o Ã© gaussiana, devido Ã  presenÃ§a de $\xi_t$.

>  A formulaÃ§Ã£o $\Delta y_t = \mu + \eta_t$ estabelece que modelos com quebras ocasionais na tendÃªncia podem ser interpretados como uma generalizaÃ§Ã£o de um processo de raiz unitÃ¡ria com inovaÃ§Ãµes nÃ£o gaussianas, ou seja, um modelo com processos integrados, mas onde a distribuiÃ§Ã£o das inovaÃ§Ãµes nÃ£o Ã© normal, e sim, caracterizada por caudas pesadas (isto Ã©, tem mais probabilidade de ocorrÃªncias de eventos extremos).

> ğŸ’¡ **Exemplo NumÃ©rico:**
>  Continuando o exemplo do PIB com uma quebra devido a uma crise econÃ´mica, suponha que $p=0.05$ (probabilidade de quebra por perÃ­odo),  $\alpha_1 = 100$ (nÃ­vel do PIB antes da crise), $\alpha_2 = 90$ (nÃ­vel do PIB apÃ³s a crise) e $\delta = 2$ (crescimento anual do PIB).  EntÃ£o:
>
> $$\mu = 0.05(90 - 100) + 2 = 1.5$$
>
> A mudanÃ§a mÃ©dia por perÃ­odo Ã© de 1.5 unidades, levando em consideraÃ§Ã£o o crescimento anual e a probabilidade de ocorrÃªncia da crise. O termo $\eta_t$ incorpora o desvio da variaÃ§Ã£o mÃ©dia para cada perÃ­odo $t$, devido a possÃ­veis novas quebras e a inovaÃ§Ãµes estocÃ¡sticas.
>
>  Caso nÃ£o haja quebra em um perÃ­odo, $\xi_t = 0$,  e o termo $\eta_t$ se reduz a:
>  $$ \eta_t = -0.05(90 - 100) + \epsilon_t - \epsilon_{t-1} = 0.5 + \epsilon_t - \epsilon_{t-1}$$
>  Ou seja, o desvio da mÃ©dia serÃ¡ funÃ§Ã£o do componente estocÃ¡stico. Caso ocorra uma quebra, por exemplo, em $T_0$, $\xi_{T_0} = -10$, e $\eta_{T_0}$ serÃ¡:
>   $$ \eta_{T_0} = -10 - 0.05(90 - 100) + \epsilon_{T_0} - \epsilon_{T_0-1} = -9.5  + \epsilon_{T_0} - \epsilon_{T_0-1}$$
> O desvio da mÃ©dia serÃ¡ muito maior, representando a magnitude da quebra.
>
>  Podemos analisar os resultados da simulaÃ§Ã£o anterior calculando $\mu$ e $\eta_t$:
>
> ```python
> # CÃ¡lculo de mu
> mu = p * (alpha2 - alpha1) + delta
>
> # CÃ¡lculo de eta
> delta_y = np.diff(y)
> eta = delta_y - mu
>
> # Imprimir os primeiros valores de eta
> print("Primeiros 10 valores de eta:")
> print(eta[:10])
> print("Eta em T0:", eta[T0-1])
> ```
>
> Os primeiros valores de $\eta_t$ mostram o comportamento de desvio da mÃ©dia, que Ã© em torno de 0.5 quando nÃ£o hÃ¡ quebra. O valor de $\eta_t$ em $T_0-1$ demonstra um desvio bem maior, que representa o efeito da quebra.

#### DistribuiÃ§Ã£o NÃ£o Gaussiana das InovaÃ§Ãµes
Uma caracterÃ­stica fundamental da modelagem de quebras ocasionais na tendÃªncia Ã© que a distribuiÃ§Ã£o das inovaÃ§Ãµes $\eta_t$ nÃ£o Ã© gaussiana, devido Ã  presenÃ§a do componente $\xi_t$, que representa a quebra e que assume valores discretos (zero quando nÃ£o hÃ¡ quebra ou o valor $\alpha_2 - \alpha_1$ no tempo da quebra). Modelos de raiz unitÃ¡ria tradicionais, por sua vez, assumem que as inovaÃ§Ãµes seguem uma distribuiÃ§Ã£o gaussiana.

Essa diferenÃ§a na distribuiÃ§Ã£o das inovaÃ§Ãµes tem implicaÃ§Ãµes importantes para a anÃ¡lise estatÃ­stica de sÃ©ries temporais com quebras ocasionais na tendÃªncia:
1. **Teste de Raiz UnitÃ¡ria:** Testes de raiz unitÃ¡ria tradicionais, que sÃ£o baseados na premissa da normalidade dos resÃ­duos, podem nÃ£o ser apropriados para modelos com quebras ocasionais na tendÃªncia. A presenÃ§a de quebras pode levar testes tradicionais a rejeitar incorretamente a hipÃ³tese nula de nÃ£o estacionariedade. Testes robustos Ã  nÃ£o normalidade devem ser utilizados.
2. **EstimaÃ§Ã£o de ParÃ¢metros:** MÃ©todos de estimaÃ§Ã£o baseados na normalidade, como o mÃ©todo de mÃ­nimos quadrados ordinÃ¡rios (OLS), nÃ£o sÃ£o apropriados para modelos com quebras ocasionais na tendÃªncia. MÃ©todos que acomodem a nÃ£o gaussianidade dos resÃ­duos, como mÃ¡xima verossimilhanÃ§a com distribuiÃ§Ãµes de cauda pesada ou mistura de distribuiÃ§Ãµes, sÃ£o mais apropriados.
3. **InferÃªncia EstatÃ­stica:** A inferÃªncia estatÃ­stica sobre os parÃ¢metros dos modelos com quebras ocasionais na tendÃªncia deve ser realizada com cautela, considerando a nÃ£o normalidade dos resÃ­duos. MÃ©todos bayesianos que permitam especificar distribuiÃ§Ãµes a priori nÃ£o gaussianas podem ser utilizados para garantir inferÃªncias mais robustas.

> A nÃ£o gaussianidade das inovaÃ§Ãµes $\eta_t$ nos modelos com quebras ocasionais na tendÃªncia surge da natureza discreta das quebras, que representam eventos raros e pontuais, ao contrÃ¡rio de modelos com raiz unitÃ¡ria em que as inovaÃ§Ãµes podem ser assumidas como gaussianas.

> ğŸ’¡ **Exemplo NumÃ©rico:**
> Para ilustrar como a distribuiÃ§Ã£o de $\eta_t$ se desvia da normalidade, podemos simular uma sÃ©rie temporal com uma quebra e analisar o histograma dos resÃ­duos $\eta_t$.
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
> from scipy.stats import norm
>
> # ParÃ¢metros do modelo
> alpha1 = 100
> alpha2 = 90
> delta = 2
> T0 = 100
> n = 200
> p = 0.05
> sigma_epsilon = 1
>
> # SimulaÃ§Ã£o da sÃ©rie temporal
> np.random.seed(42)
> epsilon = np.random.normal(0, sigma_epsilon, n)
> y = np.zeros(n)
>
> for t in range(n):
>    if t < T0:
>        y[t] = alpha1 + delta * t + epsilon[t]
>    else:
>        y[t] = alpha2 + delta * t + epsilon[t]
>
> # CÃ¡lculo de mu e eta
> mu = p * (alpha2 - alpha1) + delta
> eta = np.diff(y) - mu
>
> # Plot do histograma e da distribuiÃ§Ã£o normal
> plt.figure(figsize=(8, 6))
> plt.hist(eta, bins=30, density=True, alpha=0.6, label='ResÃ­duos Î·t')
> xmin, xmax = plt.xlim()
> x = np.linspace(xmin, xmax, 100)
> mu_eta = np.mean(eta)
> sigma_eta = np.std(eta)
> p_norm = norm.pdf(x, mu_eta, sigma_eta)
> plt.plot(x, p_norm, 'k', linewidth=2, label='DistribuiÃ§Ã£o Normal Ajustada')
> plt.xlabel('Valores de Î·t')
> plt.ylabel('Densidade')
> plt.title('Histograma dos ResÃ­duos e DistribuiÃ§Ã£o Normal Ajustada')
> plt.legend()
> plt.show()
> ```
>
> O histograma dos resÃ­duos $\eta_t$ nÃ£o segue uma distribuiÃ§Ã£o normal, como demonstrado pela comparaÃ§Ã£o com a densidade da distribuiÃ§Ã£o normal, comprovando a nÃ£o gaussianidade das inovaÃ§Ãµes em modelos com quebras ocasionais na tendÃªncia. A maior concentraÃ§Ã£o de resÃ­duos perto de 0 e em valores extremos demonstra a presenÃ§a das caudas pesadas.

**Teorema 1:** Em modelos de quebras ocasionais na tendÃªncia, o termo $\eta_t = \xi_t - p(\alpha_2 - \alpha_1) + \epsilon_t - \epsilon_{t-1}$ segue um processo MA(1) com inovaÃ§Ãµes nÃ£o gaussianas.
*Prova:*
I. A sÃ©rie temporal em primeira diferenÃ§a Ã© dada por $\Delta y_t = \mu + \eta_t$, onde $\eta_t = \xi_t - p(\alpha_2 - \alpha_1) + \epsilon_t - \epsilon_{t-1}$.
II. A funÃ§Ã£o de autocovariÃ¢ncia para $\eta_t$ pode ser calculada como $\gamma_k = E[(\eta_t - E[\eta_t])(\eta_{t-k} - E[\eta_{t-k}])]$.
III. Como $E[\eta_t] = 0$, temos $\gamma_k = E[\eta_t\eta_{t-k}]$.
IV. Para $k=0$, temos $\gamma_0 = E[\eta_t^2]$, que Ã© a variÃ¢ncia de $\eta_t$ e portanto diferente de zero.
V. Para $k=1$, temos $\gamma_1 = E[(\xi_t - p(\alpha_2 - \alpha_1) + \epsilon_t - \epsilon_{t-1})(\xi_{t-1} - p(\alpha_2 - \alpha_1) + \epsilon_{t-1} - \epsilon_{t-2})]$. Como $\xi_t$ sÃ³ Ã© nÃ£o nulo para $t=T_0$, $\epsilon_t$ Ã© ruÃ­do branco, e $\epsilon_t$ Ã© independente de $\xi_t$, resulta $\gamma_1 = - \sigma^2_\epsilon$, que Ã© diferente de zero.
VI. Para $k > 1$, temos $\gamma_k = 0$, devido a independÃªncia entre os termos $\xi_t$ e $\epsilon_t$.
VII. Portanto, a autocovariÃ¢ncia de $\eta_t$ Ã© diferente de zero apenas para o primeiro lag, caracterizando um processo MA(1).
VIII. Como $\xi_t$ assume valores discretos, e $\epsilon_t$ Ã© normal, $\eta_t$ tem uma distribuiÃ§Ã£o nÃ£o gaussiana.
IX. Portanto, $\eta_t$ segue um processo MA(1) com inovaÃ§Ãµes nÃ£o gaussianas.  $\blacksquare$
> O teorema acima demonstra formalmente que o processo $\eta_t$ tem uma distribuiÃ§Ã£o nÃ£o gaussiana e que possui dependÃªncia de primeira ordem, caracterizando um processo MA(1) com inovaÃ§Ãµes nÃ£o gaussianas.

**Teorema 1.1:** A funÃ§Ã£o de autocorrelaÃ§Ã£o de $\eta_t$, denotada por $\rho_k$, Ã© dada por $\rho_1 = \frac{-\sigma^2_\epsilon}{\sigma^2_\eta}$ e $\rho_k = 0$ para $k \neq 1$, onde $\sigma^2_\eta$ Ã© a variÃ¢ncia de $\eta_t$.
*Prova:*
I. Do Teorema 1, sabemos que $\eta_t$ segue um processo MA(1).
II. A funÃ§Ã£o de autocorrelaÃ§Ã£o Ã© definida como $\rho_k = \frac{\gamma_k}{\gamma_0}$, onde $\gamma_k$ Ã© a funÃ§Ã£o de autocovariÃ¢ncia.
III.  Do Teorema 1, temos $\gamma_1 = -\sigma^2_\epsilon$.
IV. TambÃ©m do Teorema 1, temos $\gamma_0 = E[\eta_t^2] = \sigma^2_\eta$.
V. Para $k=1$, temos $\rho_1 = \frac{\gamma_1}{\gamma_0} = \frac{-\sigma^2_\epsilon}{\sigma^2_\eta}$.
VI. Para $k \neq 1$, temos $\gamma_k = 0$, e portanto $\rho_k = 0$.
VII. Assim, a funÃ§Ã£o de autocorrelaÃ§Ã£o de $\eta_t$ Ã© nÃ£o nula apenas para $k=1$ e Ã© dada por $\rho_1 = \frac{-\sigma^2_\epsilon}{\sigma^2_\eta}$.  $\blacksquare$

> ğŸ’¡ **Exemplo NumÃ©rico:**
> Continuando o exemplo do PIB, podemos calcular o valor teÃ³rico da autocorrelaÃ§Ã£o de $\eta_t$ dado o exemplo numÃ©rico anterior.  Assumindo que $\sigma^2_\epsilon = 1$, temos  $\alpha_1 = 100$, $\alpha_2 = 90$ e $p=0.05$.  Do Lema 1.1, $\sigma^2_\eta = 0.05(1-0.05)(90-100)^2 + 2(1) = 0.05 * 0.95 * 100 + 2 = 4.75 + 2 = 6.75$.  Assim, a autocorrelaÃ§Ã£o de primeira ordem Ã© dada por $\rho_1 = \frac{-1}{6.75} \approx -0.148$.
>
> Podemos tambÃ©m calcular empiricamente a funÃ§Ã£o de autocorrelaÃ§Ã£o da sÃ©rie simulada e verificar que o valor se aproxima do valor teÃ³rico:
>
> ```python
> import statsmodels.api as sm
> # CÃ¡lculo da funÃ§Ã£o de autocorrelaÃ§Ã£o (ACF)
> acf = sm.tsa.acf(eta, nlags=10)
>
> # Plot da funÃ§Ã£o de autocorrelaÃ§Ã£o
> plt.figure(figsize=(8, 5))
> plt.stem(range(len(acf)), acf, markerfmt='o', linefmt='-')
> plt.axhline(y=0, color='k', linestyle='--', linewidth=0.8)
> plt.xlabel('Lag (k)')
> plt.ylabel('AutocorrelaÃ§Ã£o')
> plt.title('FunÃ§Ã£o de AutocorrelaÃ§Ã£o (ACF) de Î·t')
> plt.grid(True)
> plt.show()
>
> print("AutocorrelaÃ§Ã£o no lag 1:", acf[1])
> ```
> O grÃ¡fico e o valor da autocorrelaÃ§Ã£o de primeira ordem demonstram que os resultados se aproximam do valor teÃ³rico.

### ImplicaÃ§Ãµes para Modelagem e InferÃªncia
A modelagem de quebras ocasionais na tendÃªncia com a perspectiva de raiz unitÃ¡ria com inovaÃ§Ãµes nÃ£o gaussianas implica as seguintes consideraÃ§Ãµes:
1.  **Teste de Raiz UnitÃ¡ria:** Testes de raiz unitÃ¡ria tradicionais, que assumem normalidade dos resÃ­duos, podem levar Ã  rejeiÃ§Ã£o incorreta da hipÃ³tese nula de nÃ£o estacionariedade. Testes que sejam robustos Ã  nÃ£o normalidade dos resÃ­duos, tais como testes bootstrap, devem ser utilizados.
2.  **EstimaÃ§Ã£o:** A estimaÃ§Ã£o dos parÃ¢metros de modelos com quebras ocasionais na tendÃªncia deve ser feita usando mÃ©todos que nÃ£o assumam a normalidade dos resÃ­duos. MÃ©todos de mÃ¡xima verossimilhanÃ§a com distribuiÃ§Ãµes de cauda pesada ou mistura de distribuiÃ§Ãµes podem ser usados. MÃ©todos bayesianos podem ser mais adequados pois permitem incorporar incertezas com relaÃ§Ã£o ao modelo, e nÃ£o somente aos parÃ¢metros, alÃ©m de serem uma forma natural de incorporar conhecimento a priori sobre a ocorrÃªncia e magnitude das quebras.
3.  **InferÃªncia:** A inferÃªncia sobre os parÃ¢metros deve ser realizada com cautela, utilizando intervalos de confianÃ§a que levem em conta a nÃ£o normalidade dos resÃ­duos. MÃ©todos bootstrap ou inferÃªncia bayesiana podem ser apropriados.
4. **PrevisÃ£o:** A previsÃ£o de sÃ©ries com quebras ocasionais na tendÃªncia requer modelos nÃ£o lineares que incorporem a probabilidade de ocorrÃªncia de novas quebras e a incerteza sobre a sua magnitude. A previsÃ£o pode ser realizada por meio de simulaÃ§Ãµes com diferentes cenÃ¡rios para a ocorrÃªncia das quebras.
5. **ComparaÃ§Ã£o com outros modelos:** A comparaÃ§Ã£o com modelos de tendÃªncia determinÃ­stica ou de raiz unitÃ¡ria deve levar em conta nÃ£o somente o ajuste do modelo aos dados, mas tambÃ©m a capacidade de cada modelo de capturar a dinÃ¢mica da sÃ©rie e a interpretaÃ§Ã£o econÃ´mica dos parÃ¢metros.
6.  **Robustez:** A anÃ¡lise de robustez dos resultados, variando os parÃ¢metros e as premissas do modelo, Ã© fundamental para garantir a confiabilidade das conclusÃµes.

**ProposiÃ§Ã£o 1:** MÃ©todos de mÃ­nimos quadrados ordinÃ¡rios (OLS) geram estimadores enviesados e inconsistentes para modelos com quebras ocasionais na tendÃªncia.

*Proof:*
I. A representaÃ§Ã£o do modelo com quebras Ã© dada por $\Delta y_t = \mu + \eta_t$, onde $\eta_t = \xi_t - p(\alpha_2 - \alpha_1) + \epsilon_t - \epsilon_{t-1}$.
II. O mÃ©todo OLS assume que os resÃ­duos tÃªm mÃ©dia zero, variÃ¢ncia constante, e sÃ£o nÃ£o correlacionados.
III. Em modelos com quebras ocasionais na tendÃªncia, $\eta_t$ nÃ£o Ã© um ruÃ­do branco pois tem autocorrelaÃ§Ã£o de primeira ordem e nÃ£o possui distribuiÃ§Ã£o gaussiana.
IV. Como resultado, os estimadores OLS sÃ£o enviesados e inconsistentes.
V. Portanto, OLS nÃ£o Ã© um mÃ©todo apropriado para estimaÃ§Ã£o de parÃ¢metros em modelos com quebras ocasionais na tendÃªncia. $\blacksquare$
> ğŸ’¡ **Exemplo NumÃ©rico:**
> Para ilustrar a ineficiÃªncia de OLS, podemos estimar o modelo $\Delta y_t = \mu + \eta_t$ usando OLS e comparar os resultados com os parÃ¢metros conhecidos.
>
> ```python
> import statsmodels.api as sm
>
> # EstimaÃ§Ã£o do modelo usando OLS
> X = np.ones((len(delta_y), 1))  # Matriz com apenas uma coluna de 1s
> model = sm.OLS(delta_y, X)
> results = model.fit()
>
> # Resultados da estimaÃ§Ã£o
> print(results.summary())
>
> # Imprimir o valor estimado de mu e o valor real
> mu_hat = results.params[0]
> print("Valor Estimado de mu (OLS):", mu_hat)
> print("Valor Real de mu:", mu)
>
> ```
> Os resultados da estimaÃ§Ã£o demonstram que o estimador de $\mu$ via OLS Ã© diferente do valor real, o que demonstra o viÃ©s do mÃ©todo. O summary tambÃ©m mostra que os resÃ­duos nÃ£o sÃ£o normais, indicando que o modelo OLS nÃ£o Ã© apropriado.

**CorolÃ¡rio 1.1:** Testes de hipÃ³teses baseados nos resultados da estimaÃ§Ã£o por OLS para modelos com quebras ocasionais nÃ£o sÃ£o confiÃ¡veis.

*Proof:*
I. Pela ProposiÃ§Ã£o 1, estimadores OLS sÃ£o enviesados e inconsistentes em modelos com quebras ocasionais na tendÃªncia.
II. Testes de hipÃ³teses sÃ£o baseados nos resultados de estimaÃ§Ã£o, especialmente em desvios padrÃµes e estatÃ­sticas de teste calculados a partir dos estimadores.
III. Como os estimadores OLS sÃ£o enviesados e inconsistentes, seus desvios padrÃµes e estatÃ­sticas de teste nÃ£o sÃ£o vÃ¡lidos.
IV. Portanto, testes de hipÃ³teses baseados em estimadores OLS em modelos com quebras ocasionais nÃ£o sÃ£o confiÃ¡veis. $\blacksquare$

**Lema 1:** A autocovariÃ¢ncia da sÃ©rie $\Delta y_t$ nos modelos com quebras ocasionais Ã© nÃ£o nula apenas no primeiro lag.
*Prova:*
I. Pelo Teorema 1, $\eta_t$ segue um processo MA(1)
II. A sÃ©rie $\Delta y_t$ Ã© dada por $\Delta y_t = \mu + \eta_t$.
III. Como a autocovariÃ¢ncia de uma constante Ã© zero,  a autocovariÃ¢ncia de $\Delta y_t$ Ã© dada por $Cov(\Delta y_t, \Delta y_{t-k}) = Cov(\eta_t, \eta_{t-k})$.
IV. A autocovariÃ¢ncia de $\eta_t$ Ã© nÃ£o nula apenas para k=1, como demonstrado pelo Teorema 1.
V. Portanto, a autocovariÃ¢ncia de $\Delta y_t$ Ã© nÃ£o nula apenas para k=1. $\blacksquare$
> O lema acima demonstra que a sÃ©rie em primeira diferenÃ§a, nos modelos com quebras ocasionais na tendÃªncia, possui uma autocorrelaÃ§Ã£o de primeira ordem, o que justifica a modelagem de $\eta_t$ como um processo MA(1).

**Lema 1.1:** A variÃ¢ncia de $\eta_t$, denotada por $\sigma^2_\eta$, Ã© dada por $\sigma^2_\eta = p(1-p)(\alpha_2 - \alpha_1)^2 + 2\sigma^2_\epsilon$.
*Prova:*
I. Sabemos que $\eta_t = \xi_t - p(\alpha_2 - \alpha_1) + \epsilon_t - \epsilon_{t-1}$.
II. A variÃ¢ncia de $\eta_t$ Ã© $Var(\eta_t) = E[(\eta_t - E[\eta_t])^2]$.
III. Como $E[\eta_t] = 0$, temos $Var(\eta_t) = E[\eta_t^2] = E[(\xi_t - p(\alpha_2 - \alpha_1) + \epsilon_t - \epsilon_{t-1})^2]$.
IV. Expandindo o quadrado, obtemos $Var(\eta_t) = E[\xi_t^2] + p^2(\alpha_2 - \alpha_1)^2 + E[(\epsilon_t - \epsilon_{t-1})^2] + 2E[\xi_t(-p(\alpha_2 - \alpha_1) + \epsilon_t - \epsilon_{t-1})]$.
V.  Como $E[\xi_t] = p(\alpha_2-\alpha_1)$, temos $E[\xi_t^2] = Var(\xi_t) + [E(\xi_t)]^2 = p(1-p)(\alpha_2-\alpha_1)^2 + p^2(\alpha_2-\alpha_1)^2$.
VI. Como $\xi_t$ Ã© independente de $\epsilon_t$ e $\epsilon_{t-1}$, temos $2E[\xi_t(-p(\alpha_2 - \alpha_1) + \epsilon_t - \epsilon_{t-1})] = 2E[\xi_t(-p(\alpha_2 - \alpha_1))] = -2p^2(\alpha_2-\alpha_1)^2$
VII. TambÃ©m $E[(\epsilon_t - \epsilon_{t-1})^2] = E[\epsilon_t^2 - 2\epsilon_t\epsilon_{t-1} + \epsilon_{t-1}^2] = 2\sigma^2_\epsilon$.
VIII.  Assim, $Var(\eta_t) = p(1-p)(\alpha_2-\alpha_1)^2 + p^2(\alpha_2-\alpha_1)^2 + p^2(\alpha_2-\alpha_1)^2 - 2p^2(\alpha_2-\alpha_1)^2+ 2\sigma^2_\epsilon = p(1-p)(\alpha_2-\alpha_1)^2 + 2\sigma^2_\epsilon$.
IX. Portanto, a variÃ¢ncia de $\eta_t$ Ã© $\sigma^2_\eta = p(1-p)(\alpha_2 - \alpha_1)^2 + 2\sigma^2_\epsilon$. $\blacksquare$
> ğŸ’¡ **Exemplo NumÃ©rico:**
> Usando os valores do exemplo anterior $(\alpha_1=100, \alpha_2=90, p=0.05, \sigma^2_\epsilon = 1)$, a variÃ¢ncia de $\eta_t$ pode ser calculada como:
> $\sigma^2_\eta = 0.05(1-0.05)(90-100)^2 + 2(1) = 0.05 * 0.95 * 100 + 2 = 4.75 + 2 = 6.75$.  Podemos comparar o resultado com a variÃ¢ncia empÃ­rica calculada anteriormente:
>
> ```python
> # CÃ¡lculo da variÃ¢ncia empÃ­rica de eta
> var_eta_emp = np.var(eta)
>
> # CÃ¡lculo da variÃ¢ncia teÃ³rica de eta
> var_eta_teorica = p * (1-p) * (alpha2 - alpha1)**2 + 2 * sigma_epsilon**2
>
> print("VariÃ¢ncia empÃ­rica de eta:", var_eta_emp)
> print("VariÃ¢ncia teÃ³rica de eta:", var_eta_teorica)
>
> ```
> Os resultados demonstram que a variÃ¢ncia empÃ­rica se aproxima do valor teÃ³rico, confirmando o Lema 1.1.

### ConclusÃ£o
A modelagem de quebras ocasionais na tendÃªncia oferece uma abordagem flexÃ­vel e realista para a anÃ¡lise de sÃ©ries temporais nÃ£o estacionÃ¡rias. A formulaÃ§Ã£o $\Delta y_t = \mu + \eta_t$, juntamente com a interpretaÃ§Ã£o como uma generalizaÃ§Ã£o de modelos de raiz unitÃ¡ria com inovaÃ§Ãµes nÃ£o gaussianas, permite uma melhor compreensÃ£o da dinÃ¢mica de sÃ©ries temporais que sÃ£o afetadas por eventos discretos. A necessidade de mÃ©todos de estimaÃ§Ã£o e inferÃªncia que acomodem a nÃ£o gaussianidade das inovaÃ§Ãµes Ã© crucial para obter resultados confiÃ¡veis. A modelagem de quebras ocasionais na tendÃªncia representa um avanÃ§o em relaÃ§Ã£o aos modelos tradicionais, permitindo uma anÃ¡lise mais precisa e uma melhor compreensÃ£o da dinÃ¢mica de sÃ©ries temporais em diversas Ã¡reas do conhecimento.
### ReferÃªncias
[^1]: CapÃ­tulo 15 do livro "Time Series Analysis" (informaÃ§Ãµes retiradas de todo o capÃ­tulo).
<!-- END -->
