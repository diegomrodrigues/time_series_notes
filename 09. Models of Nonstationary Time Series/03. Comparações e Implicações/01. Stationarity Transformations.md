## Transforma√ß√µes para Estacionaridade: Modelos com Tend√™ncia vs. Raiz Unit√°ria

### Introdu√ß√£o
Este cap√≠tulo explora modelos de s√©ries temporais n√£o estacion√°rias, com foco em como as abordagens para modelar tend√™ncias e ra√≠zes unit√°rias afetam a an√°lise e o tratamento dos dados. Anteriormente, discutimos modelos estacion√°rios [^1], nos quais a expectativa incondicional da vari√°vel √© constante e as previs√µes convergem para essa m√©dia a longo prazo [^1]. No entanto, muitas s√©ries temporais econ√¥micas e financeiras exibem tend√™ncias que requerem modelagem espec√≠fica [^1]. Abordamos duas formas populares de lidar com essas tend√™ncias: a inclus√£o de uma tend√™ncia de tempo determin√≠stica e a modelagem da s√©rie como um processo de raiz unit√°ria [^1]. Agora, vamos nos aprofundar em como as transforma√ß√µes necess√°rias para alcan√ßar a estacionaridade diferem entre esses dois tipos de modelos.

### Conceitos Fundamentais
#### Modelos com Tend√™ncia Determin√≠stica
Modelos com tend√™ncia determin√≠stica, como apresentado na equa√ß√£o [15.1.2] [^1], substituem a m√©dia constante do processo estacion√°rio por uma fun√ß√£o linear do tempo:

$$y_t = \alpha + \delta t + \psi(L)\epsilon_t$$

Nesses modelos, a s√©rie √© considerada *trend-stationary*, pois ao subtrair a tend√™ncia $\alpha + \delta t$, o processo resultante $\psi(L)\epsilon_t$ torna-se estacion√°rio [^1]. Assim, a transforma√ß√£o necess√°ria para tornar a s√©rie estacion√°ria √© simplesmente remover essa tend√™ncia linear.

> üí° **Exemplo Num√©rico:** Suponha que temos uma s√©rie temporal $y_t$ que representa o n√∫mero de vendas de um produto ao longo de 10 per√≠odos, dada por $y_t = 5 + 2t + \epsilon_t$, onde $\epsilon_t$ √© um ru√≠do branco com m√©dia 0 e desvio padr√£o 1. Os dados brutos seriam:
```python
import numpy as np
import matplotlib.pyplot as plt

np.random.seed(42)
t = np.arange(1, 11)
alpha = 5
delta = 2
epsilon = np.random.normal(0, 1, 10)
y_t = alpha + delta * t + epsilon

plt.figure(figsize=(8, 4))
plt.plot(t, y_t, marker='o')
plt.title("S√©rie Temporal com Tend√™ncia Linear")
plt.xlabel("Tempo (t)")
plt.ylabel("y_t")
plt.grid(True)
plt.show()

```
Para tornar essa s√©rie estacion√°ria, removemos a tend√™ncia linear: $\hat{y_t} = y_t - (5 + 2t) = \epsilon_t$. O processo resultante $\epsilon_t$ √© estacion√°rio.
```python
y_t_detrended = y_t - (alpha + delta*t)

plt.figure(figsize=(8, 4))
plt.plot(t, y_t_detrended, marker='o')
plt.title("S√©rie Temporal Detrended")
plt.xlabel("Tempo (t)")
plt.ylabel("y_t - (5 + 2t)")
plt.grid(True)
plt.show()
```
Isso ilustra como a remo√ß√£o da tend√™ncia linear transforma a s√©rie em um processo estacion√°rio.
 

**Observa√ß√£o 1**
√â importante notar que a fun√ß√£o de tend√™ncia n√£o precisa ser estritamente linear. Poder√≠amos generalizar para uma fun√ß√£o polinomial do tempo, como $y_t = \alpha + \delta_1 t + \delta_2 t^2 + \psi(L)\epsilon_t$, ou mesmo outras fun√ß√µes determin√≠sticas do tempo. O ponto chave √© que a tend√™ncia √© uma fun√ß√£o conhecida e determin√≠stica do tempo que, ao ser removida, deixa o processo residual estacion√°rio.

#### Modelos com Raiz Unit√°ria
Em contraste, modelos com raiz unit√°ria, descritos na equa√ß√£o [15.1.3] [^1], representam a s√©rie como:

$$(1-L)y_t = \delta + \psi(L)\epsilon_t$$

Aqui, a s√©rie n√£o √© estacion√°ria em seu n√≠vel, mas a sua primeira diferen√ßa $(1-L)y_t$ √©. A diferen√ßa, tamb√©m denotada por $\Delta y_t$, captura as varia√ß√µes na s√©rie [^2]. Para atingir a estacionaridade em modelos com raiz unit√°ria, a transforma√ß√£o requerida √© a diferencia√ß√£o da s√©rie, em vez de uma simples subtra√ß√£o de uma tend√™ncia determin√≠stica.

> üí° **Exemplo Num√©rico:** Consideremos uma s√©rie temporal que segue um processo de random walk com drift: $y_t = y_{t-1} + 0.5 + \epsilon_t$, onde $\epsilon_t$ √© um ru√≠do branco. Se simularmos 100 passos, a s√©rie resultante apresentar√° uma tend√™ncia estoc√°stica:
```python
import numpy as np
import matplotlib.pyplot as plt
np.random.seed(42)
n = 100
delta = 0.5
epsilon = np.random.normal(0, 1, n)
y_t = np.zeros(n)
y_t[0] = 0
for t in range(1, n):
    y_t[t] = y_t[t-1] + delta + epsilon[t]
plt.figure(figsize=(8, 4))
plt.plot(range(n), y_t)
plt.title("Random Walk com Drift")
plt.xlabel("Tempo (t)")
plt.ylabel("y_t")
plt.grid(True)
plt.show()

```
Aplicando a diferencia√ß√£o, obtemos $\Delta y_t = y_t - y_{t-1} = 0.5 + \epsilon_t$. O resultado √© uma s√©rie estacion√°ria em torno de 0.5.
```python
delta_y_t = np.diff(y_t)

plt.figure(figsize=(8, 4))
plt.plot(range(n-1), delta_y_t)
plt.title("S√©rie Diferenciada")
plt.xlabel("Tempo (t)")
plt.ylabel("Œîy_t")
plt.grid(True)
plt.show()
```
Este exemplo demonstra como a diferencia√ß√£o transforma uma s√©rie n√£o estacion√°ria em uma estacion√°ria em modelos com raiz unit√°ria.

**Lema 1** A opera√ß√£o de diferencia√ß√£o, $(1-L)$, √© um filtro passa-altas, que enfatiza as mudan√ßas de curto prazo e atenua as flutua√ß√µes de baixa frequ√™ncia ou de longo prazo. Isto √© facilmente visto ao considerar a transforma√ß√£o no dom√≠nio da frequ√™ncia.
*Prova*:
I. Aplicando a Transformada de Fourier ao operador de diferen√ßa $(1-L)$, obtemos $1 - e^{-j\omega}$, onde $\omega$ representa a frequ√™ncia.
II. A magnitude desta fun√ß√£o √© dada por $|1 - e^{-j\omega}|$.
III. Usando a identidade de Euler, $e^{-j\omega} = \cos(\omega) - j\sin(\omega)$, temos $|1 - e^{-j\omega}| = |1 - (\cos(\omega) - j\sin(\omega))| = |(1 - \cos(\omega)) + j\sin(\omega)|$.
IV. A magnitude √© ent√£o dada por $\sqrt{(1 - \cos(\omega))^2 + \sin^2(\omega)}$.
V. Expandindo, obtemos $\sqrt{1 - 2\cos(\omega) + \cos^2(\omega) + \sin^2(\omega)}$.
VI. Usando a identidade trigonom√©trica $\cos^2(\omega) + \sin^2(\omega) = 1$, simplificamos para $\sqrt{2 - 2\cos(\omega)}$.
VII. Quando $\omega$ se aproxima de zero (baixas frequ√™ncias), $\cos(\omega)$ se aproxima de 1, e a magnitude se aproxima de $\sqrt{2-2} = 0$.
VIII. Quando $\omega$ se aproxima de $\pi$ (altas frequ√™ncias), $\cos(\omega)$ se aproxima de -1, e a magnitude se aproxima de $\sqrt{2 - 2(-1)} = \sqrt{4} = 2$.
IX. Assim, a diferencia√ß√£o atenua baixas frequ√™ncias e enfatiza altas frequ√™ncias, agindo como um filtro passa-altas. ‚ñ†

#### Diferen√ßas na Transforma√ß√£o
A diferen√ßa crucial entre os modelos com tend√™ncia e raiz unit√°ria reside no tratamento necess√°rio para atingir a estacionaridade [^10]. Em um modelo com tend√™ncia, a s√©rie torna-se estacion√°ria ap√≥s a remo√ß√£o de uma tend√™ncia linear ou, mais genericamente, uma fun√ß√£o determin√≠stica do tempo. Por outro lado, em modelos com raiz unit√°ria, a estacionaridade √© alcan√ßada ao tomar as diferen√ßas da s√©rie [^10].

√â fundamental notar que, se aplicarmos incorretamente a diferencia√ß√£o a uma s√©rie que √© trend-stationary, o processo resultante introduzir√° uma raiz unit√°ria no componente de m√©dia m√≥vel, resultando em um processo n√£o invert√≠vel que pode apresentar dificuldades adicionais na modelagem e interpreta√ß√£o [^10].

**Teorema 1** Aplicar diferencia√ß√£o a uma s√©rie *trend-stationary* resulta em uma s√©rie n√£o invert√≠vel.

*Prova*:
I. Seja $y_t = \alpha + \delta t + \psi(L)\epsilon_t$ uma s√©rie *trend-stationary*, onde $\psi(L) = \sum_{i=0}^{\infty} \psi_i L^i$ √© um operador polinomial de defasagem.
II. A primeira diferen√ßa √© $\Delta y_t = y_t - y_{t-1}$.
III. Substituindo $y_t$, temos $\Delta y_t = (\alpha + \delta t + \psi(L)\epsilon_t) - (\alpha + \delta (t-1) + \psi(L)\epsilon_{t-1})$.
IV. Simplificando, obtemos $\Delta y_t = \delta + \psi(L)\epsilon_t - \psi(L)\epsilon_{t-1} = \delta + \psi(L)\epsilon_t - L\psi(L)\epsilon_t = \delta + (1-L)\psi(L)\epsilon_t$.
V. O termo $(1-L)\psi(L)$ pode ser reescrito como $(1-L)\sum_{i=0}^{\infty} \psi_i L^i = \sum_{i=0}^{\infty} \psi_i L^i - \sum_{i=0}^{\infty} \psi_i L^{i+1}$.
VI. Expandindo e reagrupando os termos, temos $\psi_0 + \sum_{i=1}^{\infty} \psi_i L^i - \sum_{i=0}^{\infty} \psi_i L^{i+1} = \psi_0 + \sum_{i=1}^{\infty} \psi_i L^i - \sum_{i=1}^{\infty} \psi_{i-1} L^i = \psi_0 + \sum_{i=1}^{\infty} (\psi_i - \psi_{i-1})L^i$.
VII. A presen√ßa do fator $(1-L)$ no termo de erro introduz uma raiz unit√°ria na representa√ß√£o da m√©dia m√≥vel.
VIII. Esta raiz unit√°ria resulta em um processo n√£o invert√≠vel, indicando que o processo de m√©dia m√≥vel n√£o ter√° uma representa√ß√£o √∫nica. ‚ñ†

#### Implica√ß√µes Matem√°ticas
A necessidade de diferencia√ß√£o em modelos com raiz unit√°ria decorre do fato de que a vari√¢ncia do processo original ($y_t$) cresce com o tempo [^10]. Isso √© demonstrado no contexto de um random walk com drift [15.1.4]:

$$y_t = y_{t-1} + \delta + \epsilon_t$$
 
Neste caso, a vari√¢ncia de $y_t$ cresce linearmente com o tempo, e n√£o √© suficiente apenas remover a tend√™ncia $\delta t$. Ao tomar a primeira diferen√ßa, a vari√¢ncia resultante torna-se constante ao longo do tempo:

$$\Delta y_t = y_t - y_{t-1} = \delta + \epsilon_t$$
Onde a vari√¢ncia de $\Delta y_t$ √© igual a $\sigma^2$ [^10], a vari√¢ncia do ru√≠do branco $\epsilon_t$.

**Proposi√ß√£o 1**
Para um random walk com drift, definido recursivamente por $y_t = y_{t-1} + \delta + \epsilon_t$, com $y_0 = 0$, a vari√¢ncia de $y_t$ cresce linearmente com o tempo. Al√©m disso, $\mathbb{E}[y_t] = \delta t$ e $\text{Var}(y_t) = t\sigma^2$.

*Prova*:
I. Come√ßamos com a defini√ß√£o recursiva $y_t = y_{t-1} + \delta + \epsilon_t$, com $y_0=0$.
II. Expandindo recursivamente, temos $y_1 = \delta + \epsilon_1$, $y_2 = y_1 + \delta + \epsilon_2 = 2\delta + \epsilon_1 + \epsilon_2$, $y_3 = y_2 + \delta + \epsilon_3 = 3\delta + \epsilon_1 + \epsilon_2 + \epsilon_3$, e assim por diante.
III. Em geral, $y_t = t\delta + \sum_{i=1}^{t} \epsilon_i$.
IV. Tomando a esperan√ßa, $\mathbb{E}[y_t] = \mathbb{E}[t\delta + \sum_{i=1}^{t} \epsilon_i] = t\delta + \sum_{i=1}^{t} \mathbb{E}[\epsilon_i]$. Dado que $\mathbb{E}[\epsilon_i] = 0$ para todo $i$, temos $\mathbb{E}[y_t] = \delta t$.
V. Calculando a vari√¢ncia, $\text{Var}(y_t) = \text{Var}(t\delta + \sum_{i=1}^{t} \epsilon_i)$. Como $t\delta$ √© constante, $\text{Var}(y_t) = \text{Var}(\sum_{i=1}^{t} \epsilon_i)$.
VI. Assumindo que os $\epsilon_i$ s√£o independentes e t√™m vari√¢ncia $\sigma^2$, ent√£o $\text{Var}(\sum_{i=1}^{t} \epsilon_i) = \sum_{i=1}^{t} \text{Var}(\epsilon_i) = \sum_{i=1}^{t} \sigma^2 = t\sigma^2$.
VII. Portanto, a vari√¢ncia de $y_t$ cresce linearmente com o tempo, $\text{Var}(y_t) = t\sigma^2$. ‚ñ†

> üí° **Exemplo Num√©rico:**  Considerando o exemplo anterior de random walk com drift, podemos calcular a m√©dia e a vari√¢ncia em diferentes pontos no tempo para verificar a proposi√ß√£o 1. Usando a s√©rie simulada de 100 pontos, calculemos a m√©dia e vari√¢ncia para $t=25, 50,$ e $75$.
```python
import numpy as np

np.random.seed(42)
n = 100
delta = 0.5
sigma_sq = 1
epsilon = np.random.normal(0, 1, n)
y_t = np.zeros(n)
y_t[0] = 0
for t in range(1, n):
    y_t[t] = y_t[t-1] + delta + epsilon[t]

t_values = [25, 50, 75]
for t in t_values:
  mean_yt = np.mean(y_t[:t])
  var_yt = np.var(y_t[:t])
  theoretical_mean = delta*t
  theoretical_var = t * sigma_sq
  print(f"t = {t}, M√©dia Emp√≠rica: {mean_yt:.2f}, M√©dia Te√≥rica: {theoretical_mean:.2f}, Vari√¢ncia Emp√≠rica: {var_yt:.2f}, Vari√¢ncia Te√≥rica: {theoretical_var:.2f}")
```
Isso confirma que, √† medida que o tempo aumenta, a m√©dia emp√≠rica se aproxima de $\delta t$ e a vari√¢ncia emp√≠rica se aproxima de $t\sigma^2$. Este comportamento de vari√¢ncia crescente com o tempo evidencia que a s√©rie original n√£o √© estacion√°ria e a necessidade da transforma√ß√£o por diferencia√ß√£o para atingir a estacionaridade.

### Conclus√£o
A an√°lise e modelagem de s√©ries temporais n√£o estacion√°rias exigem um tratamento cuidadoso da tend√™ncia ou da raiz unit√°ria presentes nos dados. A distin√ß√£o fundamental entre os modelos com tend√™ncia e raiz unit√°ria reside na transforma√ß√£o necess√°ria para alcan√ßar a estacionaridade [^10]:
-   Modelos com tend√™ncia determin√≠stica: Subtrair a tend√™ncia de tempo determin√≠stica ($\alpha + \delta t$) para obter uma s√©rie estacion√°ria [^1].
-   Modelos com raiz unit√°ria: Diferenciar a s√©rie (ou seja, calcular as primeiras diferen√ßas $\Delta y_t$) para obter a estacionaridade [^1].

A aplica√ß√£o inadequada de diferencia√ß√£o a uma s√©rie trend-stationary pode levar a um processo n√£o estacion√°rio e n√£o invert√≠vel. Assim, compreender a natureza da n√£o estacionariedade √© crucial para a escolha do modelo apropriado e para realizar transforma√ß√µes adequadas, que permitam a obten√ß√£o de insights precisos sobre o comportamento da s√©rie temporal. O tratamento matem√°tico diferenciado destes dois modelos reflete a sua natureza estat√≠stica distinta e a necessidade de abordagens espec√≠ficas para o seu estudo.

### Refer√™ncias
[^1]: Cap√≠tulo 15, Se√ß√£o 15.1. Introdu√ß√£o.
[^2]: Cap√≠tulo 15, Se√ß√£o 15.1, Equa√ß√£o 15.1.4.
[^10]: Cap√≠tulo 15, Se√ß√£o 15.3, subse√ß√£o "Transformations to Achieve Stationarity"
<!-- END -->
