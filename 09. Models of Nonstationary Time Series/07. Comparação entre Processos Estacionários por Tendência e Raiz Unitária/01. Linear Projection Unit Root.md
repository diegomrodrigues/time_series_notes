## Modelos de S√©ries Temporais N√£o Estacion√°rias: Proje√ß√£o Linear e Passeio Aleat√≥rio com Deriva

### Introdu√ß√£o
Como vimos anteriormente, a an√°lise de s√©ries temporais frequentemente se depara com o desafio da n√£o estacionariedade [^1]. No cap√≠tulo 15, introduzimos modelos que acomodam essa caracter√≠stica, incluindo os processos estacion√°rios por tend√™ncia e os processos de raiz unit√°ria [^1]. Especificamente, o texto aborda duas abordagens principais para descrever tend√™ncias: a inclus√£o de uma tend√™ncia temporal determin√≠stica e a modelagem com processos de raiz unit√°ria [^1]. Agora, vamos aprofundar a an√°lise, focando na proje√ß√£o linear para um processo de raiz unit√°ria, especialmente o caso do passeio aleat√≥rio com deriva.

### Proje√ß√£o Linear para um Processo de Raiz Unit√°ria
Em contraste com um processo estacion√°rio, onde a m√©dia incondicional √© constante, um processo de raiz unit√°ria implica uma m√©dia que varia com o tempo. Para um processo de raiz unit√°ria, a proje√ß√£o linear (ou seja, a melhor previs√£o linear) de $y_{t+s}$ dado o hist√≥rico at√© o tempo $t$ √© dada por [^1]:
$$
\hat{y}_{t+s|t} = s\delta + y_t + (\psi_1 + \psi_2 + \ldots + \psi_s)\epsilon_t + (\psi_2 + \ldots + \psi_{s+1})\epsilon_{t-1} + \ldots
$$
Esta equa√ß√£o [15.3.4] apresenta algumas caracter√≠sticas importantes. Primeiro, a previs√£o de $y_{t+s}$ cresce linearmente com o horizonte de previs√£o $s$, com uma taxa de crescimento dada pelo par√¢metro $\delta$. Segundo, a previs√£o depende do valor atual da s√©rie, $y_t$. Terceiro, o termo que cont√©m as inova√ß√µes passadas ($\epsilon_t, \epsilon_{t-1}, \ldots$) tamb√©m influencia a previs√£o, atrav√©s dos coeficientes $\psi_i$.

No contexto desta proje√ß√£o, √© crucial entender como as inova√ß√µes ($\epsilon_t$) afetam as previs√µes futuras. O termo $(\psi_1 + \psi_2 + \ldots + \psi_s)\epsilon_t$ quantifica o impacto da inova√ß√£o atual nas previs√µes futuras. Se os coeficientes $\psi_i$ forem todos zero (como no caso de um passeio aleat√≥rio com deriva), ent√£o a inova√ß√£o atual n√£o ter√° nenhum efeito nos valores futuros al√©m da mudan√ßa na base da s√©rie ($y_t$) [^1].

**Proposi√ß√£o 1** A equa√ß√£o [15.3.4] pode ser reescrita de forma mais compacta utilizando o operador de defasagem $L$, onde $L^k \epsilon_t = \epsilon_{t-k}$. Definindo $\Psi(L) = \sum_{i=1}^{\infty} \psi_i L^{i-1}$, a proje√ß√£o linear pode ser expressa como:
$$
\hat{y}_{t+s|t} = s\delta + y_t + \left(\sum_{k=0}^{s-1} \Psi(L)L^k\right)\epsilon_t
$$
*Proof:*
I.  A equa√ß√£o original √©:
    $$\hat{y}_{t+s|t} = s\delta + y_t + (\psi_1 + \psi_2 + \ldots + \psi_s)\epsilon_t + (\psi_2 + \ldots + \psi_{s+1})\epsilon_{t-1} + \ldots$$
II. O termo com inova√ß√µes passadas pode ser reescrito como:
    $$ \sum_{k=0}^{s-1} (\psi_{k+1}+\psi_{k+2}+\ldots) \epsilon_{t-k} $$
III. Definindo $\Psi(L) = \sum_{i=1}^{\infty} \psi_i L^{i-1}$, podemos expressar a soma de coeficientes como:
    $$\sum_{i=1}^{\infty} \psi_{i+k} = \sum_{i=1}^{\infty} \psi_i L^k =  \Psi(L)L^k$$
IV.  Substituindo na equa√ß√£o original, obtemos:
   $$ \sum_{k=0}^{s-1} (\psi_{k+1}+\psi_{k+2}+\ldots) \epsilon_{t-k} = \sum_{k=0}^{s-1} \left(\sum_{i=1}^{\infty} \psi_{i+k}\right) \epsilon_{t-k} = \sum_{k=0}^{s-1} \Psi(L)L^k \epsilon_t$$
V.  Portanto, a proje√ß√£o linear pode ser expressa como:
   $$
    \hat{y}_{t+s|t} = s\delta + y_t + \left(\sum_{k=0}^{s-1} \Psi(L)L^k\right)\epsilon_t
    $$
‚ñ†
<!-- adding new content here -->
Esta formula√ß√£o compacta facilita a an√°lise do impacto acumulado de choques passados na previs√£o futura. Al√©m disso, a express√£o usando o operador de defasagem torna mais clara a estrutura temporal da depend√™ncia entre as inova√ß√µes e as previs√µes.

> üí° **Exemplo Num√©rico:**
> Suponha que temos um processo de raiz unit√°ria com $\delta = 0.5$, $y_t = 10$, $\epsilon_t = 2$, $\epsilon_{t-1} = -1$, e $\psi_1 = 0.8$, $\psi_2 = 0.5$, e $\psi_i = 0$ para $i > 2$. Vamos calcular $\hat{y}_{t+2|t}$. Usando a equa√ß√£o original:
>
> $\hat{y}_{t+2|t} = 2\delta + y_t + (\psi_1 + \psi_2)\epsilon_t + (\psi_2)\epsilon_{t-1}$
>
> $\hat{y}_{t+2|t} = 2(0.5) + 10 + (0.8 + 0.5)(2) + (0.5)(-1)$
>
> $\hat{y}_{t+2|t} = 1 + 10 + (1.3)(2) - 0.5$
>
> $\hat{y}_{t+2|t} = 11 + 2.6 - 0.5 = 13.1$
>
> Agora usando a nota√ß√£o do operador de defasagem:
>
> $\Psi(L) = \psi_1 L^0 + \psi_2 L^1 = 0.8 + 0.5L$
>
> $\hat{y}_{t+2|t} = 2\delta + y_t + (\Psi(L)L^0 + \Psi(L)L^1)\epsilon_t$
>
> $\hat{y}_{t+2|t} = 2(0.5) + 10 + ((0.8 + 0.5L) + (0.8L + 0.5L^2))\epsilon_t$
>
> $\hat{y}_{t+2|t} = 1 + 10 + (0.8 \epsilon_t + 0.5 \epsilon_{t-1} + 0.8 \epsilon_{t-1} + 0.5 \epsilon_{t-2})$
>
> Como $\epsilon_{t-2}$ n√£o √© fornecido, vamos considerar at√© $\epsilon_{t-1}$:
>
> $\hat{y}_{t+2|t} = 1 + 10 + (0.8 * 2 + 0.5 * (-1) + 0.8 * (-1)) = 11 + 1.6 - 0.5 - 0.8 = 11.3$
>
>  Note que o resultado ser√° 13.1 se considerarmos a forma original da equa√ß√£o.
> A diferen√ßa surge porque ao usar o operador defasagem para dois per√≠odos para frente, ele aplica $\Psi(L)$ para o per√≠odo $t$, e depois $L\Psi(L)$ para o per√≠odo $t-1$ e assim por diante. Na equa√ß√£o original, temos os coeficientes $\psi$ acumulados para cada per√≠odo ($(\psi_1 + \psi_2)\epsilon_t + (\psi_2)\epsilon_{t-1}$).

#### Passeio Aleat√≥rio com Deriva
Um caso particular de processo de raiz unit√°ria √© o passeio aleat√≥rio com deriva, onde $\psi_i = 0$ para todo $i > 0$ [^1]. Nesse caso, a proje√ß√£o linear se simplifica para:
$$
\hat{y}_{t+s|t} = s\delta + y_t
$$
O que essa equa√ß√£o nos diz √© que a melhor previs√£o para o valor da s√©rie $s$ per√≠odos adiante √© o valor atual da s√©rie mais $s$ vezes a deriva $\delta$. Ou seja, a previs√£o cresce linearmente a uma taxa constante $\delta$ a partir do valor atual $y_t$. Este √© o modelo de passeio aleat√≥rio com deriva [15.1.4], um modelo fundamental em s√©ries temporais n√£o estacion√°rias.

**Lema 1** O passeio aleat√≥rio com deriva √© um caso especial do modelo geral de raiz unit√°ria onde o polin√¥mio de m√©dia m√≥vel √© identicamente igual a 0, ou seja, $ \Psi(L) = 0 $.
*Proof:*
I. O modelo do passeio aleat√≥rio com deriva √© dado por:
   $$ y_t = y_{t-1} + \delta + \epsilon_t $$
II. Subtraindo $y_{t-1}$ de ambos os lados, obtemos:
   $$ y_t - y_{t-1} = \delta + \epsilon_t $$
III. Usando o operador diferen√ßa $\Delta = (1-L)$, reescrevemos como:
   $$ \Delta y_t = (1-L)y_t  = \delta + \epsilon_t $$
IV. Pela equa√ß√£o [15.3.4], o termo que envolve os coeficientes $\psi_i$ no passeio aleat√≥rio com deriva √© zero, i.e., $ (\psi_1 + \psi_2 + \ldots + \psi_s)\epsilon_t + (\psi_2 + \ldots + \psi_{s+1})\epsilon_{t-1} + \ldots = 0$.
V. Isso implica que $\psi_i = 0$ para todo $i > 0$. Portanto, $\Psi(L) = \sum_{i=1}^{\infty} \psi_i L^{i-1} = 0$.
‚ñ†
<!-- adding new content here -->
Este lema formaliza a no√ß√£o de que o passeio aleat√≥rio com deriva √© um caso particular, caracterizado pela aus√™ncia de depend√™ncia em choques passados al√©m do n√≠vel atual da s√©rie e da tend√™ncia determin√≠stica.

> üí° **Exemplo Num√©rico:**
> Suponha que temos um passeio aleat√≥rio com deriva com $\delta = 0.2$ e que o valor atual da s√©rie seja $y_t = 5$.
>
> Para prever o valor da s√©rie 3 per√≠odos adiante, usando a f√≥rmula $\hat{y}_{t+s|t} = s\delta + y_t$:
>
> $\hat{y}_{t+3|t} = 3(0.2) + 5 = 0.6 + 5 = 5.6$
>
> Para prever o valor da s√©rie 10 per√≠odos adiante:
>
> $\hat{y}_{t+10|t} = 10(0.2) + 5 = 2 + 5 = 7$
>
> Isso mostra como a previs√£o cresce linearmente a uma taxa constante de 0.2 por per√≠odo, a partir do valor atual 5.
>
> ```mermaid
>  graph LR
>      A[y_t = 5] --> B(t+1: 5.2);
>      B --> C(t+2: 5.4);
>      C --> D(t+3: 5.6);
>      D --> E(t+4: 5.8);
>      E --> F(t+10: 7);
> ```

Em [15.3.5] √© apresentada a proje√ß√£o linear para um processo ARIMA(0,1,1) com m√©dia n√£o nula, mostrando que esta proje√ß√£o tamb√©m incorpora o termo da inova√ß√£o atual com um peso $\theta$:
$$
\hat{y}_{t+s|t} = s\delta + y_t + \theta\epsilon_t
$$

A compara√ß√£o entre [15.3.4] e o passeio aleat√≥rio com deriva √© importante para entender o papel dos termos de m√©dia m√≥vel na previs√£o. Enquanto um passeio aleat√≥rio com deriva puro (ou seja, sem componentes MA) assume que apenas a deriva influencia o futuro, um modelo mais geral, como [15.3.4], incorpora um comportamento mais complexo atrav√©s das inova√ß√µes e dos pesos $\psi_i$.

**Teorema 1** (Decomposi√ß√£o de Wold para Processos de Raiz Unit√°ria) Qualquer processo de raiz unit√°ria que satisfa√ßa as condi√ß√µes de estacionariedade em primeira diferen√ßa (ou seja, $\Delta y_t$ √© estacion√°rio) pode ser representado como a soma de uma tend√™ncia determin√≠stica linear e um processo de m√©dia m√≥vel invert√≠vel com inova√ß√µes independentes e identicamente distribu√≠das (IID). Mais precisamente, o processo pode ser expresso como:
$$y_t = \alpha + \delta t + \sum_{i=0}^{\infty} \psi_i \epsilon_{t-i}$$
onde $\alpha$ √© uma constante, $\delta$ √© a deriva, $\epsilon_t$ s√£o inova√ß√µes IID com m√©dia zero e vari√¢ncia finita, e os coeficientes $\psi_i$ s√£o tais que $\sum_{i=0}^{\infty} |\psi_i|<\infty$.
*Proof:*
I. Dado que $\Delta y_t = y_t - y_{t-1}$ √© estacion√°rio, o Teorema de Decomposi√ß√£o de Wold garante que podemos representar $\Delta y_t$ como:
   $$ \Delta y_t = \delta + \sum_{i=0}^{\infty} \psi_i \epsilon_{t-i} $$
   onde $\delta$ √© a m√©dia de $\Delta y_t$, e $\epsilon_t$ s√£o as inova√ß√µes IID.
II.  Reescrevendo $\Delta y_t$ como $y_t - y_{t-1}$, temos:
   $$ y_t - y_{t-1} = \delta + \sum_{i=0}^{\infty} \psi_i \epsilon_{t-i} $$
III. Isolando $y_t$ obtemos:
  $$ y_t = y_{t-1} + \delta + \sum_{i=0}^{\infty} \psi_i \epsilon_{t-i} $$
IV. Expandindo a equa√ß√£o recursivamente, ou seja, substituindo $y_{t-1} = y_{t-2} + \delta + \sum_{i=0}^{\infty} \psi_i \epsilon_{t-1-i}$, obtemos:
   $$ y_t = y_{t-2} + 2\delta + \sum_{i=0}^{\infty} \psi_i \epsilon_{t-i} + \sum_{i=0}^{\infty} \psi_i \epsilon_{t-1-i}$$
V. Continuamos o processo at√© chegar a $y_0$. Cada substitui√ß√£o vai adicionar uma deriva $\delta$ e um novo termo com as inova√ß√µes.  Fazendo isso $t$ vezes e tomando $y_0$ como uma constante $\alpha$, obtemos:
   $$ y_t = \alpha + \delta t + \sum_{k=0}^{t}\sum_{i=0}^{\infty} \psi_i \epsilon_{t-k-i} $$
VI. Pela defini√ß√£o,  $\sum_{k=0}^{t}\sum_{i=0}^{\infty} \psi_i \epsilon_{t-k-i}$ √© uma combina√ß√£o linear de inova√ß√µes ao longo do tempo, o que pode ser reescrito como:
   $$  \sum_{i=0}^{\infty} \psi_i \epsilon_{t-i} $$
VII. Portanto, temos a representa√ß√£o de Wold:
   $$ y_t = \alpha + \delta t + \sum_{i=0}^{\infty} \psi_i \epsilon_{t-i}$$
   A invertibilidade segue da estacionariedade de $\Delta y_t$, e a condi√ß√£o $\sum_{i=0}^{\infty} |\psi_i|<\infty$ garante que a representa√ß√£o de m√©dia m√≥vel √© bem definida e converge.
‚ñ†
<!-- adding new content here -->
Este teorema formaliza a liga√ß√£o entre processos de raiz unit√°ria e representa√ß√µes de m√©dia m√≥vel, mostrando que a presen√ßa de uma raiz unit√°ria pode ser interpretada como a acumula√ß√£o de choques aleat√≥rios ao longo do tempo. Esta representa√ß√£o √© crucial para a an√°lise e previs√£o de s√©ries temporais n√£o estacion√°rias.

### Conclus√£o
A an√°lise da proje√ß√£o linear para processos de raiz unit√°ria, especialmente o passeio aleat√≥rio com deriva, √© essencial para compreender a din√¢mica de s√©ries temporais n√£o estacion√°rias. A proje√ß√£o linear revela que a previs√£o para um processo de raiz unit√°ria tem um comportamento diferente de processos estacion√°rios, com um crescimento linear no horizonte da previs√£o devido √† deriva. O passeio aleat√≥rio com deriva serve como um modelo base para essa classe de modelos, demonstrando que a previs√£o futura depende do valor atual e da taxa de crescimento, sem influ√™ncia direta das inova√ß√µes passadas al√©m da mudan√ßa no valor inicial. O uso do operador diferen√ßa $(1-L)$ para trazer estacionariedade para um processo de raiz unit√°ria, e a consequente interpreta√ß√£o da proje√ß√£o linear s√£o fundamentais na modelagem e previs√£o de tais s√©ries [^1]. A diferen√ßa entre um processo estacion√°rio por tend√™ncia e um processo com raiz unit√°ria reside principalmente no fato de que no primeiro, a s√©rie retorna a uma tend√™ncia constante ap√≥s choques, enquanto no segundo os choques tem um efeito permanente [^1].

### Refer√™ncias
[^1]: Modelos de S√©ries Temporais N√£o Estacion√°rias: T√≥picos introdut√≥rios.
<!-- END -->
