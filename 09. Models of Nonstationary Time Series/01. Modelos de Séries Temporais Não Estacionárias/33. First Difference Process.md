## Modelos com Raiz Unit√°ria: An√°lise da Primeira Diferen√ßa e suas Implica√ß√µes

### Introdu√ß√£o
Este cap√≠tulo explora em detalhes o conceito de **processo de raiz unit√°ria**, com foco na aplica√ß√£o do **operador de primeira diferen√ßa (1-L)** e na interpreta√ß√£o da m√©dia do processo resultante [^1], [^2]. Como vimos em cap√≠tulos anteriores, modelos com raiz unit√°ria s√£o fundamentais para modelar s√©ries temporais n√£o estacion√°rias, caracterizadas pela persist√™ncia de choques e pela vari√¢ncia n√£o constante ao longo do tempo [^3], [^4], [^5]. Ao aplicar o operador de primeira diferen√ßa a um processo com raiz unit√°ria, obtemos uma nova s√©rie que, sob certas condi√ß√µes, se torna estacion√°ria. Este cap√≠tulo ir√° analisar a defini√ß√£o formal de um processo de raiz unit√°ria, o significado do operador de primeira diferen√ßa, a interpreta√ß√£o da m√©dia do processo resultante e suas implica√ß√µes para a modelagem e a previs√£o de s√©ries temporais.

### Defini√ß√£o Formal de um Processo de Raiz Unit√°ria
Um processo de raiz unit√°ria √© definido pela seguinte equa√ß√£o:
$$ (1-L)y_t = \delta + \psi(L)\epsilon_t $$ [^1]
Onde:
*   $y_t$ √© a s√©rie temporal original, n√£o estacion√°ria.
*   $L$ √© o operador de retardo (lag operator), tal que $Ly_t = y_{t-1}$.
*   $(1-L)$ √© o operador de primeira diferen√ßa, que pode ser denotado como $\Delta y_t = y_t - y_{t-1}$.
*   $\delta$ √© uma constante, representando a deriva ou o crescimento m√©dio da s√©rie ap√≥s a diferencia√ß√£o.
*   $\psi(L)\epsilon_t$ √© um processo estacion√°rio que captura a depend√™ncia temporal dos res√≠duos ap√≥s a diferencia√ß√£o, onde $\epsilon_t$ √© um ru√≠do branco com m√©dia zero e vari√¢ncia constante $\sigma^2$, e $\psi(L)$ √© um operador de m√©dias m√≥veis (MA) ou um operador ARMA.

A equa√ß√£o define que a primeira diferen√ßa da s√©rie $y_t$ (i.e. $\Delta y_t$) √© igual a uma constante $\delta$, mais um componente estacion√°rio $\psi(L)\epsilon_t$. √â fundamental entender que a s√©rie original $y_t$ √© n√£o estacion√°ria, e que a diferencia√ß√£o √© o procedimento que remove a n√£o estacionaridade, ou seja, transforma a s√©rie em um processo estacion√°rio.

#### O Operador de Primeira Diferen√ßa e a Estacionaridade
O operador de primeira diferen√ßa $(1-L)$ desempenha um papel fundamental na transforma√ß√£o de s√©ries n√£o estacion√°rias em estacion√°rias. A aplica√ß√£o desse operador remove a raiz unit√°ria presente na s√©rie original $y_t$. Ao aplicar o operador de primeira diferen√ßa, a nova s√©rie resultante $(1-L)y_t = y_t - y_{t-1}$ representa a varia√ß√£o da s√©rie original de um per√≠odo para o seguinte, removendo a depend√™ncia temporal na m√©dia.
Como vimos anteriormente [^4], a presen√ßa de uma raiz unit√°ria no polin√¥mio caracter√≠stico do operador autoregressivo de um processo implica que o processo n√£o √© estacion√°rio, ou seja, sua m√©dia e vari√¢ncia n√£o s√£o constantes no tempo. A aplica√ß√£o do operador de primeira diferen√ßa tem como objetivo remover essa raiz unit√°ria, obtendo uma nova s√©rie temporal que pode ser modelada com abordagens estacion√°rias.

> üí° **Exemplo Num√©rico:**
>
>  Considere um passeio aleat√≥rio com deriva, dado por $y_t = y_{t-1} + \delta + \epsilon_t$.  Aplicando o operador de primeira diferen√ßa, obtemos:
>
>  $(1-L)y_t = y_t - y_{t-1} = \delta + \epsilon_t$
>
>  A s√©rie resultante $(1-L)y_t$ √© estacion√°ria, com m√©dia $\delta$ e vari√¢ncia $\sigma^2$, enquanto a s√©rie original $y_t$ √© n√£o estacion√°ria.
>
>  Este exemplo ilustra como o operador de primeira diferen√ßa remove a raiz unit√°ria do processo original, transformando-o em um processo estacion√°rio.
>
>  Suponha que temos a seguinte s√©rie temporal para os 5 primeiros per√≠odos: $y = [10, 12, 14.5, 16, 17.8]$, e que $\delta = 0.5$. A s√©rie de diferen√ßas seria:
>  $\Delta y = y_t - y_{t-1} = [12-10, 14.5-12, 16-14.5, 17.8-16] = [2, 2.5, 1.5, 1.8]$.
>
>  O valor m√©dio da s√©rie diferenciada √© $\frac{2 + 2.5 + 1.5 + 1.8}{4} = 1.95$, que √© uma estimativa da deriva $\delta$, considerando ru√≠do.

**Proposi√ß√£o 1:** O operador de primeira diferen√ßa $(1-L)$, ao transformar uma s√©rie com raiz unit√°ria em outra s√©rie, remove a depend√™ncia temporal na m√©dia da s√©rie original, obtendo um processo estacion√°rio ou com uma m√©dia constante.
*Prova:*
I. Um processo de raiz unit√°ria pode ser expresso como $(1-L)y_t = \delta + \psi(L)\epsilon_t$, onde $(1-L)$ √© o operador de primeira diferen√ßa, e $\psi(L)\epsilon_t$ √© um processo estacion√°rio.
II. A aplica√ß√£o do operador $(1-L)$ sobre a s√©rie $y_t$ elimina a raiz unit√°ria que causa a n√£o estacionaridade, resultando em uma nova s√©rie $\Delta y_t = (1-L)y_t$.
III. Esta nova s√©rie possui uma m√©dia constante dada por $E[\Delta y_t] = \delta$ e uma vari√¢ncia constante, e portanto √© um processo estacion√°rio ou com m√©dia constante.
IV. A remo√ß√£o da raiz unit√°ria e a obten√ß√£o de um processo estacion√°rio (ou de m√©dia constante) demonstra que o operador de primeira diferen√ßa remove a depend√™ncia temporal na m√©dia. $\blacksquare$

**Proposi√ß√£o 1.1:** Se a s√©rie original $y_t$ possui uma raiz unit√°ria, ent√£o a s√©rie $\Delta y_t = (1-L)y_t$ n√£o possui uma raiz unit√°ria.
*Prova:*
I.  Um processo com raiz unit√°ria satisfaz a equa√ß√£o $(1-L)y_t = \delta + \psi(L)\epsilon_t$.
II.  Se $\Delta y_t = (1-L)y_t$  tivesse uma raiz unit√°ria, ent√£o existiria um operador de primeira diferen√ßa $(1-L)$ tal que $(1-L)\Delta y_t$ resultasse em um processo estacion√°rio.
III.  No entanto, isso implicaria que $(1-L)^2 y_t$ √© estacion√°rio, o que n√£o √© o caso geral para processos com uma √∫nica raiz unit√°ria. Em geral, para processos com uma √∫nica raiz unit√°ria, apenas uma aplica√ß√£o do operador $(1-L)$ √© necess√°ria para garantir estacionaridade.
IV. Portanto, a s√©rie $\Delta y_t = (1-L)y_t$ n√£o possui raiz unit√°ria. $\blacksquare$

### A M√©dia do Processo com Raiz Unit√°ria Ap√≥s a Diferencia√ß√£o
Na defini√ß√£o do processo de raiz unit√°ria, a m√©dia do processo $(1-L)y_t$ √© dada por $\delta$, em vez de $\mu$. Essa diferen√ßa na nota√ß√£o destaca que a m√©dia do processo original, n√£o estacion√°rio, n√£o √© uma constante √∫til para a modelagem, e que, portanto, √© a m√©dia do processo ap√≥s a aplica√ß√£o do operador de primeira diferen√ßa que deve ser considerada, que nesse caso √© igual a $\delta$.
Formalmente, a m√©dia do processo $(1-L)y_t$ √© dada por:
$$E[(1-L)y_t] = E[\delta + \psi(L)\epsilon_t] = \delta + E[\psi(L)\epsilon_t] = \delta$$
Dado que $E[\epsilon_t] = 0$ e que $\psi(L)\epsilon_t$ √© um processo estacion√°rio com m√©dia zero. Portanto, a m√©dia do processo ap√≥s a diferencia√ß√£o √© igual √† deriva $\delta$, e n√£o a $\mu$.
A diferencia√ß√£o remove a tend√™ncia da m√©dia da s√©rie original, que n√£o √© constante ao longo do tempo, e o que resta √© a taxa de crescimento m√©dia do processo, dada por $\delta$.

> üí° **Exemplo Num√©rico:**
>
>  Suponha um passeio aleat√≥rio com deriva, onde $(1-L)y_t = 0.2 + \epsilon_t$.  A m√©dia do processo ap√≥s a diferencia√ß√£o, $(1-L)y_t$, √© $E[(1-L)y_t] = 0.2$.
>
>  Se o processo fosse  $(1-L)y_t = 0.2 + 0.8\epsilon_{t-1} + \epsilon_t$,  a m√©dia do processo ap√≥s a diferencia√ß√£o, $(1-L)y_t$ √© $E[(1-L)y_t] = 0.2 + 0.8E[\epsilon_{t-1}] + E[\epsilon_t] = 0.2$, pois a m√©dia de um ru√≠do branco √© zero.
>
>   O valor de $\delta$ representa a m√©dia do crescimento da s√©rie transformada, ou seja, a taxa de crescimento m√©dia da s√©rie original.
>
>   Vamos considerar uma s√©rie simulada de 10 per√≠odos:
>   ```python
>   import numpy as np
>   np.random.seed(42)
>   delta = 0.2
>   epsilon = np.random.normal(0, 1, 10)
>   y_diff = delta + epsilon
>   y = np.cumsum(y_diff)
>   print("S√©rie original (cumsum da s√©rie diferenciada):", y)
>   print("S√©rie diferenciada:", y_diff)
>   print("M√©dia da s√©rie diferenciada:", np.mean(y_diff))
>  ```
>   A sa√≠da desse c√≥digo mostrar√° que a m√©dia da s√©rie diferenciada est√° pr√≥xima de $\delta = 0.2$ (com pequenas varia√ß√µes devido √† natureza aleat√≥ria dos $\epsilon_t$).
>
>    A s√©rie original, obtida com `np.cumsum(y_diff)`,  √© a soma acumulada da s√©rie diferenciada, e ser√° claramente n√£o estacion√°ria.

**Lema 1:** O valor $\delta$ no processo de raiz unit√°ria $(1-L)y_t = \delta + \psi(L)\epsilon_t$ representa a taxa m√©dia de crescimento da s√©rie original $y_t$.
*Prova:*
I. A equa√ß√£o $(1-L)y_t = \delta + \psi(L)\epsilon_t$ implica que $y_t - y_{t-1} = \delta + \psi(L)\epsilon_t$.
II.  O termo $y_t - y_{t-1}$ representa a varia√ß√£o (crescimento) da s√©rie entre dois per√≠odos consecutivos.
III. Ao tomar a m√©dia da equa√ß√£o, temos: $E[y_t - y_{t-1}] = E[\delta + \psi(L)\epsilon_t] = \delta + E[\psi(L)\epsilon_t] = \delta$, pois $E[\psi(L)\epsilon_t] = 0$ para um processo estacion√°rio com m√©dia zero.
IV. Portanto, $\delta$ representa o crescimento m√©dio da s√©rie original $y_t$. $\blacksquare$

**Lema 1.1:** Se $\delta = 0$, ent√£o o processo $(1-L)y_t = \psi(L)\epsilon_t$ tem m√©dia zero.
*Prova:*
I. Dado que $(1-L)y_t = \delta + \psi(L)\epsilon_t$.
II. Se $\delta = 0$, ent√£o $(1-L)y_t = \psi(L)\epsilon_t$.
III. Tomando a esperan√ßa, $E[(1-L)y_t] = E[\psi(L)\epsilon_t] = 0$, pois $\psi(L)\epsilon_t$ √© um processo estacion√°rio com m√©dia zero.
IV. Portanto, se $\delta = 0$, o processo $(1-L)y_t$ tem m√©dia zero. $\blacksquare$

### Implica√ß√µes da M√©dia Œ¥ na Modelagem
A m√©dia do processo ap√≥s a diferencia√ß√£o, dada por $\delta$, tem implica√ß√µes importantes para a modelagem de s√©ries temporais n√£o estacion√°rias. Em particular:
1.  **Interpreta√ß√£o da Deriva:** A m√©dia $\delta$ representa a deriva ou tend√™ncia m√©dia de crescimento da s√©rie ap√≥s a diferencia√ß√£o. Se $\delta > 0$, a s√©rie tende a crescer em m√©dia, se $\delta < 0$, a s√©rie tende a decrescer, e se $\delta = 0$, a s√©rie n√£o tem tend√™ncia m√©dia.
2.  **Modelagem ARMA:** O modelo  $(1-L)y_t = \delta + \psi(L)\epsilon_t$ indica que a primeira diferen√ßa da s√©rie  $\Delta y_t$ pode ser modelada com um processo ARMA (ou MA, no caso de passeio aleat√≥rio) em torno da m√©dia $\delta$. Essa abordagem √© fundamental para modelar a depend√™ncia temporal dos res√≠duos ap√≥s remover a n√£o estacionaridade.
3. **Modelos ARIMA:** A m√©dia do processo ap√≥s a diferencia√ß√£o √© utilizada nos modelos ARIMA (AutoRegressive Integrated Moving Average). Os modelos ARIMA incluem a diferencia√ß√£o da s√©rie original como um passo fundamental para remover a n√£o estacionaridade, e o valor de $\delta$ (que pode ser zero) √© utilizado na modelagem dos res√≠duos. A ordem de integra√ß√£o ($d$) nos modelos ARIMA representa o n√∫mero de vezes que a s√©rie original deve ser diferenciada para que os res√≠duos se tornem estacion√°rios.

> üí° **Exemplo Num√©rico:**
>
>  Considere um modelo ARIMA(0,1,1) dado por:
>
>  $(1-L)y_t = \delta + (1+\theta L)\epsilon_t$.
>
>  Neste modelo, a m√©dia do processo $(1-L)y_t$ √© $\delta$, e o termo  $(1+\theta L)\epsilon_t$ modela a depend√™ncia temporal dos res√≠duos.
>  A s√©rie original $y_t$ √© integrada de ordem 1, pois ela deve ser diferenciada uma vez para se tornar estacion√°ria.
>
>  Vamos supor $\delta = 0.1$ e $\theta = 0.5$ e simular 100 pontos:
> ```python
> import numpy as np
> import pandas as pd
>
> np.random.seed(42)
> T = 100
> delta = 0.1
> theta = 0.5
> sigma = 0.5
> epsilon = np.random.normal(0, sigma, T+1)
> y_diff = np.zeros(T+1)
> y = np.zeros(T+1)
> for t in range(1, T+1):
>     y_diff[t] = delta + epsilon[t] + theta * epsilon[t-1]
>     y[t] = y[t-1] + y_diff[t]
>
> print(f"M√©dia da s√©rie diferenciada: {np.mean(y_diff[1:]):.4f}")
>
> import matplotlib.pyplot as plt
>
> plt.figure(figsize=(10, 6))
> plt.plot(y[1:], label='S√©rie Original (n√£o estacion√°ria)')
> plt.plot(y_diff[1:], label='S√©rie Diferenciada (estacion√°ria)')
> plt.xlabel('Tempo')
> plt.ylabel('Valor')
> plt.title('Simula√ß√£o ARIMA(0,1,1)')
> plt.legend()
> plt.grid(True)
> plt.show()
> ```
> O c√≥digo gera a s√©rie original $y_t$, que √© n√£o estacion√°ria, e a s√©rie diferenciada, $\Delta y_t$, que √© estacion√°ria e tem m√©dia pr√≥xima de 0.1, e gera um gr√°fico com ambas.
> O gr√°fico mostra a diferen√ßa entre o comportamento da s√©rie original e da s√©rie ap√≥s a diferencia√ß√£o.

### O Papel do Termo $\psi(L)\epsilon_t$
Al√©m da deriva $\delta$, o modelo de raiz unit√°ria inclui um termo $\psi(L)\epsilon_t$, que representa um processo estacion√°rio. Esse componente captura a depend√™ncia temporal dos res√≠duos ap√≥s a diferencia√ß√£o, e pode ser modelado como um processo MA, AR ou ARMA.
Em particular, se $\psi(L) = 1$, ent√£o o processo √© um passeio aleat√≥rio com deriva, onde a diferen√ßa da s√©rie original √© igual a uma constante mais um ru√≠do branco. Se $\psi(L)$ representa um operador MA, ou um operador AR ou ARMA, ent√£o o processo √© mais geral do que o passeio aleat√≥rio com deriva, e permite capturar a din√¢mica dos res√≠duos.

> üí° **Exemplo Num√©rico:**
>
>  Considere o processo de raiz unit√°ria:
>
>  $(1-L)y_t = 0.1 + (1 + 0.7L)\epsilon_t$.
>
>  Neste caso, a m√©dia do processo diferenciado √© $0.1$, e o componente estoc√°stico √© um MA(1).
>
>  Este processo tem um comportamento mais complexo do que o passeio aleat√≥rio, pois ele combina a raiz unit√°ria com um processo MA(1) nos res√≠duos.
>  Vamos simular e plotar a s√©rie diferenciada e a s√©rie original:
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
>
> np.random.seed(42)
> T = 100
> delta = 0.1
> theta = 0.7
> sigma = 0.5
> epsilon = np.random.normal(0, sigma, T+1)
> y_diff = np.zeros(T+1)
> y = np.zeros(T+1)
>
> for t in range(1, T+1):
>     y_diff[t] = delta + epsilon[t] + theta * epsilon[t-1]
>     y[t] = y[t-1] + y_diff[t]
>
> plt.figure(figsize=(10, 6))
> plt.plot(y[1:], label='S√©rie Original (n√£o estacion√°ria)')
> plt.plot(y_diff[1:], label='S√©rie Diferenciada (estacion√°ria)')
> plt.xlabel('Tempo')
> plt.ylabel('Valor')
> plt.title('Simula√ß√£o com MA(1) nos res√≠duos')
> plt.legend()
> plt.grid(True)
> plt.show()
>
> print(f"M√©dia da s√©rie diferenciada: {np.mean(y_diff[1:]):.4f}")
> ```
>  O c√≥digo gera a s√©rie original e a s√©rie diferenciada com um componente MA(1) nos res√≠duos, que resulta em um comportamento mais complexo do que um passeio aleat√≥rio.
>  O gr√°fico mostra o comportamento n√£o estacion√°rio da s√©rie original e o comportamento estacion√°rio da s√©rie diferenciada.

**Proposi√ß√£o 2:** Se $\psi(L)$ representa um operador ARMA estacion√°rio, ent√£o o processo $(1-L)y_t = \delta + \psi(L)\epsilon_t$ √© estacion√°rio.
*Prova:*
I.  O operador de primeira diferen√ßa $(1-L)$ remove a raiz unit√°ria da s√©rie original $y_t$.
II.  O termo $\psi(L)\epsilon_t$ √© um processo ARMA estacion√°rio por defini√ß√£o.
III. A soma de uma constante $\delta$ com um processo estacion√°rio $\psi(L)\epsilon_t$ resulta em um processo estacion√°rio.
IV. Portanto, o processo $(1-L)y_t$ √© estacion√°rio. $\blacksquare$

### A Diferen√ßa entre a M√©dia do Processo Original e do Processo Diferenciado
√â importante entender que, em modelos de raiz unit√°ria, a m√©dia da s√©rie original $y_t$ n√£o √© uma constante e n√£o tem significado para a modelagem. √â a m√©dia da s√©rie ap√≥s a diferencia√ß√£o, $(1-L)y_t$, que √© relevante para a an√°lise. A s√©rie original n√£o √© estacion√°ria, e sua m√©dia √© dependente do tempo, mas a diferencia√ß√£o remove essa depend√™ncia e permite modelar a s√©rie com t√©cnicas de modelos estacion√°rios.
A diferencia√ß√£o remove a tend√™ncia linear (ou outros tipos de tend√™ncia em modelos mais gerais) da m√©dia da s√©rie, que a impede de ser modelada de forma estacion√°ria, ao transformar a s√©rie original $y_t$ em uma s√©rie com m√©dia constante, $\delta$. O termo $\delta$ representa a taxa de crescimento m√©dia da s√©rie original.

**Lema 2:** A m√©dia do processo de raiz unit√°ria ap√≥s a primeira diferencia√ß√£o $(1-L)y_t$, dada por $\delta$, representa o crescimento m√©dio do processo original $y_t$, e √© o termo que permite a modelagem com s√©ries estacion√°rias.
*Prova:*
I. A equa√ß√£o $(1-L)y_t = \delta + \psi(L)\epsilon_t$ define um modelo com raiz unit√°ria.
II. Aplicando a m√©dia, temos: $E[(1-L)y_t] = E[y_t - y_{t-1}] = \delta + E[\psi(L)\epsilon_t]$. Dado que  $E[\psi(L)\epsilon_t] = 0$ para um processo estacion√°rio, obtemos:
$E[y_t - y_{t-1}] = \delta$.
III. O termo $y_t - y_{t-1}$ representa o crescimento (ou decrescimento) da s√©rie original, e a sua m√©dia √© igual a $\delta$.
IV. Portanto, o valor de $\delta$ representa o crescimento m√©dio da s√©rie original e √© a m√©dia relevante para a an√°lise ap√≥s a diferencia√ß√£o. $\blacksquare$

> üí° **Exemplo Num√©rico:**
>
>   Se temos um modelo  $(1-L)y_t = 0.1 + \epsilon_t$,  o valor de 0.1 representa o crescimento m√©dio da s√©rie original, que pode ser um passeio aleat√≥rio com deriva.
>
>   Se tiv√©ssemos $(1-L)y_t = 0.1 + 0.5 \epsilon_{t-1} + \epsilon_t$,  o valor de 0.1 continua representando a taxa de crescimento m√©dio da s√©rie original.
>
>   Vamos simular ambas as situa√ß√µes e comparar:
>   ```python
>   import numpy as np
>   import matplotlib.pyplot as plt
>
>   np.random.seed(42)
>   T = 100
>   delta = 0.1
>   sigma = 0.5
>   epsilon = np.random.normal(0, sigma, T+1)
>
>   # Modelo 1: Passeio aleat√≥rio com deriva
>   y_diff_1 = delta + epsilon[1:]
>   y1 = np.cumsum(y_diff_1)
>
>   # Modelo 2: MA(1) nos res√≠duos
>   theta = 0.5
>   y_diff_2 = np.zeros(T)
>   for t in range(T):
>      y_diff_2[t] = delta + epsilon[t+1] + theta * epsilon[t]
>   y2 = np.cumsum(y_diff_2)
>
>   plt.figure(figsize=(10, 6))
>   plt.plot(y1, label='Passeio aleat√≥rio com deriva (Modelo 1)')
>   plt.plot(y2, label='MA(1) nos res√≠duos (Modelo 2)')
>   plt.xlabel('Tempo')
>   plt.ylabel('Valor')
>   plt.title('Compara√ß√£o de modelos')
>   plt.legend()
>   plt.grid(True)
>   plt.show()
>
>   print(f"M√©dia da s√©rie diferenciada (modelo 1): {np.mean(y_diff_1):.4f}")
>   print(f"M√©dia da s√©rie diferenciada (modelo 2): {np.mean(y_diff_2):.4f}")
>   ```
>   O c√≥digo simula duas s√©ries temporais, uma com passeio aleat√≥rio com deriva e outra com MA(1) nos res√≠duos.
>   O gr√°fico mostra a diferen√ßa entre as s√©ries originais n√£o estacion√°rias, embora ambas tenham a mesma taxa de crescimento m√©dio.

### Implementa√ß√£o Computacional
A aplica√ß√£o do operador de primeira diferen√ßa em Python e R √© direta, usando fun√ß√µes que j√° est√£o dispon√≠veis.
#### Implementa√ß√£o em Python
```python
import numpy as np

def first_difference(y):
    """Calcula a primeira diferen√ßa de uma s√©rie temporal.

    Args:
        y (np.array): S√©rie temporal.

    Returns:
        np.array: S√©rie temporal ap√≥s a primeira diferen√ßa.
    """
    return np.diff(y)

# Example of use
T = 100
delta = 0.1
sigma = 0.5
np.random.seed(42)
epsilon = np.random.normal(0, sigma, T)
y = np.zeros(T)
for t in range(1,T):
    y[t] = y[t-1] + delta + epsilon[t]
y_diff = first_difference(y)
mean_diff = np.mean(y_diff)
print(f"M√©dia da s√©rie diferenciada: {mean_diff:.4f}")
```
A fun√ß√£o `first_difference` utiliza a fun√ß√£o `np.diff()` para calcular a diferen√ßa. O c√≥digo gera uma simula√ß√£o de um passeio aleat√≥rio com deriva e plota a s√©rie original e sua primeira diferen√ßa, calculando e mostrando a m√©dia da s√©rie diferenciada, que √© a estimativa do par√¢metro $\delta$.

#### Implementa√ß√£o em R
```R
first_difference <- function(y) {
  return(diff(y))
}

# Example of use
T <- 100
delta <- 0.1
sigma <- 0.5
set.seed(42)
epsilon <- rnorm(T, mean = 0, sd = sigma)
y <- numeric(T)
for (t in 2:T) {
  y[t] <- y[t-1] + delta + epsilon[t]
}
y_diff <- first_difference(y)
mean_diff <- mean(y_diff)
print(paste("M√©dia da s√©rie diferenciada:", mean_diff))
```
A fun√ß√£o `first_difference` utiliza a fun√ß√£o `diff()` para calcular a diferen√ßa. O c√≥digo gera uma simula√ß√£o de um passeio aleat√≥rio com deriva e calcula a m√©dia da s√©rie diferenciada, que corresponde √† estimativa do par√¢metro $\delta$.

### Conclus√£o
Neste cap√≠tulo, exploramos em detalhes o processo de raiz unit√°ria e a import√¢ncia do operador de primeira diferen√ßa na sua modelagem. A aplica√ß√£o do operador de primeira diferen√ßa remove a n√£o estacionaridade da s√©rie original, resultando em uma nova s√©rie cuja m√©dia √© igual a $\delta$.
Compreender o papel do operador de primeira diferen√ßa e a interpreta√ß√£o da m√©dia $\delta$ √© fundamental para a modelagem e previs√£o de s√©ries temporais n√£o estacion√°rias, especialmente aquelas com raiz unit√°ria. Os resultados deste cap√≠tulo s√£o essenciais para a modelagem adequada de s√©ries temporais n√£o estacion√°rias e para a interpreta√ß√£o correta dos resultados estat√≠sticos.
A m√©dia do processo ap√≥s a diferencia√ß√£o, dada por $\delta$, representa a taxa de crescimento m√©dio da s√©rie original, e √© um par√¢metro fundamental para modelar e entender a din√¢mica das s√©ries temporais.

### Refer√™ncias
[^1]: [15.1.3]
[^2]: [15.1.4]
[^3]: [O Passeio Aleat√≥rio com Deriva: Um Exemplo Protot√≠pico de Raiz Unit√°ria]
[^4]: [O Operador de Primeira Diferen√ßa (1-L) na Modelagem de S√©ries Temporais N√£o Estacion√°rias]
[^5]: [Modelos com Raiz Unit√°ria: An√°lise Detalhada da N√£o Estacionaridade]
<!-- END -->
