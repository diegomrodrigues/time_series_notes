## Modelagem de S√©ries Temporais N√£o Estacion√°rias e Infer√™ncia Estat√≠stica

### Introdu√ß√£o
Este cap√≠tulo aborda a modelagem de **s√©ries temporais n√£o estacion√°rias**, com foco em como a n√£o estacionaridade impacta a **infer√™ncia estat√≠stica** [^1]. Como vimos em cap√≠tulos anteriores [^2], [^3], [^4], [^5], s√©ries temporais n√£o estacion√°rias s√£o caracterizadas por propriedades estat√≠sticas que variam ao longo do tempo, o que torna a aplica√ß√£o de m√©todos estat√≠sticos tradicionais inadequada. Modelos para s√©ries n√£o estacion√°rias buscam capturar essas varia√ß√µes din√¢micas, mas a n√£o estacionaridade tamb√©m tem implica√ß√µes para a infer√™ncia estat√≠stica, como a distribui√ß√£o dos estimadores, a constru√ß√£o de intervalos de confian√ßa e os testes de hip√≥teses. Este cap√≠tulo ir√° explorar as implica√ß√µes da n√£o estacionaridade para a infer√™ncia estat√≠stica, e como a modelagem de s√©ries n√£o estacion√°rias deve levar em considera√ß√£o essas implica√ß√µes.

### Implica√ß√µes da N√£o Estacionaridade para a Infer√™ncia Estat√≠stica
A n√£o estacionaridade de uma s√©rie temporal tem implica√ß√µes diretas para a infer√™ncia estat√≠stica, que se manifestam de diversas formas:

1.  **Distribui√ß√£o dos Estimadores:** Em s√©ries n√£o estacion√°rias, a distribui√ß√£o dos estimadores dos par√¢metros do modelo pode n√£o ser assintoticamente normal, o que invalida a aplica√ß√£o de testes estat√≠sticos baseados na normalidade. A distribui√ß√£o dos estimadores tamb√©m pode ser viesada, e sua vari√¢ncia pode ser muito maior do que a vari√¢ncia dos estimadores em modelos estacion√°rios.
2.  **Intervalos de Confian√ßa:** A n√£o normalidade dos estimadores implica que os intervalos de confian√ßa baseados em suposi√ß√µes de normalidade podem ser incorretos, com cobertura inferior ou superior ao n√≠vel de confian√ßa estabelecido.
3.  **Testes de Hip√≥teses:** Testes de hip√≥teses estat√≠sticas baseados em suposi√ß√µes de estacionaridade podem levar a conclus√µes incorretas. A n√£o estacionaridade pode levar √† rejei√ß√£o da hip√≥tese nula mesmo quando ela √© verdadeira, ou √† aceita√ß√£o da hip√≥tese nula mesmo quando ela √© falsa.
4. **Resultados Esp√∫rios:** A modelagem de s√©ries n√£o estacion√°rias utilizando m√©todos para s√©ries estacion√°rias pode levar a resultados esp√∫rios, que n√£o refletem a verdadeira din√¢mica dos dados. Por exemplo, correla√ß√µes altas entre duas s√©ries n√£o estacion√°rias podem surgir puramente da presen√ßa de tend√™ncia, e n√£o de uma rela√ß√£o causal entre elas.
5. **Problemas de Previs√£o:**  A n√£o estacionaridade afeta a qualidade das previs√µes, pois os modelos estacion√°rios n√£o conseguem capturar a din√¢mica da s√©rie, ou seja, n√£o se ajustam √†s mudan√ßas no tempo na m√©dia, vari√¢ncia ou autocorrela√ß√£o.

#### Efeito da Raiz Unit√°ria na Infer√™ncia
A presen√ßa de uma raiz unit√°ria, que caracteriza um tipo espec√≠fico de n√£o estacionaridade, tem implica√ß√µes ainda mais dr√°sticas para a infer√™ncia estat√≠stica. Os estimadores de modelos com raiz unit√°ria, como os modelos autoregressivos (AR) ou autoregressivos integrados de m√©dias m√≥veis (ARIMA), n√£o possuem distribui√ß√£o assintoticamente normal, e os testes estat√≠sticos tradicionais n√£o s√£o v√°lidos, ou sua distribui√ß√£o √© n√£o-standard.
A presen√ßa de raiz unit√°ria tamb√©m implica que os choques na s√©rie s√£o permanentes, o que afeta a capacidade de prever o comportamento da s√©rie no longo prazo.
Al√©m disso, a vari√¢ncia dos estimadores de modelos com raiz unit√°ria aumenta com o tamanho da amostra, o que torna a infer√™ncia estat√≠stica mais dif√≠cil.
A distribui√ß√£o dos estimadores de modelos com raiz unit√°ria depende da especifica√ß√£o do modelo e do processo gerador dos dados, o que requer o uso de tabelas de distribui√ß√£o n√£o-standard para realizar testes de hip√≥teses.

> üí° **Exemplo Num√©rico:**
>
>   Considere um passeio aleat√≥rio simples, onde $y_t = y_{t-1} + \epsilon_t$, com $\epsilon_t$ sendo ru√≠do branco.
>
>  Se tentarmos ajustar um modelo AR(1) para essa s√©rie, dada por $y_t = \phi y_{t-1} + \epsilon_t$, o estimador do par√¢metro $\phi$ tender√° a ser pr√≥ximo de 1, mas sua distribui√ß√£o n√£o √© normal, e os testes estat√≠sticos tradicionais (t ou z) n√£o s√£o v√°lidos.
>
>  Para ilustrar isso, podemos simular v√°rias vezes um passeio aleat√≥rio e estimar o par√¢metro $\phi$, e observar o seu comportamento:
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
>
> def simulate_and_estimate(T, num_simulations):
>    phi_estimates = []
>    for _ in range(num_simulations):
>        epsilon = np.random.normal(0, 1, T)
>        y = np.cumsum(epsilon)
>        X = y[:-1].reshape(-1, 1)
>        y_dep = y[1:]
>        phi = np.linalg.lstsq(X, y_dep, rcond=None)[0][0]
>        phi_estimates.append(phi)
>    return phi_estimates
>
> T = 100
> num_simulations = 1000
> phi_estimates = simulate_and_estimate(T, num_simulations)
>
> plt.figure(figsize=(10, 6))
> plt.hist(phi_estimates, bins=30, edgecolor='black')
> plt.title('Distribui√ß√£o do Estimador de œÜ')
> plt.xlabel('Valor de œÜ')
> plt.ylabel('Frequ√™ncia')
> plt.grid(True)
> plt.show()
> print(f"M√©dia das estimativas: {np.mean(phi_estimates):.4f}")
> print(f"Desvio padr√£o das estimativas: {np.std(phi_estimates):.4f}")
> ```
>  O histograma mostra que a distribui√ß√£o do estimador de $\phi$ n√£o √© normal, com um pico em valores pr√≥ximos de 1, e uma cauda para valores menores que 1. A m√©dia das estimativas √© pr√≥xima de 1, e o desvio padr√£o √© maior que o desvio padr√£o de estimadores em modelos estacion√°rios.
>  Esse exemplo demonstra que a distribui√ß√£o dos estimadores em modelos com raiz unit√°ria n√£o √© normal, o que invalida os testes estat√≠sticos tradicionais.

**Lema 1:** Em modelos de s√©ries temporais com raiz unit√°ria, os estimadores dos par√¢metros n√£o t√™m distribui√ß√£o assintoticamente normal, e seus testes de hip√≥teses devem utilizar distribui√ß√µes n√£o-standard, derivadas da distribui√ß√£o dos processos com raiz unit√°ria.
*Prova:*
I. Para modelos de s√©ries temporais estacion√°rias, os estimadores dos par√¢metros convergem em distribui√ß√£o para uma distribui√ß√£o normal com m√©dia igual ao verdadeiro valor do par√¢metro, e desvio padr√£o que diminui com o aumento do tamanho da amostra.
II. Para modelos de s√©ries temporais com raiz unit√°ria, a distribui√ß√£o dos estimadores n√£o converge para uma distribui√ß√£o normal, e o desvio padr√£o dos estimadores n√£o diminui com o aumento do tamanho da amostra.
III. A distribui√ß√£o dos estimadores de modelos com raiz unit√°ria depende da especifica√ß√£o do modelo e do processo gerador dos dados, o que requer o uso de tabelas de distribui√ß√£o n√£o-standard, obtidas por simula√ß√£o, para realizar testes de hip√≥teses.
IV. Portanto, os estimadores de par√¢metros em modelos com raiz unit√°ria n√£o t√™m distribui√ß√£o assintoticamente normal e demandam testes com distribui√ß√µes n√£o-standard. $\blacksquare$

**Lema 1.1:** Em modelos de s√©ries temporais n√£o estacion√°rias, a vari√¢ncia dos estimadores dos par√¢metros n√£o diminui com o aumento do tamanho da amostra, o que implica que as estimativas dos par√¢metros s√£o menos precisas e mais incertas do que as estimativas em modelos estacion√°rios.
*Prova:*
I. Em modelos estacion√°rios, a vari√¢ncia dos estimadores dos par√¢metros diminui com o aumento do tamanho da amostra, e converge para zero no limite, o que implica que as estimativas s√£o mais precisas.
II. Em modelos n√£o estacion√°rios, como o passeio aleat√≥rio com deriva, a vari√¢ncia dos estimadores n√£o diminui com o aumento do tamanho da amostra, e pode at√© aumentar com o aumento do tamanho da amostra, no caso de um passeio aleat√≥rio.
III. A vari√¢ncia dos estimadores tamb√©m depende da especifica√ß√£o do modelo e da presen√ßa da raiz unit√°ria, e de outros componentes de n√£o estacionaridade.
IV. Portanto, a vari√¢ncia dos estimadores em modelos n√£o estacion√°rios n√£o diminui com o aumento do tamanho da amostra, o que indica que as estimativas s√£o menos precisas e mais incertas do que as estimativas em modelos estacion√°rios. $\blacksquare$

**Lema 1.2:** Em modelos de s√©ries temporais com raiz unit√°ria, a distribui√ß√£o dos estimadores dos par√¢metros converge para uma distribui√ß√£o funcional, que √© uma fun√ß√£o do movimento browniano. Essa distribui√ß√£o n√£o √© uma distribui√ß√£o padr√£o, e seus valores cr√≠ticos s√£o obtidos por simula√ß√£o.
*Prova:*
I. Para um modelo AR(1) com raiz unit√°ria, como  $y_t = y_{t-1} + \epsilon_t$,  o estimador de $\phi$ converge em distribui√ß√£o para uma fun√ß√£o do movimento browniano, demonstrada na teoria assint√≥tica de processos com raiz unit√°ria.
II. Esta distribui√ß√£o funcional n√£o √© uma distribui√ß√£o normal ou t, e seus valores cr√≠ticos s√£o obtidos por simula√ß√£o atrav√©s do processo de Dickey-Fuller ou outros m√©todos relacionados.
III. Portanto, os estimadores de par√¢metros em modelos com raiz unit√°ria t√™m uma distribui√ß√£o n√£o-standard que converge para uma fun√ß√£o do movimento browniano, requerendo simula√ß√µes para determinar os valores cr√≠ticos dos testes estat√≠sticos. $\blacksquare$

### Abordagens para Infer√™ncia em S√©ries N√£o Estacion√°rias
Para realizar infer√™ncia estat√≠stica em s√©ries n√£o estacion√°rias, √© necess√°rio utilizar abordagens espec√≠ficas que levam em conta as propriedades dos processos n√£o estacion√°rios:

1.  **Diferencia√ß√£o:** A diferencia√ß√£o da s√©rie temporal pode ser utilizada para remover a n√£o estacionaridade da m√©dia, tornando a s√©rie resultante estacion√°ria, de forma que podem ser utilizadas abordagens para modelos estacion√°rios nos res√≠duos ap√≥s a diferencia√ß√£o.
2.  **Testes de Raiz Unit√°ria:** Testes estat√≠sticos de raiz unit√°ria, como o teste de Dickey-Fuller Aumentado (ADF) e o teste de Phillips-Perron (PP), podem ser utilizados para verificar a presen√ßa de raiz unit√°ria, e determinar se a s√©rie deve ser diferenciada para ser modelada de forma estacion√°ria.
3.  **Modelos de Integra√ß√£o Fracion√°ria:** Modelos de integra√ß√£o fracion√°ria permitem modelar a persist√™ncia de longo prazo da s√©rie, sem a necessidade de diferenciar a s√©rie um n√∫mero inteiro de vezes.
4.  **Modelos com Quebras Estruturais:** Modelos com quebras estruturais podem ser utilizados para levar em conta mudan√ßas abruptas nos par√¢metros da s√©rie ao longo do tempo.
5.  **Testes de Cointegra√ß√£o:** Para s√©ries n√£o estacion√°rias relacionadas, testes de cointegra√ß√£o podem ser utilizados para determinar se existe uma rela√ß√£o de equil√≠brio de longo prazo entre as s√©ries, que possa ser utilizada para realizar previs√µes de longo prazo.
6.  **Bootstrapping:** T√©cnicas de bootstrapping podem ser utilizadas para construir intervalos de confian√ßa e realizar testes de hip√≥teses que n√£o dependem da distribui√ß√£o assint√≥tica dos estimadores, ou que utilizam a distribui√ß√£o dos res√≠duos (re-amostrando) para simular a distribui√ß√£o dos par√¢metros estimados.

#### Testes de Raiz Unit√°ria
Testes de raiz unit√°ria s√£o ferramentas fundamentais para a modelagem de s√©ries n√£o estacion√°rias. O teste de Dickey-Fuller Aumentado (ADF) testa a hip√≥tese nula de que a s√©rie possui raiz unit√°ria contra a alternativa de que a s√©rie √© estacion√°ria ou trend-stationary. A equa√ß√£o do teste ADF √©:
$$ \Delta y_t = \alpha + \beta t + \gamma y_{t-1} + \sum_{i=1}^p \phi_i \Delta y_{t-i} + \epsilon_t $$
onde:
*   $\Delta y_t$ √© a primeira diferen√ßa da s√©rie.
*   $\alpha$ √© uma constante.
*   $\beta t$ √© uma tend√™ncia linear.
*   $\gamma$ √© o coeficiente do termo autoregressivo de primeira ordem.
*   $\sum_{i=1}^p \phi_i \Delta y_{t-i}$ √© a parte autoregressiva que captura a depend√™ncia temporal.
*   $\epsilon_t$ √© um ru√≠do branco.
O teste avalia se o coeficiente $\gamma$ √© igual a zero. Se $\gamma=0$, ent√£o a s√©rie tem raiz unit√°ria. Se $\gamma < 0$, ent√£o a s√©rie √© estacion√°ria ou trend-stationary. A distribui√ß√£o do teste ADF n√£o √© standard, e tabelas especiais s√£o utilizadas para realizar os testes.
O teste de Phillips-Perron (PP) √© outro teste popular de raiz unit√°ria, que leva em considera√ß√£o a autocorrela√ß√£o nos res√≠duos do modelo.

> üí° **Exemplo Num√©rico:**
>
>  Vamos simular e testar um passeio aleat√≥rio com deriva para ilustrar os testes de raiz unit√°ria:
> ```python
> import numpy as np
> import pandas as pd
> import matplotlib.pyplot as plt
> from statsmodels.tsa.stattools import adfuller
>
> np.random.seed(42)
> T = 100
> y = np.cumsum(np.random.normal(0.05, 1, T))
>
> adf_result = adfuller(y)
> print("Teste ADF:")
> print(f"  Estat√≠stica do Teste: {adf_result[0]:.4f}")
> print(f"  p-valor: {adf_result[1]:.4f}")
> print("Valores cr√≠ticos:")
> for key, value in adf_result[4].items():
>    print(f"  {key}: {value:.4f}")
>
> plt.figure(figsize=(10, 6))
> plt.plot(y)
> plt.title('Passeio Aleat√≥rio com Deriva')
> plt.xlabel('Tempo')
> plt.ylabel('Valor')
> plt.grid(True)
> plt.show()
> ```
>  O c√≥digo simula um passeio aleat√≥rio com deriva, aplica o teste ADF, e imprime a estat√≠stica do teste, o p-valor e os valores cr√≠ticos. O teste ADF geralmente n√£o rejeita a hip√≥tese nula de raiz unit√°ria, como esperado. O gr√°fico mostra o comportamento n√£o estacion√°rio da s√©rie.
>
>  Aplicando o teste na s√©rie diferenciada, temos:
>
>  ```python
>  import numpy as np
>  import pandas as pd
>  import matplotlib.pyplot as plt
>  from statsmodels.tsa.stattools import adfuller
>
>  np.random.seed(42)
>  T = 100
>  y = np.cumsum(np.random.normal(0.05, 1, T))
>  y_diff = np.diff(y)
>  adf_result = adfuller(y_diff)
>  print("Teste ADF:")
>  print(f"  Estat√≠stica do Teste: {adf_result[0]:.4f}")
>  print(f"  p-valor: {adf_result[1]:.4f}")
>  print("Valores cr√≠ticos:")
>  for key, value in adf_result[4].items():
>      print(f"  {key}: {value:.4f}")
>
>  plt.figure(figsize=(10, 6))
>  plt.plot(y_diff)
>  plt.title('S√©rie Diferenciada')
>  plt.xlabel('Tempo')
>  plt.ylabel('Valor')
>  plt.grid(True)
>  plt.show()
>  ```
>
>  Aplicando o teste ADF na s√©rie diferenciada, a hip√≥tese nula de raiz unit√°ria deve ser rejeitada, confirmando que a primeira diferen√ßa removeu a n√£o estacionaridade, e resultou em uma s√©rie que pode ser modelada como estacion√°ria. O gr√°fico mostra que a s√©rie diferenciada n√£o tem tend√™ncia, e sua vari√¢ncia √© aproximadamente constante ao longo do tempo.

> üí° **Exemplo Num√©rico:**
>   Vamos comparar a infer√™ncia estat√≠stica em um modelo de regress√£o linear com e sem n√£o estacionaridade:
>
>   **Caso 1: Regress√£o com S√©ries Estacion√°rias:**
>   Simulamos duas s√©ries estacion√°rias, $x_t$ e $y_t$, e ajustamos um modelo de regress√£o linear:
>   $$y_t = \alpha + \beta x_t + \epsilon_t$$
>
>   ```python
>   import numpy as np
>   import pandas as pd
>   import statsmodels.api as sm
>   import matplotlib.pyplot as plt
>   from scipy import stats
>
>   np.random.seed(42)
>   T = 100
>
>   # Simula√ß√£o de duas s√©ries estacion√°rias AR(1)
>   def simulate_ar1(T, phi):
>       epsilon = np.random.normal(0, 1, T)
>       y = np.zeros(T)
>       y[0] = epsilon[0]
>       for t in range(1, T):
>          y[t] = phi * y[t-1] + epsilon[t]
>       return y
>
>   x_stationary = simulate_ar1(T, 0.7)
>   y_stationary = simulate_ar1(T, 0.5)
>
>   # Adicionar uma constante
>   X = sm.add_constant(x_stationary)
>
>   # Ajuste do modelo de regress√£o
>   model_stationary = sm.OLS(y_stationary, X)
>   results_stationary = model_stationary.fit()
>   print("Resultados da Regress√£o com S√©ries Estacion√°rias:")
>   print(results_stationary.summary())
>
>   # Plot dos res√≠duos
>   plt.figure(figsize=(10, 6))
>   plt.plot(results_stationary.resid)
>   plt.title('Res√≠duos da Regress√£o com S√©ries Estacion√°rias')
>   plt.xlabel('Tempo')
>   plt.ylabel('Valor')
>   plt.grid(True)
>   plt.show()
>
>   # Teste de normalidade dos res√≠duos
>   print("Teste de normalidade dos res√≠duos (Jarque-Bera):")
>   print(stats.jarque_bera(results_stationary.resid))
>   ```
>
>   Os resultados da regress√£o mostram um valor p para o coeficiente de $x$ que indica se o coeficiente √© estatisticamente significante. Os res√≠duos tamb√©m s√£o analisados para verificar se s√£o estacion√°rios e normalmente distribu√≠dos, confirmando a adequa√ß√£o do modelo.
>
>   **Caso 2: Regress√£o com S√©ries N√£o Estacion√°rias (com Raiz Unit√°ria):**
>   Simulamos duas s√©ries n√£o estacion√°rias, $x_t$ e $y_t$, que s√£o passeios aleat√≥rios e ajustamos um modelo de regress√£o linear.
>
>  ```python
>   import numpy as np
>   import pandas as pd
>   import statsmodels.api as sm
>   import matplotlib.pyplot as plt
>   from scipy import stats
>
>   np.random.seed(42)
>   T = 100
>   # Simula√ß√£o de dois passeios aleat√≥rios
>   x_non_stationary = np.cumsum(np.random.normal(0, 1, T))
>   y_non_stationary = np.cumsum(np.random.normal(0, 1, T))
>
>   # Adicionar uma constante
>   X_non_stat = sm.add_constant(x_non_stationary)
>
>   # Ajuste do modelo de regress√£o
>   model_non_stationary = sm.OLS(y_non_stationary, X_non_stat)
>   results_non_stationary = model_non_stationary.fit()
>
>   print("Resultados da Regress√£o com S√©ries N√£o Estacion√°rias:")
>   print(results_non_stationary.summary())
>   # Plot dos res√≠duos
>   plt.figure(figsize=(10, 6))
>   plt.plot(results_non_stationary.resid)
>   plt.title('Res√≠duos da Regress√£o com S√©ries N√£o Estacion√°rias')
>   plt.xlabel('Tempo')
>   plt.ylabel('Valor')
>   plt.grid(True)
>   plt.show()
>
>   # Teste de normalidade dos res√≠duos
>   print("Teste de normalidade dos res√≠duos (Jarque-Bera):")
>   print(stats.jarque_bera(results_non_stationary.resid))
>  ```
>   Os resultados da regress√£o com s√©ries n√£o estacion√°rias mostram que, mesmo quando n√£o h√° rela√ß√£o verdadeira entre $x_t$ e $y_t$, o modelo de regress√£o pode indicar uma rela√ß√£o estatisticamente significante, e os res√≠duos n√£o s√£o estacion√°rios e n√£o s√£o normalmente distribu√≠dos, indicando que o modelo n√£o √© v√°lido. Isso ocorre devido √† presen√ßa da raiz unit√°ria, que faz com que os testes estat√≠sticos tradicionais sejam inv√°lidos.
>  Este exemplo num√©rico ilustra a diferen√ßa entre regress√£o com s√©ries estacion√°rias e n√£o estacion√°rias, e como a n√£o estacionaridade pode levar a conclus√µes err√¥neas.

**Teorema 3:** A diferencia√ß√£o de uma s√©rie com raiz unit√°ria transforma a s√©rie em um processo estacion√°rio (em m√©dia), removendo a tend√™ncia estoc√°stica associada √† raiz unit√°ria, contanto que a ordem de integra√ß√£o da s√©rie original seja 1.
*Prova:*
I. Uma s√©rie com raiz unit√°ria, como um passeio aleat√≥rio, possui uma tend√™ncia estoc√°stica, ou seja, a s√©rie n√£o retorna a sua m√©dia.
II. A opera√ß√£o de diferencia√ß√£o, $\Delta y_t = y_t - y_{t-1}$, transforma a s√©rie em um processo de diferen√ßas, onde a tend√™ncia estoc√°stica √© removida.
III. No caso de um passeio aleat√≥rio, a s√©rie diferenciada se torna um ru√≠do branco, que √© um processo estacion√°rio em m√©dia.
IV. Em geral, se uma s√©rie temporal √© integrada de ordem 1, a diferencia√ß√£o a transforma em um processo estacion√°rio, com m√©dia constante, vari√¢ncia constante e autocovari√¢ncia que n√£o varia com o tempo.
V. Portanto, a diferencia√ß√£o √© uma ferramenta eficaz para transformar s√©ries n√£o estacion√°rias com raiz unit√°ria em s√©ries estacion√°rias, permitindo a aplica√ß√£o de modelos de s√©ries temporais tradicionais. $\blacksquare$

#### Modelos de Integra√ß√£o Fracion√°ria
Modelos de integra√ß√£o fracion√°ria s√£o mais flex√≠veis para modelar a depend√™ncia de longo prazo da s√©rie, e n√£o precisam de diferencia√ß√£o para se tornarem estacion√°rios. A ordem de integra√ß√£o d pode ser estimada a partir dos dados, e pode ser qualquer valor real. Para realizar infer√™ncia com modelos de integra√ß√£o fracion√°ria, t√©cnicas de estima√ß√£o de m√°xima verossimilhan√ßa podem ser utilizadas para estimar os par√¢metros do modelo, e os intervalos de confian√ßa e testes de hip√≥teses podem ser constru√≠dos utilizando a distribui√ß√£o assint√≥tica dos estimadores.

#### Modelos com Quebras Estruturais
Modelos com quebras estruturais levam em considera√ß√£o mudan√ßas abruptas nos par√¢metros da s√©rie, e os testes de hip√≥teses devem levar em considera√ß√£o esses regimes diferentes. M√©todos de estima√ß√£o de par√¢metros com mudan√ßas de regime podem ser utilizados para modelar esses modelos, como modelos Markov Switching. O teste de Chow, por exemplo, pode ser utilizado para avaliar a presen√ßa de quebras estruturais em um determinado ponto do tempo.

> üí° **Exemplo Num√©rico:**
>
> Vamos simular uma s√©rie com quebra estrutural e aplicar o teste de Chow para detectar a quebra:
>
> ```python
> import numpy as np
> import pandas as pd
> import statsmodels.api as sm
> import matplotlib.pyplot as plt
>
> def simulate_structural_break(T, break_point):
>   y = np.zeros(T)
>   for t in range(T):
>     if t < break_point:
>       y[t] = 2 + 0.5 * t + np.random.normal(0, 2)
>     else:
>       y[t] = 10 - 0.2 * t + np.random.normal(0, 2)
>   return y
>
> np.random.seed(42)
> T = 100
> break_point = 50
> y_break = simulate_structural_break(T, break_point)
>
> t = np.arange(T)
>
> # Modelo sem quebra
> X = sm.add_constant(t)
> model_no_break = sm.OLS(y_break, X)
> results_no_break = model_no_break.fit()
>
> # Modelo com quebra
> breakpoint_dummy = np.zeros(T)
> breakpoint_dummy[break_point:] = 1
> t_post_break = t.copy()
> t_post_break[:break_point] = 0
> X_break = np.vstack([np.ones(T), t, breakpoint_dummy, t_post_break]).T
> model_break = sm.OLS(y_break, X_break)
> results_break = model_break.fit()
>
> # Teste de Chow
> sse_no_break = results_no_break.ssr
> sse_break = results_break.ssr
> k_no_break = 2
> k_break = 4
> n = T
>
> chow_statistic = ((sse_no_break - sse_break) / (k_break - k_no_break)) / (sse_break / (n - k_break))
>
> # Graus de liberdade
> df1 = k_break - k_no_break
> df2 = n - k_break
> p_value = 1 - stats.f.cdf(chow_statistic, df1, df2)
>
> print("Teste de Chow:")
> print(f"Estat√≠stica do Teste: {chow_statistic:.4f}")
> print(f"p-valor: {p_value:.4f}")
>
> # Plot da s√©rie com quebra
> plt.figure(figsize=(10, 6))
> plt.plot(t, y_break)
> plt.axvline(x=break_point, color='r', linestyle='--', label='Quebra Estrutural')
> plt.title('S√©rie com Quebra Estrutural')
> plt.xlabel('Tempo')
> plt.ylabel('Valor')
> plt.legend()
> plt.grid(True)
> plt.show()
>
>
> ```
>  O teste de Chow compara a soma dos quadrados dos res√≠duos de um modelo sem quebra com um modelo com quebra. A estat√≠stica do teste e o p-valor indicam se a quebra estrutural √© estatisticamente significante. A s√©rie simulada e a localiza√ß√£o da quebra estrutural s√£o mostradas no gr√°fico, demonstrando como a quebra altera o comportamento da s√©rie.

**Proposi√ß√£o 2:** Modelos de s√©ries temporais que n√£o levam em considera√ß√£o a n√£o estacionaridade, como modelos de regress√£o linear simples, podem produzir resultados estat√≠sticos esp√∫rios, com correla√ß√µes entre s√©ries n√£o relacionadas, e com coeficientes de regress√£o viesados.
*Prova:*
I.  A regress√£o linear assume que a s√©rie dependente e as s√©ries independentes s√£o estacion√°rias, e que os res√≠duos tamb√©m s√£o estacion√°rios e n√£o correlacionados.
II.  Se as s√©ries temporais s√£o n√£o estacion√°rias, os res√≠duos n√£o ser√£o estacion√°rios e n√£o ser√£o independentes.
III. Nesse caso, a estat√≠stica t e o valor p do teste estat√≠stico ser√£o inv√°lidos, e a correla√ß√£o estimada entre as s√©ries ser√° esp√∫ria, ou seja, n√£o refletir√° uma rela√ß√£o causal, mas sim o comportamento n√£o estacion√°rio das s√©ries.
IV.  Os coeficientes estimados da regress√£o linear tamb√©m ser√£o viesados, e as suas estimativas n√£o ser√£o precisas, e seus intervalos de confian√ßa ser√£o inv√°lidos.
V.  Portanto, √© fundamental utilizar modelos apropriados para modelar s√©ries temporais n√£o estacion√°rias, para evitar obter resultados esp√∫rios e conclus√µes incorretas.  $\blacksquare$

**Corol√°rio 2.1:** A aplica√ß√£o de testes de hip√≥teses tradicionais (t ou z) em modelos com s√©ries n√£o estacion√°rias (com raiz unit√°ria) pode levar a decis√µes erradas sobre a rejei√ß√£o da hip√≥tese nula.
*Prova:*
I. Os testes de hip√≥teses tradicionais (t ou z) baseiam-se na suposi√ß√£o de que os estimadores dos par√¢metros t√™m distribui√ß√£o assintoticamente normal.
II. Em modelos com raiz unit√°ria, os estimadores dos par√¢metros n√£o t√™m distribui√ß√£o assintoticamente normal, e, portanto, os valores cr√≠ticos das distribui√ß√µes t e z n√£o s√£o v√°lidos para esses casos.
III. A utiliza√ß√£o desses testes pode levar √† rejei√ß√£o da hip√≥tese nula mesmo quando ela √© verdadeira, ou √† aceita√ß√£o da hip√≥tese nula mesmo quando ela √© falsa.
IV. Portanto, √© fundamental utilizar distribui√ß√µes n√£o-standard para realizar testes de hip√≥teses em modelos com s√©ries n√£o estacion√°rias. $\blacksquare$

**Teorema 4:** Em modelos de regress√£o com s√©ries temporais n√£o estacion√°rias, a estat√≠stica t de teste de hip√≥teses sobre os coeficientes dos regressores n√£o converge para uma distribui√ß√£o t-student, mas para uma distribui√ß√£o n√£o-standard, quando os regressores t√™m raiz unit√°ria.
*Prova:*
I.  A estat√≠stica t √© definida como o estimador do coeficiente dividido pelo seu desvio padr√£o estimado.
II. Quando os regressores s√£o estacion√°rios, sob as hip√≥teses de regress√£o, a estat√≠stica t converge para uma distribui√ß√£o t-student com graus de liberdade relacionados ao tamanho da amostra.
III.  Quando os regressores t√™m raiz unit√°ria, seus estimadores n√£o convergem para uma distribui√ß√£o normal, e seus desvios padr√£o n√£o decrescem com o aumento do tamanho da amostra, conforme demonstrado no lema 1.1 e no lema 1.2.
IV.  Como consequ√™ncia, a estat√≠stica t n√£o converge para uma distribui√ß√£o t-student, mas sim para uma distribui√ß√£o n√£o-standard que depende do processo gerador dos dados.
V. Portanto, testes de hip√≥teses baseados na distribui√ß√£o t-student em modelos de regress√£o com regressores n√£o estacion√°rios podem levar a conclus√µes incorretas, e demandam o uso de m√©todos que considerem a n√£o-estacionaridade. $\blacksquare$

### Implementa√ß√£o Computacional
A implementa√ß√£o computacional de modelos para s√©ries temporais n√£o estacion√°rias envolve a aplica√ß√£o das t√©cnicas apresentadas acima.

#### Implementa√ß√£o em Python
```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from statsmodels.tsa.stattools import adfuller
from statsmodels.tsa.arima.model import ARIMA
from sklearn.linear_model import LinearRegression
from scipy.special import gamma

def frac_diff(series, d):
     weights = [(gamma(i - d) / (gamma(i + 1) * gamma(-d))) for i in range(len(series))]
     return np.convolve(series, weights, mode='full')[:len(series)]

# Simula√ß√£o de um passeio aleat√≥rio com deriva
np.random.seed(42)
T = 100
delta = 0.1
y = np.cumsum(np.random.normal(delta, 1, T))

# Teste ADF na s√©rie original
adf_result = adfuller(y)
print("Teste ADF na s√©rie original:")
print(f"  Estat√≠stica do Teste: {adf_result[0]:.4f}")
print(f"  p-valor: {adf_result[1]:.4f}")
print("Valores cr√≠ticos:")
for key, value in adf_result[4].items():
    print(f"  {key}: {value:.4f}")

# Diferencia√ß√£o da s√©rie
y_diff = np.diff(y)

# Teste ADF na s√©rie diferenciada
adf_result_diff = adfuller(y_diff)
print("Teste ADF na s√©rie diferenciada:")
print(f"  Estat√≠stica do Teste: {adf_result_diff[0]:.4f}")
print(f"  p-valor: {adf_result_diff[1]:.4f}")
print("Valores cr√≠ticos:")
for key, value in adf_result_diff[4].items():
     print(f"  {key}: {value:.4f}")


# Ajuste de modelo ARIMA na s√©rie diferenciada
model_arima = ARIMA(y_diff, order=(1,0,1))
model_arima_fit = model_arima.fit()
print("Par√¢metros do modelo ARIMA:", model_arima_fit.summary())

# Simula√ß√£o de s√©rie temporal com tend√™ncia linear
t = np.arange(T).reshape(-1, 1)
y_trend = 5 + 0.5 * t.flatten() + np.random.normal(0, 1, T)
model_trend = LinearRegression()
model_trend.fit(t, y_trend)
y_trend_pred = model_trend.predict(t)
residuals = y_trend - y_trend_pred

# Plot dos res√≠duos
plt.figure(figsize=(10, 6))
plt.plot(residuals)
plt.title('Res√≠duos da Regress√£o Linear')
plt.xlabel('Tempo')
plt.ylabel('Valor')
plt.grid(True)
plt.show()

# Teste ADF nos res√≠duos
adf_res = adfuller(residuals)
print("Teste ADF nos res√≠duos do modelo de regress√£o:")
print(f"  Estat√≠stica do Teste: {adf_res[0]:.4f}")
print(f"  p-valor: {adf_res[1]:.4f}")
print("Valores cr√≠ticos:")
for key, value in adf_res[4].items():
      print(f"  {key}: {value:.4f}")

# Simula√ß√£o de um processo de integra√ß√£o fracion√°ria
d = 0.7
epsilon = np.random.normal(0, 1, T)
y_frac = frac_diff(epsilon, -d)

plt.figure(figsize=(10, 6))
plt.plot(y_frac)
plt.title('Processo de Integra√ß√£o Fracion√°ria')
plt.xlabel('Tempo')
plt.ylabel('Valor')
plt.grid(True)
plt.show()
```
Este c√≥digo demonstra a simula√ß√£o de um passeio aleat√≥rio com deriva, o teste ADF na s√©rie original e diferenciada, o ajuste de um modelo ARIMA, a simula√ß√£o de uma s√©rie com tend√™ncia linear, o ajuste da tend√™ncia e o teste ADF nos res√≠duos e a simula√ß√£o de um processo com integra√ß√£o fracion√°ria. As principais fun√ß√µes incluem a simula√ß√£o de uma s√©rie n√£o estacion√°ria, o teste ADF, a diferencia√ß√£o, o ajuste de um modelo ARIMA e a simula√ß√£o de um processo com integra√ß√£o fracion√°ria.

#### Implementa√ß√£o em R
```R
library(tseries)
library(forecast)
library(fracdiff)

# Simula√ß√£o de um passeio aleat√≥rio com deriva
set.seed(42)
T <- 100
delta <- 0.1
y <- cumsum(rnorm(T, mean = delta, sd = 1))

# Teste ADF na s√©rie original
adf_result <- adf.test(y)
print("Teste ADF na s√©rie original:")
print(adf_result)

# Diferencia√ß√£o da s√©rie
y_diff <- diff(y)

# Teste ADF na s√©rie diferenciada
adf_result_diff <- adf.test(y_diff)
print("Teste ADF na s√©rie diferenciada:")
print(adf_result_diff)

# Resultados

# An√°lise da autocorrela√ß√£o
acf_result <- acf(y, lag.max = 20, plot = FALSE)
print("Autocorrela√ß√£o da s√©rie original:")
print(acf_result)
plot(acf_result, main="Autocorrela√ß√£o da S√©rie Original")

acf_result_diff <- acf(y_diff, lag.max = 20, plot = FALSE)
print("Autocorrela√ß√£o da s√©rie diferenciada:")
print(acf_result_diff)
plot(acf_result_diff, main="Autocorrela√ß√£o da S√©rie Diferenciada")

# An√°lise da autocorrela√ß√£o parcial
pacf_result <- pacf(y, lag.max = 20, plot = FALSE)
print("Autocorrela√ß√£o Parcial da s√©rie original:")
print(pacf_result)
plot(pacf_result, main="Autocorrela√ß√£o Parcial da S√©rie Original")

pacf_result_diff <- pacf(y_diff, lag.max = 20, plot = FALSE)
print("Autocorrela√ß√£o Parcial da s√©rie diferenciada:")
print(pacf_result_diff)
plot(pacf_result_diff, main="Autocorrela√ß√£o Parcial da S√©rie Diferenciada")

# Decomposi√ß√£o da s√©rie temporal
y_ts <- ts(y, frequency = 12)
decomp <- decompose(y_ts)
plot(decomp)

# Modelo ARIMA
auto_arima_model <- auto.arima(y)
print("Modelo ARIMA autom√°tico:")
print(auto_arima_model)

# Previs√µes
forecast_auto_arima <- forecast(auto_arima_model, h = 24)
plot(forecast_auto_arima)

print("Previs√µes ARIMA:")
print(forecast_auto_arima)

# Avalia√ß√£o do modelo
residuals <- residuals(auto_arima_model)
plot(residuals, type = 'l', main = "Res√≠duos do Modelo ARIMA")
hist(residuals, main = "Histograma dos Res√≠duos", xlab = "Res√≠duos")
qqnorm(residuals, main = "QQ-Plot dos Res√≠duos")
qqline(residuals)
Box.test(residuals, lag = 20, type = "Ljung-Box")

# Um exemplo de modelo ARIMA (p, d, q)
arima_model_manual <- arima(y, order = c(2, 1, 2))
print("Modelo ARIMA manual:")
print(arima_model_manual)

forecast_arima_manual <- forecast(arima_model_manual, h=24)
plot(forecast_arima_manual)
print("Previs√µes do modelo ARIMA manual:")
print(forecast_arima_manual)
<!-- END -->
