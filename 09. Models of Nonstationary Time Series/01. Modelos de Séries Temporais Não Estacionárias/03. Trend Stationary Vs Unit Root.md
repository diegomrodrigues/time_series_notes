## Modelos de S√©ries Temporais N√£o Estacion√°rias: Implica√ß√µes Computacionais da Escolha entre Modelos Trend-Stationary e Unit Root

### Introdu√ß√£o

Em continuidade aos cap√≠tulos anteriores, onde discutimos a import√¢ncia da condi√ß√£o $\psi(1) \neq 0$ e a escolha entre modelar tend√™ncias determin√≠sticas ou processos de raiz unit√°ria, este cap√≠tulo aborda as implica√ß√µes computacionais dessa escolha. A modelagem de s√©ries temporais n√£o estacion√°rias exige t√©cnicas computacionais espec√≠ficas, e a decis√£o entre um modelo *trend-stationary* e um modelo *unit root* afeta diretamente a maneira como os dados s√£o processados, analisados e interpretados. Modelos *trend-stationary* muitas vezes se baseiam em t√©cnicas de regress√£o, enquanto modelos de *unit root* necessitam de opera√ß√µes de diferencia√ß√£o e podem exigir mais recursos computacionais, especialmente quando se trata de previs√µes de longo prazo e an√°lises de persist√™ncia.

### Conceitos Fundamentais

Relembrando, um modelo *trend-stationary* √© caracterizado pela seguinte equa√ß√£o:
$$y_t = \alpha + \delta t + \psi(L)\epsilon_t$$ [^1], onde $\alpha$ √© o intercepto, $\delta$ √© a inclina√ß√£o da tend√™ncia determin√≠stica e $\psi(L)\epsilon_t$ representa o componente estacion√°rio da s√©rie. Este tipo de modelo assume que a n√£o estacionariedade √© devida √† tend√™ncia linear no tempo e que, ap√≥s a remo√ß√£o dessa tend√™ncia, o processo resultante √© estacion√°rio. A implementa√ß√£o computacional deste tipo de modelo envolve principalmente a estima√ß√£o dos par√¢metros $\alpha$ e $\delta$ usando t√©cnicas de regress√£o linear, como o m√©todo dos m√≠nimos quadrados (OLS).

> üí° **Exemplo Num√©rico:** Considere uma s√©rie temporal de 100 pontos onde $y_t = 2 + 0.5t + \epsilon_t$, e $\epsilon_t$ √© ru√≠do branco com m√©dia 0 e desvio padr√£o 1. Podemos usar OLS para estimar $\alpha$ (intercepto) e $\delta$ (inclina√ß√£o) e, em seguida, analisar os res√≠duos para verificar se s√£o estacion√°rios.
```python
import numpy as np
import statsmodels.api as sm

# Generate data
np.random.seed(0)
T = 100
alpha_true = 2
delta_true = 0.5
epsilon = np.random.normal(0, 1, T)
t = np.arange(1, T + 1)
y = alpha_true + delta_true * t + epsilon

# Add a constant to the independent variable (time)
X = sm.add_constant(t)

# Fit OLS model
model = sm.OLS(y, X)
results = model.fit()

alpha_hat = results.params[0]
delta_hat = results.params[1]
residuals = results.resid

print(f"Estimated alpha: {alpha_hat:.3f}")
print(f"Estimated delta: {delta_hat:.3f}")
# Now you could perform tests on the residuals to assess stationarity
```
Isso demonstra o processo de estima√ß√£o dos par√¢metros em um modelo *trend-stationary* usando regress√£o linear.

Por outro lado, um modelo de raiz unit√°ria √© definido como:
$$(1 - L)y_t = \delta + \psi(L)\epsilon_t$$ [^1], onde $\Delta y_t = (1-L)y_t$ representa a primeira diferen√ßa da s√©rie. Neste caso, a n√£o estacionariedade √© inerente √† estrutura da s√©rie e a diferencia√ß√£o √© usada para transformar a s√©rie original em um processo estacion√°rio. A implementa√ß√£o computacional de modelos de raiz unit√°ria inclui etapas de diferencia√ß√£o, que podem aumentar o n√∫mero de opera√ß√µes e a necessidade de lidar com dados transformados. Para estimar os par√¢metros, como $\delta$ e os coeficientes de $\psi(L)$, geralmente s√£o utilizados m√©todos de estima√ß√£o de modelos ARMA.

> üí° **Exemplo Num√©rico:** Considere um processo de raiz unit√°ria definido como $y_t = y_{t-1} + 0.1 + \epsilon_t$, onde $\epsilon_t$ √© ru√≠do branco. Para torn√°-lo estacion√°rio, aplicamos a primeira diferen√ßa $\Delta y_t = y_t - y_{t-1} = 0.1 + \epsilon_t$. A implementa√ß√£o computacional envolveria subtrair cada valor do valor anterior e depois, potencialmente, estimar os par√¢metros de um modelo ARMA para $\Delta y_t$.
```python
import numpy as np
import statsmodels.api as sm
from statsmodels.tsa.arima.model import ARIMA

# Generate data
np.random.seed(0)
T = 100
delta_true = 0.1
epsilon = np.random.normal(0, 1, T)
y = np.zeros(T)
y[0] = 0
for t in range(1, T):
    y[t] = y[t-1] + delta_true + epsilon[t]
# Calculate the first difference
dy = np.diff(y)

# Fit an ARMA model on the differenced data
# In this case an ARMA(0,0) corresponds to just the mean (delta)
model = ARIMA(dy, order=(0,0,0))
results = model.fit()
delta_hat = results.params[0]


print(f"Estimated delta (after diff): {delta_hat:.3f}")
```
Aqui, demonstramos o processo de diferencia√ß√£o e estima√ß√£o de um modelo simples para um processo de raiz unit√°ria.

**Teorema 3:** *A estima√ß√£o de modelos trend-stationary √© computacionalmente menos intensiva que a de modelos unit root, especialmente para longas s√©ries temporais.*

*Prova:*
I. Em modelos *trend-stationary*, a estima√ß√£o dos par√¢metros $\alpha$ e $\delta$ envolve regress√£o linear, uma t√©cnica bem estabelecida e computacionalmente eficiente. As opera√ß√µes s√£o de complexidade $O(n^2)$, onde $n$ √© o tamanho da amostra.
II. Em modelos de *unit root*, a implementa√ß√£o computacional requer a diferencia√ß√£o da s√©rie, o que envolve a subtra√ß√£o de um valor da s√©rie pelo seu valor anterior, o que possui complexidade linear $O(n)$. A estima√ß√£o dos par√¢metros de $\psi(L)$ envolve a estima√ß√£o de modelos ARMA, que podem exigir m√©todos iterativos e n√£o lineares, com complexidade maior do que $O(n^2)$.
III. A previs√£o em modelos *trend-stationary* envolve apenas a avalia√ß√£o da tend√™ncia linear para horizontes futuros. A previs√£o em modelos de *unit root* requer a itera√ß√£o dos valores da s√©rie,  que podem consumir mais recursos computacionais √† medida que o horizonte de previs√£o se alonga.
IV. Portanto, a estima√ß√£o e previs√£o em modelos *trend-stationary* s√£o geralmente menos custosas computacionalmente em compara√ß√£o com modelos *unit root*, especialmente para longas s√©ries temporais, onde as opera√ß√µes de diferencia√ß√£o e estima√ß√£o de modelos ARMA podem se tornar mais onerosas. ‚ñ†

**Lema 3:** *A opera√ß√£o de diferencia√ß√£o em modelos unit root pode reduzir o tamanho efetivo da amostra, especialmente em s√©ries temporais curtas.*

*Prova:*
I. Em um modelo de raiz unit√°ria, a primeira diferen√ßa $\Delta y_t = y_t - y_{t-1}$ √© usada para transformar a s√©rie original em um processo estacion√°rio.
II.  Ao aplicar o operador de diferen√ßa (1-L), a primeira observa√ß√£o $y_1$ √© perdida, ou seja, a s√©rie diferenciada tem um elemento a menos. A segunda diferen√ßa (1-L)¬≤y_t resulta na perda de duas observa√ß√µes.
III. Em s√©ries temporais curtas, a perda de uma ou mais observa√ß√µes pode ter um impacto significativo na precis√£o dos resultados da estima√ß√£o e pode reduzir a confiabilidade das an√°lises.
IV. Portanto, a opera√ß√£o de diferencia√ß√£o pode reduzir o tamanho efetivo da amostra, o que √© uma considera√ß√£o importante em termos de precis√£o da estima√ß√£o.  ‚ñ†
> üí° **Exemplo Num√©rico:** Considere uma s√©rie temporal com 100 observa√ß√µes. Ao diferenciarmos essa s√©rie, reduzimos a amostra para 99 observa√ß√µes. Se aplicarmos uma segunda diferen√ßa, reduzimos a amostra para 98 observa√ß√µes. Para s√©ries com poucos dados, essa redu√ß√£o pode ser significativa.

**Proposi√ß√£o 3.1:** *Modelos unit root, devido √† sua natureza estoc√°stica, podem exigir mais simula√ß√µes e an√°lises de Monte Carlo do que modelos trend-stationary para obter resultados robustos.*

*Prova:*
I. Modelos *trend-stationary* assumem que a n√£o estacionariedade √© determin√≠stica e, portanto, as an√°lises geralmente se concentram na estima√ß√£o de par√¢metros e an√°lise de res√≠duos. As simula√ß√µes de Monte Carlo podem ser usadas para avaliar a incerteza dos par√¢metros, mas n√£o s√£o estritamente necess√°rias.
II. Modelos *unit root*, por sua natureza estoc√°stica, s√£o mais sens√≠veis a choques aleat√≥rios e a escolha dos par√¢metros. A an√°lise de Monte Carlo pode ser utilizada para avaliar a incerteza das previs√µes e para obter distribui√ß√µes emp√≠ricas dos resultados, tornando a an√°lise mais robusta.
III. A an√°lise de processos de raiz unit√°ria muitas vezes envolve a utiliza√ß√£o de testes de raiz unit√°ria, como o teste de Dickey-Fuller, que requer c√°lculos computacionais intensivos para a determina√ß√£o das distribui√ß√µes assint√≥ticas dos testes.
IV.  Portanto, modelos *unit root* podem exigir mais simula√ß√µes de Monte Carlo e procedimentos de teste, o que aumenta os custos computacionais. ‚ñ†

> üí° **Exemplo Num√©rico:** Para ilustrar a necessidade de simula√ß√µes de Monte Carlo em modelos de raiz unit√°ria, vamos gerar 100 s√©ries simuladas com raiz unit√°ria e calcular o intervalo de confian√ßa para a m√©dia.
```python
import numpy as np
import scipy.stats as st

np.random.seed(0)
num_simulations = 100
T = 100
delta_true = 0.1
all_means = []
for sim in range(num_simulations):
    epsilon = np.random.normal(0, 1, T)
    y = np.zeros(T)
    for t in range(1,T):
        y[t] = y[t-1] + delta_true + epsilon[t]
    all_means.append(y.mean())

mean_of_means = np.mean(all_means)
confidence_interval = st.t.interval(0.95, len(all_means)-1, loc=mean_of_means, scale=st.sem(all_means))
print(f"Mean of means from MC: {mean_of_means:.3f}")
print(f"95% Confidence Interval: {confidence_interval}")
```
Este exemplo demonstra como usamos Monte Carlo para obter intervalos de confian√ßa para um modelo de raiz unit√°ria.

**Lema 3.1:** *O uso de diferen√ßas de ordem superior em modelos unit root aumenta a perda de observa√ß√µes e, consequentemente, pode agravar a redu√ß√£o do tamanho efetivo da amostra.*

*Prova:*
I. A primeira diferen√ßa, $(1-L)y_t$, remove uma observa√ß√£o da s√©rie original.
II. A segunda diferen√ßa, $(1-L)^2 y_t = (1 - 2L + L^2) y_t = y_t - 2y_{t-1} + y_{t-2}$, remove duas observa√ß√µes da s√©rie original.
III. De forma geral, uma diferen√ßa de ordem $d$, $(1-L)^d y_t$, remove $d$ observa√ß√µes da s√©rie original.
IV. Portanto, o uso de diferen√ßas de ordem superior agrava a perda de observa√ß√µes e diminui o tamanho efetivo da amostra, tornando a estima√ß√£o e an√°lise mais sens√≠veis a varia√ß√µes amostrais, especialmente quando se lida com s√©ries temporais curtas. ‚ñ†

### Implica√ß√µes Computacionais Detalhadas

#### Estima√ß√£o de Par√¢metros
*   **Modelos Trend-Stationary:** A estima√ß√£o de modelos *trend-stationary* envolve a aplica√ß√£o de m√©todos de regress√£o linear, como OLS. A complexidade computacional para estima√ß√£o dos par√¢metros ($\alpha$ e $\delta$) √© relativamente baixa, de ordem $O(n^2)$, onde $n$ √© o n√∫mero de observa√ß√µes.
*   **Modelos Unit Root:** A estima√ß√£o de modelos de raiz unit√°ria, ap√≥s a diferencia√ß√£o, geralmente requer a estima√ß√£o de um modelo ARMA para a s√©rie diferenciada. Os m√©todos de estima√ß√£o de modelos ARMA podem incluir m√©todos iterativos, como o m√©todo de m√°xima verossimilhan√ßa, que podem ser mais complexos computacionalmente do que a estima√ß√£o de regress√µes lineares. M√©todos como o algoritmo de Box-Jenkins podem envolver diversas etapas de identifica√ß√£o, estima√ß√£o e avalia√ß√£o do modelo, o que tamb√©m aumenta o custo computacional.

#### Previs√£o
*   **Modelos Trend-Stationary:** A previs√£o em modelos *trend-stationary* √© direta, envolvendo a aplica√ß√£o da fun√ß√£o linear $\alpha + \delta t$ para horizontes futuros, seguida da proje√ß√£o do componente estacion√°rio. A complexidade computacional √© de ordem $O(s)$ para $s$ per√≠odos futuros.
*   **Modelos Unit Root:** A previs√£o em modelos de raiz unit√°ria envolve o uso do modelo ARMA para o processo diferenciado e a reconstru√ß√£o da s√©rie original por meio da integra√ß√£o dos valores preditos, que requer opera√ß√µes adicionais e, consequentemente, aumenta a complexidade computacional. A previs√£o pode ser escrita como $\hat{y}_{t+s|t} = \hat{y}_{t+s-1|t} + \delta + \psi_s(L)\epsilon_t$. O c√°lculo das proje√ß√µes do componente estacion√°rio, principalmente quando o polin√¥mio $\psi(L)$ tem muitos lags, pode ser bastante intensivo, com complexidade de ordem $O(s\times q)$, onde $q$ √© o n√∫mero de lags.

> üí° **Exemplo Num√©rico:** Para ilustrar a previs√£o em modelos trend-stationary, considere um modelo com $\alpha=2$ e $\delta=0.5$. A previs√£o para o per√≠odo 101 seria $\hat{y}_{101} = 2 + 0.5 * 101 = 52.5$.  Para um modelo de raiz unit√°ria, com $\delta=0.1$ e  $y_{100}=50$, a previs√£o para o per√≠odo 101 seria $\hat{y}_{101} = 50 + 0.1 = 50.1$. Para 2 per√≠odos √† frente: $\hat{y}_{102} = 50.1 + 0.1 = 50.2$. Isso mostra como a previs√£o √© mais simples em modelos trend-stationary.

```python
import numpy as np

# Trend Stationary forecast
alpha = 2
delta = 0.5
T = 100
s = 1 #forecast horizon
forecast_ts = alpha + delta*(T+s)
print(f"Trend Stationary Forecast at t+1: {forecast_ts:.2f}")

# Unit Root forecast
delta_ru = 0.1
y_t = 50
s = 1 #forecast horizon
forecast_ru = y_t + delta_ru*s
print(f"Unit Root Forecast at t+1: {forecast_ru:.2f}")
```

#### Transforma√ß√µes e Diferencia√ß√µes
*   **Modelos Trend-Stationary:** Geralmente n√£o requerem transforma√ß√µes da s√©rie al√©m da remo√ß√£o da tend√™ncia linear. A complexidade computacional √© $O(n)$, onde $n$ √© o n√∫mero de observa√ß√µes.
*   **Modelos Unit Root:** Requerem a diferencia√ß√£o da s√©rie, o que envolve subtra√ß√µes sucessivas. A primeira diferen√ßa √© $y_t - y_{t-1}$ com complexidade $O(n)$. A segunda diferen√ßa $(y_t - y_{t-1}) - (y_{t-1} - y_{t-2})$ tamb√©m tem complexidade $O(n)$. Apesar de a complexidade ser linear, a diferencia√ß√£o pode exigir o armazenamento de dados intermedi√°rios, o que aumenta o uso da mem√≥ria.

> üí° **Exemplo Num√©rico:** Se tivermos uma s√©rie `y = [10, 12, 15, 19]`, a primeira diferen√ßa seria `dy = [2, 3, 4]`, calculada como `[12-10, 15-12, 19-15]`. A segunda diferen√ßa seria `ddy = [1, 1]`, calculada como `[3-2, 4-3]`.

```python
import numpy as np

y = np.array([10, 12, 15, 19])
dy = np.diff(y)
ddy = np.diff(dy)

print(f"Original Series: {y}")
print(f"First Difference: {dy}")
print(f"Second Difference: {ddy}")
```

#### An√°lise de Monte Carlo
*   **Modelos Trend-Stationary:** A an√°lise de Monte Carlo √© usada principalmente para avaliar a incerteza dos par√¢metros estimados, mas n√£o √© crucial para a implementa√ß√£o do modelo.
*   **Modelos Unit Root:** A an√°lise de Monte Carlo √© fundamental para avaliar a incerteza das previs√µes e obter intervalos de confian√ßa, sendo computacionalmente mais intensiva. O n√∫mero de simula√ß√µes necess√°rias para garantir a converg√™ncia dos resultados pode exigir muito tempo e recursos computacionais.

#### Testes de Hip√≥tese
*   **Modelos Trend-Stationary:** Os testes de hip√≥tese s√£o diretos e envolvem principalmente o uso de testes estat√≠sticos padr√£o (teste t, teste F). A complexidade computacional √© relativamente baixa, na ordem de $O(n)$.
*   **Modelos Unit Root:** Os testes de raiz unit√°ria, como o teste de Dickey-Fuller, requerem c√°lculos computacionais intensivos para a determina√ß√£o das distribui√ß√µes assint√≥ticas, o que aumenta a complexidade computacional e pode ser um gargalo dependendo do n√∫mero de lags no modelo.

> üí° **Exemplo Num√©rico:** Para ilustrar o uso do teste de Dickey-Fuller, vamos aplicar este teste em uma s√©rie temporal simulada com raiz unit√°ria.
```python
import numpy as np
import statsmodels.tsa.stattools as ts

# Generate unit root data
np.random.seed(0)
T = 100
delta_true = 0.1
epsilon = np.random.normal(0, 1, T)
y = np.zeros(T)
for t in range(1,T):
        y[t] = y[t-1] + delta_true + epsilon[t]


# Perform Augmented Dickey-Fuller test
adf_result = ts.adfuller(y)

print(f"ADF Statistic: {adf_result[0]:.3f}")
print(f"p-value: {adf_result[1]:.3f}")
# Interpret the results based on p-value and critical values
```
Este exemplo demonstra o uso de um teste de raiz unit√°ria e como ele pode ser usado para avaliar a presen√ßa de raiz unit√°ria.

**Proposi√ß√£o 3.2:** *A estima√ß√£o de modelos ARMA em modelos unit root pode apresentar problemas de converg√™ncia, especialmente em amostras pequenas, aumentando a incerteza e o custo computacional.*

*Prova:*
I. Modelos ARMA, frequentemente utilizados ap√≥s a diferencia√ß√£o em modelos unit root, s√£o estimados por m√©todos iterativos, como o de m√°xima verossimilhan√ßa, que podem n√£o convergir para um √≥timo global, especialmente em amostras pequenas.
II. A falta de converg√™ncia pode levar a estimativas imprecisas dos par√¢metros, o que impacta a qualidade das previs√µes e an√°lises subsequentes.
III. A necessidade de m√∫ltiplos rein√≠cios do processo de otimiza√ß√£o para verificar a converg√™ncia em um √≥timo local aumenta o custo computacional da estima√ß√£o dos modelos ARMA.
IV. Portanto, a estima√ß√£o de modelos ARMA em modelos de raiz unit√°ria pode apresentar problemas de converg√™ncia, aumentando a incerteza dos resultados e o custo computacional. ‚ñ†

### Implica√ß√µes Pr√°ticas

Em termos pr√°ticos, a escolha entre modelos *trend-stationary* e modelos de *unit root* deve levar em conta os recursos computacionais dispon√≠veis e a complexidade do modelo necess√°rio para descrever a s√©rie temporal [^1]. Para grandes conjuntos de dados e previs√µes de longo prazo, modelos *trend-stationary* podem ser mais adequados devido √† sua menor demanda computacional. Por outro lado, se a s√©rie temporal exibir comportamento estoc√°stico e a an√°lise exigir avalia√ß√£o de impacto de choques a longo prazo, um modelo de *unit root* pode ser mais apropriado, mesmo com a necessidade de maior poder computacional.

A modelagem de s√©ries temporais com ra√≠zes unit√°rias, devido √† diferencia√ß√£o e aos m√©todos de estima√ß√£o de modelos ARMA, √© mais sens√≠vel a problemas computacionais, como a necessidade de determinar a ordem correta do modelo, a avalia√ß√£o da converg√™ncia dos algoritmos iterativos e a necessidade de realizar testes de hip√≥teses mais complexos. Em termos de implementa√ß√£o, os modelos *trend-stationary* tendem a ser mais simples de codificar devido √† sua natureza linear, enquanto a implementa√ß√£o de modelos *unit root* pode envolver bibliotecas e algoritmos mais avan√ßados.

A necessidade de transforma√ß√£o da s√©rie, o n√∫mero de simula√ß√µes de Monte Carlo e os procedimentos de teste tamb√©m devem ser levados em conta na escolha entre esses modelos. √â essencial que o analista avalie cuidadosamente os custos e benef√≠cios de cada abordagem antes de escolher um modelo, considerando tamb√©m o poder computacional dispon√≠vel.

> üí° **Exemplo Num√©rico:** Para ilustrar as diferen√ßas computacionais, vamos comparar os tempos de execu√ß√£o para simular 100 s√©ries temporais trend-stationary e 100 s√©ries temporais com raiz unit√°ria, usando os mesmos par√¢metros do exemplo anterior. Em seguida, vamos calcular o tempo de execu√ß√£o para prever 20 passos √† frente para cada um dos processos.

```python
import numpy as np
import time
import matplotlib.pyplot as plt

# Par√¢metros
num_simulations = 100
T = 100
max_s = 20
delta = 0.1
alpha = 2

# Medindo o tempo de simula√ß√£o do modelo trend-stationary
start_time = time.time()
for sim in range(num_simulations):
    epsilon = np.random.normal(0, 1, T)
    y_ts = np.zeros(T)
    y_ts[0] = alpha + 0.5*epsilon[0]
    for t in range(1,T):
        y_ts[t] = alpha + delta*t + 0.5*epsilon[t-1] + epsilon[t]

end_time_sim_ts = time.time()

# Medindo o tempo de simula√ß√£o do modelo unit root
start_time = time.time()
for sim in range(num_simulations):
    epsilon = np.random.normal(0, 1, T)
    y_ru = np.zeros(T)
    y_ru[0] = 0
    for t in range(1,T):
        y_ru[t] = y_ru[t-1] + delta + 0.5*epsilon[t-1] + epsilon[t]
end_time_sim_ru = time.time()


# Medindo o tempo de previs√£o do modelo trend-stationary
start_time = time.time()
for sim in range(num_simulations):
    epsilon = np.random.normal(0, 1, T+max_s)
    y_ts = np.zeros(T+max_s)
    y_ts[0] = alpha + 0.5*epsilon[0]
    for t in range(1,T+max_s):
        y_ts[t] = alpha + delta*t + 0.5*epsilon[t-1] + epsilon[t]

    for s in range(1, max_s + 1):
        forecast_ts = alpha + delta * (T + s)
end_time_pred_ts = time.time()

# Medindo o tempo de previs√£o do modelo unit root
start_time = time.time()
for sim in range(num_simulations):
    epsilon = np.random.normal(0, 1, T+max_s)
    y_ru = np.zeros(T+max_s)
    y_ru[0] = 0
    for t in range(1,T+max_s):
        y_ru[t] = y_ru[t-1] + delta + 0.5*epsilon[t-1] + epsilon[t]

    for s in range(1, max_s + 1):
        forecast_ru = y_ru[T] + delta * s
end_time_pred_ru = time.time()


print(f"Tempo de simula√ß√£o Trend-Stationary: {end_time_sim_ts - start_time:.4f} segundos")
print(f"Tempo de simula√ß√£o Unit Root: {end_time_sim_ru - start_time:.4f} segundos")
print(f"Tempo de previs√£o Trend-Stationary: {end_time_pred_ts - end_time_sim_ts:.4f} segundos")
print(f"Tempo de previs√£o Unit Root: {end_time_pred_ru - end_time_sim_ru:.4f} segundos")

```

### Conclus√£o

A escolha entre modelos *trend-stationary* e *unit root* tem implica√ß√µes computacionais importantes, que devem ser consideradas no processo de modelagem de s√©ries temporais n√£o estacion√°rias. Modelos *trend-stationary* s√£o geralmente mais simples de implementar e menos intensivos computacionalmente, enquanto modelos *unit root* requerem mais etapas de processamento, como diferencia√ß√£o, e podem envolver c√°lculos mais complexos para estima√ß√£o de par√¢metros, previs√£o e testes de hip√≥tese. A an√°lise de Monte Carlo tamb√©m √© mais comum em modelos de raiz unit√°ria para garantir a robustez dos resultados. √â crucial que o analista considere esses aspectos computacionais e escolha o modelo que melhor se adapte aos dados e aos recursos dispon√≠veis, garantindo a confiabilidade da an√°lise de s√©ries temporais n√£o estacion√°rias.

### Refer√™ncias
[^1]: [15.1.2], [15.1.3]
<!-- END -->
