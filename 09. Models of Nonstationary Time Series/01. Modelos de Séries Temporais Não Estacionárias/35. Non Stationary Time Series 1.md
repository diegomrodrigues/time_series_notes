## Modelos de S√©ries Temporais N√£o Estacion√°rias: Uma An√°lise Detalhada

### Introdu√ß√£o
Este cap√≠tulo aprofunda o estudo de **modelos de s√©ries temporais n√£o estacion√°rias**, abordando suas caracter√≠sticas, representa√ß√µes matem√°ticas e abordagens para an√°lise [^1]. Como vimos anteriormente [^2], [^3], [^4], s√©ries temporais n√£o estacion√°rias s√£o aquelas cujas propriedades estat√≠sticas, como m√©dia e vari√¢ncia, variam ao longo do tempo, em contraste com as s√©ries estacion√°rias, que possuem essas propriedades constantes. A modelagem de s√©ries n√£o estacion√°rias demanda abordagens espec√≠ficas que buscam capturar essas varia√ß√µes din√¢micas ao longo do tempo, e que permitem fazer previs√µes mais precisas em modelos com depend√™ncia temporal. Este cap√≠tulo ir√° explorar os principais modelos utilizados para an√°lise de s√©ries n√£o estacion√°rias, incluindo modelos trend-stationary, processos de raiz unit√°ria, modelos com integra√ß√£o fracion√°ria e modelos com quebras estruturais, fornecendo uma vis√£o abrangente das t√©cnicas e ferramentas dispon√≠veis para an√°lise de dados n√£o estacion√°rios.

### Defini√ß√£o e Caracter√≠sticas de S√©ries Temporais N√£o Estacion√°rias
Uma s√©rie temporal √© considerada n√£o estacion√°ria se suas propriedades estat√≠sticas (m√©dia, vari√¢ncia e autocovari√¢ncia) variam ao longo do tempo. Essa varia√ß√£o implica que a s√©rie n√£o apresenta um padr√£o constante, dificultando a aplica√ß√£o de modelos estat√≠sticos tradicionais. As principais caracter√≠sticas das s√©ries temporais n√£o estacion√°rias s√£o:

1.  **M√©dia N√£o Constante:** A m√©dia da s√©rie varia com o tempo, apresentando tend√™ncias de crescimento ou decrescimento, ou padr√µes c√≠clicos que n√£o se repetem de maneira constante.
2.  **Vari√¢ncia N√£o Constante:** A vari√¢ncia da s√©rie pode aumentar ou diminuir com o tempo, indicando uma mudan√ßa na dispers√£o dos dados.
3.  **Autocorrela√ß√£o N√£o Estacion√°ria:** A autocorrela√ß√£o, que mede a depend√™ncia entre valores da s√©rie em diferentes instantes de tempo, n√£o √© constante ao longo do tempo, o que indica que os padr√µes de depend√™ncia temporal tamb√©m se alteram com o tempo.
4.  **Persist√™ncia de Choques:** Choques aleat√≥rios na s√©rie podem ter efeitos duradouros e persistentes no n√≠vel da s√©rie, o que √© uma caracter√≠stica dos processos com raiz unit√°ria.

#### Tipos de N√£o Estacionaridade
Existem diferentes tipos de n√£o estacionaridade, que podem ser modelados com abordagens espec√≠ficas:
1. **N√£o Estacionaridade em M√©dia:** A m√©dia da s√©rie varia ao longo do tempo, o que pode ser causado por uma tend√™ncia determin√≠stica (como em modelos trend-stationary) ou por uma tend√™ncia estoc√°stica (como em modelos com raiz unit√°ria).
2. **N√£o Estacionaridade em Vari√¢ncia:** A vari√¢ncia da s√©rie varia ao longo do tempo, o que pode ser modelado com processos heteroced√°sticos (como modelos ARCH/GARCH).
3. **N√£o Estacionaridade em Autocorrela√ß√£o:** A autocorrela√ß√£o da s√©rie varia ao longo do tempo, indicando que a depend√™ncia temporal da s√©rie se modifica.
4. **Quebras Estruturais:** Mudan√ßas abruptas nos par√¢metros da s√©rie (m√©dia, vari√¢ncia ou autocovari√¢ncia) em determinados pontos do tempo, o que indica que o modelo estat√≠stico precisa de quebras no modelo, para se adequar a esses regimes diferentes.

> üí° **Exemplo Num√©rico:**
>
>   Um exemplo de s√©rie n√£o estacion√°ria √© o pre√ßo de uma a√ß√£o ao longo de v√°rios anos, pois o pre√ßo m√©dio da a√ß√£o tende a aumentar ao longo do tempo, a vari√¢ncia do pre√ßo tende a mudar, e os padr√µes de depend√™ncia temporal tamb√©m se modificam.
>
>   ```python
>   import numpy as np
>   import matplotlib.pyplot as plt
>
>   np.random.seed(42)
>   T = 200
>   y = np.cumsum(np.random.normal(0.05, 0.8, T))
>   t = np.arange(T)
>
>   plt.figure(figsize=(10, 6))
>   plt.plot(t, y)
>   plt.title('S√©rie Temporal N√£o Estacion√°ria (simula√ß√£o de um passeio aleat√≥rio com deriva)')
>   plt.xlabel('Tempo')
>   plt.ylabel('Valor')
>   plt.grid(True)
>   plt.show()
>   print(f"M√©dia da s√©rie: {np.mean(y):.4f}")
>   print(f"Vari√¢ncia da s√©rie: {np.var(y):.4f}")
>
>   ```
>  O gr√°fico mostra que a m√©dia da s√©rie aumenta ao longo do tempo, e a sua vari√¢ncia tamb√©m aumenta, o que caracteriza a n√£o estacionaridade da s√©rie.
>   As propriedades estat√≠sticas da s√©rie variam ao longo do tempo.

**Proposi√ß√£o 1:** Um processo estoc√°stico √© estacion√°rio (em sentido fraco ou de segunda ordem) se sua m√©dia e autocovari√¢ncia forem constantes ao longo do tempo.
*Prova:*
I. Um processo estoc√°stico $y_t$ √© considerado estacion√°rio (em sentido fraco ou de segunda ordem) se:
    - A m√©dia do processo √© constante ao longo do tempo: $E[y_t] = \mu$ para todo $t$, onde $\mu$ √© uma constante.
    - A autocovari√¢ncia entre dois valores da s√©rie $y_t$ e $y_{t-k}$ depende apenas da diferen√ßa de tempo (lag) $k$, e n√£o dos valores absolutos de $t$, isto √©, $Cov(y_t, y_{t-k}) = \gamma(k)$, onde $\gamma$ √© uma fun√ß√£o que depende apenas de $k$.
II. Uma s√©rie temporal n√£o estacion√°ria n√£o satisfaz uma dessas condi√ß√µes, isto √©, sua m√©dia e/ou autocovari√¢ncia variam ao longo do tempo, e n√£o s√£o constantes.
III. Portanto, para que um processo seja estacion√°rio, sua m√©dia e autocovari√¢ncia devem ser constantes ao longo do tempo, e um processo n√£o estacion√°rio n√£o satisfaz uma dessas propriedades. $\blacksquare$

**Proposi√ß√£o 1.1:** Se um processo estoc√°stico n√£o √© estacion√°rio em m√©dia ou vari√¢ncia, ent√£o ele tamb√©m n√£o √© estacion√°rio em sentido forte.
*Prova:*
I. A estacionaridade forte requer que a distribui√ß√£o conjunta de $(y_{t_1}, y_{t_2}, ..., y_{t_n})$ seja a mesma que a distribui√ß√£o conjunta de $(y_{t_1+h}, y_{t_2+h}, ..., y_{t_n+h})$ para qualquer $t_1, t_2, ..., t_n$ e qualquer $h$.
II. Se a m√©dia ou vari√¢ncia de um processo n√£o √© constante ao longo do tempo, ent√£o a sua distribui√ß√£o conjunta tamb√©m muda com o tempo, e portanto, o processo n√£o √© estacion√°rio em sentido forte.
III. Assim, se um processo n√£o √© estacion√°rio em m√©dia ou vari√¢ncia, ele tamb√©m n√£o pode ser estacion√°rio em sentido forte. $\blacksquare$

### Modelos Trend-Stationary
Modelos trend-stationary assumem que a s√©rie temporal √© composta por uma tend√™ncia determin√≠stica, e um componente estoc√°stico estacion√°rio. A equa√ß√£o b√°sica de um modelo trend-stationary √©:
$$ y_t = \alpha + \delta t + u_t $$ [^1]
onde:
*   $y_t$ √© a s√©rie temporal observada.
*   $\alpha$ √© uma constante que representa o intercepto da tend√™ncia.
*   $\delta$ √© uma constante que representa a inclina√ß√£o da tend√™ncia.
*   $t$ √© o √≠ndice de tempo.
*   $u_t$ √© um processo estoc√°stico estacion√°rio com m√©dia zero e vari√¢ncia constante.
O modelo assume que a n√£o estacionaridade da s√©rie √© devido √† tend√™ncia linear, e que, ap√≥s remover essa tend√™ncia, a s√©rie resultante √© estacion√°ria, de forma que um modelo ARMA pode ser aplicado aos res√≠duos $u_t$.

#### Generaliza√ß√µes de Modelos Trend-Stationary
O modelo trend-stationary pode ser generalizado para incluir tend√™ncias polinomiais de ordem superior:
$$ y_t = \alpha_0 + \alpha_1 t + \alpha_2 t^2 + \ldots + \alpha_p t^p + u_t $$
onde:
*   $\alpha_0, \alpha_1, \ldots, \alpha_p$ s√£o coeficientes que determinam a forma da tend√™ncia polinomial.
*   $p$ √© a ordem do polin√¥mio.
* $u_t$ √© um processo estoc√°stico estacion√°rio com m√©dia zero.

Outra generaliza√ß√£o √© a inclus√£o de componentes sazonais determin√≠sticos:
$$ y_t = \alpha + \delta t + \sum_{i=1}^k \beta_i S_i(t) + u_t $$
onde:
*   $S_i(t)$ s√£o fun√ß√µes que capturam a componente sazonal de per√≠odo $i$.
*   $\beta_i$ s√£o os coeficientes das fun√ß√µes sazonais.
*   $u_t$ √© um processo estoc√°stico estacion√°rio com m√©dia zero.
> üí° **Exemplo Num√©rico:**
>
>   Um exemplo de modelo trend-stationary √©:
>   $y_t = 10 + 0.5t + \epsilon_t$, onde $\epsilon_t$ √© um ru√≠do branco com m√©dia zero e vari√¢ncia 1.
>
>  Neste modelo, a s√©rie $y_t$ √© composta por uma tend√™ncia linear dada por $10+0.5t$, mais um termo de erro que representa as flutua√ß√µes em torno da tend√™ncia. A s√©rie $y_t$ √© n√£o estacion√°ria por causa da tend√™ncia, mas a s√©rie $y_t - (10+0.5t) = \epsilon_t$ √© estacion√°ria.
>
>   Vamos simular essa s√©rie por 100 per√≠odos:
>   ```python
>   import numpy as np
>   import matplotlib.pyplot as plt
>
>   np.random.seed(42)
>   T = 100
>   t = np.arange(T)
>   y = 10 + 0.5 * t + np.random.normal(0, 1, T)
>   plt.figure(figsize=(10, 6))
>   plt.plot(t, y)
>   plt.title('Modelo Trend-Stationary')
>   plt.xlabel('Tempo')
>   plt.ylabel('Valor')
>   plt.grid(True)
>   plt.show()
>   ```
>   O gr√°fico mostra uma s√©rie com tend√™ncia linear crescente ao longo do tempo, que demonstra a n√£o estacionaridade, e flutua√ß√µes em torno da tend√™ncia, que √© a componente estacion√°ria.
>
> Para modelar a s√©rie, podemos obter um ajuste da tend√™ncia com regress√£o linear e analisar os res√≠duos, que deveriam ser estacion√°rios.
>
>  Vamos ajustar uma regress√£o linear aos dados simulados e analisar os res√≠duos:
>
>  ```python
>  import numpy as np
>  import matplotlib.pyplot as plt
>  from sklearn.linear_model import LinearRegression
>
>  np.random.seed(42)
>  T = 100
>  t = np.arange(T).reshape(-1, 1)
>  y = 10 + 0.5 * t.flatten() + np.random.normal(0, 1, T)
>
>  model = LinearRegression()
>  model.fit(t, y)
>  y_pred = model.predict(t)
>  residuals = y - y_pred
>
>  plt.figure(figsize=(12, 6))
>  plt.subplot(1, 2, 1)
>  plt.plot(t, y, label='S√©rie Temporal')
>  plt.plot(t, y_pred, color='red', label='Tend√™ncia Estimada')
>  plt.title('S√©rie Temporal e Tend√™ncia Estimada')
>  plt.xlabel('Tempo')
>  plt.ylabel('Valor')
>  plt.legend()
>  plt.grid(True)
>
>  plt.subplot(1, 2, 2)
>  plt.plot(t, residuals)
>  plt.title('Res√≠duos do Modelo')
>  plt.xlabel('Tempo')
>  plt.ylabel('Valor')
>  plt.grid(True)
>
>  plt.tight_layout()
>  plt.show()
>
>  print(f"Coeficiente da tend√™ncia: {model.coef_[0]:.4f}")
>  print(f"Intercepto: {model.intercept_:.4f}")
>  print(f"M√©dia dos res√≠duos: {np.mean(residuals):.4f}")
>  print(f"Vari√¢ncia dos res√≠duos: {np.var(residuals):.4f}")
>  ```
> O primeiro gr√°fico mostra a s√©rie original e a tend√™ncia estimada, que √© bastante pr√≥xima da tend√™ncia verdadeira, e o segundo gr√°fico mostra os res√≠duos do modelo, que s√£o estacion√°rios em m√©dia e vari√¢ncia, como esperado. A m√©dia dos res√≠duos √© pr√≥xima de zero, e a vari√¢ncia √© pr√≥xima de 1, como no ru√≠do branco simulado.

#### Limita√ß√µes dos Modelos Trend-Stationary
Os modelos trend-stationary s√£o simples, mas apresentam algumas limita√ß√µes:
1.  **Rigidez da Tend√™ncia:** A forma da tend√™ncia √© determinada pelos par√¢metros do modelo, e n√£o se altera ao longo do tempo. Choques na s√©rie, se forem permanentes, podem levar a uma inadequa√ß√£o do modelo, pois os res√≠duos dever√£o conter autocorrela√ß√£o, o que implica que a componente estacion√°ria n√£o √© adequada para modelar os res√≠duos.
2.  **Choques Transit√≥rios:** Modelos trend-stationary assumem que os choques aleat√≥rios t√™m um efeito transit√≥rio sobre a s√©rie, ou seja, que a s√©rie tende a voltar para sua tend√™ncia de longo prazo, o que n√£o ocorre em processos com raiz unit√°ria, onde os choques t√™m efeito persistente.
3.  **N√£o Adequa√ß√£o para S√©ries com Raiz Unit√°ria:** S√©ries temporais que exibem comportamento de raiz unit√°ria (onde os choques t√™m efeito permanente) n√£o s√£o adequadamente representadas por modelos trend-stationary, pois estes n√£o modelam a persist√™ncia dos choques.
4. **Vi√©s na Estimativa da Tend√™ncia:** Se o modelo trend-stationary for aplicado a uma s√©rie com raiz unit√°ria, a tend√™ncia estimada pode ser viesada, o que leva a previs√µes imprecisas.
5. **Resultados Esp√∫rios:** A aplica√ß√£o de modelos trend-stationary a s√©ries com raiz unit√°ria pode levar a resultados estat√≠sticos esp√∫rios, que n√£o refletem a verdadeira din√¢mica da s√©rie.

**Lema 1:** A remo√ß√£o da tend√™ncia em modelos trend-stationary produz uma s√©rie estacion√°ria, enquanto que a remo√ß√£o da tend√™ncia determin√≠stica em modelos de raiz unit√°ria n√£o resulta em um processo estacion√°rio.
*Prova:*
I. Em um modelo trend-stationary, a s√©rie √© modelada como $y_t = f(t) + u_t$, onde $f(t)$ representa a tend√™ncia determin√≠stica (linear ou n√£o linear) e $u_t$ √© um processo estacion√°rio.  Ao remover a tend√™ncia, obtemos $y_t - f(t) = u_t$, que √© estacion√°rio por defini√ß√£o.
II. Em modelos de raiz unit√°ria, como o passeio aleat√≥rio com deriva,  a s√©rie √© modelada como $y_t = \delta + y_{t-1} + \epsilon_t$. Expandindo a equa√ß√£o, temos $y_t = y_0 + \delta t + \sum_{i=1}^{t} \epsilon_i$, onde $\delta t$ √© uma tend√™ncia determin√≠stica linear.
III. Ao remover a tend√™ncia linear determin√≠stica $\delta t$, obtemos: $y_t - \delta t = y_0 + \sum_{i=1}^{t} \epsilon_i$.  Este processo n√£o √© estacion√°rio, pois a vari√¢ncia cresce com o tempo: $Var(y_t - \delta t) = Var(y_0 + \sum_{i=1}^{t} \epsilon_i) = t \sigma^2$.
IV. Portanto, a remo√ß√£o da tend√™ncia em modelos trend-stationary resulta em um processo estacion√°rio, enquanto que a remo√ß√£o da tend√™ncia determin√≠stica em modelos de raiz unit√°ria n√£o resulta em um processo estacion√°rio. $\blacksquare$

**Lema 1.1:** Um modelo trend-stationary n√£o √© adequado para s√©ries que apresentam comportamento de passeio aleat√≥rio com deriva, dado que a remo√ß√£o da tend√™ncia linear resulta em uma s√©rie com vari√¢ncia crescente, o que caracteriza a n√£o estacionaridade.
*Prova:*
I. Um passeio aleat√≥rio com deriva √© modelado como $y_t = y_{t-1} + \delta + \epsilon_t$, onde $\delta$ √© a deriva e $\epsilon_t$ √© um ru√≠do branco. Expandindo a equa√ß√£o, temos $y_t = y_0 + \delta t + \sum_{i=1}^t \epsilon_i$.
II. O modelo trend-stationary assume que a s√©rie √© composta por uma tend√™ncia determin√≠stica, e um componente estacion√°rio.
III. Ao tentar modelar o passeio aleat√≥rio com deriva como trend-stationary, a tend√™ncia linear  $\delta t$ ser√° estimada.  Removendo essa tend√™ncia, a s√©rie resultante √© $y_t - \delta t = y_0 + \sum_{i=1}^t \epsilon_i$.  Esta s√©rie n√£o √© estacion√°ria, pois sua vari√¢ncia cresce com o tempo, $Var(y_0 + \sum_{i=1}^t \epsilon_i) = t \sigma^2$.
IV.  Portanto, um modelo trend-stationary n√£o √© adequado para s√©ries que apresentam comportamento de passeio aleat√≥rio com deriva. $\blacksquare$

**Lema 1.2:** Se um modelo trend-stationary √© aplicado a uma s√©rie temporal com raiz unit√°ria, os res√≠duos do modelo apresentar√£o autocorrela√ß√£o significativa, indicando uma inadequa√ß√£o do modelo.
*Prova:*
I. Uma s√©rie temporal com raiz unit√°ria n√£o pode ser tornada estacion√°ria pela remo√ß√£o de uma tend√™ncia determin√≠stica.
II. Se um modelo trend-stationary √© aplicado a uma s√©rie com raiz unit√°ria, o modelo assume que os res√≠duos s√£o estacion√°rios ap√≥s a remo√ß√£o da tend√™ncia determin√≠stica.
III. No entanto, os res√≠duos resultantes ainda conter√£o a componente n√£o estacion√°ria da s√©rie com raiz unit√°ria, que apresentar√° autocorrela√ß√£o significativa.
IV. Portanto, a presen√ßa de autocorrela√ß√£o nos res√≠duos indica que o modelo trend-stationary n√£o √© adequado para modelar uma s√©rie temporal com raiz unit√°ria. $\blacksquare$

### Processos com Raiz Unit√°ria
Processos com raiz unit√°ria s√£o caracterizados pela presen√ßa de uma raiz unit√°ria no polin√¥mio caracter√≠stico do operador autoregressivo (AR). A forma mais simples de um processo com raiz unit√°ria √© o passeio aleat√≥rio com deriva, que vimos anteriormente [^2]. A forma geral de um processo com raiz unit√°ria √©:
$$ (1-L)y_t = \delta + \psi(L)\epsilon_t $$ [^1]
onde:
*   $(1-L)$ √© o operador de primeira diferen√ßa, tal que $(1-L)y_t = y_t - y_{t-1}$.
*   $\delta$ √© a deriva ou o crescimento m√©dio da s√©rie ap√≥s a diferencia√ß√£o.
*   $\psi(L)\epsilon_t$ √© um processo estacion√°rio que modela a depend√™ncia temporal dos res√≠duos ap√≥s a diferencia√ß√£o.
*   $\epsilon_t$ √© um ru√≠do branco com m√©dia zero e vari√¢ncia constante $\sigma^2$.

#### Representa√ß√µes Equivalentes
O modelo de raiz unit√°ria pode ser expresso de forma equivalente atrav√©s da forma autoregressiva:
$$ y_t = y_{t-1} + \delta + \psi(L)\epsilon_t $$
Esta forma enfatiza a depend√™ncia da s√©rie temporal no seu valor anterior, e como a presen√ßa do componente $\psi(L)\epsilon_t$ pode ser interpretada como uma perturba√ß√£o com autocorrela√ß√£o que se acumula ao longo do tempo, e que impede a s√©rie de voltar para um valor m√©dio de longo prazo.
Expandindo recursivamente o modelo, temos:
$$ y_t = y_0 + \delta t + \sum_{i=1}^t \psi(L)\epsilon_i $$
onde $y_0$ √© o valor inicial da s√©rie. Esta forma revela que a s√©rie √© composta por uma tend√™ncia linear (drift), e por uma soma acumulada de choques que se acumulam ao longo do tempo.

> üí° **Exemplo Num√©rico:**
>
>  Um exemplo de passeio aleat√≥rio com deriva (raiz unit√°ria) √© dado por:
>   $y_t = y_{t-1} + 0.1 + \epsilon_t$, onde $\epsilon_t$ √© um ru√≠do branco.
>   Nesse caso,  a s√©rie √© n√£o estacion√°ria, porque a sua vari√¢ncia aumenta linearmente com o tempo.
>   Aplicando a primeira diferen√ßa, obtemos:
>   $(1-L)y_t = 0.1 + \epsilon_t$.
>   A s√©rie diferenciada √© estacion√°ria, com m√©dia 0.1 e vari√¢ncia $\sigma^2$.
>
>   Para simular essa s√©rie, podemos implementar o seguinte c√≥digo:
>   ```python
>   import numpy as np
>   import matplotlib.pyplot as plt
>
>   np.random.seed(42)
>   T = 100
>   y = np.zeros(T)
>   delta = 0.1
>   epsilon = np.random.normal(0, 1, T)
>   for t in range(1,T):
>      y[t] = y[t-1] + delta + epsilon[t]
>   t = np.arange(T)
>   plt.figure(figsize=(10, 6))
>   plt.plot(t, y)
>   plt.title('Passeio Aleat√≥rio com Deriva')
>   plt.xlabel('Tempo')
>   plt.ylabel('Valor')
>   plt.grid(True)
>   plt.show()
>   ```
>  O gr√°fico resultante mostra uma trajet√≥ria de uma s√©rie com raiz unit√°ria, com crescimento ao longo do tempo, e choques aleat√≥rios.  Aplicando a diferen√ßa, obtemos uma s√©rie estacion√°ria com m√©dia diferente de zero.
>
>   Vamos calcular a s√©rie diferenciada, para verificar a sua estacionaridade:
>
>   ```python
>   import numpy as np
>   import matplotlib.pyplot as plt
>
>   np.random.seed(42)
>   T = 100
>   y = np.zeros(T)
>   delta = 0.1
>   epsilon = np.random.normal(0, 1, T)
>   for t in range(1,T):
>       y[t] = y[t-1] + delta + epsilon[t]
>
>   y_diff = np.diff(y)
>   t_diff = np.arange(T-1)
>
>   plt.figure(figsize=(12, 6))
>   plt.subplot(1, 2, 1)
>   plt.plot(np.arange(T), y)
>   plt.title('S√©rie Original (Passeio Aleat√≥rio com Deriva)')
>   plt.xlabel('Tempo')
>   plt.ylabel('Valor')
>   plt.grid(True)
>
>   plt.subplot(1, 2, 2)
>   plt.plot(t_diff, y_diff)
>   plt.title('S√©rie Diferenciada')
>   plt.xlabel('Tempo')
>   plt.ylabel('Valor')
>   plt.grid(True)
>   plt.tight_layout()
>   plt.show()
>   print(f"M√©dia da s√©rie diferenciada: {np.mean(y_diff):.4f}")
>   print(f"Vari√¢ncia da s√©rie diferenciada: {np.var(y_diff):.4f}")
>   ```
>
>   O primeiro gr√°fico mostra a s√©rie original com raiz unit√°ria, e o segundo gr√°fico mostra a s√©rie diferenciada, que √© estacion√°ria em m√©dia e vari√¢ncia.  A m√©dia da s√©rie diferenciada √© pr√≥xima de 0.1 e a sua vari√¢ncia √© pr√≥xima de 1, como na simula√ß√£o original.

#### Caracter√≠sticas dos Processos com Raiz Unit√°ria
Os processos com raiz unit√°ria apresentam as seguintes caracter√≠sticas:
1.  **N√£o Estacionaridade:** A m√©dia e vari√¢ncia do processo n√£o s√£o constantes ao longo do tempo. A vari√¢ncia da s√©rie aumenta linearmente com o tempo.
2. **Persist√™ncia dos Choques:** Choques aleat√≥rios t√™m efeitos persistentes no n√≠vel da s√©rie. Um choque n√£o se dissipa ao longo do tempo, e afeta o valor da s√©rie permanentemente, que √© a caracter√≠stica da raiz unit√°ria.
3. **Necessidade de Diferencia√ß√£o:** A s√©rie original deve ser diferenciada para se tornar estacion√°ria, o que indica a presen√ßa de uma raiz unit√°ria no operador autoregressivo.
4. **Autocorrela√ß√£o:** A autocorrela√ß√£o da s√©rie n√£o decai rapidamente com o aumento do lag, indicando uma forte persist√™ncia da depend√™ncia temporal.

**Lema 2:** A aplica√ß√£o do operador de primeira diferen√ßa em um processo com raiz unit√°ria resulta em um processo estacion√°rio, ao remover a raiz unit√°ria do operador autoregressivo.
*Prova:*
I. Um processo com raiz unit√°ria pode ser expresso como: $(1-L)y_t = \delta + \psi(L)\epsilon_t$, onde $(1-L)$ √© o operador de primeira diferen√ßa.
II. O operador $(1-L)$ remove a raiz unit√°ria da s√©rie original $y_t$.
III. A s√©rie resultante $(1-L)y_t$ √© igual a uma constante $\delta$ mais um processo estacion√°rio $\psi(L)\epsilon_t$, o que torna a s√©rie resultante estacion√°ria.
IV. Portanto, a aplica√ß√£o do operador de primeira diferen√ßa remove a raiz unit√°ria da s√©rie original e resulta em um processo estacion√°rio. $\blacksquare$

**Lema 2.1:** A vari√¢ncia de um passeio aleat√≥rio com deriva $y_t = y_{t-1} + \delta + \epsilon_t$ aumenta linearmente com o tempo, dada por $t\sigma^2$, onde $\sigma^2$ √© a vari√¢ncia do ru√≠do branco.
*Prova:*
I. Expandindo a s√©rie, temos $y_t = y_0 + \delta t + \sum_{i=1}^t \epsilon_i$.
II. A vari√¢ncia da s√©rie √© $Var(y_t) = Var(y_0 + \delta t + \sum_{i=1}^t \epsilon_i) = Var(\sum_{i=1}^t \epsilon_i)$.
III. Como os $\epsilon_i$ s√£o independentes e identicamente distribu√≠dos com vari√¢ncia $\sigma^2$, temos $Var(\sum_{i=1}^t \epsilon_i) = \sum_{i=1}^t Var(\epsilon_i) = t\sigma^2$.
IV. Portanto, a vari√¢ncia de um passeio aleat√≥rio com deriva aumenta linearmente com o tempo. $\blacksquare$

**Lema 2.2:** Se a s√©rie temporal $y_t$ segue um passeio aleat√≥rio com deriva, ent√£o sua autocorrela√ß√£o n√£o decai rapidamente com o aumento do lag $k$.
*Prova:*
I. Um passeio aleat√≥rio com deriva √© definido como $y_t = y_{t-1} + \delta + \epsilon_t$.
II. A autocovari√¢ncia entre $y_t$ e $y_{t-k}$ √© dada por $Cov(y_t, y_{t-k}) = Cov(y_0 + \delta t + \sum_{i=1}^t \epsilon_i, y_0 + \delta(t-k) + \sum_{i=1}^{t-k} \epsilon_i)$.
III. Para $k>0$, essa autocovari√¢ncia √© dada por $Cov(\sum_{i=t-k+1}^{t} \epsilon_i, \sum_{i=1}^{t-k} \epsilon_i ) + Var(\sum_{i=1}^{t-k} \epsilon_i) = (t-k)\sigma^2$, onde $\sigma^2$ √© a vari√¢ncia do ru√≠do branco $\epsilon_i$.
IV. Como $Var(y_t) = t\sigma^2$, a autocorrela√ß√£o $\rho(k) = \frac{Cov(y_t, y_{t-k})}{Var(y_t)} = \frac{(t-k)\sigma^2}{t\sigma^2} = \frac{t-k}{t}$ .
V. Para $k$ pequeno em rela√ß√£o a $t$, a autocorrela√ß√£o $\rho(k)$ ser√° pr√≥xima de 1, e decai lentamente quando $k$ aumenta. Portanto, a autocorrela√ß√£o n√£o decai rapidamente. $\blacksquare$

### Modelos com Integra√ß√£o Fracion√°ria
Modelos com integra√ß√£o fracion√°ria generalizam o conceito de integra√ß√£o para valores n√£o inteiros, permitindo modelar a depend√™ncia de longo prazo em s√©ries temporais. Em modelos ARIMA, a s√©rie √© diferenciada um n√∫mero inteiro de vezes (por exemplo, uma ou duas vezes) para se tornar estacion√°ria. Modelos com integra√ß√£o fracion√°ria podem ser √∫teis quando a s√©rie temporal n√£o √© totalmente estacion√°ria, mas tamb√©m n√£o √© adequadamente modelada por uma diferen√ßa inteira.
A representa√ß√£o de um modelo com integra√ß√£o fracion√°ria √© dada por:
$$ (1-L)^d y_t = \psi(L)\epsilon_t $$
onde:
*   $d$ √© um n√∫mero real, que pode ser fracion√°rio, que indica a ordem de integra√ß√£o.
*   $\psi(L)\epsilon_t$ √© um processo estacion√°rio (ARMA) que modela os res√≠duos ap√≥s a aplica√ß√£o do operador de diferen√ßa fracion√°ria.

#### Propriedades dos Modelos com Integra√ß√£o Fracion√°ria
As principais propriedades dos modelos com integra√ß√£o fracion√°ria s√£o:
1.  **Depend√™ncia de Longo Prazo:** A autocorrela√ß√£o da s√©rie decai lentamente, capturando uma mem√≥ria de longo prazo nos dados.
2.  **Flexibilidade:** A ordem de integra√ß√£o $d$ pode assumir qualquer valor real, o que permite ajustar a modelagem da depend√™ncia temporal de forma mais flex√≠vel.
3.  **Generaliza√ß√£o dos Modelos ARMA e ARIMA:** Modelos com integra√ß√£o fracion√°ria generalizam os modelos ARMA e ARIMA, sendo que, se $d=1$ ou $d=2$, teremos um modelo ARIMA padr√£o.

> üí° **Exemplo Num√©rico:**
>
>  Um modelo com integra√ß√£o fracion√°ria pode ser modelado como
>  $(1-L)^{0.7} y_t = \epsilon_t$. Nesse modelo, a ordem de integra√ß√£o √© 0.7, que n√£o √© um n√∫mero inteiro. O operador $(1-L)^{0.7}$ pode ser expandido utilizando a expans√£o binomial, o que requer uma implementa√ß√£o computacional mais complexa do que para a primeira diferen√ßa.
>
> A implementa√ß√£o desse tipo de modelo pode ser feita em Python, utilizando a biblioteca statsmodels, ou em R, utilizando o pacote `fracdiff`.
>
>  Vamos simular um processo de integra√ß√£o fracion√°ria para fins de ilustra√ß√£o, usando um m√©todo de aproxima√ß√£o da diferen√ßa fracion√°ria:
>   ```python
>   import numpy as np
>   import matplotlib.pyplot as plt
>   from scipy.special import gamma
>
>   def frac_diff(series, d):
>        weights = [(gamma(i - d) / (gamma(i + 1) * gamma(-d))) for i in range(len(series))]
>        return np.convolve(series, weights, mode='full')[:len(series)]
>
>   np.random.seed(42)
>   T = 100
>   d = 0.7
>   epsilon = np.random.normal(0, 1, T)
>   y = frac_diff(epsilon, -d)
>   t = np.arange(T)
>
>   plt.figure(figsize=(10, 6))
>   plt.plot(t, y)
>   plt.title(f'Processo de Integra√ß√£o Fracion√°ria (d={d})')
>   plt.xlabel('Tempo')
>   plt.ylabel('Valor')
>   plt.grid(True)
>   plt.show()
>   ```
> O gr√°fico mostra uma s√©rie simulada com integra√ß√£o fracion√°ria, com depend√™ncia de longo prazo, caracterizada por flutua√ß√µes que persistem por longos per√≠odos.  Note que a simula√ß√£o do processo de integra√ß√£o fracion√°ria exige um algoritmo diferente daquele utilizado para o processo de raiz unit√°ria.
>
>  A simula√ß√£o apresentada √© uma simplifica√ß√£o da implementa√ß√£o da diferen√ßa fracion√°ria, j√° que o operador $(1-L)^d$ √© um operador n√£o local, ou seja, depende de todo o hist√≥rico da s√©rie temporal, o que implica em um algoritmo que armazena toda a hist√≥ria da s√©rie temporal.

**Lema 3:** Modelos com integra√ß√£o fracion√°ria com $0 < d < 1$ exibem um comportamento de mem√≥ria longa, onde a autocorrela√ß√£o decai hiperbolicamente, o que √© mais lento do que o decaimento exponencial em modelos estacion√°rios.
*Prova:*
I. A fun√ß√£o de autocorrela√ß√£o de um processo com integra√ß√£o fracion√°ria decai como $\gamma(k) \approx k^{2d-1}$ para grandes $k$.
II. Quando $0<d<0.5$, a autocorrela√ß√£o decai para zero, mas de forma lenta (mem√≥ria longa).
III. Quando $0.5 < d < 1$, o processo √© n√£o estacion√°rio, mas a s√©rie √© considerada de mem√≥ria longa, e √© chamada de persistente.
IV. Modelos estacion√°rios ARMA tem decaimento exponencial na sua fun√ß√£o de autocorrela√ß√£o, o que implica que a depend√™ncia temporal se dissipa rapidamente, diferente do decaimento hiperb√≥lico dos processos com integra√ß√£o fracion√°ria, que indica mem√≥ria longa. $\blacksquare$

### Modelos com Quebras Estruturais
Modelos com quebras estruturais admitem mudan√ßas abruptas nos par√¢metros do modelo (m√©dia, vari√¢ncia ou autocovari√¢ncia) em determinados pontos do tempo. Essas quebras podem ser causadas por eventos externos, como mudan√ßas de pol√≠tica econ√¥mica, crises financeiras ou choques tecnol√≥gicos. Um modelo simples de quebra estrutural na tend√™ncia √© dado por:
$$ y_t = \alpha_1 + \delta_1 t + \epsilon_t, \text{  para } t < T_b $$
$$ y_t = \alpha_2 + \delta_2 t + \epsilon_t, \text{  para } t \ge T_b $$
onde:
*   $T_b$ representa o ponto de quebra.
*   $\alpha_1$, $\delta_1$ e $\alpha_2$, $\delta_2$ representam os par√¢metros da tend√™ncia antes e depois da quebra.
*  $\epsilon_t$ representa um ru√≠do branco com m√©dia zero.

#### Outras formas de quebras estruturais:
* Quebras na vari√¢ncia
* Quebras na autocovari√¢ncia
* Quebras nos coeficientes de modelos AR ou MA.

####  Detec√ß√£o de Quebras Estruturais
A detec√ß√£o de quebras estruturais pode ser feita atrav√©s de testes estat√≠sticos, como o teste de Chow, ou m√©todos de estima√ß√£o de par√¢metros com mudan√ßas de regime, como modelos Markov Switching.
> üí° **Exemplo Num√©rico:**
>
>   Suponha que temos uma s√©rie temporal com uma quebra na tend√™ncia no tempo T=100, simulada da seguinte forma:
>   $y_t = 5 + 0.3t + \epsilon_t$, para t<100
>   $y_t = 2 + 0.7t + \epsilon_t$, para t>=100
>   Onde $\epsilon_t$ √© ru√≠do branco com m√©dia zero e vari√¢ncia 1.
>  Nesse caso, a tend√™ncia da s√©rie muda abruptamente no ponto T=100, indicando uma quebra estrutural.

*   **Implementa√ß√£o em Python**

Para simular e visualizar essa s√©rie temporal com quebra estrutural, podemos usar as seguintes bibliotecas em Python:

```python
import numpy as np
import matplotlib.pyplot as plt

# Par√¢metros
T = 200
t = np.arange(1, T+1)
epsilon = np.random.normal(0, 1, T)

# Simula√ß√£o da s√©rie temporal
yt = np.zeros(T)
for i in range(T):
    if i < 100:
        yt[i] = 1 + 0.5 * (i+1) + epsilon[i]
    else:
        yt[i] = 2 + 0.7 * (i+1) + epsilon[i]

# Plot
plt.figure(figsize=(10, 6))
plt.plot(t, yt)
plt.xlabel('Tempo (t)')
plt.ylabel('y(t)')
plt.title('S√©rie Temporal com Quebra Estrutural')
plt.grid(True)
plt.show()
```

Este c√≥digo simula uma s√©rie temporal com uma quebra estrutural no tempo t=100. A visualiza√ß√£o gr√°fica mostra claramente a mudan√ßa na tend√™ncia da s√©rie neste ponto.

*   **Outro exemplo: Mudan√ßa na Sazonalidade**

Considere uma s√©rie temporal com uma sazonalidade anual, onde a amplitude da sazonalidade muda ap√≥s um determinado ponto. Por exemplo:

$y_t =  cos(2\pi t/12) + \epsilon_t$, para t < 100

$y_t =  2 cos(2\pi t/12) + \epsilon_t$, para t>=100

>   Onde $\epsilon_t$ √© ru√≠do branco com m√©dia zero e vari√¢ncia 1.

Nesse caso, a amplitude da sazonalidade da s√©rie temporal dobra no ponto T=100.

*   **Implementa√ß√£o em Python**

```python
import numpy as np
import matplotlib.pyplot as plt

# Par√¢metros
T = 200
t = np.arange(1, T+1)
epsilon = np.random.normal(0, 0.5, T)

# Simula√ß√£o da s√©rie temporal
yt = np.zeros(T)
for i in range(T):
    if i < 100:
        yt[i] = np.cos(2 * np.pi * (i+1)/12) + epsilon[i]
    else:
        yt[i] = 2 * np.cos(2 * np.pi * (i+1)/12) + epsilon[i]


# Plot
plt.figure(figsize=(10, 6))
plt.plot(t, yt)
plt.xlabel('Tempo (t)')
plt.ylabel('y(t)')
plt.title('S√©rie Temporal com Mudan√ßa na Sazonalidade')
plt.grid(True)
plt.show()
```

Este c√≥digo demonstra uma mudan√ßa na sazonalidade, onde a amplitude do componente sazonal aumenta ap√≥s o tempo t=100.

### Testes de Quebra Estrutural

Existem diversos testes estat√≠sticos que podem ser usados para identificar a ocorr√™ncia de quebras estruturais em s√©ries temporais. Alguns dos testes mais utilizados incluem:

*   **Teste de Chow:** Este √© um teste cl√°ssico para detectar quebras estruturais, que assume que a quebra ocorre em um ponto conhecido a priori. Ele compara a soma dos quadrados dos res√≠duos de dois modelos: um modelo que assume que a s√©rie temporal √© homog√™nea e um modelo que assume que a s√©rie √© dividida em duas partes com par√¢metros diferentes.

    $$ F = \frac{(RSS_{homogeneo} - (RSS_1 + RSS_2)) / k}{((RSS_1 + RSS_2)/(n_1 + n_2 - 2k))}$$

    Onde:
    *   $RSS_{homogeneo}$ √© a soma dos quadrados dos res√≠duos do modelo sem quebra.
    *   $RSS_1$ √© a soma dos quadrados dos res√≠duos do modelo antes da quebra.
    *   $RSS_2$ √© a soma dos quadrados dos res√≠duos do modelo depois da quebra.
    *   $k$ √© o n√∫mero de par√¢metros estimados em cada modelo.
    *   $n_1$ √© o n√∫mero de observa√ß√µes antes da quebra.
    *   $n_2$ √© o n√∫mero de observa√ß√µes ap√≥s a quebra.

*   **Teste de Quandt:** Este teste √© utilizado quando o ponto da quebra n√£o √© conhecido. Ele avalia a presen√ßa de uma quebra estrutural, testando todas as poss√≠veis datas de quebra e tomando o valor m√°ximo da estat√≠stica de teste de Chow.

*   **Teste de Cusum:** Este teste acumula os res√≠duos do modelo e verifica se eles se desviam significativamente do zero, indicando uma poss√≠vel quebra estrutural.

*   **Teste de Bai-Perron:** Este teste permite a detec√ß√£o de m√∫ltiplas quebras estruturais em uma s√©rie temporal.

O teste de Chow e o teste de Quandt s√£o adequados para detectar quebras estruturais em modelos de regress√£o, enquanto o teste de Cusum e o teste de Bai-Perron s√£o mais adequados para modelos de s√©ries temporais.

<!-- END -->
