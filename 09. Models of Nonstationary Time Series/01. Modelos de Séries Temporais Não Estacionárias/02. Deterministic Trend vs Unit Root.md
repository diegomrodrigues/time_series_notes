## Modelos de S√©ries Temporais N√£o Estacion√°rias: Escolha entre Tend√™ncia Determin√≠stica e Raiz Unit√°ria

### Introdu√ß√£o

Em continuidade ao cap√≠tulo anterior, onde exploramos a import√¢ncia da condi√ß√£o $\psi(1) \neq 0$ em processos de raiz unit√°ria, este cap√≠tulo aprofunda-se na distin√ß√£o entre a modelagem de tend√™ncias determin√≠sticas e processos de raiz unit√°ria. A escolha entre estas abordagens √© crucial, pois impacta significativamente a forma como as s√©ries temporais s√£o processadas computacionalmente e interpretadas estatisticamente. Como vimos anteriormente, processos estacion√°rios possuem uma m√©dia constante, enquanto processos n√£o estacion√°rios apresentam varia√ß√µes na m√©dia ao longo do tempo [^1]. Estas varia√ß√µes podem ser modeladas atrav√©s de uma tend√™ncia determin√≠stica ou atrav√©s de um processo de raiz unit√°ria. Compreender as nuances de cada abordagem √© essencial para uma an√°lise robusta de s√©ries temporais n√£o estacion√°rias.

### Conceitos Fundamentais

Relembrando, um processo *trend-stationary* √© modelado como $y_t = \alpha + \delta t + \psi(L)\epsilon_t$ [^1], onde a tend√™ncia √© dada por $\alpha + \delta t$.  Este modelo assume que a n√£o estacionariedade √© devido a um componente linear no tempo, e a remo√ß√£o desta tend√™ncia resulta em um processo estacion√°rio. A previs√£o para este tipo de processo converge para uma linha reta com inclina√ß√£o $\delta$ e intercepto que √© dado por $\alpha$ [^4].

Em contrapartida, um processo de raiz unit√°ria √© modelado como $(1 - L)y_t = \delta + \psi(L)\epsilon_t$ [^1]. Nesse caso, a n√£o estacionariedade √© devido √† presen√ßa de uma raiz unit√°ria no polin√¥mio autorregressivo, e a primeira diferen√ßa da s√©rie, $\Delta y_t = y_t - y_{t-1}$, √© modelada como um processo estacion√°rio. O processo de raiz unit√°ria pode ser visto como um processo que cresce estocasticamente ao longo do tempo, onde o choque $\epsilon_t$ tem um impacto permanente na s√©rie [^1]. A previs√£o converge para uma linha reta com inclina√ß√£o $\delta$, mas o intercepto muda a cada nova observa√ß√£o [^4].

A escolha entre estes dois modelos depende da natureza da n√£o estacionariedade da s√©rie temporal. O modelo de tend√™ncia determin√≠stica √© apropriado quando a s√©rie apresenta uma tend√™ncia clara que pode ser bem representada por uma fun√ß√£o linear do tempo. O modelo de raiz unit√°ria, por outro lado, √© mais adequado quando a s√©rie n√£o apresenta uma tend√™ncia determin√≠stica clara, mas sim um comportamento aleat√≥rio com impacto permanente de choques.

√â importante notar que a diferencia√ß√£o √© um processo que afeta a representa√ß√£o da s√©rie. No caso da s√©rie trend-stationary, a diferencia√ß√£o introduz uma raiz unit√°ria na parte MA, resultando em um processo n√£o-invert√≠vel e potencialmente problem√°tico [^1]. Enquanto que, no caso do processo de raiz unit√°ria, a diferencia√ß√£o resulta numa representa√ß√£o estacion√°ria.

A equa√ß√£o [15.1.5] introduz uma generaliza√ß√£o que abrange ambos os casos [^1]:
$$y_t = \alpha + \delta t + u_t$$
onde $u_t$ segue um processo ARMA de m√©dia zero [^1]. Se o polin√¥mio AR de $u_t$ tiver todas as ra√≠zes dentro do c√≠rculo unit√°rio, ent√£o o processo √© *trend-stationary* [^1]. Se, por outro lado, o polin√¥mio AR tiver uma raiz unit√°ria, ent√£o a s√©rie $y_t$ segue um processo de raiz unit√°ria [^1].

A distin√ß√£o entre modelar uma tend√™ncia determin√≠stica e um processo de raiz unit√°ria tem implica√ß√µes diretas no tratamento da s√©rie temporal, tanto em termos de previs√£o quanto de an√°lise.

**Lema 2:** *Se $y_t$ segue um processo trend-stationary $y_t = \alpha + \delta t + \psi(L)\epsilon_t$, a diferencia√ß√£o resulta em $\Delta y_t = \delta + (1-L)\psi(L)\epsilon_t$, que √© um processo estacion√°rio, mas com um componente MA n√£o-invert√≠vel.*

*Prova:*
I.  Assumimos que $y_t = \alpha + \delta t + \psi(L)\epsilon_t$ √© um processo trend-stationary.
II.  Aplicando o operador de diferen√ßa $(1-L)$, temos $\Delta y_t = (1-L)(\alpha + \delta t + \psi(L)\epsilon_t)$.
III.  Como $(1-L)\alpha = 0$ e $(1-L)t = 1$, obtemos $\Delta y_t = \delta + (1-L)\psi(L)\epsilon_t$.
IV.  Definimos $\psi^*(L) = (1-L)\psi(L)$.
V.  Portanto, $\Delta y_t = \delta + \psi^*(L)\epsilon_t$, onde $\psi^*(L)$ cont√©m uma raiz unit√°ria em $z=1$. ‚ñ†

**Lema 2.1:** *Se $y_t$ segue um processo trend-stationary $y_t = \alpha + \delta t + \psi(L)\epsilon_t$, ent√£o a segunda diferen√ßa $\Delta^2 y_t$ √© um processo estacion√°rio e invert√≠vel.*

*Prova:*
I. Do Lema 2, temos que $\Delta y_t = \delta + (1-L)\psi(L)\epsilon_t$.
II. Aplicando o operador de diferen√ßa novamente, obtemos $\Delta^2 y_t = (1-L)\Delta y_t = (1-L)(\delta + (1-L)\psi(L)\epsilon_t)$.
III. Como $(1-L)\delta = 0$, temos $\Delta^2 y_t = (1-L)^2\psi(L)\epsilon_t$.
IV. Definindo $\psi^{**}(L) = (1-L)^2\psi(L)$, obtemos $\Delta^2 y_t = \psi^{**}(L)\epsilon_t$.
V. Como $\psi(L)$ √© invert√≠vel (por defini√ß√£o do processo trend-stationary) e $(1-L)^2$ n√£o introduz ra√≠zes fora do c√≠rculo unit√°rio (exceto em $z=1$, que n√£o afeta a invertibilidade do polin√¥mio resultante), $\psi^{**}(L)$ resulta em um processo estacion√°rio e invert√≠vel. ‚ñ†

> üí° **Exemplo Num√©rico:** Para ilustrar os Lemas 2 e 2.1, consideremos um processo trend-stationary com $\psi(L) = 1 + 0.5L$. Ent√£o, $y_t = \alpha + \delta t + \epsilon_t + 0.5\epsilon_{t-1}$. Usando $\alpha = 2$ e $\delta = 0.1$, vamos calcular a primeira e a segunda diferen√ßa de $y_t$.
>
> $\text{Lema 2: } \Delta y_t = \delta + (1-L)\psi(L)\epsilon_t = 0.1 + (1-L)(1 + 0.5L)\epsilon_t = 0.1 + (1 - 0.5L - 0.5L^2)\epsilon_t = 0.1 + \epsilon_t - 0.5\epsilon_{t-1} - 0.5\epsilon_{t-2}$.
>
> Observe que a primeira diferen√ßa introduz um componente MA n√£o invert√≠vel.
>
> $\text{Lema 2.1: } \Delta^2 y_t = (1-L)^2\psi(L)\epsilon_t = (1-2L+L^2)(1 + 0.5L)\epsilon_t = (1 - 1.5L - L^2 + 0.5L^3)\epsilon_t = \epsilon_t - 1.5\epsilon_{t-1} - \epsilon_{t-2} + 0.5\epsilon_{t-3}$.
>
> A segunda diferen√ßa resulta em um processo estacion√°rio e invert√≠vel. Observe que as ra√≠zes do polin√¥mio MA est√£o todas dentro do c√≠rculo unit√°rio, o que garante a invertibilidade.

**Teorema 2:** *A previs√£o de um processo trend-stationary converge para uma linha reta com inclina√ß√£o $\delta$, enquanto a previs√£o de um processo de raiz unit√°ria converge para uma linha reta com a mesma inclina√ß√£o $\delta$, mas cujo intercepto √© atualizado a cada nova observa√ß√£o.*

*Prova:*
I.  Para o processo trend-stationary $y_t = \alpha + \delta t + \psi(L)\epsilon_t$, a previs√£o de $y_{t+s}$ √© dada por $\hat{y}_{t+s|t} = \alpha + \delta(t+s) + \psi_s(L)\epsilon_t$.  Onde $\psi_s(L)$ √© o componente estacion√°rio do processo. √Ä medida que $s \to \infty$, o termo $\psi_s(L)\epsilon_t$ tende a zero, e a previs√£o converge para $\alpha + \delta(t+s)$ , uma linha reta com inclina√ß√£o $\delta$.
II. Para o processo de raiz unit√°ria $(1-L)y_t = \delta + \psi(L)\epsilon_t$, a previs√£o de $y_{t+s}$ √© dada por $\hat{y}_{t+s|t} = s\delta + y_t + \psi_s(L)\epsilon_t$, onde $y_t$ √© o n√≠vel da s√©rie no momento t. √Ä medida que $s \to \infty$, o componente $\psi_s(L)\epsilon_t$ tende a zero, a previs√£o converge para uma reta com inclina√ß√£o $\delta$. No entanto, o intercepto depende do valor corrente da s√©rie, $y_t$, ou seja, o intercepto varia a cada observa√ß√£o.
III. Portanto, demonstramos que as previs√µes de ambos os modelos convergem para linhas retas com inclina√ß√£o $\delta$, mas diferem no comportamento do intercepto. ‚ñ†

> üí° **Exemplo Num√©rico:** Para o Teorema 2, vamos comparar a previs√£o de um processo trend-stationary com um processo de raiz unit√°ria. Assumimos um processo trend-stationary $y_t = 2 + 0.1t + 0.5\epsilon_{t-1} + \epsilon_t$ e um processo de raiz unit√°ria (random walk com drift) $\Delta y_t = 0.1 + 0.5\epsilon_{t-1} + \epsilon_t$. Vamos gerar 100 observa√ß√µes para cada s√©rie e calcular a previs√£o para $t+10$. O ru√≠do branco tem m√©dia zero e vari√¢ncia 1.

```python
import numpy as np
import matplotlib.pyplot as plt

# Simula√ß√£o dos processos
T = 100
delta = 0.1
alpha = 2
epsilon = np.random.normal(0, 1, T+10)
y_ts = np.zeros(T+10)
y_ru = np.zeros(T+10)

# Inicializa√ß√£o
y_ts[0] = alpha + 0.5*epsilon[0]
y_ru[0] = 0


for t in range(1,T+10):
  y_ts[t] = alpha + delta*t + 0.5*epsilon[t-1] + epsilon[t]
  y_ru[t] = y_ru[t-1] + delta + 0.5*epsilon[t-1] + epsilon[t]

# Previs√£o para t+10
s = 10
forecast_ts = alpha + delta*(T + s) # A previs√£o para o processo trend-stationary converge para 2 + 0.1*(t+s)
forecast_ru = y_ru[T] + delta * s # A previs√£o para o processo de raiz unit√°ria √© atualizada usando o √∫ltimo valor da s√©rie.

print(f"Previs√£o trend-stationary para o tempo {T+s} = {forecast_ts:.2f}")
print(f"Previs√£o raiz unit√°ria para o tempo {T+s} = {forecast_ru:.2f}")

# Visualiza√ß√£o
plt.plot(y_ts[:T+1], label='Trend-Stationary')
plt.plot(y_ru[:T+1], label = "Random Walk with Drift")
plt.axhline(y=forecast_ts, color='r', linestyle='--', label = "Forecast Trend Stationary")
plt.axhline(y=forecast_ru, color='g', linestyle='--', label = "Forecast Random Walk")
plt.legend()
plt.xlabel('Tempo')
plt.ylabel('y_t')
plt.title('Compara√ß√£o de Processo Trend-Stationary com Raiz Unit√°ria')
plt.show()
```

**Teorema 2.1:** *A vari√¢ncia do erro de previs√£o de um processo trend-stationary converge para um valor finito quando o horizonte de previs√£o aumenta, enquanto a vari√¢ncia do erro de previs√£o de um processo de raiz unit√°ria cresce linearmente com o horizonte de previs√£o.*

*Prova:*
I. Para um processo trend-stationary $y_t = \alpha + \delta t + \psi(L)\epsilon_t$, o erro de previs√£o $e_{t+s} = y_{t+s} - \hat{y}_{t+s|t} = \psi_s(L)\epsilon_t$. A vari√¢ncia do erro de previs√£o √© dada por $Var(e_{t+s}) = Var(\psi_s(L)\epsilon_t)$. Como $\psi(L)$ representa um processo estacion√°rio, o efeito dos choques $\epsilon_t$ decai ao longo do tempo. Portanto, $Var(e_{t+s})$ converge para um valor finito √† medida que $s \to \infty$.
II. Para um processo de raiz unit√°ria $(1-L)y_t = \delta + \psi(L)\epsilon_t$, o erro de previs√£o pode ser escrito como  $e_{t+s} = y_{t+s} - \hat{y}_{t+s|t} = \sum_{i=1}^s\epsilon_{t+i} + \psi_s(L)\epsilon_t$.  A vari√¢ncia do erro de previs√£o √© dada por $Var(e_{t+s}) = Var(\sum_{i=1}^s\epsilon_{t+i}) + Var(\psi_s(L)\epsilon_t) = s\sigma^2 + Var(\psi_s(L)\epsilon_t)$, onde $\sigma^2$ √© a vari√¢ncia de $\epsilon_t$.  Como $Var(\psi_s(L)\epsilon_t)$ converge para um valor finito √† medida que $s \to \infty$, a vari√¢ncia do erro de previs√£o cresce linearmente com $s$, ou seja, o horizonte de previs√£o.
III. Portanto, a vari√¢ncia do erro de previs√£o de um processo trend-stationary converge para um valor finito, enquanto a vari√¢ncia do erro de previs√£o de um processo de raiz unit√°ria cresce linearmente com o horizonte de previs√£o. ‚ñ†

> üí° **Exemplo Num√©rico:** Para o Teorema 2.1, vamos simular 100 s√©ries temporais de cada tipo (trend-stationary e raiz unit√°ria) para calcular a vari√¢ncia do erro de previs√£o para diferentes horizontes de previs√£o (s). Usaremos os mesmos par√¢metros do exemplo anterior: $y_t = 2 + 0.1t + 0.5\epsilon_{t-1} + \epsilon_t$ para o processo trend-stationary e $\Delta y_t = 0.1 + 0.5\epsilon_{t-1} + \epsilon_t$ para o processo de raiz unit√°ria.

```python
num_simulations = 100
T = 100
max_s = 20
var_error_ts = np.zeros(max_s)
var_error_ru = np.zeros(max_s)
delta = 0.1
alpha = 2

for sim in range(num_simulations):
    epsilon = np.random.normal(0, 1, T+max_s)
    y_ts = np.zeros(T+max_s)
    y_ru = np.zeros(T+max_s)
    y_ts[0] = alpha + 0.5*epsilon[0]
    y_ru[0] = 0
    for t in range(1,T+max_s):
        y_ts[t] = alpha + delta*t + 0.5*epsilon[t-1] + epsilon[t]
        y_ru[t] = y_ru[t-1] + delta + 0.5*epsilon[t-1] + epsilon[t]

    for s in range(1, max_s + 1):
        forecast_ts = alpha + delta * (T + s)
        forecast_ru = y_ru[T] + delta * s
        error_ts = y_ts[T+s] - forecast_ts
        error_ru = y_ru[T+s] - forecast_ru
        var_error_ts[s-1] += error_ts**2
        var_error_ru[s-1] += error_ru**2

var_error_ts /= num_simulations
var_error_ru /= num_simulations

plt.plot(range(1, max_s + 1), var_error_ts, label='Trend-Stationary')
plt.plot(range(1, max_s + 1), var_error_ru, label='Raiz Unit√°ria')
plt.xlabel('Horizonte de Previs√£o (s)')
plt.ylabel('Vari√¢ncia do Erro de Previs√£o')
plt.legend()
plt.title('Vari√¢ncia do Erro de Previs√£o vs. Horizonte de Previs√£o')
plt.show()

print("Vari√¢ncia do erro de previs√£o do modelo Trend-stationary:")
print(var_error_ts)
print("Vari√¢ncia do erro de previs√£o do modelo Raiz Unit√°ria:")
print(var_error_ru)
```

### Implica√ß√µes Pr√°ticas

A escolha entre modelar uma tend√™ncia determin√≠stica e um processo de raiz unit√°ria afeta diretamente a interpreta√ß√£o dos resultados e o processo de previs√£o [^4]. Se uma s√©rie temporal √© modelada como *trend-stationary*, a interpreta√ß√£o √© que a s√©rie flutua ao redor de uma tend√™ncia linear. A remo√ß√£o da tend√™ncia linear resulta em um processo estacion√°rio, o que significa que a s√©rie retornar√° √† tend√™ncia ap√≥s um choque. Por outro lado, se uma s√©rie temporal √© modelada como um processo de raiz unit√°ria, a interpreta√ß√£o √© que a s√©rie n√£o tem uma tend√™ncia determin√≠stica fixa, mas sim um comportamento estoc√°stico com um impacto permanente de choques [^4]. A diferencia√ß√£o da s√©rie estacionariza o processo, mas a s√©rie original n√£o tem uma tend√™ncia fixa.

No contexto de previs√£o, um modelo *trend-stationary* converge para uma tend√™ncia linear com intercepto fixo, enquanto um modelo de raiz unit√°ria converge para uma tend√™ncia linear com um intercepto que se ajusta a cada nova observa√ß√£o [^4]. Em outras palavras, em um processo de raiz unit√°ria, o valor presente da s√©rie ($y_t$) √© utilizado para atualizar o n√≠vel de onde a s√©rie crescer√° no futuro.

Adicionalmente, a escolha entre estes modelos tem implica√ß√µes para a an√°lise da persist√™ncia de choques. Em um modelo *trend-stationary*, um choque tem um efeito tempor√°rio, enquanto em um modelo de raiz unit√°ria, um choque tem um efeito permanente sobre o n√≠vel da s√©rie [^1]. Essa diferen√ßa √© crucial para entender os efeitos de pol√≠ticas econ√¥micas ou eventos externos.

A an√°lise da vari√¢ncia do erro de previs√£o tamb√©m √© afetada pela escolha entre estes modelos [^4]. No modelo *trend-stationary*, a vari√¢ncia do erro de previs√£o converge para um valor finito, enquanto no modelo de raiz unit√°ria, a vari√¢ncia do erro de previs√£o cresce linearmente com o horizonte de previs√£o [^4]. Portanto, no caso de um processo de raiz unit√°ria, a incerteza da previs√£o aumenta √† medida que o horizonte de previs√£o se estende [^4].

### Conclus√£o

A escolha entre modelar uma tend√™ncia determin√≠stica e um processo de raiz unit√°ria √© crucial para uma an√°lise precisa e interpretativa de s√©ries temporais n√£o estacion√°rias. Modelos de tend√™ncia determin√≠stica removem a tend√™ncia linear, resultando em processos estacion√°rios que retornam √† tend√™ncia ap√≥s um choque, enquanto modelos de raiz unit√°ria modelam a s√©rie como um processo estoc√°stico que √© persistentemente afetado por choques. A diferencia√ß√£o √© utilizada para estacionarizar processos de raiz unit√°ria e tamb√©m resulta em processos estacion√°rios, no entanto, o processo trend-stationary diferenciado apresenta um componente MA n√£o-invert√≠vel. A escolha entre esses modelos impacta a interpreta√ß√£o da persist√™ncia de choques e o processo de previs√£o, bem como a vari√¢ncia do erro de previs√£o, sendo fundamental para obter resultados significativos e confi√°veis na an√°lise de s√©ries temporais n√£o estacion√°rias. As implica√ß√µes dessas escolhas para testes de hip√≥teses ser√£o exploradas em cap√≠tulos subsequentes.

### Refer√™ncias
[^1]:  [15.1.1], [15.1.2], [15.1.3], [15.1.5]
[^4]: [15.3.1], [15.3.4]
<!-- END -->
