## Modelos com Raiz UnitÃ¡ria: AnÃ¡lise Detalhada da NÃ£o Estacionaridade

### IntroduÃ§Ã£o
Este capÃ­tulo explora em profundidade o conceito de **raiz unitÃ¡ria** em modelos de sÃ©ries temporais nÃ£o estacionÃ¡rias, um tÃ³pico fundamental para a compreensÃ£o do comportamento de sÃ©ries temporais cujas propriedades estatÃ­sticas variam ao longo do tempo [^1]. Construindo sobre os conceitos jÃ¡ apresentados sobre modelos estacionÃ¡rios e a necessidade de modelar sÃ©ries com comportamento nÃ£o estacionÃ¡rio [^2], exploraremos como a presenÃ§a de uma raiz unitÃ¡ria no polinÃ´mio caracterÃ­stico do operador autoregressivo implica que a sÃ©rie nÃ£o tem mÃ©dia e variÃ¢ncia constantes ao longo do tempo. Este capÃ­tulo tambÃ©m irÃ¡ discutir o significado da raiz unitÃ¡ria e como ela se manifesta em processos nÃ£o estacionÃ¡rios, bem como a diferenÃ§a entre modelos com raiz unitÃ¡ria e outros modelos de nÃ£o estacionaridade [^3]. A anÃ¡lise detalhada desses modelos Ã© crucial para a modelagem precisa de sÃ©ries temporais nÃ£o estacionÃ¡rias e para a interpretaÃ§Ã£o correta dos resultados estatÃ­sticos.

### O Conceito de Raiz UnitÃ¡ria
A definiÃ§Ã£o formal de um modelo com raiz unitÃ¡ria surge da anÃ¡lise do polinÃ´mio caracterÃ­stico do operador autoregressivo. Considere um processo autoregressivo de ordem p, AR(p), dado por:
$$ y_t = \phi_1 y_{t-1} + \phi_2 y_{t-2} + \dots + \phi_p y_{t-p} + \epsilon_t $$
Este processo pode ser reescrito usando o operador de retardo $L$ como:
$$ (1 - \phi_1 L - \phi_2 L^2 - \dots - \phi_p L^p)y_t = \epsilon_t $$
Definimos o polinÃ´mio caracterÃ­stico como:
$$ \phi(z) = 1 - \phi_1 z - \phi_2 z^2 - \dots - \phi_p z^p $$
onde $z$ Ã© uma variÃ¡vel complexa. A presenÃ§a de uma raiz unitÃ¡ria implica que uma das raÃ­zes do polinÃ´mio $\phi(z)$ Ã© igual a 1. Formalmente, isso significa que $\phi(1) = 0$.
Quando $\phi(1) = 0$, o operador autoregressivo contÃ©m um termo $(1-L)$, o que implica que a sÃ©rie temporal $y_t$ nÃ£o Ã© estacionÃ¡ria. A intuiÃ§Ã£o por trÃ¡s da raiz unitÃ¡ria Ã© que um choque aleatÃ³rio $\epsilon_t$ tem um efeito permanente sobre o nÃ­vel da sÃ©rie temporal, em contraste com modelos estacionÃ¡rios onde o efeito de um choque desaparece com o tempo.

#### RepresentaÃ§Ã£o de um Modelo com Raiz UnitÃ¡ria
A representaÃ§Ã£o de um modelo com raiz unitÃ¡ria pode ser expressa de diversas formas. Uma forma comum Ã© atravÃ©s da introduÃ§Ã£o do operador de primeira diferenÃ§a $(1-L)$. Considere um processo AR(1) com raiz unitÃ¡ria:
$$ y_t = y_{t-1} + \epsilon_t $$
Esta equaÃ§Ã£o indica que o valor da sÃ©rie no tempo $t$ Ã© igual ao valor no tempo $t-1$ mais um choque aleatÃ³rio $\epsilon_t$. A forma geral para um processo com raiz unitÃ¡ria pode ser escrita como:
$$ (1 - L)y_t = \delta + \psi(L)\epsilon_t $$ [^1]
onde:
*   $(1-L)$ Ã© o operador de primeira diferenÃ§a que remove a raiz unitÃ¡ria.
*   $\delta$ Ã© uma constante, que representa uma deriva na sÃ©rie temporal.
*   $\psi(L)\epsilon_t$ Ã© um processo estacionÃ¡rio, modelado como uma mÃ©dia mÃ³vel, ou similar.
O processo  $(1-L)y_t$ Ã© estacionÃ¡rio, enquanto a sÃ©rie original $y_t$ Ã© nÃ£o estacionÃ¡ria. A constante $\delta$ representa a taxa mÃ©dia de crescimento da sÃ©rie.
> ðŸ’¡ **Exemplo NumÃ©rico:**
>
>  Considere um processo AR(2) definido por $y_t = 1.5y_{t-1} - 0.5y_{t-2} + \epsilon_t$. O polinÃ´mio caracterÃ­stico Ã© $\phi(z) = 1 - 1.5z + 0.5z^2$.
>  Para verificar se existe uma raiz unitÃ¡ria, avaliamos $\phi(1) = 1 - 1.5(1) + 0.5(1)^2 = 1 - 1.5 + 0.5 = 0$. Como $\phi(1) = 0$, este processo tem uma raiz unitÃ¡ria. Se reescrevermos o polinÃ´mio $\phi(z) = (1-z)(1-0.5z)$, vemos que as raÃ­zes sÃ£o $z=1$ e $z=2$. Como uma das raÃ­zes Ã© 1, hÃ¡ uma raiz unitÃ¡ria.
>
> Agora considere o processo AR(1) dado por $y_t = 0.8y_{t-1} + \epsilon_t$. O polinÃ´mio caracterÃ­stico Ã© $\phi(z) = 1 - 0.8z$.  Calculando $\phi(1) = 1 - 0.8(1) = 0.2 \neq 0$. Portanto, este processo nÃ£o tem raiz unitÃ¡ria.
>
> No caso de um processo com raiz unitÃ¡ria, como $y_t = y_{t-1} + \epsilon_t$, o polinÃ´mio caracterÃ­stico Ã© $\phi(z) = 1 - z$.  Calculando $\phi(1) = 1 - 1 = 0$. Logo, este processo tem uma raiz unitÃ¡ria.
#### A ImplicaÃ§Ã£o da Raiz UnitÃ¡ria na NÃ£o Estacionaridade
A presenÃ§a de uma raiz unitÃ¡ria implica que a sÃ©rie temporal nÃ£o Ã© **estacionÃ¡ria**, ou seja, sua mÃ©dia e variÃ¢ncia nÃ£o sÃ£o constantes ao longo do tempo. Isso pode ser demonstrado considerando a representaÃ§Ã£o de um processo com raiz unitÃ¡ria:
$$ y_t = \sum_{i=1}^t \epsilon_i $$
A mÃ©dia deste processo Ã© $E[y_t] = 0$ para todos os $t$, mas sua variÃ¢ncia Ã© dada por $Var[y_t] = t\sigma^2$, que aumenta linearmente com o tempo. Este Ã© um exemplo de um passeio aleatÃ³rio sem deriva, que possui uma raiz unitÃ¡ria. Em um processo com deriva, a mÃ©dia tambÃ©m nÃ£o serÃ¡ constante ao longo do tempo. Essa caracterÃ­stica de variÃ¢ncia nÃ£o constante distingue um processo com raiz unitÃ¡ria de um processo estacionÃ¡rio.
> ðŸ’¡ **Exemplo NumÃ©rico:**
>
>  Considere a seguinte simulaÃ§Ã£o de um passeio aleatÃ³rio (random walk) sem deriva:
>   $$ y_t = y_{t-1} + \epsilon_t $$
>   onde $\epsilon_t$ Ã© um ruÃ­do branco com mÃ©dia zero e variÃ¢ncia $\sigma^2 = 1$. A sÃ©rie inicial Ã© $y_0=0$.
>   O grÃ¡fico da simulaÃ§Ã£o mostra que a sÃ©rie nÃ£o possui uma mÃ©dia constante e que sua variÃ¢ncia aumenta com o tempo. A sÃ©rie apresenta um comportamento aleatÃ³rio e nÃ£o estacionÃ¡rio.
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
>
> # Parameters
> T = 100
> sigma_epsilon = 1
>
> # Generate random noise
> np.random.seed(42)
> epsilon = np.random.normal(0, sigma_epsilon, T)
>
> # Simulate the random walk
> y = np.zeros(T)
> for t in range(1, T):
>    y[t] = y[t-1] + epsilon[t]
>
> # Plotting
> plt.figure(figsize=(10, 6))
> plt.plot(y)
> plt.title('Random Walk com raiz unitÃ¡ria')
> plt.xlabel('Tempo')
> plt.ylabel('Valor')
> plt.grid(True)
> plt.show()
> ```
> O cÃ³digo gera e plota a sÃ©rie temporal. O grÃ¡fico resultante mostra o comportamento nÃ£o estacionÃ¡rio da sÃ©rie, tÃ­pico de um passeio aleatÃ³rio.

**ProposiÃ§Ã£o 1:** A presenÃ§a de uma raiz unitÃ¡ria no polinÃ´mio caracterÃ­stico do operador autoregressivo implica que a sÃ©rie temporal nÃ£o Ã© estacionÃ¡ria, e que os choques tÃªm um efeito permanente sobre o nÃ­vel da sÃ©rie.
*Prova:*
I.  Um modelo com raiz unitÃ¡ria tem um polinÃ´mio caracterÃ­stico $\phi(z)$ tal que $\phi(1) = 0$.
II.  Isso implica que o operador autorregressivo pode ser expresso na forma $(1-L)\phi^*(L)$, onde $L$ Ã© o operador de retardo.
III.  A presenÃ§a do termo $(1-L)$ indica que a sÃ©rie original deve ser diferenciada para obter uma sÃ©rie estacionÃ¡ria.
IV. A diferenciaÃ§Ã£o da sÃ©rie nÃ£o remove o efeito de choques passados, pois estes se acumulam, ou seja, tem um efeito persistente sobre o nÃ­vel da sÃ©rie.
V. Portanto, a presenÃ§a de uma raiz unitÃ¡ria implica que a sÃ©rie nÃ£o Ã© estacionÃ¡ria e que os choques tÃªm um efeito permanente. $\blacksquare$

**Lema 1.1:** Se um processo autoregressivo tem uma raiz unitÃ¡ria, entÃ£o a soma dos seus coeficientes autoregressivos Ã© igual a 1.
*Prova:*
I. Seja um processo AR(p) definido como $y_t = \phi_1 y_{t-1} + \phi_2 y_{t-2} + \dots + \phi_p y_{t-p} + \epsilon_t$.
II. O polinÃ´mio caracterÃ­stico Ã© dado por $\phi(z) = 1 - \phi_1 z - \phi_2 z^2 - \dots - \phi_p z^p$.
III. Uma raiz unitÃ¡ria implica que $\phi(1) = 0$.
IV. Substituindo $z = 1$ em $\phi(z)$, temos $0 = 1 - \phi_1 - \phi_2 - \dots - \phi_p$.
V. Rearranjando a equaÃ§Ã£o, temos $\phi_1 + \phi_2 + \dots + \phi_p = 1$. Portanto, a soma dos coeficientes autoregressivos Ã© igual a 1. $\blacksquare$
> ðŸ’¡ **Exemplo NumÃ©rico:**
> Considere um processo AR(2) com uma raiz unitÃ¡ria, como  $y_t = 1.2 y_{t-1} - 0.2 y_{t-2} + \epsilon_t$. Os coeficientes autoregressivos sÃ£o $\phi_1 = 1.2$ e $\phi_2 = -0.2$. A soma dos coeficientes Ã© $\phi_1 + \phi_2 = 1.2 - 0.2 = 1$. Isso confirma que a soma dos coeficientes AR Ã© igual a 1 quando hÃ¡ uma raiz unitÃ¡ria.

### Modelos de Raiz UnitÃ¡ria com Deriva
A inclusÃ£o de uma **deriva** ($\delta$) em um modelo com raiz unitÃ¡ria introduz uma tendÃªncia determinÃ­stica na mÃ©dia da sÃ©rie temporal. O modelo torna-se um passeio aleatÃ³rio com deriva, e Ã© definido como:
$$ y_t = \delta + y_{t-1} + \epsilon_t $$
Esta equaÃ§Ã£o indica que o valor da sÃ©rie no tempo $t$ Ã© igual ao valor no tempo $t-1$, mais uma deriva constante $\delta$ e um choque aleatÃ³rio $\epsilon_t$. Em termos do operador de retardo, o modelo Ã© dado por:
$$ (1-L)y_t = \delta + \epsilon_t $$
A deriva $\delta$ representa a taxa de crescimento mÃ©dia da sÃ©rie, e a presenÃ§a da raiz unitÃ¡ria implica que os choques tÃªm um efeito permanente sobre o nÃ­vel da sÃ©rie.
A mÃ©dia da sÃ©rie em um modelo com raiz unitÃ¡ria e deriva Ã© dada por $E[y_t] = y_0 + \delta t$, onde $y_0$ Ã© o valor inicial da sÃ©rie e a variÃ¢ncia Ã© $Var[y_t] = t\sigma^2$, que aumenta com o tempo. Portanto, tanto a mÃ©dia como a variÃ¢ncia variam com o tempo, e o processo nÃ£o Ã© estacionÃ¡rio.
> ðŸ’¡ **Exemplo NumÃ©rico:**
>
>  Vamos simular um passeio aleatÃ³rio com deriva, com uma deriva $\delta = 0.2$:
>  $$ y_t = 0.2 + y_{t-1} + \epsilon_t $$
>  A simulaÃ§Ã£o mostra que a sÃ©rie apresenta uma tendÃªncia de crescimento ao longo do tempo, e que a sua variÃ¢ncia aumenta com o tempo. A sÃ©rie apresenta um comportamento nÃ£o estacionÃ¡rio.
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
>
> # Parameters
> T = 100
> delta = 0.2
> sigma_epsilon = 1
>
> # Generate random noise
> np.random.seed(42)
> epsilon = np.random.normal(0, sigma_epsilon, T)
>
> # Simulate the random walk with drift
> y = np.zeros(T)
> for t in range(1, T):
>    y[t] = delta + y[t-1] + epsilon[t]
>
> # Plotting
> plt.figure(figsize=(10, 6))
> plt.plot(y)
> plt.title('Random Walk com deriva')
> plt.xlabel('Tempo')
> plt.ylabel('Valor')
> plt.grid(True)
> plt.show()
> ```
> O cÃ³digo simula e plota o passeio aleatÃ³rio com deriva. O grÃ¡fico resultante mostra a tendÃªncia de crescimento da sÃ©rie, alÃ©m de seu comportamento nÃ£o estacionÃ¡rio.

**Lema 1:** A inclusÃ£o de uma deriva constante ($\delta$) em um modelo com raiz unitÃ¡ria introduz uma tendÃªncia determinÃ­stica na mÃ©dia da sÃ©rie temporal, que cresce linearmente com o tempo, mas a presenÃ§a da raiz unitÃ¡ria garante que a sÃ©rie continue nÃ£o estacionÃ¡ria.
*Prova:*
I. O modelo de raiz unitÃ¡ria com deriva Ã© dado por $y_t = \delta + y_{t-1} + \epsilon_t$, onde $y_0$ Ã© um valor inicial, $\delta$ Ã© a deriva, e $\epsilon_t$ Ã© ruÃ­do branco.
II. A partir desta definiÃ§Ã£o, podemos escrever $y_t = \delta t + \sum_{i=1}^t \epsilon_i$.
III. A mÃ©dia da sÃ©rie Ã© dada por $E[y_t] = E[\delta t + \sum_{i=1}^t \epsilon_i] = \delta t$, pois a mÃ©dia de $\epsilon_t$ Ã© zero. Isso demonstra que a mÃ©dia da sÃ©rie varia linearmente com o tempo, ou seja, existe uma tendÃªncia determinÃ­stica.
IV. A variÃ¢ncia da sÃ©rie Ã© dada por $Var[y_t] = Var[\delta t + \sum_{i=1}^t \epsilon_i] = t\sigma^2$, pois a variÃ¢ncia de $\delta t$ Ã© zero e a variÃ¢ncia de cada $\epsilon_i$ Ã© $\sigma^2$. A variÃ¢ncia aumenta linearmente com o tempo.
V. Como a mÃ©dia e a variÃ¢ncia variam com o tempo, a sÃ©rie nÃ£o Ã© estacionÃ¡ria. $\blacksquare$

**Teorema 1.1:** Um passeio aleatÃ³rio com deriva, definido por $y_t = \delta + y_{t-1} + \epsilon_t$, pode ser expressa como uma soma acumulada de choques mais uma tendÃªncia linear.
*Prova:*
I. A definiÃ§Ã£o do modelo Ã© $y_t = \delta + y_{t-1} + \epsilon_t$.
II. Expandindo recursivamente a equaÃ§Ã£o:
    $y_t = \delta + (\delta + y_{t-2} + \epsilon_{t-1}) + \epsilon_t = 2\delta + y_{t-2} + \epsilon_{t-1} + \epsilon_t$
    $y_t = 3\delta + y_{t-3} + \epsilon_{t-2} + \epsilon_{t-1} + \epsilon_t$
    ...
    $y_t = t\delta + y_0 + \sum_{i=1}^{t} \epsilon_i$.
III. Definindo $y_0 = 0$, temos $y_t = t\delta + \sum_{i=1}^{t} \epsilon_i$.
IV. Assim, um passeio aleatÃ³rio com deriva pode ser expresso como a soma de uma tendÃªncia determinÃ­stica linear ($\delta t$) e uma soma acumulada de choques aleatÃ³rios ($\sum_{i=1}^{t} \epsilon_i$). $\blacksquare$
> ðŸ’¡ **Exemplo NumÃ©rico:**
>
>   Seja um passeio aleatÃ³rio com deriva dado por $y_t = 0.5 + y_{t-1} + \epsilon_t$, com $y_0=0$, e $\epsilon_t$ sendo ruÃ­do branco com mÃ©dia zero e variÃ¢ncia 1. Para $t=3$, temos:
>
>   $y_1 = 0.5 + y_0 + \epsilon_1 = 0.5 + \epsilon_1$
>
>   $y_2 = 0.5 + y_1 + \epsilon_2 = 0.5 + 0.5 + \epsilon_1 + \epsilon_2 = 1 + \epsilon_1 + \epsilon_2$
>
>   $y_3 = 0.5 + y_2 + \epsilon_3 = 0.5 + 1 + \epsilon_1 + \epsilon_2 + \epsilon_3 = 1.5 + \epsilon_1 + \epsilon_2 + \epsilon_3$.
>
>   Generalizando, $y_t = 0.5t + \sum_{i=1}^t \epsilon_i$.

### DiferenÃ§a entre Modelos com Raiz UnitÃ¡ria e Modelos Trend-Stationary
Ã‰ essencial distinguir entre modelos com raiz unitÃ¡ria e modelos **trend-stationary**. Em ambos os casos, as sÃ©ries temporais apresentam nÃ£o estacionaridade, mas a natureza dessa nÃ£o estacionaridade e a forma de tratÃ¡-la sÃ£o diferentes.

#### Modelos Trend-Stationary
Em modelos trend-stationary, a nÃ£o estacionaridade Ã© causada por uma tendÃªncia determinÃ­stica, como uma funÃ§Ã£o linear ou polinomial do tempo. A remoÃ§Ã£o dessa tendÃªncia, atravÃ©s da subtraÃ§Ã£o da tendÃªncia estimada da sÃ©rie original, resulta em um processo estacionÃ¡rio. A representaÃ§Ã£o geral de um modelo trend-stationary Ã© dada por:
$$ y_t = \alpha + \delta t + \psi(L)\epsilon_t $$
onde:
*   $\alpha$ Ã© o intercepto.
*   $\delta$ Ã© a inclinaÃ§Ã£o da tendÃªncia.
*   $t$ Ã© o Ã­ndice de tempo.
*   $\psi(L)\epsilon_t$ Ã© um processo estacionÃ¡rio.
A remoÃ§Ã£o da tendÃªncia, $y_t - (\alpha + \delta t) = \psi(L)\epsilon_t$, resulta em uma sÃ©rie estacionÃ¡ria.

#### Modelos com Raiz UnitÃ¡ria
Em modelos com raiz unitÃ¡ria, a nÃ£o estacionaridade Ã© causada pela presenÃ§a de uma raiz unitÃ¡ria no operador autoregressivo, que faz com que os choques tenham efeito permanente sobre o nÃ­vel da sÃ©rie temporal. A remoÃ§Ã£o da nÃ£o estacionaridade em um processo com raiz unitÃ¡ria Ã© realizada atravÃ©s da diferenciaÃ§Ã£o da sÃ©rie, dada por:
$$ (1-L)y_t = \delta + \psi(L)\epsilon_t $$
onde:
*   $(1-L)$ Ã© o operador de primeira diferenÃ§a.
*   $\delta$ Ã© uma constante (deriva).
*   $\psi(L)\epsilon_t$ Ã© um processo estacionÃ¡rio.

#### ComparaÃ§Ã£o
As principais diferenÃ§as entre os modelos trend-stationary e com raiz unitÃ¡ria sÃ£o:
1.  **Natureza da NÃ£o Estacionaridade:** Modelos trend-stationary apresentam uma tendÃªncia determinÃ­stica, enquanto modelos com raiz unitÃ¡ria apresentam uma nÃ£o estacionaridade estocÃ¡stica, caracterizada por choques com efeito permanente.
2.  **TransformaÃ§Ã£o para Estacionaridade:** Modelos trend-stationary sÃ£o tornados estacionÃ¡rios pela remoÃ§Ã£o da tendÃªncia, enquanto modelos com raiz unitÃ¡ria sÃ£o tornados estacionÃ¡rios pela diferenciaÃ§Ã£o.
3.  **Impacto dos Choques:** Em modelos trend-stationary, os choques tÃªm um efeito transitÃ³rio sobre o nÃ­vel da sÃ©rie, que converge para a tendÃªncia de longo prazo. Em modelos com raiz unitÃ¡ria, os choques tÃªm um efeito permanente sobre o nÃ­vel da sÃ©rie, que nÃ£o retorna para um nÃ­vel anterior.
4.  **ImplicaÃ§Ãµes para a PrevisÃ£o:** Em modelos trend-stationary, a previsÃ£o converge para uma tendÃªncia determinÃ­stica de longo prazo. Em modelos com raiz unitÃ¡ria, a previsÃ£o nÃ£o converge para um valor fixo, e a variÃ¢ncia da previsÃ£o aumenta com o horizonte de previsÃ£o.
5. **InterpretaÃ§Ã£o:** Modelos trend-stationary implicam que existe uma tendÃªncia que deve ser removida, e que o processo volta a uma trajetÃ³ria de equilÃ­brio apÃ³s flutuaÃ§Ãµes. Modelos com raiz unitÃ¡ria implicam que choques afetam a trajetÃ³ria da sÃ©rie de forma permanente, e, portanto, o processo nÃ£o volta a uma trajetÃ³ria anterior.
**Teorema 1.** A aplicaÃ§Ã£o da primeira diferenÃ§a em um modelo trend-stationary nÃ£o resulta em um processo estacionÃ¡rio, enquanto a subtraÃ§Ã£o da tendÃªncia linear em um processo com raiz unitÃ¡ria nÃ£o o torna estacionÃ¡rio.
*Prova:*
I.  Em um modelo trend-stationary, a sÃ©rie Ã© definida como $y_t = \alpha + \delta t + \psi(L)\epsilon_t$. Aplicando a primeira diferenÃ§a, obtemos:
    $$(1-L)y_t = (1-L)(\alpha + \delta t + \psi(L)\epsilon_t) = \delta + (1-L)\psi(L)\epsilon_t.$$
II.  O componente estocÃ¡stico $(1-L)\psi(L)\epsilon_t$ continua estacionÃ¡rio, mas a presenÃ§a da constante $\delta$ indica que a primeira diferenÃ§a da sÃ©rie nÃ£o Ã© um processo de mÃ©dia zero.  Portanto, ao diferenciar um processo trend-stationary, nÃ£o obtemos um processo estacionÃ¡rio.
III.  Em um modelo com raiz unitÃ¡ria, a sÃ©rie Ã© definida como $(1-L)y_t = \delta + \psi(L)\epsilon_t$. Subtraindo um termo linear $at+b$, obtemos:
    $$(1-L)y_t - at - b = \delta - at -b + \psi(L)\epsilon_t $$
    A sÃ©rie resultante nÃ£o Ã© estacionÃ¡ria devido ao termo determinÃ­stico linear $-at$.
IV.  Portanto, a diferenciaÃ§Ã£o nÃ£o torna um processo trend-stationary estacionÃ¡rio e a remoÃ§Ã£o da tendÃªncia nÃ£o torna um processo de raiz unitÃ¡ria estacionÃ¡rio.  $\blacksquare$
> ðŸ’¡ **Exemplo NumÃ©rico:**
>
>  Considere um modelo trend-stationary $y_t = 2 + 0.1t + \epsilon_t$. Aplicando a primeira diferenÃ§a, obtemos:
>
>  $(1-L)y_t = y_t - y_{t-1} = (2+0.1t+\epsilon_t) - (2+0.1(t-1)+\epsilon_{t-1}) = 0.1 + \epsilon_t - \epsilon_{t-1}$.
>
>  A primeira diferenÃ§a resulta em um processo com mÃ©dia 0.1, que nÃ£o Ã© zero. Portanto, a primeira diferenÃ§a nÃ£o torna o processo estacionÃ¡rio, pois ele tem um componente determinÃ­stico diferente de zero.
>
>  Por outro lado, considere um processo de raiz unitÃ¡ria $y_t = y_{t-1} + \epsilon_t$. Se tentarmos remover a tendÃªncia $0.5t$, obtemos $y_t - 0.5t$, o que nÃ£o torna a sÃ©rie estacionÃ¡ria pois a sÃ©rie original Ã© nÃ£o estacionÃ¡ria, e a subtraÃ§Ã£o da tendÃªncia nÃ£o remove o componente de raiz unitÃ¡ria.
**ProposiÃ§Ã£o 2:** A variÃ¢ncia da primeira diferenÃ§a de um modelo trend-stationary converge para uma constante, enquanto a variÃ¢ncia da primeira diferenÃ§a de um modelo de raiz unitÃ¡ria sem deriva converge para uma constante, e para um termo que cresce linearmente quando hÃ¡ deriva.
*Prova:*
I. Para um modelo trend-stationary $y_t = \alpha + \delta t + \psi(L)\epsilon_t$, a primeira diferenÃ§a Ã© $\Delta y_t = y_t - y_{t-1} = \delta + \Delta \psi(L)\epsilon_t$. Como  $\Delta \psi(L)\epsilon_t$ Ã© estacionÃ¡rio, a variÃ¢ncia de $\Delta y_t$ converge para uma constante.
II. Para um modelo com raiz unitÃ¡ria sem deriva $y_t = y_{t-1} + \epsilon_t$, a primeira diferenÃ§a Ã© $\Delta y_t = \epsilon_t$, cuja variÃ¢ncia Ã© $\sigma^2$, que Ã© constante.
III. Para um modelo com raiz unitÃ¡ria com deriva $y_t = \delta + y_{t-1} + \epsilon_t$, a primeira diferenÃ§a Ã© $\Delta y_t = \delta + \epsilon_t$. A variÃ¢ncia de $\Delta y_t$ Ã© constante e igual a $\sigma^2$.
IV.  No entanto, se considerarmos a sÃ©rie original do modelo com raiz unitÃ¡ria e deriva, temos $y_t = y_0 + \delta t + \sum_{i=1}^t \epsilon_i$.  A variÃ¢ncia Ã© $Var(y_t) = t\sigma^2$, que aumenta com o tempo.  Se tomarmos a primeira diferenÃ§a repetidamente, $y_t-y_{t-1} = \delta+\epsilon_t$, a variÃ¢ncia da diferenÃ§a primeira Ã© $\sigma^2$, mas a variÃ¢ncia da sÃ©rie original continua a aumentar com o tempo.  $\blacksquare$

> ðŸ’¡ **Exemplo NumÃ©rico:**
>
>  Vamos ilustrar a diferenÃ§a entre modelos trend-stationary e modelos com raiz unitÃ¡ria atravÃ©s da simulaÃ§Ã£o de dois processos.
>
> *   **Modelo Trend-Stationary:**
>
>     $$ y_t = 5 + 0.2t + \epsilon_t $$
>
>     onde $\epsilon_t$ Ã© ruÃ­do branco com mÃ©dia zero e variÃ¢ncia 1. A sÃ©rie apresenta uma tendÃªncia linear de crescimento, mas pode se desviar da tendÃªncia por causa de ruÃ­do estocÃ¡stico.
> *   **Modelo com Raiz UnitÃ¡ria:**
>
>     $$ y_t = y_{t-1} + 0.1 + \epsilon_t $$
>     onde $\epsilon_t$ Ã© ruÃ­do branco com mÃ©dia zero e variÃ¢ncia 1. A sÃ©rie apresenta um passeio aleatÃ³rio com deriva 0.1, e o efeito de cada choque Ã© permanente.
>
>     O grÃ¡fico mostra claramente a diferenÃ§a entre os dois processos.
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
>
> # Parameters
> T = 100
> alpha = 5
> delta_trend = 0.2
> delta_rw = 0.1
> sigma_epsilon = 1
>
> # Generate random noise
> np.random.seed(42)
> epsilon_trend = np.random.normal(0, sigma_epsilon, T)
> epsilon_rw = np.random.normal(0, sigma_epsilon, T)
>
> # Simulate the trend-stationary process
> t = np.arange(1, T + 1)
> y_trend = alpha + delta_trend * t + epsilon_trend
>
> # Simulate the random walk with drift
> y_rw = np.zeros(T)
> for i in range(1, T):
>    y_rw[i] = y_rw[i-1] + delta_rw + epsilon_rw[i]
>
> # Plotting
> fig, axs = plt.subplots(1, 2, figsize=(15, 5))
> axs[0].plot(y_trend)
> axs[0].set_title('Trend-Stationary Process')
> axs[0].set_xlabel('Tempo')
> axs[0].set_ylabel('Valor')
> axs[0].grid(True)
> axs[1].plot(y_rw)
> axs[1].set_title('Random Walk with Drift')
> axs[1].set_xlabel('Tempo')
> axs[1].set_ylabel('Valor')
> axs[1].grid(True)
> plt.tight_layout()
> plt.show()
> ```
>
> Os grÃ¡ficos mostram que a sÃ©rie trend-stationary tem uma tendÃªncia de crescimento bem definida e que as flutuaÃ§Ãµes em torno da tendÃªncia sÃ£o estacionÃ¡rias, ao passo que a sÃ©rie com raiz unitÃ¡ria tem uma trajetÃ³ria mais aleatÃ³ria e nÃ£o estacionÃ¡ria. A tendÃªncia aparente Ã© uma consequÃªncia do componente de deriva e nÃ£o uma tendÃªncia fixa.
### Modelos de Raiz UnitÃ¡ria com Componentes ARMA
Modelos de raiz unitÃ¡ria podem ser combinados com componentes ARMA para modelar a dependÃªncia temporal dos resÃ­duos. A representaÃ§Ã£o geral Ã© dada por:
$$ (1-L)y_t = \delta + \psi(L)\epsilon_t $$
onde $\psi(L)\epsilon_t$ Ã© um processo ARMA, que captura a dependÃªncia temporal dos resÃ­duos apÃ³s a diferenciaÃ§Ã£o. Por exemplo, podemos ter um modelo com raiz unitÃ¡ria e componente AR(1):
$$ (1-L)y_t = \delta + \phi(L)u_t $$
$$ u_t = \phi_1 u_{t-1} + \epsilon_t $$
A modelagem combinada de raiz unitÃ¡ria e ARMA permite capturar tanto a nÃ£o estacionaridade quanto a dependÃªncia temporal das sÃ©ries.
> ðŸ’¡ **Exemplo NumÃ©rico:**
>
> Um modelo com raiz unitÃ¡ria e componente AR(1) pode ser especificado como
>
> $(1-L)y_t = 0.1 + u_t$
>
> $u_t = 0.7 u_{t-1} + \epsilon_t$
>
>  Onde $\epsilon_t$ Ã© ruÃ­do branco com mÃ©dia zero e variÃ¢ncia 1.
>  Neste caso, a primeira diferenÃ§a de $y_t$ Ã© um processo AR(1). O termo $0.1$ representa a deriva.

#### Modelos ARIMA
Os modelos ARIMA (Autoregressive Integrated Moving Average) sÃ£o uma classe de modelos que combinam a diferenciaÃ§Ã£o (para remover a raiz unitÃ¡ria) com componentes AR e MA para capturar a dependÃªncia temporal da sÃ©rie. Um modelo ARIMA(p, d, q) Ã© definido por:
*   p: ordem do componente autoregressivo
*   d: ordem da diferenciaÃ§Ã£o
*   q: ordem do componente de mÃ©dias mÃ³veis.
Modelos ARIMA sÃ£o Ãºteis para modelar sÃ©ries temporais que apresentam nÃ£o estacionaridade e dependÃªncia temporal, e sÃ£o uma ferramenta fundamental para a anÃ¡lise e previsÃ£o de sÃ©ries nÃ£o estacionÃ¡rias.
> ðŸ’¡ **Exemplo NumÃ©rico:**
> Um modelo ARIMA(1,1,1) pode ser escrito como:
>
> $(1-\phi_1L)(1-L)y_t = (1+\theta_1L)\epsilon_t$
>
> onde $\phi_1$ Ã© o coeficiente do AR(1), e $\theta_1$ Ã© o coeficiente do MA(1). $(1-L)$ Ã© o operador de primeira diferenÃ§a, e o valor $d=1$ representa uma raiz unitÃ¡ria.
> Este modelo pode ser usado para modelar uma sÃ©rie que precisa de diferenciaÃ§Ã£o para se tornar estacionÃ¡ria, e tambÃ©m possui um componente AR(1) e MA(1) em sua estrutura.

**Lema 2.1** Um modelo ARIMA(p, d, q) com d > 0 possui uma raiz unitÃ¡ria de multiplicidade *d*.
*Prova:*
I.  Um modelo ARIMA(p, d, q) pode ser representado como $\phi(L)(1-L)^d y_t = \theta(L)\epsilon_t$, onde $\phi(L)$ Ã© o polinÃ´mio AR, $(1-L)^d$ representa o operador de diferenciaÃ§Ã£o de ordem d, e $\theta(L)$ Ã© o polinÃ´mio MA.
II.  O polinÃ´mio caracterÃ­stico do operador autoregressivo Ã© $\phi(z)(1-z)^d$.
III.  A condiÃ§Ã£o para a existÃªncia de uma raiz unitÃ¡ria Ã© que o polinÃ´mio caracterÃ­stico seja zero para $z=1$.
IV.  Quando $z=1$, temos $\phi(1)(1-1)^d = \phi(1)0^d = 0$. Portanto, $z=1$ Ã© uma raiz do polinÃ´mio caracterÃ­stico com multiplicidade *d*.  $\blacksquare$
### Testes de Raiz UnitÃ¡ria
A presenÃ§a de uma raiz unitÃ¡ria nÃ£o pode ser verificada com testes estatÃ­sticos tradicionais, e a sua existÃªncia Ã© uma hipÃ³tese que necessita de testes especÃ­ficos. Diversos testes de raiz unitÃ¡ria foram desenvolvidos para determinar se uma sÃ©rie temporal possui ou nÃ£o uma raiz unitÃ¡ria. Os mais comuns sÃ£o:
1. **Teste de Dickey-Fuller (DF):** O teste de Dickey-Fuller testa a hipÃ³tese nula de que uma sÃ©rie tem uma raiz unitÃ¡ria. O teste Ã© baseado na estimaÃ§Ã£o de um modelo autoregressivo de primeira ordem e na anÃ¡lise da significÃ¢ncia estatÃ­stica do coeficiente de autoregressÃ£o.

2. **Teste de Dickey-Fuller Aumentado (ADF):** O teste ADF Ã© uma extensÃ£o do teste de Dickey-Fuller, que inclui lags da primeira diferenÃ§a da sÃ©rie para corrigir a autocorrelaÃ§Ã£o dos resÃ­duos. A hipÃ³tese nula tambÃ©m Ã© a presenÃ§a de raiz unitÃ¡ria.
3. **Teste de Phillips-Perron (PP):** O teste de Phillips-Perron Ã© uma alternativa nÃ£o paramÃ©trica ao teste ADF, que corrige para a heterocedasticidade e a autocorrelaÃ§Ã£o dos resÃ­duos.
4. **Teste KPSS (Kwiatkowski-Phillips-Schmidt-Shin):** O teste KPSS testa a hipÃ³tese nula de estacionaridade, em contraste com os testes ADF e PP, cuja hipÃ³tese nula Ã© a presenÃ§a de uma raiz unitÃ¡ria.
A escolha do teste a ser utilizado depende das caracterÃ­sticas especÃ­ficas da sÃ©rie temporal e da natureza da hipÃ³tese a ser testada.
> ðŸ’¡ **Exemplo NumÃ©rico:**
>
> Vamos aplicar o teste ADF Ã  sÃ©rie simulada com passeio aleatÃ³rio com deriva, para ilustrar o uso de testes estatÃ­sticos para determinar a presenÃ§a de raiz unitÃ¡ria em uma sÃ©rie temporal.
>
> ```python
> import numpy as np
> from statsmodels.tsa.stattools import adfuller
>
> # Parameters
> T = 100
> delta = 0.2
> sigma_epsilon = 1
>
> # Generate random noise
> np.random.seed(42)
> epsilon = np.random.normal(0, sigma_epsilon, T)
>
> # Simulate the random walk with drift
> y = np.zeros(T)
> for t in range(1, T):
>    y[t] = delta + y[t-1] + epsilon[t]
>
> # Perform the ADF test
> adf_result = adfuller(y)
>
> # Output results
> print("ADF Statistic:", adf_result[0])
> print("p-value:", adf_result[1])
> print("Critical Values:", adf_result[4])
> ```
> Os resultados indicam a estatÃ­stica do teste ADF, o p-valor, e os valores crÃ­ticos para os diferentes nÃ­veis de significÃ¢ncia. O p-valor Ã© maior que 0.05, indicando que nÃ£o podemos rejeitar a hipÃ³tese nula de que a sÃ©rie possui uma raiz unitÃ¡ria.
>
> Se rodarmos o teste ADF na primeira diferenÃ§a da sÃ©rie (para remover a raiz unitÃ¡ria), o resultado serÃ¡ diferente.
> ```python
> # Perform ADF test on differenced series
> y_diff = np.diff(y)
> adf_diff_result = adfuller(y_diff)
> print("\nADF test on differenced series")
> print("ADF Statistic:", adf_diff_result[0])
> print("p-value:", adf_diff_result[1])
> print("Critical Values:", adf_diff_result[4])
> ```
> O p-valor deve ser menor que 0.05, indicando que podemos rejeitar a hipÃ³tese nula de raizunitÃ¡ria.

```python
def kpss_test(timeseries, regression='c', nlags='auto'):
    kpss_input = timeseries
    kpss_result = kpss(kpss_input, regression=regression, nlags=nlags)
    print('KPSS Statistic: %f' % kpss_result[0])
    print('p-value: %f' % kpss_result[1])
    print('Critical Values:')
    for key, value in kpss_result[3].items():
        print('\t%s: %.3f' % (key, value))

kpss_test(data['close'].dropna())
```

O teste KPSS, por outro lado, testa a hipÃ³tese nula de estacionariedade.  Um p-valor baixo aqui indica que devemos rejeitar a hipÃ³tese nula e concluir que a sÃ©rie nÃ£o Ã© estacionÃ¡ria.

Para sÃ©ries temporais com tendÃªncia, Ã© importante aplicar diferenciaÃ§Ã£o e teste de raiz unitÃ¡ria para remover essa tendÃªncia antes de realizar anÃ¡lise e previsÃ£o. Uma forma de lidar com isso Ã© aplicar a diferenciaÃ§Ã£o e entÃ£o verificar se a sÃ©rie diferenciada se torna estacionÃ¡ria.

Aqui, usamos o teste KPSS tambÃ©m para verificar a estacionariedade apÃ³s a diferenciaÃ§Ã£o.

```python
kpss_test(data['close'].diff().dropna())
```

Se a sÃ©rie for estacionÃ¡ria apÃ³s a primeira diferenciaÃ§Ã£o, dizemos que ela Ã© integrada de ordem 1 (I(1)). Se precisar de mais uma diferenciaÃ§Ã£o para se tornar estacionÃ¡ria, ela Ã© integrada de ordem 2 (I(2)), e assim por diante. O nÃºmero de diferenciaÃ§Ãµes necessÃ¡rias para tornar a sÃ©rie estacionÃ¡ria Ã© a ordem de integraÃ§Ã£o da sÃ©rie.

```mermaid
graph LR
    A[SÃ©rie Temporal Original] --> B{Teste de Raiz UnitÃ¡ria (ADF)};
    B -- NÃ£o EstacionÃ¡ria --> C[DiferenciaÃ§Ã£o];
    C --> D{Teste de Raiz UnitÃ¡ria (ADF)};
    D -- NÃ£o EstacionÃ¡ria --> E[DiferenciaÃ§Ã£o];
    D -- EstacionÃ¡ria --> F[SÃ©rie EstacionÃ¡ria];
    E --> G{Teste de Raiz UnitÃ¡ria (ADF)};
    G -- EstacionÃ¡ria --> H[SÃ©rie EstacionÃ¡ria];
    G -- NÃ£o EstacionÃ¡ria --> I[Outras TransformaÃ§Ãµes];
    I --> J[SÃ©rie EstacionÃ¡ria];
    F --> K[AnÃ¡lise e PrevisÃ£o];
    H --> K;
    J --> K;
    style C fill:#f9f,stroke:#333,stroke-width:2px
    style E fill:#f9f,stroke:#333,stroke-width:2px
```
<!-- END -->
