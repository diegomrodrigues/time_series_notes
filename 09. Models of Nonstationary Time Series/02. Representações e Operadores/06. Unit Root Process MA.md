## Representa√ß√£o de Processos com Raiz Unit√°ria como Soma de Componentes Determin√≠sticos e Estoc√°sticos

### Introdu√ß√£o

Em continuidade ao estudo de modelos de s√©ries temporais n√£o estacion√°rias, especialmente ap√≥s a discuss√£o sobre modelos ARIMA, diferencia√ß√£o fracion√°ria e processos integrados [^1], este cap√≠tulo aborda a representa√ß√£o de um processo com raiz unit√°ria como a soma de um componente determin√≠stico, denominado *drift*, e um componente estoc√°stico, modelado por um operador de m√©dia m√≥vel (MA). Esta representa√ß√£o √© fundamental para entender o comportamento de s√©ries temporais que apresentam tend√™ncias estoc√°sticas, permitindo separar o crescimento linear da variabilidade aleat√≥ria. A capacidade de decompor um processo n√£o estacion√°rio em componentes mais simples facilita a modelagem e a previs√£o de s√©ries temporais com raiz unit√°ria.

### Conceitos Fundamentais

Como vimos anteriormente [^1], um processo com raiz unit√°ria √© caracterizado pela presen√ßa de uma raiz igual a 1 no polin√¥mio caracter√≠stico do operador auto-regressivo (AR). Essa caracter√≠stica implica que a s√©rie temporal n√£o √© estacion√°ria, pois choques passados t√™m um efeito permanente sobre o n√≠vel da s√©rie. A forma geral de um processo com raiz unit√°ria √© dada por:

$$(1 - L)y_t = \delta + \psi(L)\epsilon_t$$

Onde:
- $y_t$ √© a s√©rie temporal n√£o estacion√°ria.
- $L$ √© o operador de defasagem.
- $\delta$ √© a deriva (drift), um termo determin√≠stico.
- $\psi(L) = 1 + \psi_1 L + \psi_2 L^2 + ...$ √© o operador de m√©dia m√≥vel (MA) que captura a din√¢mica do componente estoc√°stico.
- $\epsilon_t$ √© um ru√≠do branco com m√©dia zero e vari√¢ncia $\sigma^2$.

Esta equa√ß√£o expressa que a primeira diferen√ßa da s√©rie $y_t$ ($\Delta y_t = (1-L)y_t$) √© um processo estacion√°rio com m√©dia $\delta$ e um componente de m√©dia m√≥vel definido por $\psi(L)\epsilon_t$.
O operador de primeira diferen√ßa $(1-L)$ pode ser reescrito como [^1]:

$$ y_t = y_{t-1} + \delta + \psi(L)\epsilon_t $$

Esta express√£o mostra que o valor atual da s√©rie ($y_t$) √© igual ao valor anterior ($y_{t-1}$), mais um termo determin√≠stico ($\delta$) e um choque estoc√°stico que depende dos valores passados de $\epsilon_t$.

O operador $\psi(L)$ representa um processo de m√©dia m√≥vel, onde o choque $\epsilon_t$ e seus valores passados afetam o presente valor da s√©rie. A forma expandida do operador $\psi(L)$ √© [^1]:

$$\psi(L)\epsilon_t = \epsilon_t + \psi_1 \epsilon_{t-1} + \psi_2 \epsilon_{t-2} + \ldots$$
O processo pode ser representado como uma soma de termos determin√≠sticos e estoc√°sticos, aplicando o operador $(1-L)^{-1}$ na equa√ß√£o original:

$$y_t = (1-L)^{-1}\delta + (1-L)^{-1}\psi(L)\epsilon_t$$
Considerando que $(1-L)^{-1} = 1 + L + L^2 + \ldots$, a equa√ß√£o anterior pode ser expandida para [^1]:
$$ y_t = \delta \sum_{i=0}^{\infty} L^i + (1-L)^{-1}\psi(L)\epsilon_t$$

A primeira parte desta express√£o, $\delta \sum_{i=0}^{\infty} L^i$, resulta na soma acumulada da deriva, que implica em uma trajet√≥ria linear ao longo do tempo: $\delta t$, com o crescimento partindo de um valor inicial $y_0$. A segunda parte, $(1-L)^{-1}\psi(L)\epsilon_t$, descreve o componente estoc√°stico que consiste de um passeio aleat√≥rio ($1-L)^{-1}$) e que incorpora o operador de m√©dia m√≥vel que modela a depend√™ncia temporal dos choques passados. Note que $(1-L)^{-1} = 1 + L + L^2 + ...$, logo $(1-L)^{-1}\epsilon_t = \epsilon_t + \epsilon_{t-1} + \epsilon_{t-2} + ...$.

Para expandir $(1-L)^{-1}\psi(L)\epsilon_t$, podemos considerar os primeiros termos do operador $\psi(L)$, e expandir $(1-L)^{-1}$ como uma s√©rie de pot√™ncias de $L$:
$$(1-L)^{-1}\psi(L) = (1 + L + L^2 + L^3 + \ldots)(1+\psi_1L + \psi_2L^2 + \ldots)$$
Multiplicando os termos e agrupando por pot√™ncias de $L$, obtemos:
$$(1-L)^{-1}\psi(L) = 1 + (1 + \psi_1)L + (1+\psi_1+\psi_2)L^2 + (1+\psi_1+\psi_2+\psi_3)L^3 + \ldots $$
O componente estoc√°stico √© portanto:
$$(1-L)^{-1}\psi(L)\epsilon_t = \epsilon_t + (1+\psi_1)\epsilon_{t-1} + (1+\psi_1+\psi_2)\epsilon_{t-2} + ... $$
Esta expans√£o mostra que o componente estoc√°stico do processo √© uma soma ponderada dos choques passados, onde os pesos s√£o uma soma cumulativa dos coeficientes do operador $\psi(L)$.
Reescrevendo a equa√ß√£o para $y_t$ como uma soma de termo determin√≠stico e estoc√°stico, temos:

$$y_t = y_0 + \delta t +  (1-L)^{-1}\psi(L)\epsilon_t$$

Esta representa√ß√£o demonstra que a s√©rie temporal $y_t$ √© composta por um *drift* linear ($\delta t$) e um componente estoc√°stico que √© uma combina√ß√£o ponderada dos choques passados, al√©m de um valor inicial $y_0$.

> üí° **Exemplo Num√©rico:** Considere um processo com raiz unit√°ria dado por:
>
> $$(1-L)y_t = 0.2 + (1 + 0.5L)\epsilon_t $$
>
> Aqui, $\delta = 0.2$ e $\psi(L) = 1 + 0.5L$, e portanto, $\psi_1=0.5$. Podemos expandir o processo como:
>
> $$y_t = y_{t-1} + 0.2 + \epsilon_t + 0.5\epsilon_{t-1}$$
>
> O componente determin√≠stico √© $0.2t$, e o componente estoc√°stico √© $(1-L)^{-1}(1 + 0.5L)\epsilon_t$, que pode ser expandido como:
> $$ \epsilon_t + (1+0.5)\epsilon_{t-1} + (1+0.5+0)\epsilon_{t-2} + (1+0.5+0+0)\epsilon_{t-3} + ...$$
> $$ = \epsilon_t + 1.5\epsilon_{t-1} + 1.5\epsilon_{t-2} + 1.5\epsilon_{t-3} + ...$$
> Portanto, o processo com raiz unit√°ria pode ser escrito como:
> $$ y_t = y_0 + 0.2t + \epsilon_t + 1.5\epsilon_{t-1} + 1.5\epsilon_{t-2} + 1.5\epsilon_{t-3} + ...$$
> Para simular este processo, podemos gerar uma s√©rie de ru√≠do branco $\epsilon_t$ e aplicar a express√£o acima:
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
>
> # Define parameters
> delta = 0.2
> psi1 = 0.5
> num_points = 200
>
> # Generate epsilon series
> np.random.seed(42)
> epsilon = np.random.normal(0, 1, num_points)
>
> # Initialize y
> y = np.zeros(num_points)
> y[0] = 0 # Initial value
>
> # Generate the time series
> for t in range(1, num_points):
>  y[t] = y[t-1] + delta + epsilon[t] + psi1*epsilon[t-1]
>
> # Plot the time series
> plt.figure(figsize=(10, 5))
> plt.plot(y)
> plt.title('Processo com Raiz Unit√°ria e Drift')
> plt.xlabel('Tempo')
> plt.ylabel('Valor de y_t')
> plt.show()
>
> # Plot the components of the time series
>
> y_linear = delta * np.arange(num_points)
>
> y_stochastic = np.zeros(num_points)
> for t in range(1, num_points):
>    y_stochastic[t] = y_stochastic[t-1] + epsilon[t] + psi1*epsilon[t-1]
>
> plt.figure(figsize=(10, 5))
> plt.plot(y_linear, label = 'Componente Determin√≠stico (Drift)')
> plt.plot(y_stochastic, label = 'Componente Estoc√°stico')
> plt.plot(y, label = 'Soma dos Componentes (Processo Completo)')
> plt.title('Processo com Raiz Unit√°ria e seus Componentes')
> plt.xlabel('Tempo')
> plt.ylabel('Valor')
> plt.legend()
> plt.show()
>
> ```
> A visualiza√ß√£o da s√©rie temporal $y_t$ demonstra um comportamento n√£o estacion√°rio com um crescimento linear (drift) e flutua√ß√µes aleat√≥rias. Ao plotar cada um dos componentes separadamente, podemos visualizar como cada um deles contribui para a forma√ß√£o da s√©rie original. Note que a s√©rie estoc√°stica √© um passeio aleat√≥rio, onde os choques $\epsilon_t$ s√£o acumulados ao longo do tempo.

Esta representa√ß√£o, em termos de componentes determin√≠sticos e estoc√°sticos, permite uma melhor compreens√£o dos modelos com raiz unit√°ria, separando a tend√™ncia linear e o efeito dos choques aleat√≥rios. Esta representa√ß√£o destaca que o valor esperado da s√©rie, $E(y_t)$, evolui linearmente com o tempo, mas o valor real da s√©rie desvia desta trajet√≥ria linear devido ao componente estoc√°stico. A amplitude dos desvios em rela√ß√£o √† trajet√≥ria linear depende do operador de m√©dia m√≥vel $\psi(L)$ e da vari√¢ncia do ru√≠do branco $\epsilon_t$.

**Lema 1**
A representa√ß√£o de um processo com raiz unit√°ria como a soma de um componente determin√≠stico e um componente estoc√°stico √© uma consequ√™ncia direta da aplica√ß√£o do operador inverso $(1-L)^{-1}$ na equa√ß√£o do processo com raiz unit√°ria.

*Prova:*
I. A equa√ß√£o de um processo com raiz unit√°ria √© dada por:
$$(1-L)y_t = \delta + \psi(L)\epsilon_t$$

II.  Aplicando o operador $(1-L)^{-1}$ em ambos os lados da equa√ß√£o, obtemos:
$$ y_t = (1-L)^{-1}\delta + (1-L)^{-1}\psi(L)\epsilon_t$$

III. Expandindo o operador $(1-L)^{-1}$, temos:
$$ (1-L)^{-1} = 1 + L + L^2 + L^3 + \ldots $$
IV.  Portanto, $(1-L)^{-1}\delta = \delta + \delta L + \delta L^2 + \delta L^3 + \ldots = \delta \sum_{i=0}^{\infty} L^i$.  A soma $\sum_{i=0}^{\infty} L^i$ representa a acumula√ß√£o da constante $\delta$ ao longo do tempo.  Assim, essa soma equivale a $\delta t$ adicionada a um valor inicial $y_0$, ou seja, a parte determin√≠stica do modelo.

V. O componente estoc√°stico √© $(1-L)^{-1}\psi(L)\epsilon_t$, que pode ser expandido como:
$$ (1-L)^{-1}\psi(L)\epsilon_t = (1 + L + L^2 + \ldots)(\epsilon_t + \psi_1 \epsilon_{t-1} + \psi_2 \epsilon_{t-2} + ...) $$
VI.  Reescrevendo o componente estoc√°stico, obtemos:
   $$(1-L)^{-1}\psi(L)\epsilon_t = \epsilon_t + (1+\psi_1)\epsilon_{t-1} + (1+\psi_1+\psi_2)\epsilon_{t-2} + \ldots$$
VII.  Assim, o processo com raiz unit√°ria pode ser representado como a soma de um componente determin√≠stico ($y_0 + \delta t$) e um componente estoc√°stico, concluindo a prova. $\blacksquare$

**Teorema 1.1**
Em um processo com raiz unit√°ria descrito por $(1 - L)y_t = \delta + \psi(L)\epsilon_t$, a vari√¢ncia do termo estoc√°stico cresce linearmente com o tempo.

*Prova:*
I.   A parte estoc√°stica do processo pode ser expressa como:
$$  x_t =  (1-L)^{-1}\psi(L)\epsilon_t = \sum_{i=0}^{\infty} h_i \epsilon_{t-i} $$
onde $h_i$ s√£o os coeficientes da expans√£o de $(1-L)^{-1}\psi(L)$.
II.  O operador $(1-L)^{-1}$ cria uma soma acumulada, resultando em termos como $\sum_{i=0}^{t} \epsilon_{t-i}$.
III.  A vari√¢ncia do componente estoc√°stico √© dada por:
$$\text{Var}(x_t) = \text{Var}(\sum_{i=0}^{\infty} h_i \epsilon_{t-i})$$
IV. Como $\epsilon_t$ √© um ru√≠do branco, $\text{Var}(\epsilon_t) = \sigma^2$ e $\text{Cov}(\epsilon_i,\epsilon_j) = 0$ para $i \neq j$, ent√£o:
$$\text{Var}(x_t) = \sigma^2 \sum_{i=0}^{\infty} h_i^2$$

V. A an√°lise do comportamento dos coeficientes $h_i$ para um modelo com raiz unit√°ria demonstra que eles n√£o decaem para zero. Para um modelo com raiz unit√°ria, o operador $(1-L)^{-1}$ √© o principal respons√°vel pelo crescimento da vari√¢ncia. Considerando apenas este operador, temos:
$(1-L)^{-1}\epsilon_t = \sum_{i=0}^{\infty} \epsilon_{t-i}$.  Neste caso, $h_i = 1$ para todos os $i$.  Logo, $\text{Var}((1-L)^{-1}\epsilon_t) = \sigma^2 \sum_{i=0}^t 1^2 = (t+1)\sigma^2$.  Em um modelo mais geral com um operador $\psi(L)$ qualquer, o comportamento assint√≥tico √© similar, e portanto,
    $$ \text{Var}(x_t) \approx t \sigma^2 (1 + \psi_1 + \psi_2 + \ldots)^2$$

VI. Portanto, a vari√¢ncia do componente estoc√°stico de um processo com raiz unit√°ria cresce linearmente com o tempo, devido ao efeito cumulativo da soma dos choques passados, o que caracteriza a sua n√£o estacionariedade. $\blacksquare$

> üí° **Exemplo Num√©rico:** Vamos simular um processo com raiz unit√°ria e calcular a sua vari√¢ncia para o componente estoc√°stico ao longo do tempo.
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
>
> # Define parameters
> delta = 0.2
> psi1 = 0.5
> num_points = 200
>
> # Generate epsilon series
> np.random.seed(42)
> epsilon = np.random.normal(0, 1, num_points)
>
> # Initialize y and y_stochastic
> y = np.zeros(num_points)
> y[0] = 0
> y_stochastic = np.zeros(num_points)
>
> # Generate the time series and the stochastic component
> for t in range(1, num_points):
>     y[t] = y[t-1] + delta + epsilon[t] + psi1*epsilon[t-1]
>     y_stochastic[t] = y_stochastic[t-1] + epsilon[t] + psi1*epsilon[t-1]
>
> # Calculate variances of stochastic component
> variances = [np.var(y_stochastic[:t]) for t in range(2, num_points)]
> plt.figure(figsize=(10,5))
> plt.plot(range(2, num_points), variances)
> plt.title('Vari√¢ncia do Componente Estoc√°stico ao Longo do Tempo')
> plt.xlabel('Tempo')
> plt.ylabel('Vari√¢ncia')
> plt.show()
>
>
> # Linear Regression to check the growth
> from sklearn.linear_model import LinearRegression
> time = np.array(range(2, num_points)).reshape(-1,1)
> model = LinearRegression().fit(time, variances)
> print(f"Coeficiente da regress√£o linear: {model.coef_[0]:.4f}")
>
> ```
> A visualiza√ß√£o da vari√¢ncia do componente estoc√°stico ao longo do tempo demonstra que a vari√¢ncia cresce aproximadamente linearmente com o tempo, o que √© caracter√≠stico de processos com raiz unit√°ria. O coeficiente da regress√£o linear quantifica a taxa de crescimento da vari√¢ncia ao longo do tempo.

**Observa√ß√£o:** √â importante destacar que, embora a representa√ß√£o do processo com raiz unit√°ria como a soma de componentes determin√≠sticos e estoc√°sticos seja √∫til para a compreens√£o do comportamento do processo, a estima√ß√£o e previs√£o de modelos com raiz unit√°ria √© frequentemente realizada utilizando a forma diferenciada da s√©rie, isto √©, o modelo em primeiras diferen√ßas.

**Teorema 1.2**
Se um processo com raiz unit√°ria √© descrito por $(1-L)y_t = \delta + \psi(L)\epsilon_t$, e o operador $\psi(L)$ possui todos os seus coeficientes positivos, ou seja $\psi_i \geq 0 \; \forall i$, ent√£o o componente estoc√°stico $x_t = (1-L)^{-1}\psi(L)\epsilon_t$ √© um processo com *mem√≥ria longa* no sentido de que os choques passados t√™m um efeito cumulativo e persistente no valor presente da s√©rie.

*Prova:*
I. O componente estoc√°stico $x_t$ √© dado por:
$$x_t = (1-L)^{-1}\psi(L)\epsilon_t = \sum_{j=0}^{\infty} h_j \epsilon_{t-j} $$
onde $h_j$ s√£o os coeficientes da expans√£o de $(1-L)^{-1}\psi(L)$.

II.  Da expans√£o de $(1-L)^{-1}\psi(L)$, como j√° demonstrado, temos que:
$$h_j = 1 + \psi_1 + \psi_2 + ... + \psi_j$$

III.  Dado que $\psi_i \geq 0 \; \forall i$, ent√£o $h_j$ √© uma soma cumulativa de termos n√£o negativos, o que implica que $h_j$ √© n√£o decrescente em $j$.

IV. O fato de $h_j$ n√£o decrescer com o aumento de j significa que os choques passados $\epsilon_{t-j}$ recebem um peso cada vez maior ou igual ao longo do tempo, e n√£o decrescem em import√¢ncia.

V. Consequentemente, choques passados t√™m um efeito persistente e crescente no valor presente da s√©rie, caracterizando um comportamento de *mem√≥ria longa* e o efeito cumulativo dos choques passados no valor presente da s√©rie. $\blacksquare$

**Corol√°rio 1.2.1**
Sob as condi√ß√µes do Teorema 1.2, se a soma dos coeficientes $\psi_i$ diverge, ou seja, $\sum_{i=1}^\infty \psi_i = \infty$, ent√£o o efeito dos choques passados no componente estoc√°stico $x_t$ √© ilimitado.

*Prova:*
I.  Pelo Teorema 1.2, $h_j = 1 + \psi_1 + \psi_2 + ... + \psi_j$
II. Se $\sum_{i=1}^\infty \psi_i = \infty$, ent√£o $\lim_{j \to \infty} h_j = \infty$.
III.  Isso implica que o efeito dos choques passados $\epsilon_{t-j}$ em $x_t$ n√£o se atenua com o tempo, e pode crescer ilimitadamente com o tempo.
IV. Portanto, o efeito dos choques passados √© ilimitado e persistente no componente estoc√°stico $x_t$.  $\blacksquare$

> üí° **Exemplo Num√©rico:** Para ilustrar o conceito de mem√≥ria longa, vamos considerar um modelo com $\psi_i = 0.8^i$, onde a soma dos coeficientes $\psi_i$ √© finita, mas os coeficientes decaem lentamente, resultando em um efeito persistente dos choques passados. Simularemos esse processo e analisaremos como o efeito dos choques passados se acumula no componente estoc√°stico.
>
> ```python
> import numpy as np
> import matplotlib.pyplot as plt
>
> # Parameters
> delta = 0.1
> num_points = 200
> psi_coeff = 0.8
>
> # Generate white noise
> np.random.seed(42)
> epsilon = np.random.normal(0, 1, num_points)
>
> # Initialize y and stochastic component
> y = np.zeros(num_points)
> y[0] = 0
> y_stochastic = np.zeros(num_points)
>
> # Generate the time series and the stochastic component
> for t in range(1, num_points):
>     y[t] = y[t-1] + delta + epsilon[t]
>     for j in range(1, t + 1):
>          y[t] = y[t] + (psi_coeff**(j)) * epsilon[t-j]
>     y_stochastic[t] = y[t] - delta*t # Subtract the deterministic drift for comparison.
>
> # Create a matrix of past shocks
> epsilon_matrix = np.zeros((num_points, num_points))
> for t in range(num_points):
>   for j in range(t):
>     epsilon_matrix[t,j] = epsilon[t-j]
>
> # Calculate the weights for each shock
> weights_matrix = np.zeros((num_points,num_points))
> for t in range(num_points):
>     for j in range(t):
>        weights_matrix[t,j] =  psi_coeff**(j)
>
> # Compute weighted sums for illustration purposes
> weighted_shocks = np.array([np.dot(weights_matrix[t,:t], epsilon_matrix[t,:t]) for t in range(num_points)])
>
>
> # Plot the stochastic component and the weighted sum
> plt.figure(figsize=(10, 6))
> plt.plot(y_stochastic, label='Componente Estoc√°stico')
> plt.plot(weighted_shocks, label = 'Soma Ponderada dos Choques Passados')
> plt.title('Efeito dos Choques Passados em um Processo com Mem√≥ria Longa')
> plt.xlabel('Tempo')
> plt.ylabel('Valor')
> plt.legend()
> plt.show()
>
> # Show a small portion of the weights matrix
> print ("Tabela dos pesos dos choques passados: \n", weights_matrix[:5,:5])
> ```
>
> O gr√°fico mostra como os choques passados se acumulam, formando o componente estoc√°stico da s√©rie. A matriz dos pesos demonstra como cada choque √© ponderado por um fator de $\psi_i$. Note que, embora os pesos decaiam, eles decaem de forma mais lenta do que em um processo de m√©dia m√≥vel padr√£o, dando origem ao comportamento de mem√≥ria longa.

**Proposi√ß√£o 1**
Em um processo com raiz unit√°ria, a previs√£o de longo prazo converge para uma trajet√≥ria linear determinada pelo *drift*, com uma incerteza crescente devido ao ac√∫mulo do componente estoc√°stico.

*Prova:*
I. A representa√ß√£o do processo com raiz unit√°ria √© $y_t = y_0 + \delta t + (1-L)^{-1}\psi(L)\epsilon_t$.
II.  O termo $(1-L)^{-1}\psi(L)\epsilon_t$ representa o componente estoc√°stico.
III. A previs√£o do componente estoc√°stico em um horizonte longo torna-se cada vez mais incerta devido ao aumento de sua vari√¢ncia, como estabelecido no Teorema 1.1.
IV. A previs√£o de longo prazo, $E[y_{t+h} | y_t]$, converge para $y_0 + \delta(t+h)$, que √© a trajet√≥ria linear definida pelo drift. Isso acontece pois, no longo prazo, o valor esperado do componente estoc√°stico converge para zero, dado que a m√©dia do ru√≠do branco √© zero.
V. A incerteza da previs√£o aumenta com o horizonte devido ao componente estoc√°stico, cuja vari√¢ncia cresce linearmente com o tempo. $\blacksquare$

### Conclus√£o

A representa√ß√£o de processos com raiz unit√°ria como a soma de um termo determin√≠stico (drift) e um componente estoc√°stico √© uma ferramenta valiosa para a an√°lise e modelagem de s√©ries temporais n√£o estacion√°rias. Esta decomposi√ß√£o permite separar o crescimento linear da variabilidade aleat√≥ria, fornecendo uma compreens√£o mais clara da din√¢mica temporal do processo. O componente determin√≠stico representa a tend√™ncia linear, enquanto o componente estoc√°stico representa a soma ponderada dos choques passados, capturando a mem√≥ria longa e o comportamento n√£o estacion√°rio da s√©rie. Esta representa√ß√£o auxilia na modelagem e previs√£o de s√©ries temporais com raiz unit√°ria.

### Refer√™ncias

[^1]: Modelos de S√©ries Temporais N√£o Estacion√°rias. *[Cap√≠tulo 15 do livro]*
<!-- END -->
