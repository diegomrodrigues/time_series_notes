## Modelos ARIMA(p, d, q): Uma Vis√£o Abrangente

### Introdu√ß√£o

Em continuidade ao nosso estudo de modelos para s√©ries temporais n√£o estacion√°rias, abordando conceitos como diferencia√ß√£o fracion√°ria, processos integrados de ordem 1 (I(1)) e os operadores de diferencia√ß√£o e integra√ß√£o fracion√°ria [^1], este cap√≠tulo introduz os modelos **Autoregressive Integrated Moving Average (ARIMA)**. Os modelos ARIMA, denotados como ARIMA(p, d, q), combinam componentes auto-regressivos (AR), integrados (I) e de m√©dia m√≥vel (MA) para modelar uma vasta gama de s√©ries temporais. A compreens√£o dos par√¢metros $p$, $d$ e $q$, que representam, respectivamente, a ordem da parte AR, a ordem de integra√ß√£o e a ordem da parte MA, √© essencial para o ajuste do modelo √† din√¢mica espec√≠fica de cada s√©rie.

### Conceitos Fundamentais

Como vimos anteriormente, muitas s√©ries temporais n√£o s√£o estacion√°rias e, portanto, n√£o podem ser modeladas diretamente por modelos ARMA [^1]. A abordagem para lidar com a n√£o estacionariedade envolve a aplica√ß√£o de diferencia√ß√£o. Um processo *integrado* de ordem *d*, denotado como I(d), √© um processo que se torna estacion√°rio ap√≥s a aplica√ß√£o da diferencia√ß√£o *d* vezes. O modelo ARIMA generaliza o modelo ARMA, incorporando o componente de integra√ß√£o para acomodar a n√£o estacionariedade. A representa√ß√£o geral de um modelo ARIMA(p, d, q) √© dada por [^1]:

$$ \phi(L) (1-L)^d y_t = \theta(L) \epsilon_t $$

onde:
- $y_t$ representa a s√©rie temporal observada.
- $L$ √© o operador de defasagem (lag).
- $\phi(L) = 1 - \phi_1 L - \phi_2 L^2 - \ldots - \phi_p L^p$ √© o operador auto-regressivo (AR) de ordem $p$.
- $(1-L)^d$ √© o operador de diferencia√ß√£o de ordem $d$.
- $\theta(L) = 1 + \theta_1 L + \theta_2 L^2 + \ldots + \theta_q L^q$ √© o operador de m√©dia m√≥vel (MA) de ordem $q$.
- $\epsilon_t$ √© o termo de erro ou ru√≠do branco, com m√©dia zero e vari√¢ncia $\sigma^2$.

O par√¢metro $d$ representa a ordem de integra√ß√£o, que √© o n√∫mero de vezes que a s√©rie precisa ser diferenciada para se tornar estacion√°ria. Se $d = 0$, o modelo se reduz a um ARMA(p, q). Se $d=1$, o modelo representa um processo que √© I(1), conforme explorado no cap√≠tulo anterior [^1]. A aplica√ß√£o do operador $(1-L)^d$ sobre $y_t$ transforma a s√©rie original $y_t$ numa nova s√©rie $\Delta^d y_t = (1-L)^d y_t$ que √© estacion√°ria e que pode ser modelada por um processo ARMA(p,q) [^1]. O termo $\Delta^d y_t$ pode ser escrito como:

$$\Delta^d y_t =  \sum_{j=0}^{\infty} h_j y_{t-j}$$

onde os coeficientes $h_j$ s√£o os coeficientes do operador $(1-L)^d$.

> üí° **Exemplo Num√©rico:** Considere um processo ARIMA(1, 1, 1), definido por:
>
> $$ (1 - \phi_1 L)(1-L)y_t = (1 + \theta_1 L)\epsilon_t $$
>
> Aqui, $p=1$, $d=1$, e $q=1$. A s√©rie $y_t$ precisa ser diferenciada uma vez para se tornar estacion√°ria, e o processo resultante $\Delta y_t$ √© modelado por um ARMA(1,1). Para ilustrar, vamos definir $\phi_1 = 0.7$ e $\theta_1=0.5$. A equa√ß√£o torna-se:
>
> $$ (1 - 0.7L)(1-L)y_t = (1 + 0.5L)\epsilon_t $$
>
> Expandindo o operador autoregressivo temos:
>
> $$ (1 - 1.7L + 0.7L^2)y_t = (1 + 0.5L)\epsilon_t $$
>
> ou seja:
>
> $$ y_t = 1.7y_{t-1} - 0.7y_{t-2} + \epsilon_t + 0.5\epsilon_{t-1}$$
>
> Para simular este modelo, precisamos gerar um ru√≠do branco $\epsilon_t$ e inicializar os primeiros valores de $y_t$.
> ```python
> import numpy as np
> import pandas as pd
> import matplotlib.pyplot as plt
> from statsmodels.tsa.arima_process import arma_generate_sample
>
> # Define parameters
> phi1 = 0.7
> theta1 = 0.5
> p = 1
> d = 1
> q = 1
> num_points = 200
>
> # Generate epsilon series (white noise)
> np.random.seed(42)
> epsilon = np.random.normal(0, 1, num_points)
>
> # Generate ARIMA series
> arparams = np.array([phi1])
> maparams = np.array([theta1])
> ar = np.r_[1, -arparams]
> ma = np.r_[1, maparams]
> y = arma_generate_sample(ar, ma, num_points,  sigma=1)
>
> # Apply (1-L)^-1
> y_integrated = np.cumsum(y)
>
> plt.figure(figsize=(10, 5))
> plt.plot(y_integrated, label='ARIMA(1,1,1) Process')
> plt.title('Simula√ß√£o de um Processo ARIMA(1, 1, 1)')
> plt.xlabel('Tempo')
> plt.ylabel('Valor de y_t')
> plt.legend()
> plt.show()
>
> dy = np.diff(y_integrated)
>
> plt.figure(figsize=(10,5))
> plt.plot(dy, label='Primeira diferen√ßa de y')
> plt.title('Primeira Diferen√ßa do Processo ARIMA(1, 1, 1)')
> plt.xlabel('Tempo')
> plt.ylabel('Valor de dy_t')
> plt.legend()
> plt.show()
>
>
> print(f'M√©dia de y_t: {np.mean(y_integrated):.2f}')
> print(f'Vari√¢ncia de y_t: {np.var(y_integrated):.2f}')
> print(f'M√©dia de dy_t: {np.mean(dy):.2f}')
> print(f'Vari√¢ncia de dy_t: {np.var(dy):.2f}')
> ```
> A visualiza√ß√£o da s√©rie $y_t$ mostra um comportamento n√£o estacion√°rio, enquanto a primeira diferen√ßa $\Delta y_t$ aparenta ser estacion√°ria, indicando que o modelo ARIMA(1, 1, 1) consegue capturar a din√¢mica da s√©rie simulada.
>
> üí° **Exemplo Num√©rico:** Para ilustrar como os coeficientes $h_j$ do operador de diferencia√ß√£o se comportam, vamos considerar o caso de uma diferencia√ß√£o de ordem $d=2$. A s√©rie diferenciada duas vezes ser√°:
>
> $$ \Delta^2 y_t = (1-L)^2 y_t = (1 - 2L + L^2)y_t = y_t - 2y_{t-1} + y_{t-2} $$
>
> Aqui, os coeficientes $h_j$ para $j = 0, 1, 2$ s√£o $1, -2, 1$, respectivamente, que correspondem aos elementos da linha $d=2$ do Tri√¢ngulo de Pascal (1, 2, 1) com sinais alternados. Para $j>2$, $h_j = 0$. Se $d=3$, temos:
>
> $$ (1-L)^3 y_t = (1 - 3L + 3L^2 - L^3)y_t = y_t - 3y_{t-1} + 3y_{t-2} - y_{t-3} $$
>
> Neste caso, os coeficientes s√£o $h_0 = 1, h_1=-3, h_2=3, h_3=-1$, que correspondem aos elementos da linha $d=3$ do Tri√¢ngulo de Pascal (1, 3, 3, 1) com sinais alternados.

O modelo ARIMA(p, d, q) engloba outros modelos como casos especiais. Se $d=0$, temos um modelo ARMA(p, q). Se $p=0$, temos um modelo IMA(d, q), e se $q=0$, temos um modelo ARI(p, d).
A sele√ß√£o dos valores apropriados para $p$, $d$ e $q$ √© um passo crucial na modelagem ARIMA e envolve a an√°lise da fun√ß√£o de autocorrela√ß√£o (ACF) e da fun√ß√£o de autocorrela√ß√£o parcial (PACF).

- **p (ordem do AR):** Determina quantos lags da s√©rie temporal s√£o usados no componente autoregressivo. √â comumente determinado a partir da PACF. Um corte abrupto na PACF em um determinado lag sugere um valor adequado para p.
- **d (ordem de integra√ß√£o):** Determina quantas vezes a s√©rie precisa ser diferenciada para se tornar estacion√°ria. √â comumente determinado atrav√©s de testes de raiz unit√°ria, como o teste de Dickey-Fuller.
- **q (ordem do MA):** Determina quantos lags do erro s√£o usados no componente de m√©dia m√≥vel. √â comumente determinado a partir da ACF. Um corte abrupto na ACF em um determinado lag sugere um valor adequado para q.

**Observa√ß√£o:** √â importante ressaltar que a escolha da ordem de integra√ß√£o $d$ pode tamb√©m ser influenciada pelo comportamento das m√©dias amostrais da s√©rie temporal. Se a m√©dia da s√©rie apresentar uma tend√™ncia clara, a diferencia√ß√£o de primeira ordem (d=1) √© frequentemente utilizada. Em casos mais complexos, onde a tend√™ncia n√£o √© linear, uma diferencia√ß√£o de segunda ordem (d=2) pode ser necess√°ria. Essa observa√ß√£o complementa a import√¢ncia dos testes de raiz unit√°ria para determinar a ordem de integra√ß√£o.

O processo de identifica√ß√£o, estima√ß√£o e diagn√≥stico de um modelo ARIMA segue passos bem definidos. Inicialmente, √© preciso determinar se a s√©rie √© estacion√°ria. Se n√£o for, √© necess√°rio aplicar diferencia√ß√£o at√© que a s√©rie se torne estacion√°ria [^1]. Em seguida, com a an√°lise das fun√ß√µes de autocorrela√ß√£o (ACF) e autocorrela√ß√£o parcial (PACF) da s√©rie transformada, os valores de $p$ e $q$ s√£o definidos. Uma vez que os par√¢metros foram estimados, o modelo precisa ser diagnosticado, verificando a aleatoriedade dos res√≠duos. Caso a an√°lise dos res√≠duos demonstre algum padr√£o, o modelo deve ser reavaliado e, se necess√°rio, ajustado.

> üí° **Exemplo Num√©rico:** Consideremos o caso de uma s√©rie temporal gerada por um processo ARIMA(2, 1, 1). Suponha que a s√©rie real √© dada por:
> $$ (1 - 0.8L - 0.3L^2)(1-L)y_t = (1 + 0.5L)\epsilon_t $$
> Para simular e identificar o modelo, vamos seguir os passos descritos:
> 1. Gerar os dados
> 2. Verificar se a s√©rie √© estacion√°ria
> 3. Obter a ACF e PACF da s√©rie
> 4. Ajustar um modelo ARIMA usando os par√¢metros definidos pelas fun√ß√µes de autocorrela√ß√£o.
> ```python
> import numpy as np
> import pandas as pd
> import matplotlib.pyplot as plt
> from statsmodels.tsa.arima_process import arma_generate_sample
> from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
> from statsmodels.tsa.arima.model import ARIMA
>
> # Define parameters
> phi1 = 0.8
> phi2 = 0.3
> theta1 = 0.5
> p = 2
> d = 1
> q = 1
> num_points = 200
>
> # Generate epsilon series (white noise)
> np.random.seed(42)
> epsilon = np.random.normal(0, 1, num_points)
>
> # Generate ARIMA series
> arparams = np.array([phi1, phi2])
> maparams = np.array([theta1])
> ar = np.r_[1, -arparams]
> ma = np.r_[1, maparams]
> y = arma_generate_sample(ar, ma, num_points, sigma=1)
> # Apply (1-L)^-1
> y_integrated = np.cumsum(y)
>
> # Plot the series
> plt.figure(figsize=(10, 5))
> plt.plot(y_integrated, label='ARIMA(2,1,1) Process')
> plt.title('S√©rie Temporal Gerada pelo Modelo ARIMA(2, 1, 1)')
> plt.xlabel('Tempo')
> plt.ylabel('Valor de y_t')
> plt.legend()
> plt.show()
>
> # Check stationarity by taking the first difference
> dy = np.diff(y_integrated)
> plt.figure(figsize=(10, 5))
> plt.plot(dy, label='First Difference of the Series')
> plt.title('Primeira Diferen√ßa da S√©rie Temporal')
> plt.xlabel('Tempo')
> plt.ylabel('Valor de dy_t')
> plt.legend()
> plt.show()
>
> # Plot ACF and PACF
> fig, ax = plt.subplots(nrows=2, ncols=1,figsize=(10, 6))
> plot_acf(dy, lags=20, ax = ax[0], title='Fun√ß√£o de Autocorrela√ß√£o (ACF)')
> plot_pacf(dy, lags=20, ax = ax[1], title='Fun√ß√£o de Autocorrela√ß√£o Parcial (PACF)')
> plt.tight_layout()
> plt.show()
>
> # Fit the ARIMA model
> model = ARIMA(y_integrated, order=(p, d, q))
> model_fit = model.fit()
> print(model_fit.summary())
>
> # Diagnostic Check
> residuals = model_fit.resid
>
> fig, ax = plt.subplots(nrows=2, ncols=1,figsize=(10, 6))
> plot_acf(residuals, lags=20, ax = ax[0], title='Fun√ß√£o de Autocorrela√ß√£o dos Res√≠duos')
> ax[1].hist(residuals, bins = 20)
> ax[1].set_title('Histograma dos Res√≠duos')
> plt.tight_layout()
> plt.show()
> ```
> O c√≥digo simula um modelo ARIMA(2, 1, 1), plota a s√©rie original e a s√©rie diferenciada, plota as fun√ß√µes ACF e PACF da s√©rie diferenciada e, finalmente, ajusta o modelo ARIMA aos dados. Os res√≠duos devem se comportar como ru√≠do branco.
>
> As fun√ß√µes ACF e PACF da s√©rie diferenciada sugerem os valores para p e q (neste caso, p=2 e q=1). O modelo estimado reproduz os par√¢metros originais com boa aproxima√ß√£o. A plotagem dos res√≠duos e a sua ACF demonstra que os res√≠duos se comportam como ru√≠do branco.

**Teorema 1** (Invertibilidade de Modelos MA). Um modelo MA(q) definido por $\theta(L) \epsilon_t$ √© invert√≠vel se todas as ra√≠zes do polin√¥mio $\theta(z) = 1 + \theta_1 z + \theta_2 z^2 + \ldots + \theta_q z^q$ estiverem fora do c√≠rculo unit√°rio no plano complexo (i.e., tiverem m√≥dulo maior que 1).

*   **Justificativa:** A invertibilidade √© uma propriedade crucial para a estima√ß√£o de modelos MA. Ela garante que o processo possa ser representado como uma fun√ß√£o do passado da s√©rie temporal, o que √© necess√°rio para a estima√ß√£o e previs√£o. A condi√ß√£o de ra√≠zes fora do c√≠rculo unit√°rio garante que o operador $\theta(L)^{-1}$ seja convergente, permitindo representar o ru√≠do branco $\epsilon_t$ como uma combina√ß√£o linear dos valores passados da s√©rie.

O uso dos modelos ARIMA √© generalizado em diversas √°reas. Em economia, os modelos ARIMA s√£o utilizados para prever vari√°veis macroecon√¥micas, como infla√ß√£o e produto interno bruto. Em finan√ßas, s√£o usados para modelar e prever pre√ßos de ativos e volatilidade. Na √°rea de marketing, s√£o usados para analisar s√©ries temporais de vendas e entender tend√™ncias de comportamento dos consumidores. Em estudos clim√°ticos, modelam padr√µes de temperatura, precipita√ß√£o e outros fen√¥menos meteorol√≥gicos.

> üí° **Exemplo Num√©rico:** Um exemplo cl√°ssico da aplica√ß√£o de modelos ARIMA √© a previs√£o do n√∫mero mensal de passageiros de companhias a√©reas (AirPassengers).
>
> Vamos importar e analisar esta s√©rie:
> ```python
> import pandas as pd
> import matplotlib.pyplot as plt
> from statsmodels.tsa.arima.model import ARIMA
> from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
>
> # Load data
> df = pd.read_csv('AirPassengers.csv')
>
> # Convert month to date and set it as index
> df['Month'] = pd.to_datetime(df['Month'])
> df.set_index('Month', inplace=True)
>
> # Plot the series
> plt.figure(figsize=(10, 5))
> plt.plot(df['#Passengers'])
> plt.title('S√©rie Temporal: N√∫mero de Passageiros A√©reos')
> plt.xlabel('Tempo')
> plt.ylabel('N√∫mero de Passageiros')
> plt.show()
>
> # Apply First Difference
> dy = np.diff(df['#Passengers'])
> plt.figure(figsize=(10, 5))
> plt.plot(dy)
> plt.title('Primeira Diferen√ßa da S√©rie Temporal')
> plt.xlabel('Tempo')
> plt.ylabel('Valor de dy_t')
> plt.show()
>
> # Plot ACF and PACF
> fig, ax = plt.subplots(nrows=2, ncols=1,figsize=(10, 6))
> plot_acf(dy, lags=20, ax = ax[0], title='Fun√ß√£o de Autocorrela√ß√£o (ACF)')
> plot_pacf(dy, lags=20, ax = ax[1], title='Fun√ß√£o de Autocorrela√ß√£o Parcial (PACF)')
> plt.tight_layout()
> plt.show()
>
> # Fit ARIMA Model
> model = ARIMA(df['#Passengers'], order=(2, 1, 2))
> model_fit = model.fit()
> print(model_fit.summary())
>
> # Diagnostic check
> residuals = model_fit.resid
> fig, ax = plt.subplots(nrows=2, ncols=1,figsize=(10, 6))
> plot_acf(residuals, lags=20, ax = ax[0], title='Fun√ß√£o de Autocorrela√ß√£o dos Res√≠duos')
> ax[1].hist(residuals, bins = 20)
> ax[1].set_title('Histograma dos Res√≠duos')
> plt.tight_layout()
> plt.show()
>
> ```
> A an√°lise da s√©rie original revela uma tend√™ncia de crescimento e ciclos sazonais, sugerindo que ela n√£o √© estacion√°ria. Ap√≥s a diferencia√ß√£o, a s√©rie parece ser estacion√°ria. As fun√ß√µes ACF e PACF da s√©rie diferenciada sugerem que um modelo ARMA(2,2) possa ser adequado para o processo diferenciado.  O resumo do modelo demonstra que os coeficientes s√£o significantes. A an√°lise dos res√≠duos verifica a aleatoriedade, demostrando que o modelo consegue modelar adequadamente a s√©rie temporal original.

**Teorema 1.1** (Condi√ß√£o de Causalidade para Modelos AR). Um modelo AR(p) definido por $\phi(L)y_t = \epsilon_t$ √© causal (ou estacion√°rio) se todas as ra√≠zes do polin√¥mio $\phi(z) = 1 - \phi_1 z - \phi_2 z^2 - \ldots - \phi_p z^p$ estiverem fora do c√≠rculo unit√°rio no plano complexo (i.e., tiverem m√≥dulo maior que 1).
    
*   **Justificativa:** A causalidade garante que o presente valor da s√©rie temporal depende apenas dos valores passados e do ru√≠do branco. Esta condi√ß√£o √© necess√°ria para que o modelo AR tenha uma representa√ß√£o est√°vel e possa ser utilizado para previs√µes. A condi√ß√£o sobre as ra√≠zes do polin√¥mio assegura a converg√™ncia da representa√ß√£o do processo como uma fun√ß√£o dos ru√≠dos passados, $\epsilon_t$.

**Proposi√ß√£o 1** (Rela√ß√£o entre os Coeficientes de $(1-L)^d$ e o Tri√¢ngulo de Pascal): Os coeficientes $h_j$ da expans√£o $\Delta^d y_t = (1-L)^d y_t = \sum_{j=0}^{\infty} h_j y_{t-j}$ correspondem aos valores da linha *d* do Tri√¢ngulo de Pascal, alternados em sinal. Mais especificamente, $h_j = (-1)^j \binom{d}{j}$, onde $\binom{d}{j}$ √© o coeficiente binomial "d escolhe j".

* **Demonstra√ß√£o:**
    I. O operador de diferen√ßa $\Delta$ √© definido como $\Delta y_t = (1-L)y_t = y_t - y_{t-1}$.

    II. Para um operador de diferen√ßa de segunda ordem, temos $\Delta^2 y_t = (1-L)^2 y_t = (1 - 2L + L^2)y_t = y_t - 2y_{t-1} + y_{t-2}$.
    
    III. Generalizando para uma diferen√ßa de ordem d, podemos usar o Teorema Binomial: $(1-L)^d = \sum_{j=0}^{d} \binom{d}{j} (-L)^j = \sum_{j=0}^{d} (-1)^j \binom{d}{j} L^j$.

    IV. Aplicando este operador a $y_t$, obtemos $\Delta^d y_t = (1-L)^d y_t = \sum_{j=0}^{d} (-1)^j \binom{d}{j} L^j y_t = \sum_{j=0}^{d} (-1)^j \binom{d}{j} y_{t-j}$.

    V.  Comparando com a express√£o $\Delta^d y_t = \sum_{j=0}^{\infty} h_j y_{t-j}$, temos que $h_j = (-1)^j \binom{d}{j}$ para $j \leq d$ e $h_j = 0$ para $j>d$.

    VI. Portanto, os coeficientes $h_j$ s√£o os elementos da linha *d* do tri√¢ngulo de Pascal, com sinais alternados. ‚ñ†

### Conclus√£o

Os modelos ARIMA(p, d, q) representam uma ferramenta poderosa e flex√≠vel para a modelagem de s√©ries temporais, combinando componentes auto-regressivos, integrados e de m√©dia m√≥vel. A ordem de integra√ß√£o $d$ permite lidar com a n√£o estacionariedade, enquanto as ordens $p$ e $q$ permitem capturar a din√¢mica da s√©rie temporal. A identifica√ß√£o, estima√ß√£o e diagn√≥stico do modelo ARIMA requerem a an√°lise cuidadosa das caracter√≠sticas da s√©rie temporal, suas fun√ß√µes de autocorrela√ß√£o e autocorrela√ß√£o parcial e o comportamento dos res√≠duos. A versatilidade e a capacidade de modelar uma ampla gama de padr√µes temporais tornam os modelos ARIMA essenciais para an√°lise e previs√£o em diversas √°reas do conhecimento.

### Refer√™ncias

[^1]: Modelos de S√©ries Temporais N√£o Estacion√°rias. *[Cap√≠tulo 15 do livro]*
<!-- END -->
