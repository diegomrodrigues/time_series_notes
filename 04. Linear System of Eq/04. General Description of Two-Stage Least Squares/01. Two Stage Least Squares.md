## O Método dos Mínimos Quadrados em Dois Estágios (2SLS) e Identificação

### Introdução

O método dos **Mínimos Quadrados em Dois Estágios (2SLS)** é uma ferramenta essencial para a análise de modelos de equações simultâneas, estendendo a lógica das variáveis instrumentais para cenários onde múltiplas variáveis endógenas estão presentes. Como vimos no capítulo anterior, a correlação entre variáveis explicativas e o termo de erro (endogeneidade) causa viés na estimação por Mínimos Quadrados Ordinários (OLS). O 2SLS é crucial para obter estimativas consistentes dos parâmetros estruturais nesses contextos, utilizando instrumentos para contornar esse problema [^1]. Este capítulo aprofunda o conceito de 2SLS, explorando suas bases teóricas, as condições de identificação e o papel das variáveis predeterminadas.

### Conceitos Fundamentais

#### Variáveis Endógenas e Predeterminadas
Em modelos econométricos, é fundamental distinguir entre **variáveis endógenas** e **predeterminadas**. Variáveis endógenas são aquelas que são determinadas dentro do modelo e, crucialmente, são correlacionadas com o termo de erro da equação de regressão [^1]. Essa correlação viola um dos pressupostos fundamentais do OLS, levando a estimativas viesadas e inconsistentes [^1]. Em contraste, as **variáveis predeterminadas** são exógenas, não correlacionadas com o termo de erro e são determinadas fora do modelo, sendo componentes chave para a construção de instrumentos válidos [^1].

#### O Método 2SLS
O método 2SLS opera em dois estágios distintos [^1]:

1.  **Primeiro Estágio:** Regressão de cada variável endógena sobre um conjunto de variáveis instrumentais e as variáveis predeterminadas do modelo. As variáveis instrumentais são selecionadas com o cuidado de serem correlacionadas com as variáveis endógenas, mas não correlacionadas com o termo de erro da equação original. O resultado desse primeiro estágio são os valores preditos de cada variável endógena [^1].

2. **Segundo Estágio:** Regressão da variável dependente sobre os valores preditos das variáveis endógenas, obtidos no primeiro estágio, e as demais variáveis predeterminadas do modelo. As variáveis endógenas originais são substituídas por suas versões preditas para eliminar a correlação com o termo de erro [^1].

O estimador 2SLS é obtido através da regressão de *$y$* sobre *$\hat{z}$*, onde *$\hat{z}$* representa os valores ajustados (fitted values) das variáveis explicativas endógenas obtidos a partir da regressão no primeiro estágio [^6, 9.2.6]:
$$
\hat{\beta}_{2SLS} = [\sum_{t=1}^T \hat{z}_t \hat{z}_t']^{-1} [\sum_{t=1}^T \hat{z}_t y_t]
$$

onde *$z_{it}$* (a *$i$-ésima* variável explicativa em [9.2.1]) é regressada sobre as variáveis instrumentais *$x_t$* [^6, 9.2.2]:
$$
z_{it} = \delta_i'x_t + e_{it}
$$
e
$$
\hat{z}_{it} = \hat{\delta}_i'x_t
$$
onde  $\hat{\delta}_i = [\sum_{t=1}^T x_t x_t']^{-1}[\sum_{t=1}^T x_t z_{it}]$ [^6, 9.2.5] e *$e_{it}$* é o resíduo da regressão [^6, 9.2.7].

A consistência do estimador 2SLS pode ser demonstrada substituindo a equação [9.2.1] em [9.2.8], obtendo [^8, 9.2.9]:
$$
\hat{\beta}_{2SLS,T} = \beta + [\sum_{t=1}^T \hat{z}_t \hat{z}_t']^{-1} [\sum_{t=1}^T \hat{z}_t u_t]
$$
onde o subscrito *$T$* denota o tamanho da amostra [^8, 9.2.9]. A diferença entre o estimador 2SLS e o valor verdadeiro é dada por [^8, 9.2.10]:
$$
\hat{\beta}_{2SLS,T} - \beta = [(1/T) \sum_{t=1}^T \hat{z}_t \hat{z}_t']^{-1} [(1/T) \sum_{t=1}^T \hat{z}_t u_t]
$$
Utilizando a lei dos grandes números e a ergodicidade, podemos demonstrar que o termo $(1/T) \sum_{t=1}^T \hat{z}_t \hat{z}_t'$ converge para uma matriz *$Q$*, enquanto $(1/T) \sum_{t=1}^T \hat{z}_t u_t$ converge para zero [^8, 9.2.11-9.2.15]. Assim,  $\hat{\beta}_{2SLS,T}$ é consistente, ou seja, converge em probabilidade para o valor verdadeiro *$\beta$* [^8].

#### Condições de Identificação: Ordem e Posto
Para que o 2SLS possa ser aplicado e para que os parâmetros do modelo sejam identificados, duas condições cruciais devem ser satisfeitas [^1, 9.3]:

1. **Condição de Ordem:** O número de variáveis instrumentais (incluindo as variáveis predeterminadas) deve ser maior ou igual ao número de variáveis explicativas endógenas [^6, 9.2].  Esta condição garante que haja instrumentos suficientes para identificar os parâmetros do modelo.  Se esta condição não for satisfeita, o modelo não é identificável e os parâmetros não podem ser estimados de forma consistente.

2. **Condição de Posto:** Esta é uma condição mais restritiva que a condição de ordem. Ela exige que a matriz de correlação entre as variáveis instrumentais e as variáveis endógenas tenha posto completo [^9].  Isso implica que os instrumentos devem ser linearmente independentes e que devem ter uma relação linear com as variáveis endógenas, garantindo que as estimativas dos parâmetros sejam únicas e identificadas. A condição de posto também garante que as variáveis instrumentais são suficientemente "fortes", isto é, que há uma correlação relevante entre as variáveis instrumentais e as variáveis endógenas.

A condição de posto pode ser expressa formalmente usando a matriz de covariância *$M$* [^14, 9.3.11], que contém os produtos cruzados entre as variáveis explicativas endógenas e predeterminadas e as variáveis predeterminadas para todo o sistema:
$$
M = \begin{bmatrix}
E(y_{1t} x_t') & E(y_{1t} x_t')\\
E(y_{2t} x_t') & E(y_{2t} x_t')
\end{bmatrix}
$$
onde *$y_{1t}$* representa as variáveis endógenas da primeira equação, *$y_{2t}$* as variáveis endógenas das outras equações e *$x_t$* são as variáveis predeterminadas para todo o sistema [^14, 9.3.11]. A condição de posto exige que as linhas da matriz M sejam linearmente independentes [^14].

Alternativamente, a condição de posto pode ser expressa em termos das matrizes dos parâmetros estruturais B e Γ, ou da matriz dos parâmetros da forma reduzida Π [^14, 9.3]. No caso da matriz Π, a condição de posto se reduz a verificar se a matriz  Π$_{12}$ (que contém os parâmetros que relacionam as variáveis endógenas com as variáveis predeterminadas excluídas da primeira equação) tem linhas linearmente independentes [^14, 9.3.12].

### Conclusão

O método 2SLS é uma ferramenta poderosa para lidar com problemas de endogeneidade em modelos de equações simultâneas. A consistência dos estimadores 2SLS é garantida sob a validade das condições de identificação (ordem e posto) e a adequada escolha de variáveis instrumentais. Em particular, a identificação requer a presença de instrumentos que sejam correlacionados com as variáveis endógenas, mas não correlacionados com o termo de erro das equações estruturais, assegurando que as estimativas dos parâmetros sejam não enviesadas. Compreender as nuances da aplicação do 2SLS e das condições de identificação é essencial para a análise econométrica e a obtenção de resultados confiáveis em modelos com múltiplas variáveis endógenas.

### Referências
[^1]:  *The previous chapter described a number of possible departures from the ideal regression model arising from errors that are non-Gaussian, heteroskedastic, or autocorrelated. We saw that while these factors can make a difference for the small-sample validity of t and F tests, under any of Assumptions 8.1 through 8.6, the OLS estimator by is either unbiased or consistent. This is because all these cases retained the crucial assumption that u,, the error term for observation t, is uncorrelated with x₁, the explanatory variables for that observation. Unfortunately, this critical assumption is unlikely to be satisfied in many important applications.*
[^2]:  *Section 9.1 discusses why this assumption often fails to hold, by examining a concrete example of simultaneous equations bias. Subsequent sections discuss a variety of techniques for dealing with this problem. These results will be used in the structural interpretation of vector autoregressions in Chapter 11 and for understanding generalized method of moments estimation in Chapter 14.*
[^3]:  *To illustrate the difficulties with endogenous regressors, consider an investigation of the public's demand for oranges. Let p, denote the log of the price of oranges in a particular year and qe the log of the quantity the public is willing to buy.*
[^4]:  *To keep the example very simple, suppose that price and quantity are covariance- stationary and that each is measured as deviations from its population mean.*
[^5]:  *The demand curve is presumed to take the form q = βρ. + εἱ, with ẞ < 0; a higher price reduces the quantity that the public is willing to buy.*
[^6]: *Collect the predetermined explanatory variables together with the instruments in an (r × 1) vector x,. For example, to estimate the demand curve, there were no predetermined explanatory variables in equation [9.1.1] and only a single instrument; hence, r = 1, and x, would be the scalar w,.*
[^7]: *As a second example, suppose that the equation to be estimated is Ус = β + β222 + β3738 + B4Z4r + B5Z5t + Ur.*
[^8]: *Consistency of 2SLS Estimator*
[^9]: *General Description of Two-Stage Least Squares*
[^10]: *An alternative way of writing [9.2.6] is sometimes useful.*
[^11]: *Let e denote the sample residual from OLS estimation of [9.2.2]; that is, let zit = 8x + 2 = 2 + .*
[^12]: *OLS causes this residual to be orthogonal to x,: Σ x = 0.*
[^13]: *Meaning that the residual is orthogonal to 2,: Σ = Σ 8 Σx = 0.*
[^14]: *The rank condition for identification can be summarized more explicitly by specifying a complete system of equations for all of the endogenous variables. Let y, denote an (n × 1) vector containing all of the endogenous variables in the system, and let x, denote an (m × 1) vector containing all of the predetermined variables.*
<!-- END -->
